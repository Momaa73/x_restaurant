[2025-07-19T21:02:12.983+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: restaurant_pipeline.stream_to_bronze scheduled__2025-07-19T21:00:00+00:00 [queued]>
[2025-07-19T21:02:12.988+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: restaurant_pipeline.stream_to_bronze scheduled__2025-07-19T21:00:00+00:00 [queued]>
[2025-07-19T21:02:12.988+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2025-07-19T21:02:12.994+0000] {taskinstance.py:1382} INFO - Executing <Task(BashOperator): stream_to_bronze> on 2025-07-19 21:00:00+00:00
[2025-07-19T21:02:12.996+0000] {standard_task_runner.py:57} INFO - Started process 4036 to run task
[2025-07-19T21:02:12.998+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'restaurant_pipeline', 'stream_to_bronze', 'scheduled__2025-07-19T21:00:00+00:00', '--job-id', '1227', '--raw', '--subdir', 'DAGS_FOLDER/restaurant_pipeline.py', '--cfg-path', '/tmp/tmpn5t4ee9s']
[2025-07-19T21:02:13.000+0000] {standard_task_runner.py:85} INFO - Job 1227: Subtask stream_to_bronze
[2025-07-19T21:02:13.025+0000] {task_command.py:416} INFO - Running <TaskInstance: restaurant_pipeline.stream_to_bronze scheduled__2025-07-19T21:00:00+00:00 [running]> on host e3f5d8fc4eef
[2025-07-19T21:02:13.066+0000] {taskinstance.py:1662} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='moran' AIRFLOW_CTX_DAG_ID='restaurant_pipeline' AIRFLOW_CTX_TASK_ID='stream_to_bronze' AIRFLOW_CTX_EXECUTION_DATE='2025-07-19T21:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-07-19T21:00:00+00:00'
[2025-07-19T21:02:13.067+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-07-19T21:02:13.067+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', "docker exec -e AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-07-19T21:00:00+00:00' spark-iceberg spark-submit /home/iceberg/spark/stream_to_bronze.py"]
[2025-07-19T21:02:13.074+0000] {subprocess.py:86} INFO - Output:
[2025-07-19T21:02:14.617+0000] {subprocess.py:93} INFO - 25/07/19 21:02:14 INFO SparkContext: Running Spark version 3.5.6
[2025-07-19T21:02:14.619+0000] {subprocess.py:93} INFO - 25/07/19 21:02:14 INFO SparkContext: OS info Linux, 6.10.14-linuxkit, aarch64
[2025-07-19T21:02:14.620+0000] {subprocess.py:93} INFO - 25/07/19 21:02:14 INFO SparkContext: Java version 17.0.15
[2025-07-19T21:02:14.636+0000] {subprocess.py:93} INFO - 25/07/19 21:02:14 INFO ResourceUtils: ==============================================================
[2025-07-19T21:02:14.636+0000] {subprocess.py:93} INFO - 25/07/19 21:02:14 INFO ResourceUtils: No custom resources configured for spark.driver.
[2025-07-19T21:02:14.637+0000] {subprocess.py:93} INFO - 25/07/19 21:02:14 INFO ResourceUtils: ==============================================================
[2025-07-19T21:02:14.637+0000] {subprocess.py:93} INFO - 25/07/19 21:02:14 INFO SparkContext: Submitted application: StreamToBronze
[2025-07-19T21:02:14.656+0000] {subprocess.py:93} INFO - 25/07/19 21:02:14 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-07-19T21:02:14.662+0000] {subprocess.py:93} INFO - 25/07/19 21:02:14 INFO ResourceProfile: Limiting resource is cpu
[2025-07-19T21:02:14.663+0000] {subprocess.py:93} INFO - 25/07/19 21:02:14 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2025-07-19T21:02:14.694+0000] {subprocess.py:93} INFO - 25/07/19 21:02:14 INFO SecurityManager: Changing view acls to: root,spark
[2025-07-19T21:02:14.694+0000] {subprocess.py:93} INFO - 25/07/19 21:02:14 INFO SecurityManager: Changing modify acls to: root,spark
[2025-07-19T21:02:14.694+0000] {subprocess.py:93} INFO - 25/07/19 21:02:14 INFO SecurityManager: Changing view acls groups to:
[2025-07-19T21:02:14.694+0000] {subprocess.py:93} INFO - 25/07/19 21:02:14 INFO SecurityManager: Changing modify acls groups to:
[2025-07-19T21:02:14.695+0000] {subprocess.py:93} INFO - 25/07/19 21:02:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
[2025-07-19T21:02:14.726+0000] {subprocess.py:93} INFO - 25/07/19 21:02:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2025-07-19T21:02:14.862+0000] {subprocess.py:93} INFO - 25/07/19 21:02:14 INFO Utils: Successfully started service 'sparkDriver' on port 35857.
[2025-07-19T21:02:14.878+0000] {subprocess.py:93} INFO - 25/07/19 21:02:14 INFO SparkEnv: Registering MapOutputTracker
[2025-07-19T21:02:14.913+0000] {subprocess.py:93} INFO - 25/07/19 21:02:14 INFO SparkEnv: Registering BlockManagerMaster
[2025-07-19T21:02:14.924+0000] {subprocess.py:93} INFO - 25/07/19 21:02:14 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-07-19T21:02:14.924+0000] {subprocess.py:93} INFO - 25/07/19 21:02:14 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2025-07-19T21:02:14.927+0000] {subprocess.py:93} INFO - 25/07/19 21:02:14 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2025-07-19T21:02:14.941+0000] {subprocess.py:93} INFO - 25/07/19 21:02:14 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-26d5c353-dd4a-4925-98a0-2ea0d03a60d8
[2025-07-19T21:02:14.949+0000] {subprocess.py:93} INFO - 25/07/19 21:02:14 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2025-07-19T21:02:14.957+0000] {subprocess.py:93} INFO - 25/07/19 21:02:14 INFO SparkEnv: Registering OutputCommitCoordinator
[2025-07-19T21:02:15.014+0000] {subprocess.py:93} INFO - 25/07/19 21:02:15 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[2025-07-19T21:02:15.044+0000] {subprocess.py:93} INFO - 25/07/19 21:02:15 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[2025-07-19T21:02:15.048+0000] {subprocess.py:93} INFO - 25/07/19 21:02:15 INFO Utils: Successfully started service 'SparkUI' on port 4041.
[2025-07-19T21:02:15.106+0000] {subprocess.py:93} INFO - 25/07/19 21:02:15 INFO Executor: Starting executor ID driver on host 8b44f3d35cfa
[2025-07-19T21:02:15.107+0000] {subprocess.py:93} INFO - 25/07/19 21:02:15 INFO Executor: OS info Linux, 6.10.14-linuxkit, aarch64
[2025-07-19T21:02:15.107+0000] {subprocess.py:93} INFO - 25/07/19 21:02:15 INFO Executor: Java version 17.0.15
[2025-07-19T21:02:15.111+0000] {subprocess.py:93} INFO - 25/07/19 21:02:15 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
[2025-07-19T21:02:15.111+0000] {subprocess.py:93} INFO - 25/07/19 21:02:15 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@34233 for default.
[2025-07-19T21:02:15.131+0000] {subprocess.py:93} INFO - 25/07/19 21:02:15 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38433.
[2025-07-19T21:02:15.132+0000] {subprocess.py:93} INFO - 25/07/19 21:02:15 INFO NettyBlockTransferService: Server created on 8b44f3d35cfa:38433
[2025-07-19T21:02:15.132+0000] {subprocess.py:93} INFO - 25/07/19 21:02:15 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-07-19T21:02:15.137+0000] {subprocess.py:93} INFO - 25/07/19 21:02:15 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 8b44f3d35cfa, 38433, None)
[2025-07-19T21:02:15.141+0000] {subprocess.py:93} INFO - 25/07/19 21:02:15 INFO BlockManagerMasterEndpoint: Registering block manager 8b44f3d35cfa:38433 with 434.4 MiB RAM, BlockManagerId(driver, 8b44f3d35cfa, 38433, None)
[2025-07-19T21:02:15.142+0000] {subprocess.py:93} INFO - 25/07/19 21:02:15 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 8b44f3d35cfa, 38433, None)
[2025-07-19T21:02:15.143+0000] {subprocess.py:93} INFO - 25/07/19 21:02:15 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 8b44f3d35cfa, 38433, None)
[2025-07-19T21:02:15.431+0000] {subprocess.py:93} INFO - 25/07/19 21:02:15 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-07-19T21:02:15.439+0000] {subprocess.py:93} INFO - 25/07/19 21:02:15 INFO SharedState: Warehouse path is 'file:/app/spark-warehouse'.
[2025-07-19T21:02:16.466+0000] {subprocess.py:93} INFO - 25/07/19 21:02:16 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
[2025-07-19T21:02:16.472+0000] {subprocess.py:93} INFO - 25/07/19 21:02:16 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
[2025-07-19T21:02:16.472+0000] {subprocess.py:93} INFO - 25/07/19 21:02:16 INFO MetricsSystemImpl: s3a-file-system metrics system started
[2025-07-19T21:02:17.385+0000] {subprocess.py:93} INFO - 25/07/19 21:02:17 INFO BaseMetastoreCatalog: Table loaded by catalog: my_catalog.bronze.Reservations_raw
[2025-07-19T21:02:17.409+0000] {subprocess.py:93} INFO - 25/07/19 21:02:17 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
[2025-07-19T21:02:17.480+0000] {subprocess.py:93} INFO - 25/07/19 21:02:17 INFO ResolveWriteToStream: Checkpoint root /tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00 resolved to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00.
[2025-07-19T21:02:17.481+0000] {subprocess.py:93} INFO - 25/07/19 21:02:17 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
[2025-07-19T21:02:17.562+0000] {subprocess.py:93} INFO - 25/07/19 21:02:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/metadata using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/.metadata.5d36367c-18d3-423f-bef1-f6dea2fef38f.tmp
[2025-07-19T21:02:17.671+0000] {subprocess.py:93} INFO - 25/07/19 21:02:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/.metadata.5d36367c-18d3-423f-bef1-f6dea2fef38f.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/metadata
[2025-07-19T21:02:17.772+0000] {subprocess.py:93} INFO - 25/07/19 21:02:17 INFO MicroBatchExecution: Starting [id = 73830d4c-ed35-482d-8a53-860d8476043f, runId = 40450798-f492-4fd3-9974-3406c234d637]. Use file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00 to store the query checkpoint.
[2025-07-19T21:02:17.789+0000] {subprocess.py:93} INFO - 25/07/19 21:02:17 INFO MicroBatchExecution: Reading table [org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@487a437] from DataSourceV2 named 'kafka' [org.apache.spark.sql.kafka010.KafkaSourceProvider@8733564]
[2025-07-19T21:02:17.826+0000] {subprocess.py:93} INFO - 25/07/19 21:02:17 INFO OffsetSeqLog: BatchIds found from listing:
[2025-07-19T21:02:17.828+0000] {subprocess.py:93} INFO - 25/07/19 21:02:17 INFO OffsetSeqLog: BatchIds found from listing:
[2025-07-19T21:02:17.829+0000] {subprocess.py:93} INFO - 25/07/19 21:02:17 INFO MicroBatchExecution: Starting new streaming query.
[2025-07-19T21:02:17.832+0000] {subprocess.py:93} INFO - 25/07/19 21:02:17 INFO MicroBatchExecution: Stream started from {}
[2025-07-19T21:02:18.078+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO BaseMetastoreCatalog: Table loaded by catalog: my_catalog.bronze.Checkins_raw
[2025-07-19T21:02:18.114+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO ResolveWriteToStream: Checkpoint root /tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00 resolved to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00.
[2025-07-19T21:02:18.115+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
[2025-07-19T21:02:18.158+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/metadata using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/.metadata.c5f40d4d-77f5-47e2-b505-4e9439129449.tmp
[2025-07-19T21:02:18.235+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/.metadata.c5f40d4d-77f5-47e2-b505-4e9439129449.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/metadata
[2025-07-19T21:02:18.258+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO MicroBatchExecution: Starting [id = 857c6a97-8a45-4319-91e0-4d8882460008, runId = fe455bb9-f78f-4c5d-a439-a7e861a32bf0]. Use file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00 to store the query checkpoint.
[2025-07-19T21:02:18.262+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO MicroBatchExecution: Reading table [org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@22897088] from DataSourceV2 named 'kafka' [org.apache.spark.sql.kafka010.KafkaSourceProvider@2c4e9b71]
[2025-07-19T21:02:18.263+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO OffsetSeqLog: BatchIds found from listing:
[2025-07-19T21:02:18.263+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO OffsetSeqLog: BatchIds found from listing:
[2025-07-19T21:02:18.264+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO MicroBatchExecution: Starting new streaming query.
[2025-07-19T21:02:18.264+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO MicroBatchExecution: Stream started from {}
[2025-07-19T21:02:18.297+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO AdminClientConfig: AdminClientConfig values:
[2025-07-19T21:02:18.298+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-19T21:02:18.298+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-07-19T21:02:18.298+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-19T21:02:18.299+0000] {subprocess.py:93} INFO - 	client.id =
[2025-07-19T21:02:18.299+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 300000
[2025-07-19T21:02:18.300+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-19T21:02:18.300+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-19T21:02:18.300+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-19T21:02:18.301+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-19T21:02:18.301+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-19T21:02:18.301+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-19T21:02:18.302+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-19T21:02:18.302+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-19T21:02:18.308+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-19T21:02:18.309+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-19T21:02:18.310+0000] {subprocess.py:93} INFO - 	retries = 2147483647
[2025-07-19T21:02:18.310+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-19T21:02:18.310+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-19T21:02:18.311+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-19T21:02:18.311+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-19T21:02:18.311+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-19T21:02:18.312+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-19T21:02:18.312+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-19T21:02:18.312+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-19T21:02:18.313+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-19T21:02:18.313+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-19T21:02:18.313+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-19T21:02:18.314+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-19T21:02:18.316+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-19T21:02:18.317+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-19T21:02:18.319+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-19T21:02:18.320+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-19T21:02:18.320+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-19T21:02:18.321+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-19T21:02:18.322+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-19T21:02:18.322+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-19T21:02:18.323+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-19T21:02:18.323+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-19T21:02:18.324+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-19T21:02:18.325+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-19T21:02:18.325+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-19T21:02:18.326+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-19T21:02:18.326+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-19T21:02:18.326+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-19T21:02:18.327+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-19T21:02:18.327+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-19T21:02:18.328+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-19T21:02:18.329+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-19T21:02:18.330+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-19T21:02:18.330+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-19T21:02:18.331+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-19T21:02:18.331+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-19T21:02:18.332+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-19T21:02:18.333+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-19T21:02:18.334+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-19T21:02:18.334+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-19T21:02:18.335+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-19T21:02:18.335+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-19T21:02:18.335+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-19T21:02:18.336+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-19T21:02:18.337+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-19T21:02:18.338+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-19T21:02:18.339+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-19T21:02:18.340+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-19T21:02:18.341+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-19T21:02:18.341+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-19T21:02:18.342+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-19T21:02:18.342+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-19T21:02:18.343+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-19T21:02:18.343+0000] {subprocess.py:93} INFO - 
[2025-07-19T21:02:18.344+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO AdminClientConfig: AdminClientConfig values:
[2025-07-19T21:02:18.344+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-19T21:02:18.344+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-07-19T21:02:18.345+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-19T21:02:18.345+0000] {subprocess.py:93} INFO - 	client.id =
[2025-07-19T21:02:18.345+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 300000
[2025-07-19T21:02:18.345+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-19T21:02:18.345+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-19T21:02:18.345+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-19T21:02:18.346+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-19T21:02:18.346+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-19T21:02:18.346+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-19T21:02:18.346+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-19T21:02:18.346+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-19T21:02:18.346+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-19T21:02:18.346+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-19T21:02:18.346+0000] {subprocess.py:93} INFO - 	retries = 2147483647
[2025-07-19T21:02:18.346+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-19T21:02:18.346+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-19T21:02:18.346+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-19T21:02:18.347+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-19T21:02:18.347+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-19T21:02:18.347+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-19T21:02:18.347+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-19T21:02:18.347+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-19T21:02:18.347+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-19T21:02:18.347+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-19T21:02:18.347+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-19T21:02:18.347+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-19T21:02:18.347+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-19T21:02:18.347+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-19T21:02:18.348+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-19T21:02:18.348+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-19T21:02:18.348+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-19T21:02:18.348+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-19T21:02:18.348+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-19T21:02:18.348+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-19T21:02:18.348+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-19T21:02:18.348+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-19T21:02:18.348+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-19T21:02:18.348+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-19T21:02:18.348+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-19T21:02:18.348+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-19T21:02:18.349+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-19T21:02:18.349+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-19T21:02:18.349+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-19T21:02:18.349+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-19T21:02:18.349+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-19T21:02:18.349+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-19T21:02:18.349+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-19T21:02:18.349+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-19T21:02:18.349+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-19T21:02:18.349+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-19T21:02:18.349+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-19T21:02:18.349+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-19T21:02:18.349+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-19T21:02:18.350+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-19T21:02:18.350+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-19T21:02:18.350+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-19T21:02:18.350+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-19T21:02:18.350+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-19T21:02:18.350+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-19T21:02:18.351+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-19T21:02:18.351+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-19T21:02:18.351+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-19T21:02:18.351+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-19T21:02:18.351+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-19T21:02:18.351+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-19T21:02:18.351+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-19T21:02:18.351+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-19T21:02:18.351+0000] {subprocess.py:93} INFO - 
[2025-07-19T21:02:18.399+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
[2025-07-19T21:02:18.399+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
[2025-07-19T21:02:18.400+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-19T21:02:18.401+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-19T21:02:18.401+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO AppInfoParser: Kafka startTimeMs: 1752958938398
[2025-07-19T21:02:18.403+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-19T21:02:18.403+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-19T21:02:18.404+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO AppInfoParser: Kafka startTimeMs: 1752958938398
[2025-07-19T21:02:18.421+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO BaseMetastoreCatalog: Table loaded by catalog: my_catalog.bronze.Feedback_raw
[2025-07-19T21:02:18.436+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO ResolveWriteToStream: Checkpoint root /tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00 resolved to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00.
[2025-07-19T21:02:18.437+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
[2025-07-19T21:02:18.456+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/metadata using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/.metadata.6e681e25-5486-406d-b4af-83aa78c7a07e.tmp
[2025-07-19T21:02:18.531+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/.metadata.6e681e25-5486-406d-b4af-83aa78c7a07e.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/metadata
[2025-07-19T21:02:18.554+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO MicroBatchExecution: Starting [id = 30463049-c973-45be-97a0-fdd3d358740a, runId = 07295437-5b62-45a1-8005-3d2155adaa4b]. Use file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00 to store the query checkpoint.
[2025-07-19T21:02:18.555+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO MicroBatchExecution: Reading table [org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@31e0a894] from DataSourceV2 named 'kafka' [org.apache.spark.sql.kafka010.KafkaSourceProvider@3f275100]
[2025-07-19T21:02:18.564+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO OffsetSeqLog: BatchIds found from listing:
[2025-07-19T21:02:18.565+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO OffsetSeqLog: BatchIds found from listing:
[2025-07-19T21:02:18.566+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO MicroBatchExecution: Starting new streaming query.
[2025-07-19T21:02:18.568+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO MicroBatchExecution: Stream started from {}
[2025-07-19T21:02:18.597+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO AdminClientConfig: AdminClientConfig values:
[2025-07-19T21:02:18.597+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-19T21:02:18.598+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-07-19T21:02:18.598+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-19T21:02:18.598+0000] {subprocess.py:93} INFO - 	client.id =
[2025-07-19T21:02:18.599+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 300000
[2025-07-19T21:02:18.600+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-19T21:02:18.604+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-19T21:02:18.604+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-19T21:02:18.604+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-19T21:02:18.604+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-19T21:02:18.605+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-19T21:02:18.605+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-19T21:02:18.605+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-19T21:02:18.605+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-19T21:02:18.605+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-19T21:02:18.605+0000] {subprocess.py:93} INFO - 	retries = 2147483647
[2025-07-19T21:02:18.605+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-19T21:02:18.605+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-19T21:02:18.605+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-19T21:02:18.605+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-19T21:02:18.605+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-19T21:02:18.605+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-19T21:02:18.605+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-19T21:02:18.605+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-19T21:02:18.606+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-19T21:02:18.606+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-19T21:02:18.606+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-19T21:02:18.606+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-19T21:02:18.606+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-19T21:02:18.606+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-19T21:02:18.606+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-19T21:02:18.606+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-19T21:02:18.606+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-19T21:02:18.606+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-19T21:02:18.606+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-19T21:02:18.606+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-19T21:02:18.606+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-19T21:02:18.606+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-19T21:02:18.607+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-19T21:02:18.607+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-19T21:02:18.607+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-19T21:02:18.607+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-19T21:02:18.607+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-19T21:02:18.607+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-19T21:02:18.607+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-19T21:02:18.607+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-19T21:02:18.607+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-19T21:02:18.607+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-19T21:02:18.608+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-19T21:02:18.608+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-19T21:02:18.608+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-19T21:02:18.608+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-19T21:02:18.608+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-19T21:02:18.609+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-19T21:02:18.609+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-19T21:02:18.609+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-19T21:02:18.609+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-19T21:02:18.609+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-19T21:02:18.609+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-19T21:02:18.609+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-19T21:02:18.609+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-19T21:02:18.609+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-19T21:02:18.609+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-19T21:02:18.609+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-19T21:02:18.609+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-19T21:02:18.609+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-19T21:02:18.609+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-19T21:02:18.609+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-19T21:02:18.610+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-19T21:02:18.610+0000] {subprocess.py:93} INFO - 
[2025-07-19T21:02:18.610+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
[2025-07-19T21:02:18.610+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-19T21:02:18.610+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-19T21:02:18.610+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO AppInfoParser: Kafka startTimeMs: 1752958938598
[2025-07-19T21:02:18.733+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/sources/0/0 using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/sources/0/.0.c7f11b0a-7632-4410-a6e6-fc05cedb4a65.tmp
[2025-07-19T21:02:18.735+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/sources/0/0 using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/sources/0/.0.0d3fd492-4245-42fb-a211-de2ac156219f.tmp
[2025-07-19T21:02:18.737+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/sources/0/0 using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/sources/0/.0.e901a00f-5493-4e48-b9f6-afe2bccc13c9.tmp
[2025-07-19T21:02:18.798+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/sources/0/.0.e901a00f-5493-4e48-b9f6-afe2bccc13c9.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/sources/0/0
[2025-07-19T21:02:18.799+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/sources/0/.0.0d3fd492-4245-42fb-a211-de2ac156219f.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/sources/0/0
[2025-07-19T21:02:18.800+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO KafkaMicroBatchStream: Initial offsets: {"checkins":{"0":0}}
[2025-07-19T21:02:18.800+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO KafkaMicroBatchStream: Initial offsets: {"reservations":{"0":0}}
[2025-07-19T21:02:18.802+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/sources/0/.0.c7f11b0a-7632-4410-a6e6-fc05cedb4a65.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/sources/0/0
[2025-07-19T21:02:18.803+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO KafkaMicroBatchStream: Initial offsets: {"feedback":{"0":0}}
[2025-07-19T21:02:18.824+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/offsets/0 using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/offsets/.0.d3d9115d-8ed6-4aff-bb5c-4afb5bd079bc.tmp
[2025-07-19T21:02:18.824+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/offsets/0 using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/offsets/.0.6fac4e51-7f05-471b-b246-d880b69e05c0.tmp
[2025-07-19T21:02:18.826+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/offsets/0 using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/offsets/.0.8cdaaf52-6e19-416c-aac5-89b9b9d34129.tmp
[2025-07-19T21:02:18.906+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/offsets/.0.6fac4e51-7f05-471b-b246-d880b69e05c0.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/offsets/0
[2025-07-19T21:02:18.910+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/offsets/.0.d3d9115d-8ed6-4aff-bb5c-4afb5bd079bc.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/offsets/0
[2025-07-19T21:02:18.911+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO MicroBatchExecution: Committed offsets for batch 0. Metadata OffsetSeqMetadata(0,1752958938808,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.optimizer.pruneFiltersCanPruneStreamingSubplan -> false, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2025-07-19T21:02:18.914+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO MicroBatchExecution: Committed offsets for batch 0. Metadata OffsetSeqMetadata(0,1752958938808,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.optimizer.pruneFiltersCanPruneStreamingSubplan -> false, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2025-07-19T21:02:18.924+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/offsets/.0.8cdaaf52-6e19-416c-aac5-89b9b9d34129.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/offsets/0
[2025-07-19T21:02:18.925+0000] {subprocess.py:93} INFO - 25/07/19 21:02:18 INFO MicroBatchExecution: Committed offsets for batch 0. Metadata OffsetSeqMetadata(0,1752958938808,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.optimizer.pruneFiltersCanPruneStreamingSubplan -> false, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2025-07-19T21:02:19.090+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Feedback_raw
[2025-07-19T21:02:19.090+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Reservations_raw
[2025-07-19T21:02:19.090+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Feedback_raw
[2025-07-19T21:02:19.091+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Reservations_raw
[2025-07-19T21:02:19.091+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Checkins_raw
[2025-07-19T21:02:19.091+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Checkins_raw
[2025-07-19T21:02:19.092+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Checkins_raw
[2025-07-19T21:02:19.092+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Reservations_raw
[2025-07-19T21:02:19.092+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Feedback_raw
[2025-07-19T21:02:19.303+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO CodeGenerator: Code generated in 102.219917 ms
[2025-07-19T21:02:19.320+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T21:02:19.320+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T21:02:19.320+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T21:02:19.354+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T21:02:19.354+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T21:02:19.354+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T21:02:19.413+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Feedback_raw
[2025-07-19T21:02:19.414+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Feedback_raw
[2025-07-19T21:02:19.414+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Feedback_raw
[2025-07-19T21:02:19.414+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Checkins_raw
[2025-07-19T21:02:19.415+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Checkins_raw
[2025-07-19T21:02:19.415+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Checkins_raw
[2025-07-19T21:02:19.415+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Reservations_raw
[2025-07-19T21:02:19.415+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Reservations_raw
[2025-07-19T21:02:19.415+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Reservations_raw
[2025-07-19T21:02:19.415+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T21:02:19.415+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T21:02:19.416+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T21:02:19.417+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T21:02:19.418+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T21:02:19.419+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T21:02:19.463+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Checkins_raw
[2025-07-19T21:02:19.465+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Checkins_raw
[2025-07-19T21:02:19.466+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Checkins_raw
[2025-07-19T21:02:19.467+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Reservations_raw
[2025-07-19T21:02:19.469+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Reservations_raw
[2025-07-19T21:02:19.471+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Reservations_raw
[2025-07-19T21:02:19.472+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T21:02:19.472+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T21:02:19.473+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T21:02:19.473+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Feedback_raw
[2025-07-19T21:02:19.473+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Feedback_raw
[2025-07-19T21:02:19.474+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Feedback_raw
[2025-07-19T21:02:19.476+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T21:02:19.478+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T21:02:19.483+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T21:02:19.579+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO CodeGenerator: Code generated in 34.624083 ms
[2025-07-19T21:02:19.579+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO CodeGenerator: Code generated in 36.1625 ms
[2025-07-19T21:02:19.682+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO CodeGenerator: Code generated in 124.767542 ms
[2025-07-19T21:02:19.897+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 209.0 KiB, free 434.2 MiB)
[2025-07-19T21:02:19.898+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 209.0 KiB, free 434.0 MiB)
[2025-07-19T21:02:19.899+0000] {subprocess.py:93} INFO - 25/07/19 21:02:19 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 209.0 KiB, free 433.8 MiB)
[2025-07-19T21:02:20.016+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.7 MiB)
[2025-07-19T21:02:20.020+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.7 MiB)
[2025-07-19T21:02:20.023+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.7 MiB)
[2025-07-19T21:02:20.027+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 8b44f3d35cfa:38433 (size: 35.4 KiB, free: 434.4 MiB)
[2025-07-19T21:02:20.028+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 8b44f3d35cfa:38433 (size: 35.4 KiB, free: 434.3 MiB)
[2025-07-19T21:02:20.073+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 8b44f3d35cfa:38433 (size: 35.4 KiB, free: 434.3 MiB)
[2025-07-19T21:02:20.074+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO SparkContext: Created broadcast 1 from start at <unknown>:0
[2025-07-19T21:02:20.074+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO SparkContext: Created broadcast 2 from start at <unknown>:0
[2025-07-19T21:02:20.074+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO SparkContext: Created broadcast 0 from start at <unknown>:0
[2025-07-19T21:02:20.090+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 32.0 KiB, free 433.6 MiB)
[2025-07-19T21:02:20.090+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 32.0 KiB, free 433.6 MiB)
[2025-07-19T21:02:20.097+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 32.0 KiB, free 433.6 MiB)
[2025-07-19T21:02:20.113+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 433.5 MiB)
[2025-07-19T21:02:20.114+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 433.5 MiB)
[2025-07-19T21:02:20.115+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 433.5 MiB)
[2025-07-19T21:02:20.116+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 8b44f3d35cfa:38433 (size: 29.6 KiB, free: 434.3 MiB)
[2025-07-19T21:02:20.117+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO SparkContext: Created broadcast 5 from start at <unknown>:0
[2025-07-19T21:02:20.117+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 8b44f3d35cfa:38433 (size: 29.5 KiB, free: 434.2 MiB)
[2025-07-19T21:02:20.117+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 8b44f3d35cfa:38433 (size: 29.6 KiB, free: 434.2 MiB)
[2025-07-19T21:02:20.118+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO SparkContext: Created broadcast 3 from start at <unknown>:0
[2025-07-19T21:02:20.118+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO SparkContext: Created broadcast 4 from start at <unknown>:0
[2025-07-19T21:02:20.118+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO WriteToDataSourceV2Exec: Start processing data source write support: MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Checkins_raw, format=PARQUET)]. The input RDD has 200 partitions.
[2025-07-19T21:02:20.118+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO WriteToDataSourceV2Exec: Start processing data source write support: MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Reservations_raw, format=PARQUET)]. The input RDD has 200 partitions.
[2025-07-19T21:02:20.119+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO WriteToDataSourceV2Exec: Start processing data source write support: MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Feedback_raw, format=PARQUET)]. The input RDD has 200 partitions.
[2025-07-19T21:02:20.129+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO SparkContext: Starting job: start at <unknown>:0
[2025-07-19T21:02:20.129+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO SparkContext: Starting job: start at <unknown>:0
[2025-07-19T21:02:20.129+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO SparkContext: Starting job: start at <unknown>:0
[2025-07-19T21:02:20.142+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO DAGScheduler: Registering RDD 17 (start at <unknown>:0) as input to shuffle 0
[2025-07-19T21:02:20.145+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO DAGScheduler: Got job 1 (start at <unknown>:0) with 200 output partitions
[2025-07-19T21:02:20.145+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO DAGScheduler: Final stage: ResultStage 1 (start at <unknown>:0)
[2025-07-19T21:02:20.146+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
[2025-07-19T21:02:20.146+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
[2025-07-19T21:02:20.148+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[17] at start at <unknown>:0), which has no missing parents
[2025-07-19T21:02:20.166+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 33.8 KiB, free 433.5 MiB)
[2025-07-19T21:02:20.167+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.6 KiB, free 433.5 MiB)
[2025-07-19T21:02:20.167+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 8b44f3d35cfa:38433 (size: 14.6 KiB, free: 434.2 MiB)
[2025-07-19T21:02:20.167+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1611
[2025-07-19T21:02:20.184+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[17] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-07-19T21:02:20.186+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2025-07-19T21:02:20.199+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO DAGScheduler: Registering RDD 16 (start at <unknown>:0) as input to shuffle 2
[2025-07-19T21:02:20.200+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO DAGScheduler: Got job 2 (start at <unknown>:0) with 200 output partitions
[2025-07-19T21:02:20.201+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO DAGScheduler: Final stage: ResultStage 3 (start at <unknown>:0)
[2025-07-19T21:02:20.201+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
[2025-07-19T21:02:20.201+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
[2025-07-19T21:02:20.201+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[16] at start at <unknown>:0), which has no missing parents
[2025-07-19T21:02:20.206+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 32.3 KiB, free 433.4 MiB)
[2025-07-19T21:02:20.207+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 433.4 MiB)
[2025-07-19T21:02:20.210+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 8b44f3d35cfa:38433 (size: 14.1 KiB, free: 434.2 MiB)
[2025-07-19T21:02:20.211+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1611
[2025-07-19T21:02:20.211+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[16] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-07-19T21:02:20.212+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
[2025-07-19T21:02:20.219+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 9927 bytes)
[2025-07-19T21:02:20.229+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO DAGScheduler: Registering RDD 15 (start at <unknown>:0) as input to shuffle 1
[2025-07-19T21:02:20.230+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO DAGScheduler: Got job 0 (start at <unknown>:0) with 200 output partitions
[2025-07-19T21:02:20.230+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO DAGScheduler: Final stage: ResultStage 5 (start at <unknown>:0)
[2025-07-19T21:02:20.231+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
[2025-07-19T21:02:20.232+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
[2025-07-19T21:02:20.232+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[15] at start at <unknown>:0), which has no missing parents
[2025-07-19T21:02:20.233+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 1) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 9923 bytes)
[2025-07-19T21:02:20.234+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 35.8 KiB, free 433.4 MiB)
[2025-07-19T21:02:20.236+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 15.8 KiB, free 433.4 MiB)
[2025-07-19T21:02:20.238+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO Executor: Running task 0.0 in stage 2.0 (TID 1)
[2025-07-19T21:02:20.238+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 8b44f3d35cfa:38433 (size: 15.8 KiB, free: 434.2 MiB)
[2025-07-19T21:02:20.239+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
[2025-07-19T21:02:20.239+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1611
[2025-07-19T21:02:20.240+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[15] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-07-19T21:02:20.241+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
[2025-07-19T21:02:20.244+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 2) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 9924 bytes)
[2025-07-19T21:02:20.248+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO Executor: Running task 0.0 in stage 4.0 (TID 2)
[2025-07-19T21:02:20.369+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO CodeGenerator: Code generated in 18.772417 ms
[2025-07-19T21:02:20.370+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO CodeGenerator: Code generated in 19.328792 ms
[2025-07-19T21:02:20.392+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO CodeGenerator: Code generated in 42.386208 ms
[2025-07-19T21:02:20.408+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO CodeGenerator: Code generated in 38.146417 ms
[2025-07-19T21:02:20.410+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO CodeGenerator: Code generated in 41.277333 ms
[2025-07-19T21:02:20.420+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO CodeGenerator: Code generated in 28.327375 ms
[2025-07-19T21:02:20.421+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO CodeGenerator: Code generated in 7.949958 ms
[2025-07-19T21:02:20.438+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO CodeGenerator: Code generated in 14.546584 ms
[2025-07-19T21:02:20.441+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO CodeGenerator: Code generated in 12.159333 ms
[2025-07-19T21:02:20.459+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO CodeGenerator: Code generated in 17.658417 ms
[2025-07-19T21:02:20.460+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=reservations-0 fromOffset=0 untilOffset=234, for query queryId=73830d4c-ed35-482d-8a53-860d8476043f batchId=0 taskId=0 partitionId=0
[2025-07-19T21:02:20.460+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=feedback-0 fromOffset=0 untilOffset=234, for query queryId=30463049-c973-45be-97a0-fdd3d358740a batchId=0 taskId=1 partitionId=0
[2025-07-19T21:02:20.462+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=checkins-0 fromOffset=0 untilOffset=234, for query queryId=857c6a97-8a45-4319-91e0-4d8882460008 batchId=0 taskId=2 partitionId=0
[2025-07-19T21:02:20.498+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO CodeGenerator: Code generated in 14.790667 ms
[2025-07-19T21:02:20.516+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO CodeGenerator: Code generated in 10.285083 ms
[2025-07-19T21:02:20.534+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO ConsumerConfig: ConsumerConfig values:
[2025-07-19T21:02:20.535+0000] {subprocess.py:93} INFO - 	allow.auto.create.topics = true
[2025-07-19T21:02:20.535+0000] {subprocess.py:93} INFO - 	auto.commit.interval.ms = 5000
[2025-07-19T21:02:20.535+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-19T21:02:20.535+0000] {subprocess.py:93} INFO - 	auto.offset.reset = none
[2025-07-19T21:02:20.535+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-07-19T21:02:20.536+0000] {subprocess.py:93} INFO - 	check.crcs = true
[2025-07-19T21:02:20.536+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-19T21:02:20.536+0000] {subprocess.py:93} INFO - 	client.id = consumer-spark-kafka-source-2bd68d88-049e-43cb-ab08-0df98b53357a-906712184-executor-1
[2025-07-19T21:02:20.537+0000] {subprocess.py:93} INFO - 	client.rack =
[2025-07-19T21:02:20.537+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 540000
[2025-07-19T21:02:20.537+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-19T21:02:20.538+0000] {subprocess.py:93} INFO - 	enable.auto.commit = false
[2025-07-19T21:02:20.538+0000] {subprocess.py:93} INFO - 	exclude.internal.topics = true
[2025-07-19T21:02:20.538+0000] {subprocess.py:93} INFO - 	fetch.max.bytes = 52428800
[2025-07-19T21:02:20.538+0000] {subprocess.py:93} INFO - 	fetch.max.wait.ms = 500
[2025-07-19T21:02:20.538+0000] {subprocess.py:93} INFO - 	fetch.min.bytes = 1
[2025-07-19T21:02:20.538+0000] {subprocess.py:93} INFO - 	group.id = spark-kafka-source-2bd68d88-049e-43cb-ab08-0df98b53357a-906712184-executor
[2025-07-19T21:02:20.538+0000] {subprocess.py:93} INFO - 	group.instance.id = null
[2025-07-19T21:02:20.539+0000] {subprocess.py:93} INFO - 	heartbeat.interval.ms = 3000
[2025-07-19T21:02:20.539+0000] {subprocess.py:93} INFO - 	interceptor.classes = []
[2025-07-19T21:02:20.539+0000] {subprocess.py:93} INFO - 	internal.leave.group.on.close = true
[2025-07-19T21:02:20.539+0000] {subprocess.py:93} INFO - 	internal.throw.on.fetch.stable.offset.unsupported = false
[2025-07-19T21:02:20.539+0000] {subprocess.py:93} INFO - 	isolation.level = read_uncommitted
[2025-07-19T21:02:20.539+0000] {subprocess.py:93} INFO - 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-07-19T21:02:20.539+0000] {subprocess.py:93} INFO - 	max.partition.fetch.bytes = 1048576
[2025-07-19T21:02:20.539+0000] {subprocess.py:93} INFO - 	max.poll.interval.ms = 300000
[2025-07-19T21:02:20.539+0000] {subprocess.py:93} INFO - 	max.poll.records = 500
[2025-07-19T21:02:20.540+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-19T21:02:20.540+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-19T21:02:20.540+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-19T21:02:20.540+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-19T21:02:20.540+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-19T21:02:20.540+0000] {subprocess.py:93} INFO - 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
[2025-07-19T21:02:20.540+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-19T21:02:20.540+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-19T21:02:20.541+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-19T21:02:20.541+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-19T21:02:20.541+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-19T21:02:20.541+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-19T21:02:20.541+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-19T21:02:20.541+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-19T21:02:20.541+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-19T21:02:20.542+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-19T21:02:20.542+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-19T21:02:20.542+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-19T21:02:20.542+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-19T21:02:20.542+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-19T21:02:20.542+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-19T21:02:20.542+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-19T21:02:20.543+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-19T21:02:20.543+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-19T21:02:20.543+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-19T21:02:20.543+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-19T21:02:20.543+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-19T21:02:20.544+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-19T21:02:20.544+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-19T21:02:20.544+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-19T21:02:20.545+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-19T21:02:20.545+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-19T21:02:20.546+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-19T21:02:20.546+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-19T21:02:20.546+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-19T21:02:20.547+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-19T21:02:20.547+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-19T21:02:20.547+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-19T21:02:20.547+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-19T21:02:20.548+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-19T21:02:20.548+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-19T21:02:20.548+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-19T21:02:20.548+0000] {subprocess.py:93} INFO - 	session.timeout.ms = 45000
[2025-07-19T21:02:20.549+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-19T21:02:20.549+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-19T21:02:20.549+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-19T21:02:20.550+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-19T21:02:20.550+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-19T21:02:20.550+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-19T21:02:20.551+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-19T21:02:20.551+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-19T21:02:20.551+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-19T21:02:20.552+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-19T21:02:20.552+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-19T21:02:20.552+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-19T21:02:20.553+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-19T21:02:20.553+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-19T21:02:20.555+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-19T21:02:20.555+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-19T21:02:20.555+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-19T21:02:20.556+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-19T21:02:20.557+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-19T21:02:20.557+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-19T21:02:20.558+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-19T21:02:20.558+0000] {subprocess.py:93} INFO - 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-07-19T21:02:20.558+0000] {subprocess.py:93} INFO - 
[2025-07-19T21:02:20.558+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO ConsumerConfig: ConsumerConfig values:
[2025-07-19T21:02:20.559+0000] {subprocess.py:93} INFO - 	allow.auto.create.topics = true
[2025-07-19T21:02:20.559+0000] {subprocess.py:93} INFO - 	auto.commit.interval.ms = 5000
[2025-07-19T21:02:20.559+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-19T21:02:20.560+0000] {subprocess.py:93} INFO - 	auto.offset.reset = none
[2025-07-19T21:02:20.560+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-07-19T21:02:20.560+0000] {subprocess.py:93} INFO - 	check.crcs = true
[2025-07-19T21:02:20.564+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-19T21:02:20.565+0000] {subprocess.py:93} INFO - 	client.id = consumer-spark-kafka-source-ddf60d79-58fd-40c4-95ff-4219c515ff0a--71257894-executor-3
[2025-07-19T21:02:20.566+0000] {subprocess.py:93} INFO - 	client.rack =
[2025-07-19T21:02:20.566+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 540000
[2025-07-19T21:02:20.567+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-19T21:02:20.568+0000] {subprocess.py:93} INFO - 	enable.auto.commit = false
[2025-07-19T21:02:20.569+0000] {subprocess.py:93} INFO - 	exclude.internal.topics = true
[2025-07-19T21:02:20.569+0000] {subprocess.py:93} INFO - 	fetch.max.bytes = 52428800
[2025-07-19T21:02:20.570+0000] {subprocess.py:93} INFO - 	fetch.max.wait.ms = 500
[2025-07-19T21:02:20.570+0000] {subprocess.py:93} INFO - 	fetch.min.bytes = 1
[2025-07-19T21:02:20.570+0000] {subprocess.py:93} INFO - 	group.id = spark-kafka-source-ddf60d79-58fd-40c4-95ff-4219c515ff0a--71257894-executor
[2025-07-19T21:02:20.571+0000] {subprocess.py:93} INFO - 	group.instance.id = null
[2025-07-19T21:02:20.571+0000] {subprocess.py:93} INFO - 	heartbeat.interval.ms = 3000
[2025-07-19T21:02:20.571+0000] {subprocess.py:93} INFO - 	interceptor.classes = []
[2025-07-19T21:02:20.571+0000] {subprocess.py:93} INFO - 	internal.leave.group.on.close = true
[2025-07-19T21:02:20.571+0000] {subprocess.py:93} INFO - 	internal.throw.on.fetch.stable.offset.unsupported = false
[2025-07-19T21:02:20.571+0000] {subprocess.py:93} INFO - 	isolation.level = read_uncommitted
[2025-07-19T21:02:20.571+0000] {subprocess.py:93} INFO - 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-07-19T21:02:20.571+0000] {subprocess.py:93} INFO - 	max.partition.fetch.bytes = 1048576
[2025-07-19T21:02:20.571+0000] {subprocess.py:93} INFO - 	max.poll.interval.ms = 300000
[2025-07-19T21:02:20.571+0000] {subprocess.py:93} INFO - 	max.poll.records = 500
[2025-07-19T21:02:20.571+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-19T21:02:20.571+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-19T21:02:20.572+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-19T21:02:20.572+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-19T21:02:20.572+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-19T21:02:20.572+0000] {subprocess.py:93} INFO - 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
[2025-07-19T21:02:20.572+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-19T21:02:20.572+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-19T21:02:20.572+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-19T21:02:20.572+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-19T21:02:20.572+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-19T21:02:20.572+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-19T21:02:20.572+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-19T21:02:20.572+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-19T21:02:20.572+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-19T21:02:20.573+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-19T21:02:20.573+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-19T21:02:20.573+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-19T21:02:20.573+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-19T21:02:20.573+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-19T21:02:20.573+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-19T21:02:20.573+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-19T21:02:20.573+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-19T21:02:20.574+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-19T21:02:20.574+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-19T21:02:20.574+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-19T21:02:20.574+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-19T21:02:20.574+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-19T21:02:20.575+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-19T21:02:20.575+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-19T21:02:20.575+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-19T21:02:20.575+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-19T21:02:20.575+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-19T21:02:20.576+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-19T21:02:20.576+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-19T21:02:20.576+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-19T21:02:20.576+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-19T21:02:20.576+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-19T21:02:20.576+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-19T21:02:20.576+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-19T21:02:20.576+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-19T21:02:20.577+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-19T21:02:20.577+0000] {subprocess.py:93} INFO - 	session.timeout.ms = 45000
[2025-07-19T21:02:20.577+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-19T21:02:20.577+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-19T21:02:20.577+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-19T21:02:20.577+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-19T21:02:20.577+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-19T21:02:20.577+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-19T21:02:20.577+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-19T21:02:20.578+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-19T21:02:20.578+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-19T21:02:20.578+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-19T21:02:20.579+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-19T21:02:20.579+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-19T21:02:20.580+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-19T21:02:20.580+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-19T21:02:20.580+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-19T21:02:20.581+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-19T21:02:20.581+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-19T21:02:20.581+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-19T21:02:20.585+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-19T21:02:20.587+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-19T21:02:20.588+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-19T21:02:20.588+0000] {subprocess.py:93} INFO - 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-07-19T21:02:20.588+0000] {subprocess.py:93} INFO - 
[2025-07-19T21:02:20.588+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO ConsumerConfig: ConsumerConfig values:
[2025-07-19T21:02:20.588+0000] {subprocess.py:93} INFO - 	allow.auto.create.topics = true
[2025-07-19T21:02:20.588+0000] {subprocess.py:93} INFO - 	auto.commit.interval.ms = 5000
[2025-07-19T21:02:20.589+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-19T21:02:20.589+0000] {subprocess.py:93} INFO - 	auto.offset.reset = none
[2025-07-19T21:02:20.589+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-07-19T21:02:20.589+0000] {subprocess.py:93} INFO - 	check.crcs = true
[2025-07-19T21:02:20.589+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-19T21:02:20.589+0000] {subprocess.py:93} INFO - 	client.id = consumer-spark-kafka-source-5e160dd6-92fc-4677-b523-b14859d09e7e-1454210137-executor-2
[2025-07-19T21:02:20.589+0000] {subprocess.py:93} INFO - 	client.rack =
[2025-07-19T21:02:20.590+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 540000
[2025-07-19T21:02:20.590+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-19T21:02:20.590+0000] {subprocess.py:93} INFO - 	enable.auto.commit = false
[2025-07-19T21:02:20.590+0000] {subprocess.py:93} INFO - 	exclude.internal.topics = true
[2025-07-19T21:02:20.590+0000] {subprocess.py:93} INFO - 	fetch.max.bytes = 52428800
[2025-07-19T21:02:20.590+0000] {subprocess.py:93} INFO - 	fetch.max.wait.ms = 500
[2025-07-19T21:02:20.590+0000] {subprocess.py:93} INFO - 	fetch.min.bytes = 1
[2025-07-19T21:02:20.591+0000] {subprocess.py:93} INFO - 	group.id = spark-kafka-source-5e160dd6-92fc-4677-b523-b14859d09e7e-1454210137-executor
[2025-07-19T21:02:20.591+0000] {subprocess.py:93} INFO - 	group.instance.id = null
[2025-07-19T21:02:20.591+0000] {subprocess.py:93} INFO - 	heartbeat.interval.ms = 3000
[2025-07-19T21:02:20.591+0000] {subprocess.py:93} INFO - 	interceptor.classes = []
[2025-07-19T21:02:20.591+0000] {subprocess.py:93} INFO - 	internal.leave.group.on.close = true
[2025-07-19T21:02:20.591+0000] {subprocess.py:93} INFO - 	internal.throw.on.fetch.stable.offset.unsupported = false
[2025-07-19T21:02:20.591+0000] {subprocess.py:93} INFO - 	isolation.level = read_uncommitted
[2025-07-19T21:02:20.591+0000] {subprocess.py:93} INFO - 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-07-19T21:02:20.591+0000] {subprocess.py:93} INFO - 	max.partition.fetch.bytes = 1048576
[2025-07-19T21:02:20.592+0000] {subprocess.py:93} INFO - 	max.poll.interval.ms = 300000
[2025-07-19T21:02:20.592+0000] {subprocess.py:93} INFO - 	max.poll.records = 500
[2025-07-19T21:02:20.592+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-19T21:02:20.592+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-19T21:02:20.593+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-19T21:02:20.593+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-19T21:02:20.593+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-19T21:02:20.593+0000] {subprocess.py:93} INFO - 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
[2025-07-19T21:02:20.593+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-19T21:02:20.594+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-19T21:02:20.594+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-19T21:02:20.594+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-19T21:02:20.595+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-19T21:02:20.595+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-19T21:02:20.595+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-19T21:02:20.595+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-19T21:02:20.596+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-19T21:02:20.596+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-19T21:02:20.596+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-19T21:02:20.596+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-19T21:02:20.596+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-19T21:02:20.596+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-19T21:02:20.596+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-19T21:02:20.596+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-19T21:02:20.596+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-19T21:02:20.597+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-19T21:02:20.597+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-19T21:02:20.597+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-19T21:02:20.599+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-19T21:02:20.600+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-19T21:02:20.600+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-19T21:02:20.601+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-19T21:02:20.601+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-19T21:02:20.601+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-19T21:02:20.602+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-19T21:02:20.602+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-19T21:02:20.603+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-19T21:02:20.603+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-19T21:02:20.604+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-19T21:02:20.604+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-19T21:02:20.604+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-19T21:02:20.604+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-19T21:02:20.604+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-19T21:02:20.604+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-19T21:02:20.604+0000] {subprocess.py:93} INFO - 	session.timeout.ms = 45000
[2025-07-19T21:02:20.604+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-19T21:02:20.605+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-19T21:02:20.605+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-19T21:02:20.605+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-19T21:02:20.605+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-19T21:02:20.605+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-19T21:02:20.605+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-19T21:02:20.605+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-19T21:02:20.606+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-19T21:02:20.606+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-19T21:02:20.606+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-19T21:02:20.606+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-19T21:02:20.606+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-19T21:02:20.606+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-19T21:02:20.606+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-19T21:02:20.606+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-19T21:02:20.606+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-19T21:02:20.606+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-19T21:02:20.607+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-19T21:02:20.607+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-19T21:02:20.607+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-19T21:02:20.607+0000] {subprocess.py:93} INFO - 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-07-19T21:02:20.607+0000] {subprocess.py:93} INFO - 
[2025-07-19T21:02:20.607+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-19T21:02:20.608+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-19T21:02:20.608+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO AppInfoParser: Kafka startTimeMs: 1752958940596
[2025-07-19T21:02:20.608+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-19T21:02:20.608+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-19T21:02:20.608+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO AppInfoParser: Kafka startTimeMs: 1752958940596
[2025-07-19T21:02:20.609+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-19T21:02:20.609+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-19T21:02:20.609+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO AppInfoParser: Kafka startTimeMs: 1752958940596
[2025-07-19T21:02:20.609+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-5e160dd6-92fc-4677-b523-b14859d09e7e-1454210137-executor-2, groupId=spark-kafka-source-5e160dd6-92fc-4677-b523-b14859d09e7e-1454210137-executor] Assigned to partition(s): checkins-0
[2025-07-19T21:02:20.609+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2bd68d88-049e-43cb-ab08-0df98b53357a-906712184-executor-1, groupId=spark-kafka-source-2bd68d88-049e-43cb-ab08-0df98b53357a-906712184-executor] Assigned to partition(s): reservations-0
[2025-07-19T21:02:20.609+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ddf60d79-58fd-40c4-95ff-4219c515ff0a--71257894-executor-3, groupId=spark-kafka-source-ddf60d79-58fd-40c4-95ff-4219c515ff0a--71257894-executor] Assigned to partition(s): feedback-0
[2025-07-19T21:02:20.610+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ddf60d79-58fd-40c4-95ff-4219c515ff0a--71257894-executor-3, groupId=spark-kafka-source-ddf60d79-58fd-40c4-95ff-4219c515ff0a--71257894-executor] Seeking to offset 0 for partition feedback-0
[2025-07-19T21:02:20.610+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2bd68d88-049e-43cb-ab08-0df98b53357a-906712184-executor-1, groupId=spark-kafka-source-2bd68d88-049e-43cb-ab08-0df98b53357a-906712184-executor] Seeking to offset 0 for partition reservations-0
[2025-07-19T21:02:20.612+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-5e160dd6-92fc-4677-b523-b14859d09e7e-1454210137-executor-2, groupId=spark-kafka-source-5e160dd6-92fc-4677-b523-b14859d09e7e-1454210137-executor] Seeking to offset 0 for partition checkins-0
[2025-07-19T21:02:20.618+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO Metadata: [Consumer clientId=consumer-spark-kafka-source-ddf60d79-58fd-40c4-95ff-4219c515ff0a--71257894-executor-3, groupId=spark-kafka-source-ddf60d79-58fd-40c4-95ff-4219c515ff0a--71257894-executor] Cluster ID: iIlr_WxeQ6OmNSr-bYGtHA
[2025-07-19T21:02:20.618+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO Metadata: [Consumer clientId=consumer-spark-kafka-source-5e160dd6-92fc-4677-b523-b14859d09e7e-1454210137-executor-2, groupId=spark-kafka-source-5e160dd6-92fc-4677-b523-b14859d09e7e-1454210137-executor] Cluster ID: iIlr_WxeQ6OmNSr-bYGtHA
[2025-07-19T21:02:20.618+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO Metadata: [Consumer clientId=consumer-spark-kafka-source-2bd68d88-049e-43cb-ab08-0df98b53357a-906712184-executor-1, groupId=spark-kafka-source-2bd68d88-049e-43cb-ab08-0df98b53357a-906712184-executor] Cluster ID: iIlr_WxeQ6OmNSr-bYGtHA
[2025-07-19T21:02:20.661+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ddf60d79-58fd-40c4-95ff-4219c515ff0a--71257894-executor-3, groupId=spark-kafka-source-ddf60d79-58fd-40c4-95ff-4219c515ff0a--71257894-executor] Seeking to earliest offset of partition feedback-0
[2025-07-19T21:02:20.662+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-5e160dd6-92fc-4677-b523-b14859d09e7e-1454210137-executor-2, groupId=spark-kafka-source-5e160dd6-92fc-4677-b523-b14859d09e7e-1454210137-executor] Seeking to earliest offset of partition checkins-0
[2025-07-19T21:02:20.662+0000] {subprocess.py:93} INFO - 25/07/19 21:02:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2bd68d88-049e-43cb-ab08-0df98b53357a-906712184-executor-1, groupId=spark-kafka-source-2bd68d88-049e-43cb-ab08-0df98b53357a-906712184-executor] Seeking to earliest offset of partition reservations-0
[2025-07-19T21:02:21.173+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-5e160dd6-92fc-4677-b523-b14859d09e7e-1454210137-executor-2, groupId=spark-kafka-source-5e160dd6-92fc-4677-b523-b14859d09e7e-1454210137-executor] Resetting offset for partition checkins-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-07-19T21:02:21.174+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2bd68d88-049e-43cb-ab08-0df98b53357a-906712184-executor-1, groupId=spark-kafka-source-2bd68d88-049e-43cb-ab08-0df98b53357a-906712184-executor] Resetting offset for partition reservations-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-07-19T21:02:21.175+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ddf60d79-58fd-40c4-95ff-4219c515ff0a--71257894-executor-3, groupId=spark-kafka-source-ddf60d79-58fd-40c4-95ff-4219c515ff0a--71257894-executor] Resetting offset for partition feedback-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-07-19T21:02:21.175+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2bd68d88-049e-43cb-ab08-0df98b53357a-906712184-executor-1, groupId=spark-kafka-source-2bd68d88-049e-43cb-ab08-0df98b53357a-906712184-executor] Seeking to latest offset of partition reservations-0
[2025-07-19T21:02:21.176+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-5e160dd6-92fc-4677-b523-b14859d09e7e-1454210137-executor-2, groupId=spark-kafka-source-5e160dd6-92fc-4677-b523-b14859d09e7e-1454210137-executor] Seeking to latest offset of partition checkins-0
[2025-07-19T21:02:21.176+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ddf60d79-58fd-40c4-95ff-4219c515ff0a--71257894-executor-3, groupId=spark-kafka-source-ddf60d79-58fd-40c4-95ff-4219c515ff0a--71257894-executor] Seeking to latest offset of partition feedback-0
[2025-07-19T21:02:21.177+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-5e160dd6-92fc-4677-b523-b14859d09e7e-1454210137-executor-2, groupId=spark-kafka-source-5e160dd6-92fc-4677-b523-b14859d09e7e-1454210137-executor] Resetting offset for partition checkins-0 to position FetchPosition{offset=234, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-07-19T21:02:21.177+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ddf60d79-58fd-40c4-95ff-4219c515ff0a--71257894-executor-3, groupId=spark-kafka-source-ddf60d79-58fd-40c4-95ff-4219c515ff0a--71257894-executor] Resetting offset for partition feedback-0 to position FetchPosition{offset=234, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-07-19T21:02:21.178+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2bd68d88-049e-43cb-ab08-0df98b53357a-906712184-executor-1, groupId=spark-kafka-source-2bd68d88-049e-43cb-ab08-0df98b53357a-906712184-executor] Resetting offset for partition reservations-0 to position FetchPosition{offset=234, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-07-19T21:02:21.444+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO KafkaDataConsumer: From Kafka topicPartition=reservations-0 groupId=spark-kafka-source-2bd68d88-049e-43cb-ab08-0df98b53357a-906712184-executor read 234 records through 1 polls (polled  out 234 records), taking 566824959 nanos, during time span of 838604584 nanos.
[2025-07-19T21:02:21.448+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO KafkaDataConsumer: From Kafka topicPartition=feedback-0 groupId=spark-kafka-source-ddf60d79-58fd-40c4-95ff-4219c515ff0a--71257894-executor read 234 records through 1 polls (polled  out 234 records), taking 566728209 nanos, during time span of 841514959 nanos.
[2025-07-19T21:02:21.451+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO KafkaDataConsumer: From Kafka topicPartition=checkins-0 groupId=spark-kafka-source-5e160dd6-92fc-4677-b523-b14859d09e7e-1454210137-executor read 234 records through 1 polls (polled  out 234 records), taking 566607417 nanos, during time span of 844677959 nanos.
[2025-07-19T21:02:21.455+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2642 bytes result sent to driver
[2025-07-19T21:02:21.455+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO Executor: Finished task 0.0 in stage 4.0 (TID 2). 2599 bytes result sent to driver
[2025-07-19T21:02:21.455+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO Executor: Finished task 0.0 in stage 2.0 (TID 1). 2642 bytes result sent to driver
[2025-07-19T21:02:21.473+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 1) in 1235 ms on 8b44f3d35cfa (executor driver) (1/1)
[2025-07-19T21:02:21.475+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2025-07-19T21:02:21.477+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1263 ms on 8b44f3d35cfa (executor driver) (1/1)
[2025-07-19T21:02:21.477+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2025-07-19T21:02:21.478+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 2) in 1231 ms on 8b44f3d35cfa (executor driver) (1/1)
[2025-07-19T21:02:21.478+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool
[2025-07-19T21:02:21.489+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO DAGScheduler: ShuffleMapStage 2 (start at <unknown>:0) finished in 1.281 s
[2025-07-19T21:02:21.490+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO DAGScheduler: looking for newly runnable stages
[2025-07-19T21:02:21.490+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO DAGScheduler: running: Set(ShuffleMapStage 0, ShuffleMapStage 4)
[2025-07-19T21:02:21.491+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO DAGScheduler: waiting: Set(ResultStage 1, ResultStage 5, ResultStage 3)
[2025-07-19T21:02:21.492+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO DAGScheduler: failed: Set()
[2025-07-19T21:02:21.496+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO DAGScheduler: Submitting ResultStage 3 (StateStoreRDD[22] at start at <unknown>:0), which has no missing parents
[2025-07-19T21:02:21.586+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 38.8 KiB, free 433.3 MiB)
[2025-07-19T21:02:21.587+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 19.3 KiB, free 433.3 MiB)
[2025-07-19T21:02:21.588+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 8b44f3d35cfa:38433 (size: 19.3 KiB, free: 434.1 MiB)
[2025-07-19T21:02:21.588+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1611
[2025-07-19T21:02:21.591+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 3 (StateStoreRDD[22] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-07-19T21:02:21.592+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO TaskSchedulerImpl: Adding task set 3.0 with 200 tasks resource profile 0
[2025-07-19T21:02:21.596+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO DAGScheduler: ShuffleMapStage 0 (start at <unknown>:0) finished in 1.437 s
[2025-07-19T21:02:21.597+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO DAGScheduler: looking for newly runnable stages
[2025-07-19T21:02:21.599+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO DAGScheduler: running: Set(ResultStage 3, ShuffleMapStage 4)
[2025-07-19T21:02:21.602+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO DAGScheduler: waiting: Set(ResultStage 1, ResultStage 5)
[2025-07-19T21:02:21.606+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (8b44f3d35cfa, executor driver, partition 0, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:21.607+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO DAGScheduler: failed: Set()
[2025-07-19T21:02:21.611+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 4) (8b44f3d35cfa, executor driver, partition 1, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:21.612+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO DAGScheduler: Submitting ResultStage 1 (StateStoreRDD[23] at start at <unknown>:0), which has no missing parents
[2025-07-19T21:02:21.612+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 5) (8b44f3d35cfa, executor driver, partition 2, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:21.612+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 6) (8b44f3d35cfa, executor driver, partition 3, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:21.613+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 7) (8b44f3d35cfa, executor driver, partition 4, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:21.613+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO TaskSetManager: Starting task 7.0 in stage 3.0 (TID 8) (8b44f3d35cfa, executor driver, partition 7, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:21.614+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO TaskSetManager: Starting task 8.0 in stage 3.0 (TID 9) (8b44f3d35cfa, executor driver, partition 8, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:21.614+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO TaskSetManager: Starting task 9.0 in stage 3.0 (TID 10) (8b44f3d35cfa, executor driver, partition 9, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:21.614+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO Executor: Running task 2.0 in stage 3.0 (TID 5)
[2025-07-19T21:02:21.615+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
[2025-07-19T21:02:21.615+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO Executor: Running task 1.0 in stage 3.0 (TID 4)
[2025-07-19T21:02:21.616+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO Executor: Running task 3.0 in stage 3.0 (TID 6)
[2025-07-19T21:02:21.616+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO Executor: Running task 8.0 in stage 3.0 (TID 9)
[2025-07-19T21:02:21.618+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO Executor: Running task 7.0 in stage 3.0 (TID 8)
[2025-07-19T21:02:21.619+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO Executor: Running task 9.0 in stage 3.0 (TID 10)
[2025-07-19T21:02:21.619+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO Executor: Running task 4.0 in stage 3.0 (TID 7)
[2025-07-19T21:02:21.642+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 39.6 KiB, free 433.3 MiB)
[2025-07-19T21:02:21.643+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 19.6 KiB, free 433.2 MiB)
[2025-07-19T21:02:21.644+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 8b44f3d35cfa:38433 (size: 19.6 KiB, free: 434.1 MiB)
[2025-07-19T21:02:21.645+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1611
[2025-07-19T21:02:21.646+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 1 (StateStoreRDD[23] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-07-19T21:02:21.647+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO TaskSchedulerImpl: Adding task set 1.0 with 200 tasks resource profile 0
[2025-07-19T21:02:21.654+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO DAGScheduler: ShuffleMapStage 4 (start at <unknown>:0) finished in 1.421 s
[2025-07-19T21:02:21.655+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:21.656+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:21.658+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:21.659+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:21.660+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:21.660+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO DAGScheduler: looking for newly runnable stages
[2025-07-19T21:02:21.662+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:21.663+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:21.663+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO DAGScheduler: running: Set(ResultStage 1, ResultStage 3)
[2025-07-19T21:02:21.664+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:21.666+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO DAGScheduler: waiting: Set(ResultStage 5)
[2025-07-19T21:02:21.667+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO DAGScheduler: failed: Set()
[2025-07-19T21:02:21.668+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 16 ms
[2025-07-19T21:02:21.669+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 15 ms
[2025-07-19T21:02:21.670+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO DAGScheduler: Submitting ResultStage 5 (StateStoreRDD[21] at start at <unknown>:0), which has no missing parents
[2025-07-19T21:02:21.670+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 15 ms
[2025-07-19T21:02:21.671+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 16 ms
[2025-07-19T21:02:21.671+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 16 ms
[2025-07-19T21:02:21.672+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 16 ms
[2025-07-19T21:02:21.672+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 19 ms
[2025-07-19T21:02:21.673+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 19 ms
[2025-07-19T21:02:21.673+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO StateStore: State Store maintenance task started
[2025-07-19T21:02:21.693+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d2a4a75
[2025-07-19T21:02:21.699+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=4, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:21.704+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/4] for update
[2025-07-19T21:02:21.708+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b54df6e
[2025-07-19T21:02:21.710+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=9, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:21.712+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/9] for update
[2025-07-19T21:02:21.722+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a42cdca
[2025-07-19T21:02:21.727+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=8, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:21.729+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/8] for update
[2025-07-19T21:02:21.744+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO CodeGenerator: Code generated in 29.499084 ms
[2025-07-19T21:02:21.747+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 40.1 KiB, free 433.2 MiB)
[2025-07-19T21:02:21.748+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 19.9 KiB, free 433.2 MiB)
[2025-07-19T21:02:21.750+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 8b44f3d35cfa:38433 (size: 19.9 KiB, free: 434.1 MiB)
[2025-07-19T21:02:21.754+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1611
[2025-07-19T21:02:21.755+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 5 (StateStoreRDD[21] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-07-19T21:02:21.756+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO TaskSchedulerImpl: Adding task set 5.0 with 200 tasks resource profile 0
[2025-07-19T21:02:21.758+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d764ddb
[2025-07-19T21:02:21.761+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=2, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:21.762+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/2] for update
[2025-07-19T21:02:21.763+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO CodeGenerator: Code generated in 3.463416 ms
[2025-07-19T21:02:21.768+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d7877b1
[2025-07-19T21:02:21.771+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=1, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:21.771+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/1] for update
[2025-07-19T21:02:21.783+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@598fb77b
[2025-07-19T21:02:21.784+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=3, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:21.785+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/3] for update
[2025-07-19T21:02:21.836+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/0/_metadata/schema using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/0/_metadata/.schema.90086e8d-9d14-4ea0-8ee5-5c4e8fb87e81.TID3.tmp
[2025-07-19T21:02:21.852+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:21.852+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:21.853+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:21.853+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:21.853+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:21.854+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:21.896+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/0/_metadata/.schema.90086e8d-9d14-4ea0-8ee5-5c4e8fb87e81.TID3.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/0/_metadata/schema
[2025-07-19T21:02:21.898+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6b1c0a7e
[2025-07-19T21:02:21.901+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=0, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:21.901+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/0] for update
[2025-07-19T21:02:21.909+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:21.909+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@12973b85
[2025-07-19T21:02:21.910+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=7, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:21.910+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/7] for update
[2025-07-19T21:02:21.910+0000] {subprocess.py:93} INFO - 25/07/19 21:02:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:22.140+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/0/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/0/.1.delta.4024a182-52ae-4b5f-b860-1e9b3a9aecd8.TID3.tmp
[2025-07-19T21:02:22.146+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/2/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/2/.1.delta.c3264e64-af75-4b36-848d-edff40f5f02c.TID5.tmp
[2025-07-19T21:02:22.150+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/8/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/8/.1.delta.67558029-3aa4-49d5-b692-723c928a240c.TID9.tmp
[2025-07-19T21:02:22.152+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/3/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/3/.1.delta.d1d7ec33-fd56-4895-af3d-dd1e1dfc15d3.TID6.tmp
[2025-07-19T21:02:22.153+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/7/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/7/.1.delta.4e8c9379-eee7-4a20-9a21-8d08db090d9c.TID8.tmp
[2025-07-19T21:02:22.154+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/4/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/4/.1.delta.668083e5-b906-40f8-a99d-e43ce96a4025.TID7.tmp
[2025-07-19T21:02:22.155+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/9/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/9/.1.delta.3ad759cd-419d-4de6-855f-de6fd1ca3b51.TID10.tmp
[2025-07-19T21:02:22.155+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/1/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/1/.1.delta.34335508-6815-4d65-80b3-4c40be695f3c.TID4.tmp
[2025-07-19T21:02:22.157+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO CodeGenerator: Code generated in 7.925208 ms
[2025-07-19T21:02:22.272+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/9/.1.delta.3ad759cd-419d-4de6-855f-de6fd1ca3b51.TID10.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/9/1.delta
[2025-07-19T21:02:22.273+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/9] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/9/1.delta
[2025-07-19T21:02:22.277+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/8/.1.delta.67558029-3aa4-49d5-b692-723c928a240c.TID9.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/8/1.delta
[2025-07-19T21:02:22.278+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/8] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/8/1.delta
[2025-07-19T21:02:22.278+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/0/.1.delta.4024a182-52ae-4b5f-b860-1e9b3a9aecd8.TID3.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/0/1.delta
[2025-07-19T21:02:22.279+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/0] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/0/1.delta
[2025-07-19T21:02:22.279+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/3/.1.delta.d1d7ec33-fd56-4895-af3d-dd1e1dfc15d3.TID6.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/3/1.delta
[2025-07-19T21:02:22.280+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/3] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/3/1.delta
[2025-07-19T21:02:22.282+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/4/.1.delta.668083e5-b906-40f8-a99d-e43ce96a4025.TID7.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/4/1.delta
[2025-07-19T21:02:22.282+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/4] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/4/1.delta
[2025-07-19T21:02:22.284+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/7/.1.delta.4e8c9379-eee7-4a20-9a21-8d08db090d9c.TID8.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/7/1.delta
[2025-07-19T21:02:22.285+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/7] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/7/1.delta
[2025-07-19T21:02:22.286+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO DataWritingSparkTask: Commit authorized for partition 9 (task 10, attempt 0, stage 3.0)
[2025-07-19T21:02:22.289+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO DataWritingSparkTask: Commit authorized for partition 4 (task 7, attempt 0, stage 3.0)
[2025-07-19T21:02:22.289+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/2/.1.delta.c3264e64-af75-4b36-848d-edff40f5f02c.TID5.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/2/1.delta
[2025-07-19T21:02:22.290+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/1/.1.delta.34335508-6815-4d65-80b3-4c40be695f3c.TID4.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/1/1.delta
[2025-07-19T21:02:22.290+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO DataWritingSparkTask: Commit authorized for partition 8 (task 9, attempt 0, stage 3.0)
[2025-07-19T21:02:22.290+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/1] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/1/1.delta
[2025-07-19T21:02:22.290+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO DataWritingSparkTask: Commit authorized for partition 3 (task 6, attempt 0, stage 3.0)
[2025-07-19T21:02:22.290+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 3, attempt 0, stage 3.0)
[2025-07-19T21:02:22.291+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO DataWritingSparkTask: Commit authorized for partition 7 (task 8, attempt 0, stage 3.0)
[2025-07-19T21:02:22.291+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO DataWritingSparkTask: Commit authorized for partition 1 (task 4, attempt 0, stage 3.0)
[2025-07-19T21:02:22.291+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/2] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/2/1.delta
[2025-07-19T21:02:22.294+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO DataWritingSparkTask: Commit authorized for partition 2 (task 5, attempt 0, stage 3.0)
[2025-07-19T21:02:22.591+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO DataWritingSparkTask: Committed partition 4 (task 7, attempt 0, stage 3.0)
[2025-07-19T21:02:22.593+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO DataWritingSparkTask: Committed partition 9 (task 10, attempt 0, stage 3.0)
[2025-07-19T21:02:22.594+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO DataWritingSparkTask: Committed partition 3 (task 6, attempt 0, stage 3.0)
[2025-07-19T21:02:22.595+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO DataWritingSparkTask: Committed partition 0 (task 3, attempt 0, stage 3.0)
[2025-07-19T21:02:22.595+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO DataWritingSparkTask: Committed partition 1 (task 4, attempt 0, stage 3.0)
[2025-07-19T21:02:22.596+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO DataWritingSparkTask: Committed partition 2 (task 5, attempt 0, stage 3.0)
[2025-07-19T21:02:22.600+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO DataWritingSparkTask: Committed partition 7 (task 8, attempt 0, stage 3.0)
[2025-07-19T21:02:22.601+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO DataWritingSparkTask: Committed partition 8 (task 9, attempt 0, stage 3.0)
[2025-07-19T21:02:22.602+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO Executor: Finished task 4.0 in stage 3.0 (TID 7). 9199 bytes result sent to driver
[2025-07-19T21:02:22.604+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO Executor: Finished task 8.0 in stage 3.0 (TID 9). 9154 bytes result sent to driver
[2025-07-19T21:02:22.605+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 9197 bytes result sent to driver
[2025-07-19T21:02:22.605+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO Executor: Finished task 3.0 in stage 3.0 (TID 6). 9193 bytes result sent to driver
[2025-07-19T21:02:22.605+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO Executor: Finished task 2.0 in stage 3.0 (TID 5). 9197 bytes result sent to driver
[2025-07-19T21:02:22.606+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 11) (8b44f3d35cfa, executor driver, partition 1, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:22.606+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO Executor: Finished task 1.0 in stage 3.0 (TID 4). 9212 bytes result sent to driver
[2025-07-19T21:02:22.606+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO Executor: Finished task 7.0 in stage 3.0 (TID 8). 9189 bytes result sent to driver
[2025-07-19T21:02:22.606+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO Executor: Running task 1.0 in stage 5.0 (TID 11)
[2025-07-19T21:02:22.606+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO Executor: Finished task 9.0 in stage 3.0 (TID 10). 9215 bytes result sent to driver
[2025-07-19T21:02:22.606+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 12) (8b44f3d35cfa, executor driver, partition 2, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:22.610+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO Executor: Running task 2.0 in stage 5.0 (TID 12)
[2025-07-19T21:02:22.610+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 13) (8b44f3d35cfa, executor driver, partition 3, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:22.611+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO TaskSetManager: Starting task 5.0 in stage 5.0 (TID 14) (8b44f3d35cfa, executor driver, partition 5, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:22.612+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO Executor: Running task 5.0 in stage 5.0 (TID 14)
[2025-07-19T21:02:22.612+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO TaskSetManager: Starting task 6.0 in stage 5.0 (TID 15) (8b44f3d35cfa, executor driver, partition 6, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:22.612+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO Executor: Running task 3.0 in stage 5.0 (TID 13)
[2025-07-19T21:02:22.613+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO TaskSetManager: Starting task 7.0 in stage 5.0 (TID 16) (8b44f3d35cfa, executor driver, partition 7, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:22.613+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO Executor: Running task 6.0 in stage 5.0 (TID 15)
[2025-07-19T21:02:22.613+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:22.614+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO TaskSetManager: Starting task 8.0 in stage 5.0 (TID 17) (8b44f3d35cfa, executor driver, partition 8, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:22.614+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:22.614+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO Executor: Running task 7.0 in stage 5.0 (TID 16)
[2025-07-19T21:02:22.615+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO Executor: Running task 8.0 in stage 5.0 (TID 17)
[2025-07-19T21:02:22.615+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:22.615+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:22.619+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO TaskSetManager: Starting task 10.0 in stage 5.0 (TID 18) (8b44f3d35cfa, executor driver, partition 10, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:22.620+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO Executor: Running task 10.0 in stage 5.0 (TID 18)
[2025-07-19T21:02:22.621+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 6) in 1017 ms on 8b44f3d35cfa (executor driver) (1/200)
[2025-07-19T21:02:22.621+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 1020 ms on 8b44f3d35cfa (executor driver) (2/200)
[2025-07-19T21:02:22.621+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 4) in 1021 ms on 8b44f3d35cfa (executor driver) (3/200)
[2025-07-19T21:02:22.621+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO TaskSetManager: Finished task 8.0 in stage 3.0 (TID 9) in 1021 ms on 8b44f3d35cfa (executor driver) (4/200)
[2025-07-19T21:02:22.622+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:22.622+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO TaskSetManager: Finished task 9.0 in stage 3.0 (TID 10) in 1021 ms on 8b44f3d35cfa (executor driver) (5/200)
[2025-07-19T21:02:22.622+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 7) in 1022 ms on 8b44f3d35cfa (executor driver) (6/200)
[2025-07-19T21:02:22.622+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2025-07-19T21:02:22.622+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:22.622+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:22.623+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:22.623+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:22.623+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:22.623+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:22.623+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 5) in 1026 ms on 8b44f3d35cfa (executor driver) (7/200)
[2025-07-19T21:02:22.626+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:22.626+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:22.626+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:22.626+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:22.627+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO TaskSetManager: Finished task 7.0 in stage 3.0 (TID 8) in 1031 ms on 8b44f3d35cfa (executor driver) (8/200)
[2025-07-19T21:02:22.630+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7ae66ef0
[2025-07-19T21:02:22.631+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=3, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:22.631+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/3] for update
[2025-07-19T21:02:22.643+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1021eb1c
[2025-07-19T21:02:22.643+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=5, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:22.644+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/5] for update
[2025-07-19T21:02:22.644+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO CodeGenerator: Code generated in 10.0145 ms
[2025-07-19T21:02:22.652+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@548ba569
[2025-07-19T21:02:22.653+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=7, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:22.654+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/7] for update
[2025-07-19T21:02:22.655+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO CodeGenerator: Code generated in 4.826167 ms
[2025-07-19T21:02:22.657+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:22.662+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:22.663+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e8e4bbe
[2025-07-19T21:02:22.663+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:22.667+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=2, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:22.670+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/2] for update
[2025-07-19T21:02:22.671+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:22.681+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/3/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/3/.1.delta.f7868527-60ef-4304-89b7-81e8d65336c3.TID13.tmp
[2025-07-19T21:02:22.682+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/5/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/5/.1.delta.10717b6e-dfaf-45c5-82a9-08c500d99116.TID14.tmp
[2025-07-19T21:02:22.684+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@658cec4f
[2025-07-19T21:02:22.685+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=8, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:22.685+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/8] for update
[2025-07-19T21:02:22.694+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:22.696+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/7/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/7/.1.delta.6bc49224-b279-45ef-9c4d-7749d3f327e2.TID16.tmp
[2025-07-19T21:02:22.696+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/2/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/2/.1.delta.b58e823a-c40f-4dfd-8b11-4a502cf322bf.TID12.tmp
[2025-07-19T21:02:22.709+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b9f79db
[2025-07-19T21:02:22.710+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=10, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:22.711+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=10),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/10] for update
[2025-07-19T21:02:22.715+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:22.728+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@15725bc1
[2025-07-19T21:02:22.730+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=6, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:22.730+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/6] for update
[2025-07-19T21:02:22.734+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/8/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/8/.1.delta.f97e08d9-27cf-4158-945f-84dfcc1837cf.TID17.tmp
[2025-07-19T21:02:22.742+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:22.763+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43a8aff5
[2025-07-19T21:02:22.767+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=1, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:22.783+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/1] for update
[2025-07-19T21:02:22.788+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:22.791+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/10/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/10/.1.delta.91b9863f-f0ac-4e91-94d3-99a18a7f905e.TID18.tmp
[2025-07-19T21:02:22.872+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/3/.1.delta.f7868527-60ef-4304-89b7-81e8d65336c3.TID13.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/3/1.delta
[2025-07-19T21:02:22.874+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/3] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/3/1.delta
[2025-07-19T21:02:22.881+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO DataWritingSparkTask: Commit authorized for partition 3 (task 13, attempt 0, stage 5.0)
[2025-07-19T21:02:22.895+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/1/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/1/.1.delta.0ddc2883-0bc4-40c5-bae8-1bed675fb1dd.TID11.tmp
[2025-07-19T21:02:22.913+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/6/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/6/.1.delta.27812500-f3c4-453f-9ac1-cc8ada8fc15a.TID15.tmp
[2025-07-19T21:02:22.915+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/5/.1.delta.10717b6e-dfaf-45c5-82a9-08c500d99116.TID14.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/5/1.delta
[2025-07-19T21:02:22.916+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/5] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/5/1.delta
[2025-07-19T21:02:22.924+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO DataWritingSparkTask: Commit authorized for partition 5 (task 14, attempt 0, stage 5.0)
[2025-07-19T21:02:22.978+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/7/.1.delta.6bc49224-b279-45ef-9c4d-7749d3f327e2.TID16.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/7/1.delta
[2025-07-19T21:02:22.981+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/7] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/7/1.delta
[2025-07-19T21:02:22.983+0000] {subprocess.py:93} INFO - 25/07/19 21:02:22 INFO DataWritingSparkTask: Commit authorized for partition 7 (task 16, attempt 0, stage 5.0)
[2025-07-19T21:02:23.048+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/2/.1.delta.b58e823a-c40f-4dfd-8b11-4a502cf322bf.TID12.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/2/1.delta
[2025-07-19T21:02:23.060+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/2] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/2/1.delta
[2025-07-19T21:02:23.061+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Commit authorized for partition 2 (task 12, attempt 0, stage 5.0)
[2025-07-19T21:02:23.137+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Committed partition 5 (task 14, attempt 0, stage 5.0)
[2025-07-19T21:02:23.139+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Committed partition 7 (task 16, attempt 0, stage 5.0)
[2025-07-19T21:02:23.142+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Finished task 5.0 in stage 5.0 (TID 14). 9277 bytes result sent to driver
[2025-07-19T21:02:23.145+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Finished task 7.0 in stage 5.0 (TID 16). 9252 bytes result sent to driver
[2025-07-19T21:02:23.152+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Starting task 11.0 in stage 5.0 (TID 19) (8b44f3d35cfa, executor driver, partition 11, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:23.158+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Running task 11.0 in stage 5.0 (TID 19)
[2025-07-19T21:02:23.159+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Starting task 12.0 in stage 5.0 (TID 20) (8b44f3d35cfa, executor driver, partition 12, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:23.164+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Committed partition 3 (task 13, attempt 0, stage 5.0)
[2025-07-19T21:02:23.165+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Running task 12.0 in stage 5.0 (TID 20)
[2025-07-19T21:02:23.170+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/8/.1.delta.f97e08d9-27cf-4158-945f-84dfcc1837cf.TID17.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/8/1.delta
[2025-07-19T21:02:23.171+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/8] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/8/1.delta
[2025-07-19T21:02:23.172+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Finished task 5.0 in stage 5.0 (TID 14) in 569 ms on 8b44f3d35cfa (executor driver) (1/200)
[2025-07-19T21:02:23.172+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Finished task 7.0 in stage 5.0 (TID 16) in 569 ms on 8b44f3d35cfa (executor driver) (2/200)
[2025-07-19T21:02:23.173+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Commit authorized for partition 8 (task 17, attempt 0, stage 5.0)
[2025-07-19T21:02:23.174+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:23.176+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:23.177+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/6/.1.delta.27812500-f3c4-453f-9ac1-cc8ada8fc15a.TID15.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/6/1.delta
[2025-07-19T21:02:23.178+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/6] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/6/1.delta
[2025-07-19T21:02:23.179+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Commit authorized for partition 6 (task 15, attempt 0, stage 5.0)
[2025-07-19T21:02:23.192+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Finished task 3.0 in stage 5.0 (TID 13). 9249 bytes result sent to driver
[2025-07-19T21:02:23.195+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Starting task 13.0 in stage 5.0 (TID 21) (8b44f3d35cfa, executor driver, partition 13, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:23.198+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Running task 13.0 in stage 5.0 (TID 21)
[2025-07-19T21:02:23.199+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Committed partition 2 (task 12, attempt 0, stage 5.0)
[2025-07-19T21:02:23.200+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 13) in 600 ms on 8b44f3d35cfa (executor driver) (3/200)
[2025-07-19T21:02:23.201+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@467eea27
[2025-07-19T21:02:23.204+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=11, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:23.205+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=11),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/11] for update
[2025-07-19T21:02:23.206+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/1/.1.delta.0ddc2883-0bc4-40c5-bae8-1bed675fb1dd.TID11.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/1/1.delta
[2025-07-19T21:02:23.206+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/1] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/1/1.delta
[2025-07-19T21:02:23.207+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Commit authorized for partition 1 (task 11, attempt 0, stage 5.0)
[2025-07-19T21:02:23.208+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Finished task 2.0 in stage 5.0 (TID 12). 9302 bytes result sent to driver
[2025-07-19T21:02:23.208+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:23.290+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:23.292+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Starting task 14.0 in stage 5.0 (TID 22) (8b44f3d35cfa, executor driver, partition 14, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:23.293+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Running task 14.0 in stage 5.0 (TID 22)
[2025-07-19T21:02:23.298+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 28 ms
[2025-07-19T21:02:23.305+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/10/.1.delta.91b9863f-f0ac-4e91-94d3-99a18a7f905e.TID18.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/10/1.delta
[2025-07-19T21:02:23.306+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=10),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/10] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/10/1.delta
[2025-07-19T21:02:23.311+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Commit authorized for partition 10 (task 18, attempt 0, stage 5.0)
[2025-07-19T21:02:23.312+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 12) in 684 ms on 8b44f3d35cfa (executor driver) (4/200)
[2025-07-19T21:02:23.316+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:23.325+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
[2025-07-19T21:02:23.326+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:23.327+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:23.328+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@67ae985
[2025-07-19T21:02:23.328+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=12, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:23.329+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=12),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/12] for update
[2025-07-19T21:02:23.330+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Committed partition 6 (task 15, attempt 0, stage 5.0)
[2025-07-19T21:02:23.330+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/11/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/11/.1.delta.6bb72890-7198-47b6-b512-fa0c24cad96e.TID19.tmp
[2025-07-19T21:02:23.331+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:23.335+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Finished task 6.0 in stage 5.0 (TID 15). 9288 bytes result sent to driver
[2025-07-19T21:02:23.348+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Starting task 15.0 in stage 5.0 (TID 23) (8b44f3d35cfa, executor driver, partition 15, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:23.355+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Committed partition 1 (task 11, attempt 0, stage 5.0)
[2025-07-19T21:02:23.358+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Finished task 6.0 in stage 5.0 (TID 15) in 746 ms on 8b44f3d35cfa (executor driver) (5/200)
[2025-07-19T21:02:23.359+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Committed partition 8 (task 17, attempt 0, stage 5.0)
[2025-07-19T21:02:23.359+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6364133
[2025-07-19T21:02:23.360+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Finished task 1.0 in stage 5.0 (TID 11). 9329 bytes result sent to driver
[2025-07-19T21:02:23.360+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Finished task 8.0 in stage 5.0 (TID 17). 9292 bytes result sent to driver
[2025-07-19T21:02:23.360+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=14, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:23.360+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 11) in 759 ms on 8b44f3d35cfa (executor driver) (6/200)
[2025-07-19T21:02:23.367+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Starting task 16.0 in stage 5.0 (TID 24) (8b44f3d35cfa, executor driver, partition 16, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:23.369+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Running task 16.0 in stage 5.0 (TID 24)
[2025-07-19T21:02:23.370+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=14),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/14] for update
[2025-07-19T21:02:23.370+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Starting task 17.0 in stage 5.0 (TID 25) (8b44f3d35cfa, executor driver, partition 17, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:23.371+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Running task 15.0 in stage 5.0 (TID 23)
[2025-07-19T21:02:23.372+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Running task 17.0 in stage 5.0 (TID 25)
[2025-07-19T21:02:23.372+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:23.373+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Finished task 8.0 in stage 5.0 (TID 17) in 753 ms on 8b44f3d35cfa (executor driver) (7/200)
[2025-07-19T21:02:23.377+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Committed partition 10 (task 18, attempt 0, stage 5.0)
[2025-07-19T21:02:23.379+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Finished task 10.0 in stage 5.0 (TID 18). 9288 bytes result sent to driver
[2025-07-19T21:02:23.380+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Starting task 18.0 in stage 5.0 (TID 26) (8b44f3d35cfa, executor driver, partition 18, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:23.380+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Running task 18.0 in stage 5.0 (TID 26)
[2025-07-19T21:02:23.380+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:23.381+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:23.381+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Finished task 10.0 in stage 5.0 (TID 18) in 760 ms on 8b44f3d35cfa (executor driver) (8/200)
[2025-07-19T21:02:23.381+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:23.382+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/12/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/12/.1.delta.c9a0b75c-121b-4171-aef8-23ec261347f8.TID20.tmp
[2025-07-19T21:02:23.382+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ceef4db
[2025-07-19T21:02:23.382+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:23.382+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=13, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:23.383+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=13),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/13] for update
[2025-07-19T21:02:23.384+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:23.385+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:23.386+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:23.386+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/14/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/14/.1.delta.e3a45933-d670-424d-87eb-3c66fa61a732.TID22.tmp
[2025-07-19T21:02:23.390+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:23.391+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:23.392+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@135df2fc
[2025-07-19T21:02:23.393+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=17, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:23.394+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=17),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/17] for update
[2025-07-19T21:02:23.400+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:23.407+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/13/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/13/.1.delta.c7c8338d-5382-4813-990b-1ef7180608fa.TID21.tmp
[2025-07-19T21:02:23.408+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d22d041
[2025-07-19T21:02:23.409+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=15, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:23.409+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=15),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/15] for update
[2025-07-19T21:02:23.422+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:23.424+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/17/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/17/.1.delta.40678294-bba4-4315-a9bd-e24e4340c913.TID25.tmp
[2025-07-19T21:02:23.431+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@8316c19
[2025-07-19T21:02:23.433+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=16, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:23.433+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=16),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/16] for update
[2025-07-19T21:02:23.441+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:23.443+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1f5dfa2d
[2025-07-19T21:02:23.447+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=18, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:23.449+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=18),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/18] for update
[2025-07-19T21:02:23.458+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/15/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/15/.1.delta.8c08c9b5-9f1e-4de6-a25a-8828feef7069.TID23.tmp
[2025-07-19T21:02:23.460+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:23.468+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/11/.1.delta.6bb72890-7198-47b6-b512-fa0c24cad96e.TID19.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/11/1.delta
[2025-07-19T21:02:23.471+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=11),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/11] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/11/1.delta
[2025-07-19T21:02:23.483+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Commit authorized for partition 11 (task 19, attempt 0, stage 5.0)
[2025-07-19T21:02:23.484+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/16/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/16/.1.delta.6faa58aa-9c9e-4be3-81c9-3a7cec9d0067.TID24.tmp
[2025-07-19T21:02:23.507+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/14/.1.delta.e3a45933-d670-424d-87eb-3c66fa61a732.TID22.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/14/1.delta
[2025-07-19T21:02:23.508+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=14),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/14] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/14/1.delta
[2025-07-19T21:02:23.514+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Commit authorized for partition 14 (task 22, attempt 0, stage 5.0)
[2025-07-19T21:02:23.515+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/12/.1.delta.c9a0b75c-121b-4171-aef8-23ec261347f8.TID20.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/12/1.delta
[2025-07-19T21:02:23.516+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=12),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/12] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/12/1.delta
[2025-07-19T21:02:23.516+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Commit authorized for partition 12 (task 20, attempt 0, stage 5.0)
[2025-07-19T21:02:23.525+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/18/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/18/.1.delta.58f22c7c-d796-4331-bd00-527235277961.TID26.tmp
[2025-07-19T21:02:23.526+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/13/.1.delta.c7c8338d-5382-4813-990b-1ef7180608fa.TID21.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/13/1.delta
[2025-07-19T21:02:23.527+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=13),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/13] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/13/1.delta
[2025-07-19T21:02:23.527+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Commit authorized for partition 13 (task 21, attempt 0, stage 5.0)
[2025-07-19T21:02:23.527+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/17/.1.delta.40678294-bba4-4315-a9bd-e24e4340c913.TID25.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/17/1.delta
[2025-07-19T21:02:23.528+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=17),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/17] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/17/1.delta
[2025-07-19T21:02:23.528+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Commit authorized for partition 17 (task 25, attempt 0, stage 5.0)
[2025-07-19T21:02:23.537+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Committed partition 11 (task 19, attempt 0, stage 5.0)
[2025-07-19T21:02:23.538+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Finished task 11.0 in stage 5.0 (TID 19). 9292 bytes result sent to driver
[2025-07-19T21:02:23.538+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Starting task 19.0 in stage 5.0 (TID 27) (8b44f3d35cfa, executor driver, partition 19, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:23.538+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Running task 19.0 in stage 5.0 (TID 27)
[2025-07-19T21:02:23.541+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Finished task 11.0 in stage 5.0 (TID 19) in 392 ms on 8b44f3d35cfa (executor driver) (9/200)
[2025-07-19T21:02:23.546+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:23.547+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:23.560+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@42c3a6a8
[2025-07-19T21:02:23.561+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=19, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:23.561+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=19),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/19] for update
[2025-07-19T21:02:23.570+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/15/.1.delta.8c08c9b5-9f1e-4de6-a25a-8828feef7069.TID23.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/15/1.delta
[2025-07-19T21:02:23.571+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=15),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/15] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/15/1.delta
[2025-07-19T21:02:23.575+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Commit authorized for partition 15 (task 23, attempt 0, stage 5.0)
[2025-07-19T21:02:23.577+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:23.578+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Committed partition 14 (task 22, attempt 0, stage 5.0)
[2025-07-19T21:02:23.595+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Finished task 14.0 in stage 5.0 (TID 22). 9335 bytes result sent to driver
[2025-07-19T21:02:23.606+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Starting task 20.0 in stage 5.0 (TID 28) (8b44f3d35cfa, executor driver, partition 20, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:23.614+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Committed partition 12 (task 20, attempt 0, stage 5.0)
[2025-07-19T21:02:23.619+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Finished task 12.0 in stage 5.0 (TID 20). 9300 bytes result sent to driver
[2025-07-19T21:02:23.620+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Finished task 14.0 in stage 5.0 (TID 22) in 353 ms on 8b44f3d35cfa (executor driver) (10/200)
[2025-07-19T21:02:23.621+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Committed partition 17 (task 25, attempt 0, stage 5.0)
[2025-07-19T21:02:23.621+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Starting task 22.0 in stage 5.0 (TID 29) (8b44f3d35cfa, executor driver, partition 22, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:23.621+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Running task 20.0 in stage 5.0 (TID 28)
[2025-07-19T21:02:23.622+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Finished task 17.0 in stage 5.0 (TID 25). 9294 bytes result sent to driver
[2025-07-19T21:02:23.622+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Running task 22.0 in stage 5.0 (TID 29)
[2025-07-19T21:02:23.633+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/16/.1.delta.6faa58aa-9c9e-4be3-81c9-3a7cec9d0067.TID24.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/16/1.delta
[2025-07-19T21:02:23.637+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=16),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/16] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/16/1.delta
[2025-07-19T21:02:23.640+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Commit authorized for partition 16 (task 24, attempt 0, stage 5.0)
[2025-07-19T21:02:23.643+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Committed partition 13 (task 21, attempt 0, stage 5.0)
[2025-07-19T21:02:23.651+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Starting task 24.0 in stage 5.0 (TID 30) (8b44f3d35cfa, executor driver, partition 24, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:23.653+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:23.654+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:23.665+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:23.668+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:23.675+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Finished task 13.0 in stage 5.0 (TID 21). 9290 bytes result sent to driver
[2025-07-19T21:02:23.679+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Finished task 12.0 in stage 5.0 (TID 20) in 477 ms on 8b44f3d35cfa (executor driver) (11/200)
[2025-07-19T21:02:23.681+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Running task 24.0 in stage 5.0 (TID 30)
[2025-07-19T21:02:23.681+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/19/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/19/.1.delta.b493590e-869a-4fb0-809e-1a7775a48b19.TID27.tmp
[2025-07-19T21:02:23.682+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e8c4aae
[2025-07-19T21:02:23.682+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=22, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:23.682+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=22),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/22] for update
[2025-07-19T21:02:23.683+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:23.684+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:23.685+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Finished task 17.0 in stage 5.0 (TID 25) in 306 ms on 8b44f3d35cfa (executor driver) (12/200)
[2025-07-19T21:02:23.685+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:23.686+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Starting task 26.0 in stage 5.0 (TID 31) (8b44f3d35cfa, executor driver, partition 26, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:23.690+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Finished task 13.0 in stage 5.0 (TID 21) in 475 ms on 8b44f3d35cfa (executor driver) (13/200)
[2025-07-19T21:02:23.691+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/18/.1.delta.58f22c7c-d796-4331-bd00-527235277961.TID26.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/18/1.delta
[2025-07-19T21:02:23.692+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=18),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/18] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/18/1.delta
[2025-07-19T21:02:23.692+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Commit authorized for partition 18 (task 26, attempt 0, stage 5.0)
[2025-07-19T21:02:23.692+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Running task 26.0 in stage 5.0 (TID 31)
[2025-07-19T21:02:23.693+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:23.693+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:23.693+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@989b91a
[2025-07-19T21:02:23.694+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=20, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:23.695+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=20),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/20] for update
[2025-07-19T21:02:23.697+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:23.698+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/22/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/22/.1.delta.1290aff5-f593-4f4e-b2df-2efbfaf194c5.TID29.tmp
[2025-07-19T21:02:23.703+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Committed partition 15 (task 23, attempt 0, stage 5.0)
[2025-07-19T21:02:23.705+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Finished task 15.0 in stage 5.0 (TID 23). 9305 bytes result sent to driver
[2025-07-19T21:02:23.712+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Starting task 27.0 in stage 5.0 (TID 32) (8b44f3d35cfa, executor driver, partition 27, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:23.713+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Running task 27.0 in stage 5.0 (TID 32)
[2025-07-19T21:02:23.713+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Finished task 15.0 in stage 5.0 (TID 23) in 378 ms on 8b44f3d35cfa (executor driver) (14/200)
[2025-07-19T21:02:23.724+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Committed partition 16 (task 24, attempt 0, stage 5.0)
[2025-07-19T21:02:23.725+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Finished task 16.0 in stage 5.0 (TID 24). 9303 bytes result sent to driver
[2025-07-19T21:02:23.726+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Starting task 28.0 in stage 5.0 (TID 33) (8b44f3d35cfa, executor driver, partition 28, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:23.727+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:23.737+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5bb7c43c
[2025-07-19T21:02:23.739+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T21:02:23.740+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Running task 28.0 in stage 5.0 (TID 33)
[2025-07-19T21:02:23.741+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=26, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:23.742+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Finished task 16.0 in stage 5.0 (TID 24) in 382 ms on 8b44f3d35cfa (executor driver) (15/200)
[2025-07-19T21:02:23.742+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/20/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/20/.1.delta.3edc5e25-0bf6-4507-a6de-fd41b9febe3d.TID28.tmp
[2025-07-19T21:02:23.743+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=26),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/26] for update
[2025-07-19T21:02:23.748+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:23.750+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:23.753+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Committed partition 18 (task 26, attempt 0, stage 5.0)
[2025-07-19T21:02:23.754+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2025-07-19T21:02:23.755+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4af6f8b0
[2025-07-19T21:02:23.756+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=24, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:23.757+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=24),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/24] for update
[2025-07-19T21:02:23.757+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Finished task 18.0 in stage 5.0 (TID 26). 9330 bytes result sent to driver
[2025-07-19T21:02:23.760+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:23.764+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Finished task 18.0 in stage 5.0 (TID 26) in 395 ms on 8b44f3d35cfa (executor driver) (16/200)
[2025-07-19T21:02:23.770+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@9ae5875
[2025-07-19T21:02:23.771+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=28, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:23.772+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=28),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/28] for update
[2025-07-19T21:02:23.772+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Starting task 29.0 in stage 5.0 (TID 34) (8b44f3d35cfa, executor driver, partition 29, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:23.776+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Running task 29.0 in stage 5.0 (TID 34)
[2025-07-19T21:02:23.783+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:23.808+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/26/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/26/.1.delta.1f2940dd-dcfc-49d0-918f-6709a85498a6.TID31.tmp
[2025-07-19T21:02:23.809+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@655c813
[2025-07-19T21:02:23.809+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/24/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/24/.1.delta.65c3210c-b86d-4005-92ab-a07ca532a83b.TID30.tmp
[2025-07-19T21:02:23.810+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=27, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:23.810+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:23.811+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 22 ms
[2025-07-19T21:02:23.811+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=27),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/27] for update
[2025-07-19T21:02:23.817+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/19/.1.delta.b493590e-869a-4fb0-809e-1a7775a48b19.TID27.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/19/1.delta
[2025-07-19T21:02:23.818+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=19),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/19] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/19/1.delta
[2025-07-19T21:02:23.820+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Commit authorized for partition 19 (task 27, attempt 0, stage 5.0)
[2025-07-19T21:02:23.820+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/22/.1.delta.1290aff5-f593-4f4e-b2df-2efbfaf194c5.TID29.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/22/1.delta
[2025-07-19T21:02:23.821+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=22),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/22] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/22/1.delta
[2025-07-19T21:02:23.821+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:23.821+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Commit authorized for partition 22 (task 29, attempt 0, stage 5.0)
[2025-07-19T21:02:23.828+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b42f033
[2025-07-19T21:02:23.829+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=29, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:23.829+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=29),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/29] for update
[2025-07-19T21:02:23.849+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:23.850+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/28/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/28/.1.delta.6ecc2208-85ad-40cb-ae37-1cbc2e717b48.TID33.tmp
[2025-07-19T21:02:23.851+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/27/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/27/.1.delta.4cdf4930-086c-4dd7-82b9-bad75286c633.TID32.tmp
[2025-07-19T21:02:23.858+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/20/.1.delta.3edc5e25-0bf6-4507-a6de-fd41b9febe3d.TID28.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/20/1.delta
[2025-07-19T21:02:23.859+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=20),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/20] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/20/1.delta
[2025-07-19T21:02:23.859+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Commit authorized for partition 20 (task 28, attempt 0, stage 5.0)
[2025-07-19T21:02:23.873+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/29/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/29/.1.delta.c4987c27-d2e0-4c22-9626-24c5fe0ba10e.TID34.tmp
[2025-07-19T21:02:23.874+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Committed partition 19 (task 27, attempt 0, stage 5.0)
[2025-07-19T21:02:23.875+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Committed partition 22 (task 29, attempt 0, stage 5.0)
[2025-07-19T21:02:23.881+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Finished task 19.0 in stage 5.0 (TID 27). 9346 bytes result sent to driver
[2025-07-19T21:02:23.883+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Finished task 22.0 in stage 5.0 (TID 29). 9337 bytes result sent to driver
[2025-07-19T21:02:23.886+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Starting task 30.0 in stage 5.0 (TID 35) (8b44f3d35cfa, executor driver, partition 30, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:23.887+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Running task 30.0 in stage 5.0 (TID 35)
[2025-07-19T21:02:23.888+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Starting task 31.0 in stage 5.0 (TID 36) (8b44f3d35cfa, executor driver, partition 31, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:23.889+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Running task 31.0 in stage 5.0 (TID 36)
[2025-07-19T21:02:23.889+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Finished task 22.0 in stage 5.0 (TID 29) in 277 ms on 8b44f3d35cfa (executor driver) (17/200)
[2025-07-19T21:02:23.889+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Finished task 19.0 in stage 5.0 (TID 27) in 351 ms on 8b44f3d35cfa (executor driver) (18/200)
[2025-07-19T21:02:23.894+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/26/.1.delta.1f2940dd-dcfc-49d0-918f-6709a85498a6.TID31.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/26/1.delta
[2025-07-19T21:02:23.895+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=26),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/26] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/26/1.delta
[2025-07-19T21:02:23.898+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:23.900+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Commit authorized for partition 26 (task 31, attempt 0, stage 5.0)
[2025-07-19T21:02:23.901+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:23.902+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:23.904+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:23.917+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/24/.1.delta.65c3210c-b86d-4005-92ab-a07ca532a83b.TID30.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/24/1.delta
[2025-07-19T21:02:23.918+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@435de2b4
[2025-07-19T21:02:23.920+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=24),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/24] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/24/1.delta
[2025-07-19T21:02:23.921+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=31, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:23.921+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Commit authorized for partition 24 (task 30, attempt 0, stage 5.0)
[2025-07-19T21:02:23.922+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=31),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/31] for update
[2025-07-19T21:02:23.922+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Committed partition 20 (task 28, attempt 0, stage 5.0)
[2025-07-19T21:02:23.923+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Finished task 20.0 in stage 5.0 (TID 28). 9271 bytes result sent to driver
[2025-07-19T21:02:23.923+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Starting task 32.0 in stage 5.0 (TID 37) (8b44f3d35cfa, executor driver, partition 32, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:23.923+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Running task 32.0 in stage 5.0 (TID 37)
[2025-07-19T21:02:23.924+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Finished task 20.0 in stage 5.0 (TID 28) in 325 ms on 8b44f3d35cfa (executor driver) (19/200)
[2025-07-19T21:02:23.928+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d62da63
[2025-07-19T21:02:23.929+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=30, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:23.929+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=30),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/30] for update
[2025-07-19T21:02:23.930+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:23.931+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:23.932+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:23.932+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/27/.1.delta.4cdf4930-086c-4dd7-82b9-bad75286c633.TID32.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/27/1.delta
[2025-07-19T21:02:23.933+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=27),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/27] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/27/1.delta
[2025-07-19T21:02:23.933+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Commit authorized for partition 27 (task 32, attempt 0, stage 5.0)
[2025-07-19T21:02:23.935+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:23.938+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/29/.1.delta.c4987c27-d2e0-4c22-9626-24c5fe0ba10e.TID34.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/29/1.delta
[2025-07-19T21:02:23.942+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=29),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/29] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/29/1.delta
[2025-07-19T21:02:23.946+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Commit authorized for partition 29 (task 34, attempt 0, stage 5.0)
[2025-07-19T21:02:23.947+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52119706
[2025-07-19T21:02:23.948+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=32, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:23.949+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=32),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/32] for update
[2025-07-19T21:02:23.949+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Committed partition 26 (task 31, attempt 0, stage 5.0)
[2025-07-19T21:02:23.949+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:23.955+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Finished task 26.0 in stage 5.0 (TID 31). 9293 bytes result sent to driver
[2025-07-19T21:02:23.957+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/30/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/30/.1.delta.6986ece0-924e-4b86-81b2-990b23403ee6.TID35.tmp
[2025-07-19T21:02:23.958+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/31/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/31/.1.delta.a9b61af6-dfd7-47b7-b3ff-0472f9695bea.TID36.tmp
[2025-07-19T21:02:23.964+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/28/.1.delta.6ecc2208-85ad-40cb-ae37-1cbc2e717b48.TID33.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/28/1.delta
[2025-07-19T21:02:23.964+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=28),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/28] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/28/1.delta
[2025-07-19T21:02:23.968+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Commit authorized for partition 28 (task 33, attempt 0, stage 5.0)
[2025-07-19T21:02:23.968+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Starting task 33.0 in stage 5.0 (TID 38) (8b44f3d35cfa, executor driver, partition 33, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:23.968+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Running task 33.0 in stage 5.0 (TID 38)
[2025-07-19T21:02:23.969+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/32/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/32/.1.delta.979456f8-c5b6-4a67-ac73-79fb5fbd8977.TID37.tmp
[2025-07-19T21:02:23.969+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:23.970+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:23.988+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Committed partition 27 (task 32, attempt 0, stage 5.0)
[2025-07-19T21:02:23.996+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO DataWritingSparkTask: Committed partition 24 (task 30, attempt 0, stage 5.0)
[2025-07-19T21:02:24.000+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Finished task 26.0 in stage 5.0 (TID 31) in 332 ms on 8b44f3d35cfa (executor driver) (20/200)
[2025-07-19T21:02:24.001+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Finished task 24.0 in stage 5.0 (TID 30). 9292 bytes result sent to driver
[2025-07-19T21:02:24.002+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Finished task 27.0 in stage 5.0 (TID 32). 9305 bytes result sent to driver
[2025-07-19T21:02:24.009+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Starting task 34.0 in stage 5.0 (TID 39) (8b44f3d35cfa, executor driver, partition 34, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.011+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO Executor: Running task 34.0 in stage 5.0 (TID 39)
[2025-07-19T21:02:24.012+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO TaskSetManager: Finished task 24.0 in stage 5.0 (TID 30) in 364 ms on 8b44f3d35cfa (executor driver) (21/200)
[2025-07-19T21:02:24.012+0000] {subprocess.py:93} INFO - 25/07/19 21:02:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65010e2c
[2025-07-19T21:02:24.014+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=33, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.018+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=33),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/33] for update
[2025-07-19T21:02:24.018+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 35.0 in stage 5.0 (TID 40) (8b44f3d35cfa, executor driver, partition 35, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.019+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.020+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 35.0 in stage 5.0 (TID 40)
[2025-07-19T21:02:24.022+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 27.0 in stage 5.0 (TID 32) in 295 ms on 8b44f3d35cfa (executor driver) (22/200)
[2025-07-19T21:02:24.024+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.025+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T21:02:24.025+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.026+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:24.027+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@397f4313
[2025-07-19T21:02:24.030+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=34, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.030+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=34),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/34] for update
[2025-07-19T21:02:24.031+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/33/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/33/.1.delta.c34836dc-0d94-4f14-a110-cc19ede5d592.TID38.tmp
[2025-07-19T21:02:24.032+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3a9fc192
[2025-07-19T21:02:24.032+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=35, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.033+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=35),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/35] for update
[2025-07-19T21:02:24.034+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.042+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.043+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 28 (task 33, attempt 0, stage 5.0)
[2025-07-19T21:02:24.043+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 28.0 in stage 5.0 (TID 33). 9312 bytes result sent to driver
[2025-07-19T21:02:24.043+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 29 (task 34, attempt 0, stage 5.0)
[2025-07-19T21:02:24.043+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 36.0 in stage 5.0 (TID 41) (8b44f3d35cfa, executor driver, partition 36, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.063+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 28.0 in stage 5.0 (TID 33) in 329 ms on 8b44f3d35cfa (executor driver) (23/200)
[2025-07-19T21:02:24.065+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 36.0 in stage 5.0 (TID 41)
[2025-07-19T21:02:24.066+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/31/.1.delta.a9b61af6-dfd7-47b7-b3ff-0472f9695bea.TID36.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/31/1.delta
[2025-07-19T21:02:24.066+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=31),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/31] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/31/1.delta
[2025-07-19T21:02:24.066+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 31 (task 36, attempt 0, stage 5.0)
[2025-07-19T21:02:24.066+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 29.0 in stage 5.0 (TID 34). 9331 bytes result sent to driver
[2025-07-19T21:02:24.067+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 29.0 in stage 5.0 (TID 34) in 287 ms on 8b44f3d35cfa (executor driver) (24/200)
[2025-07-19T21:02:24.068+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 39.0 in stage 5.0 (TID 42) (8b44f3d35cfa, executor driver, partition 39, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.068+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 39.0 in stage 5.0 (TID 42)
[2025-07-19T21:02:24.069+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.070+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T21:02:24.072+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.072+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:24.072+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/35/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/35/.1.delta.e7035651-080f-4b45-9087-b942783e6425.TID40.tmp
[2025-07-19T21:02:24.072+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/34/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/34/.1.delta.e09d6273-5775-4e5a-8111-0b56448c837c.TID39.tmp
[2025-07-19T21:02:24.073+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/30/.1.delta.6986ece0-924e-4b86-81b2-990b23403ee6.TID35.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/30/1.delta
[2025-07-19T21:02:24.073+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=30),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/30] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/30/1.delta
[2025-07-19T21:02:24.076+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 30 (task 35, attempt 0, stage 5.0)
[2025-07-19T21:02:24.081+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d84a87c
[2025-07-19T21:02:24.082+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=36, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.086+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=36),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/36] for update
[2025-07-19T21:02:24.087+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 31 (task 36, attempt 0, stage 5.0)
[2025-07-19T21:02:24.088+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.089+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 31.0 in stage 5.0 (TID 36). 9278 bytes result sent to driver
[2025-07-19T21:02:24.090+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 40.0 in stage 5.0 (TID 43) (8b44f3d35cfa, executor driver, partition 40, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.095+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 40.0 in stage 5.0 (TID 43)
[2025-07-19T21:02:24.095+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 31.0 in stage 5.0 (TID 36) in 207 ms on 8b44f3d35cfa (executor driver) (25/200)
[2025-07-19T21:02:24.096+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@42acf45
[2025-07-19T21:02:24.098+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/33/.1.delta.c34836dc-0d94-4f14-a110-cc19ede5d592.TID38.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/33/1.delta
[2025-07-19T21:02:24.098+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=33),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/33] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/33/1.delta
[2025-07-19T21:02:24.101+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=39, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.103+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 33 (task 38, attempt 0, stage 5.0)
[2025-07-19T21:02:24.104+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=39),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/39] for update
[2025-07-19T21:02:24.104+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.105+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:24.106+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/36/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/36/.1.delta.0a2a5d49-1918-4d92-8b8b-b69eeb4e1a60.TID41.tmp
[2025-07-19T21:02:24.106+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/32/.1.delta.979456f8-c5b6-4a67-ac73-79fb5fbd8977.TID37.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/32/1.delta
[2025-07-19T21:02:24.106+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=32),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/32] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/32/1.delta
[2025-07-19T21:02:24.107+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 32 (task 37, attempt 0, stage 5.0)
[2025-07-19T21:02:24.107+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.110+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2382735b
[2025-07-19T21:02:24.111+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=40, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.111+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=40),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/40] for update
[2025-07-19T21:02:24.112+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.122+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 30 (task 35, attempt 0, stage 5.0)
[2025-07-19T21:02:24.124+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 30.0 in stage 5.0 (TID 35). 9286 bytes result sent to driver
[2025-07-19T21:02:24.126+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 41.0 in stage 5.0 (TID 44) (8b44f3d35cfa, executor driver, partition 41, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.128+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 41.0 in stage 5.0 (TID 44)
[2025-07-19T21:02:24.130+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 30.0 in stage 5.0 (TID 35) in 245 ms on 8b44f3d35cfa (executor driver) (26/200)
[2025-07-19T21:02:24.149+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/39/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/39/.1.delta.6c652e43-def6-4a8c-b384-a7d5555bac99.TID42.tmp
[2025-07-19T21:02:24.154+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.155+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:24.156+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 32 (task 37, attempt 0, stage 5.0)
[2025-07-19T21:02:24.164+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 32.0 in stage 5.0 (TID 37). 9335 bytes result sent to driver
[2025-07-19T21:02:24.167+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 42.0 in stage 5.0 (TID 45) (8b44f3d35cfa, executor driver, partition 42, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.170+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 33 (task 38, attempt 0, stage 5.0)
[2025-07-19T21:02:24.172+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/40/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/40/.1.delta.6c5f9860-b685-44ce-ad03-141a5105bce9.TID43.tmp
[2025-07-19T21:02:24.173+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 33.0 in stage 5.0 (TID 38). 9288 bytes result sent to driver
[2025-07-19T21:02:24.174+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 32.0 in stage 5.0 (TID 37) in 251 ms on 8b44f3d35cfa (executor driver) (27/200)
[2025-07-19T21:02:24.174+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 44.0 in stage 5.0 (TID 46) (8b44f3d35cfa, executor driver, partition 44, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.175+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 42.0 in stage 5.0 (TID 45)
[2025-07-19T21:02:24.175+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 33.0 in stage 5.0 (TID 38) in 205 ms on 8b44f3d35cfa (executor driver) (28/200)
[2025-07-19T21:02:24.176+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 44.0 in stage 5.0 (TID 46)
[2025-07-19T21:02:24.179+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.179+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:24.179+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.179+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:24.186+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/34/.1.delta.e09d6273-5775-4e5a-8111-0b56448c837c.TID39.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/34/1.delta
[2025-07-19T21:02:24.188+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=34),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/34] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/34/1.delta
[2025-07-19T21:02:24.188+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@77aa8e76
[2025-07-19T21:02:24.189+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=41, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.190+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=41),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/41] for update
[2025-07-19T21:02:24.191+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/35/.1.delta.e7035651-080f-4b45-9087-b942783e6425.TID40.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/35/1.delta
[2025-07-19T21:02:24.192+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=35),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/35] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/35/1.delta
[2025-07-19T21:02:24.193+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 35 (task 40, attempt 0, stage 5.0)
[2025-07-19T21:02:24.193+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 34 (task 39, attempt 0, stage 5.0)
[2025-07-19T21:02:24.195+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.200+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d4bbe6b
[2025-07-19T21:02:24.201+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=42, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.202+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=42),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/42] for update
[2025-07-19T21:02:24.208+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.213+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@30257d99
[2025-07-19T21:02:24.214+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=44, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.215+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=44),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/44] for update
[2025-07-19T21:02:24.215+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/36/.1.delta.0a2a5d49-1918-4d92-8b8b-b69eeb4e1a60.TID41.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/36/1.delta
[2025-07-19T21:02:24.215+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=36),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/36] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/36/1.delta
[2025-07-19T21:02:24.215+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 36 (task 41, attempt 0, stage 5.0)
[2025-07-19T21:02:24.216+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/41/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/41/.1.delta.a05154b4-3492-42cb-8e11-674a4c9c067c.TID44.tmp
[2025-07-19T21:02:24.221+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/42/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/42/.1.delta.ea1b345e-fb8d-46d1-bb82-807c87afbbac.TID45.tmp
[2025-07-19T21:02:24.222+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.223+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/39/.1.delta.6c652e43-def6-4a8c-b384-a7d5555bac99.TID42.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/39/1.delta
[2025-07-19T21:02:24.224+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=39),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/39] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/39/1.delta
[2025-07-19T21:02:24.224+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 39 (task 42, attempt 0, stage 5.0)
[2025-07-19T21:02:24.235+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 34 (task 39, attempt 0, stage 5.0)
[2025-07-19T21:02:24.236+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 35 (task 40, attempt 0, stage 5.0)
[2025-07-19T21:02:24.238+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 34.0 in stage 5.0 (TID 39). 9335 bytes result sent to driver
[2025-07-19T21:02:24.239+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 35.0 in stage 5.0 (TID 40). 9289 bytes result sent to driver
[2025-07-19T21:02:24.240+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 46.0 in stage 5.0 (TID 47) (8b44f3d35cfa, executor driver, partition 46, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.241+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 47.0 in stage 5.0 (TID 48) (8b44f3d35cfa, executor driver, partition 47, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.242+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 46.0 in stage 5.0 (TID 47)
[2025-07-19T21:02:24.243+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 34.0 in stage 5.0 (TID 39) in 245 ms on 8b44f3d35cfa (executor driver) (29/200)
[2025-07-19T21:02:24.245+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/40/.1.delta.6c5f9860-b685-44ce-ad03-141a5105bce9.TID43.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/40/1.delta
[2025-07-19T21:02:24.246+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=40),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/40] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/40/1.delta
[2025-07-19T21:02:24.246+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 40 (task 43, attempt 0, stage 5.0)
[2025-07-19T21:02:24.246+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/44/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/44/.1.delta.092c5a2c-5195-4148-b84c-5a8195046549.TID46.tmp
[2025-07-19T21:02:24.247+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 35.0 in stage 5.0 (TID 40) in 239 ms on 8b44f3d35cfa (executor driver) (30/200)
[2025-07-19T21:02:24.247+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 47.0 in stage 5.0 (TID 48)
[2025-07-19T21:02:24.248+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.249+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:24.251+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.252+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:24.262+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@849e865
[2025-07-19T21:02:24.262+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=47, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.262+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=47),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/47] for update
[2025-07-19T21:02:24.266+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 36 (task 41, attempt 0, stage 5.0)
[2025-07-19T21:02:24.267+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 39 (task 42, attempt 0, stage 5.0)
[2025-07-19T21:02:24.268+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.268+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 39.0 in stage 5.0 (TID 42). 9226 bytes result sent to driver
[2025-07-19T21:02:24.269+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 36.0 in stage 5.0 (TID 41). 9229 bytes result sent to driver
[2025-07-19T21:02:24.269+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 48.0 in stage 5.0 (TID 49) (8b44f3d35cfa, executor driver, partition 48, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.269+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 48.0 in stage 5.0 (TID 49)
[2025-07-19T21:02:24.270+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 49.0 in stage 5.0 (TID 50) (8b44f3d35cfa, executor driver, partition 49, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.273+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 49.0 in stage 5.0 (TID 50)
[2025-07-19T21:02:24.275+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 36.0 in stage 5.0 (TID 41) in 229 ms on 8b44f3d35cfa (executor driver) (31/200)
[2025-07-19T21:02:24.276+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 39.0 in stage 5.0 (TID 42) in 213 ms on 8b44f3d35cfa (executor driver) (32/200)
[2025-07-19T21:02:24.276+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.276+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:24.276+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 40 (task 43, attempt 0, stage 5.0)
[2025-07-19T21:02:24.277+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ec5b598
[2025-07-19T21:02:24.284+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/42/.1.delta.ea1b345e-fb8d-46d1-bb82-807c87afbbac.TID45.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/42/1.delta
[2025-07-19T21:02:24.287+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=42),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/42] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/42/1.delta
[2025-07-19T21:02:24.288+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 42 (task 45, attempt 0, stage 5.0)
[2025-07-19T21:02:24.289+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/41/.1.delta.a05154b4-3492-42cb-8e11-674a4c9c067c.TID44.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/41/1.delta
[2025-07-19T21:02:24.289+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=41),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/41] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/41/1.delta
[2025-07-19T21:02:24.290+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=46, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.290+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=46),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/46] for update
[2025-07-19T21:02:24.290+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 41 (task 44, attempt 0, stage 5.0)
[2025-07-19T21:02:24.290+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.294+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T21:02:24.296+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/47/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/47/.1.delta.e4080e6e-4681-43b4-a738-79b2322f2589.TID48.tmp
[2025-07-19T21:02:24.299+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 40.0 in stage 5.0 (TID 43). 9346 bytes result sent to driver
[2025-07-19T21:02:24.302+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.302+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ca9b90
[2025-07-19T21:02:24.303+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=49, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.304+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=49),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/49] for update
[2025-07-19T21:02:24.305+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 51.0 in stage 5.0 (TID 51) (8b44f3d35cfa, executor driver, partition 51, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.305+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 51.0 in stage 5.0 (TID 51)
[2025-07-19T21:02:24.306+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 40.0 in stage 5.0 (TID 43) in 211 ms on 8b44f3d35cfa (executor driver) (33/200)
[2025-07-19T21:02:24.306+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.306+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:24.307+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@237abea5
[2025-07-19T21:02:24.307+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.307+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=48, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.308+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=48),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/48] for update
[2025-07-19T21:02:24.314+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/46/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/46/.1.delta.c117f883-1bc1-4813-84e1-8fa1d23e50db.TID47.tmp
[2025-07-19T21:02:24.319+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/44/.1.delta.092c5a2c-5195-4148-b84c-5a8195046549.TID46.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/44/1.delta
[2025-07-19T21:02:24.322+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=44),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/44] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/44/1.delta
[2025-07-19T21:02:24.322+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 44 (task 46, attempt 0, stage 5.0)
[2025-07-19T21:02:24.323+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 42 (task 45, attempt 0, stage 5.0)
[2025-07-19T21:02:24.323+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.341+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 42.0 in stage 5.0 (TID 45). 9294 bytes result sent to driver
[2025-07-19T21:02:24.350+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 54.0 in stage 5.0 (TID 52) (8b44f3d35cfa, executor driver, partition 54, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.351+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 41 (task 44, attempt 0, stage 5.0)
[2025-07-19T21:02:24.352+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 42.0 in stage 5.0 (TID 45) in 167 ms on 8b44f3d35cfa (executor driver) (34/200)
[2025-07-19T21:02:24.353+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 54.0 in stage 5.0 (TID 52)
[2025-07-19T21:02:24.356+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 41.0 in stage 5.0 (TID 44). 9331 bytes result sent to driver
[2025-07-19T21:02:24.357+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 55.0 in stage 5.0 (TID 53) (8b44f3d35cfa, executor driver, partition 55, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.358+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 55.0 in stage 5.0 (TID 53)
[2025-07-19T21:02:24.358+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 41.0 in stage 5.0 (TID 44) in 214 ms on 8b44f3d35cfa (executor driver) (35/200)
[2025-07-19T21:02:24.359+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.359+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:24.359+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.360+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/49/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/49/.1.delta.9e1074d9-25dd-4251-a9d9-0435028a822a.TID50.tmp
[2025-07-19T21:02:24.362+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:24.365+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3e3e3bf4
[2025-07-19T21:02:24.370+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=51, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.372+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=51),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/51] for update
[2025-07-19T21:02:24.373+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.374+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/48/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/48/.1.delta.c0bbbb3b-330d-4cd0-94dd-b601ee357a7b.TID49.tmp
[2025-07-19T21:02:24.375+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 44 (task 46, attempt 0, stage 5.0)
[2025-07-19T21:02:24.378+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56dd0dad
[2025-07-19T21:02:24.378+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=55, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.379+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 44.0 in stage 5.0 (TID 46). 9301 bytes result sent to driver
[2025-07-19T21:02:24.379+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=55),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/55] for update
[2025-07-19T21:02:24.379+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 44.0 in stage 5.0 (TID 46) in 198 ms on 8b44f3d35cfa (executor driver) (36/200)
[2025-07-19T21:02:24.380+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.380+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 57.0 in stage 5.0 (TID 54) (8b44f3d35cfa, executor driver, partition 57, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.380+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/47/.1.delta.e4080e6e-4681-43b4-a738-79b2322f2589.TID48.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/47/1.delta
[2025-07-19T21:02:24.381+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=47),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/47] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/47/1.delta
[2025-07-19T21:02:24.381+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 57.0 in stage 5.0 (TID 54)
[2025-07-19T21:02:24.381+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/51/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/51/.1.delta.48b99151-6b4a-44ac-b8c3-75e72209f93e.TID51.tmp
[2025-07-19T21:02:24.382+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@32cf4685
[2025-07-19T21:02:24.382+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 47 (task 48, attempt 0, stage 5.0)
[2025-07-19T21:02:24.383+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=54, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.385+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=54),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/54] for update
[2025-07-19T21:02:24.387+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.387+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.392+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/55/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/55/.1.delta.66b15148-224c-4559-b499-db92cd378816.TID53.tmp
[2025-07-19T21:02:24.393+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T21:02:24.401+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/46/.1.delta.c117f883-1bc1-4813-84e1-8fa1d23e50db.TID47.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/46/1.delta
[2025-07-19T21:02:24.401+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=46),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/46] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/46/1.delta
[2025-07-19T21:02:24.402+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 46 (task 47, attempt 0, stage 5.0)
[2025-07-19T21:02:24.408+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@705421cc
[2025-07-19T21:02:24.410+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=57, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.411+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=57),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/57] for update
[2025-07-19T21:02:24.412+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/54/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/54/.1.delta.66ce0a76-361e-4f88-a55b-5833d37dbb6c.TID52.tmp
[2025-07-19T21:02:24.413+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.422+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/48/.1.delta.c0bbbb3b-330d-4cd0-94dd-b601ee357a7b.TID49.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/48/1.delta
[2025-07-19T21:02:24.424+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=48),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/48] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/48/1.delta
[2025-07-19T21:02:24.425+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 48 (task 49, attempt 0, stage 5.0)
[2025-07-19T21:02:24.426+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/49/.1.delta.9e1074d9-25dd-4251-a9d9-0435028a822a.TID50.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/49/1.delta
[2025-07-19T21:02:24.427+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=49),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/49] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/49/1.delta
[2025-07-19T21:02:24.427+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 49 (task 50, attempt 0, stage 5.0)
[2025-07-19T21:02:24.436+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/57/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/57/.1.delta.bf94ba8c-34fb-459c-8ae1-7336d6e94bcf.TID54.tmp
[2025-07-19T21:02:24.440+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/51/.1.delta.48b99151-6b4a-44ac-b8c3-75e72209f93e.TID51.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/51/1.delta
[2025-07-19T21:02:24.442+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=51),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/51] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/51/1.delta
[2025-07-19T21:02:24.443+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 47 (task 48, attempt 0, stage 5.0)
[2025-07-19T21:02:24.448+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 47.0 in stage 5.0 (TID 48). 9361 bytes result sent to driver
[2025-07-19T21:02:24.449+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 58.0 in stage 5.0 (TID 55) (8b44f3d35cfa, executor driver, partition 58, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.449+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 51 (task 51, attempt 0, stage 5.0)
[2025-07-19T21:02:24.450+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 58.0 in stage 5.0 (TID 55)
[2025-07-19T21:02:24.451+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/55/.1.delta.66b15148-224c-4559-b499-db92cd378816.TID53.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/55/1.delta
[2025-07-19T21:02:24.452+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=55),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/55] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/55/1.delta
[2025-07-19T21:02:24.453+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 55 (task 53, attempt 0, stage 5.0)
[2025-07-19T21:02:24.454+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 47.0 in stage 5.0 (TID 48) in 215 ms on 8b44f3d35cfa (executor driver) (37/200)
[2025-07-19T21:02:24.456+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.457+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:24.458+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 46 (task 47, attempt 0, stage 5.0)
[2025-07-19T21:02:24.459+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 46.0 in stage 5.0 (TID 47). 9286 bytes result sent to driver
[2025-07-19T21:02:24.460+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 48 (task 49, attempt 0, stage 5.0)
[2025-07-19T21:02:24.462+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 60.0 in stage 5.0 (TID 56) (8b44f3d35cfa, executor driver, partition 60, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.465+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 46.0 in stage 5.0 (TID 47) in 225 ms on 8b44f3d35cfa (executor driver) (38/200)
[2025-07-19T21:02:24.466+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 60.0 in stage 5.0 (TID 56)
[2025-07-19T21:02:24.466+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 48.0 in stage 5.0 (TID 49). 9351 bytes result sent to driver
[2025-07-19T21:02:24.467+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 62.0 in stage 5.0 (TID 57) (8b44f3d35cfa, executor driver, partition 62, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.467+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 62.0 in stage 5.0 (TID 57)
[2025-07-19T21:02:24.467+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 48.0 in stage 5.0 (TID 49) in 199 ms on 8b44f3d35cfa (executor driver) (39/200)
[2025-07-19T21:02:24.468+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2739d5fd
[2025-07-19T21:02:24.470+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=58, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.471+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=58),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/58] for update
[2025-07-19T21:02:24.474+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.475+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:24.475+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.476+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:24.477+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 49 (task 50, attempt 0, stage 5.0)
[2025-07-19T21:02:24.485+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b6ec4cf
[2025-07-19T21:02:24.486+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=62, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.487+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=62),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/62] for update
[2025-07-19T21:02:24.488+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/54/.1.delta.66ce0a76-361e-4f88-a55b-5833d37dbb6c.TID52.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/54/1.delta
[2025-07-19T21:02:24.488+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=54),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/54] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/54/1.delta
[2025-07-19T21:02:24.489+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.489+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 54 (task 52, attempt 0, stage 5.0)
[2025-07-19T21:02:24.489+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 49.0 in stage 5.0 (TID 50). 9354 bytes result sent to driver
[2025-07-19T21:02:24.491+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 63.0 in stage 5.0 (TID 58) (8b44f3d35cfa, executor driver, partition 63, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.494+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 63.0 in stage 5.0 (TID 58)
[2025-07-19T21:02:24.494+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 49.0 in stage 5.0 (TID 50) in 216 ms on 8b44f3d35cfa (executor driver) (40/200)
[2025-07-19T21:02:24.495+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.497+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.497+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:24.497+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 55 (task 53, attempt 0, stage 5.0)
[2025-07-19T21:02:24.498+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 55.0 in stage 5.0 (TID 53). 9283 bytes result sent to driver
[2025-07-19T21:02:24.498+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 64.0 in stage 5.0 (TID 59) (8b44f3d35cfa, executor driver, partition 64, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.498+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 64.0 in stage 5.0 (TID 59)
[2025-07-19T21:02:24.499+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d4f3855
[2025-07-19T21:02:24.499+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 51 (task 51, attempt 0, stage 5.0)
[2025-07-19T21:02:24.499+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 51.0 in stage 5.0 (TID 51). 9311 bytes result sent to driver
[2025-07-19T21:02:24.500+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 55.0 in stage 5.0 (TID 53) in 158 ms on 8b44f3d35cfa (executor driver) (41/200)
[2025-07-19T21:02:24.500+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=60, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.501+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=60),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/60] for update
[2025-07-19T21:02:24.502+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 66.0 in stage 5.0 (TID 60) (8b44f3d35cfa, executor driver, partition 66, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.503+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 51.0 in stage 5.0 (TID 51) in 206 ms on 8b44f3d35cfa (executor driver) (42/200)
[2025-07-19T21:02:24.504+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 66.0 in stage 5.0 (TID 60)
[2025-07-19T21:02:24.504+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/62/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/62/.1.delta.88a35059-35e5-4a8b-ac06-f9259a216d06.TID57.tmp
[2025-07-19T21:02:24.504+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c6ea46f
[2025-07-19T21:02:24.505+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.505+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:24.506+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/58/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/58/.1.delta.389a306b-88a4-4492-8892-68788ac58281.TID55.tmp
[2025-07-19T21:02:24.506+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.508+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.509+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:24.510+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=63, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.511+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=63),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/63] for update
[2025-07-19T21:02:24.512+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.513+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/57/.1.delta.bf94ba8c-34fb-459c-8ae1-7336d6e94bcf.TID54.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/57/1.delta
[2025-07-19T21:02:24.514+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=57),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/57] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/57/1.delta
[2025-07-19T21:02:24.514+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 57 (task 54, attempt 0, stage 5.0)
[2025-07-19T21:02:24.530+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 54 (task 52, attempt 0, stage 5.0)
[2025-07-19T21:02:24.531+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/60/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/60/.1.delta.a25c700f-3ee5-4a20-bf79-0234570e6543.TID56.tmp
[2025-07-19T21:02:24.533+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 54.0 in stage 5.0 (TID 52). 9301 bytes result sent to driver
[2025-07-19T21:02:24.534+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 67.0 in stage 5.0 (TID 61) (8b44f3d35cfa, executor driver, partition 67, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.534+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 54.0 in stage 5.0 (TID 52) in 202 ms on 8b44f3d35cfa (executor driver) (43/200)
[2025-07-19T21:02:24.534+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 67.0 in stage 5.0 (TID 61)
[2025-07-19T21:02:24.538+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.538+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:24.543+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ec23023
[2025-07-19T21:02:24.545+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=66, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.545+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=66),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/66] for update
[2025-07-19T21:02:24.546+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 57 (task 54, attempt 0, stage 5.0)
[2025-07-19T21:02:24.546+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/63/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/63/.1.delta.4ac87a33-7135-43a9-a190-2ae57f359d55.TID58.tmp
[2025-07-19T21:02:24.547+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 57.0 in stage 5.0 (TID 54). 9286 bytes result sent to driver
[2025-07-19T21:02:24.547+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 57.0 in stage 5.0 (TID 54) in 176 ms on 8b44f3d35cfa (executor driver) (44/200)
[2025-07-19T21:02:24.547+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 68.0 in stage 5.0 (TID 62) (8b44f3d35cfa, executor driver, partition 68, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.548+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 68.0 in stage 5.0 (TID 62)
[2025-07-19T21:02:24.551+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.554+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@256540cc
[2025-07-19T21:02:24.555+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=64, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.555+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=64),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/64] for update
[2025-07-19T21:02:24.556+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.556+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:24.564+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@250a91b2
[2025-07-19T21:02:24.568+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=67, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.569+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=67),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/67] for update
[2025-07-19T21:02:24.572+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.573+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.575+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/62/.1.delta.88a35059-35e5-4a8b-ac06-f9259a216d06.TID57.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/62/1.delta
[2025-07-19T21:02:24.575+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=62),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/62] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/62/1.delta
[2025-07-19T21:02:24.576+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 62 (task 57, attempt 0, stage 5.0)
[2025-07-19T21:02:24.582+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/66/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/66/.1.delta.846f99ef-07ab-4ef1-9733-476b07bf6908.TID60.tmp
[2025-07-19T21:02:24.585+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@277d281c
[2025-07-19T21:02:24.587+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=68, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.587+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=68),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/68] for update
[2025-07-19T21:02:24.587+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.590+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/58/.1.delta.389a306b-88a4-4492-8892-68788ac58281.TID55.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/58/1.delta
[2025-07-19T21:02:24.591+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=58),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/58] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/58/1.delta
[2025-07-19T21:02:24.592+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/67/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/67/.1.delta.6da6d36c-77ce-47fa-849d-88b52c5a4ed2.TID61.tmp
[2025-07-19T21:02:24.594+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 58 (task 55, attempt 0, stage 5.0)
[2025-07-19T21:02:24.595+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/64/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/64/.1.delta.6cf7a24c-38f9-40aa-aafa-10a9fb6d84da.TID59.tmp
[2025-07-19T21:02:24.608+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/68/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/68/.1.delta.dc21a416-e71b-4958-96d3-8248f56c99a4.TID62.tmp
[2025-07-19T21:02:24.614+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/60/.1.delta.a25c700f-3ee5-4a20-bf79-0234570e6543.TID56.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/60/1.delta
[2025-07-19T21:02:24.615+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=60),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/60] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/60/1.delta
[2025-07-19T21:02:24.615+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 60 (task 56, attempt 0, stage 5.0)
[2025-07-19T21:02:24.623+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 62 (task 57, attempt 0, stage 5.0)
[2025-07-19T21:02:24.626+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 62.0 in stage 5.0 (TID 57). 9294 bytes result sent to driver
[2025-07-19T21:02:24.627+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/63/.1.delta.4ac87a33-7135-43a9-a190-2ae57f359d55.TID58.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/63/1.delta
[2025-07-19T21:02:24.628+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=63),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/63] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/63/1.delta
[2025-07-19T21:02:24.628+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 71.0 in stage 5.0 (TID 63) (8b44f3d35cfa, executor driver, partition 71, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.628+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 58 (task 55, attempt 0, stage 5.0)
[2025-07-19T21:02:24.629+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 58.0 in stage 5.0 (TID 55). 9288 bytes result sent to driver
[2025-07-19T21:02:24.629+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 63 (task 58, attempt 0, stage 5.0)
[2025-07-19T21:02:24.630+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 71.0 in stage 5.0 (TID 63)
[2025-07-19T21:02:24.633+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 73.0 in stage 5.0 (TID 64) (8b44f3d35cfa, executor driver, partition 73, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.634+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 58.0 in stage 5.0 (TID 55) in 185 ms on 8b44f3d35cfa (executor driver) (45/200)
[2025-07-19T21:02:24.636+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 73.0 in stage 5.0 (TID 64)
[2025-07-19T21:02:24.637+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 62.0 in stage 5.0 (TID 57) in 167 ms on 8b44f3d35cfa (executor driver) (46/200)
[2025-07-19T21:02:24.642+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.644+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T21:02:24.646+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.650+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:24.652+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/66/.1.delta.846f99ef-07ab-4ef1-9733-476b07bf6908.TID60.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/66/1.delta
[2025-07-19T21:02:24.654+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=66),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/66] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/66/1.delta
[2025-07-19T21:02:24.654+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 66 (task 60, attempt 0, stage 5.0)
[2025-07-19T21:02:24.655+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4274db84
[2025-07-19T21:02:24.655+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=73, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.656+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=73),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/73] for update
[2025-07-19T21:02:24.656+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.672+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/67/.1.delta.6da6d36c-77ce-47fa-849d-88b52c5a4ed2.TID61.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/67/1.delta
[2025-07-19T21:02:24.673+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=67),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/67] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/67/1.delta
[2025-07-19T21:02:24.675+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f1f2450
[2025-07-19T21:02:24.676+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 67 (task 61, attempt 0, stage 5.0)
[2025-07-19T21:02:24.677+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=71, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.677+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=71),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/71] for update
[2025-07-19T21:02:24.678+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/68/.1.delta.dc21a416-e71b-4958-96d3-8248f56c99a4.TID62.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/68/1.delta
[2025-07-19T21:02:24.678+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=68),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/68] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/68/1.delta
[2025-07-19T21:02:24.678+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.678+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 68 (task 62, attempt 0, stage 5.0)
[2025-07-19T21:02:24.681+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 63 (task 58, attempt 0, stage 5.0)
[2025-07-19T21:02:24.682+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/73/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/73/.1.delta.f6bd2dd6-8a5c-4648-ae06-6bdc2c169ce5.TID64.tmp
[2025-07-19T21:02:24.683+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 63.0 in stage 5.0 (TID 58). 9290 bytes result sent to driver
[2025-07-19T21:02:24.685+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 74.0 in stage 5.0 (TID 65) (8b44f3d35cfa, executor driver, partition 74, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.686+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 63.0 in stage 5.0 (TID 58) in 201 ms on 8b44f3d35cfa (executor driver) (47/200)
[2025-07-19T21:02:24.686+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 74.0 in stage 5.0 (TID 65)
[2025-07-19T21:02:24.689+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.690+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:24.694+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/64/.1.delta.6cf7a24c-38f9-40aa-aafa-10a9fb6d84da.TID59.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/64/1.delta
[2025-07-19T21:02:24.694+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=64),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/64] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/64/1.delta
[2025-07-19T21:02:24.698+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/71/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/71/.1.delta.3ad24def-4adb-4774-af59-4f64aabdb3c1.TID63.tmp
[2025-07-19T21:02:24.699+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 66 (task 60, attempt 0, stage 5.0)
[2025-07-19T21:02:24.699+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 60 (task 56, attempt 0, stage 5.0)
[2025-07-19T21:02:24.699+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 66.0 in stage 5.0 (TID 60). 9312 bytes result sent to driver
[2025-07-19T21:02:24.700+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 60.0 in stage 5.0 (TID 56). 9294 bytes result sent to driver
[2025-07-19T21:02:24.700+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 75.0 in stage 5.0 (TID 66) (8b44f3d35cfa, executor driver, partition 75, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.700+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 64 (task 59, attempt 0, stage 5.0)
[2025-07-19T21:02:24.701+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 75.0 in stage 5.0 (TID 66)
[2025-07-19T21:02:24.702+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 76.0 in stage 5.0 (TID 67) (8b44f3d35cfa, executor driver, partition 76, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.702+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@48eb872c
[2025-07-19T21:02:24.704+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=74, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.705+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=74),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/74] for update
[2025-07-19T21:02:24.706+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 66.0 in stage 5.0 (TID 60) in 205 ms on 8b44f3d35cfa (executor driver) (48/200)
[2025-07-19T21:02:24.708+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 60.0 in stage 5.0 (TID 56) in 243 ms on 8b44f3d35cfa (executor driver) (49/200)
[2025-07-19T21:02:24.708+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.708+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.708+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 67 (task 61, attempt 0, stage 5.0)
[2025-07-19T21:02:24.709+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T21:02:24.709+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 67.0 in stage 5.0 (TID 61). 9279 bytes result sent to driver
[2025-07-19T21:02:24.709+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 77.0 in stage 5.0 (TID 68) (8b44f3d35cfa, executor driver, partition 77, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.709+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 77.0 in stage 5.0 (TID 68)
[2025-07-19T21:02:24.709+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 67.0 in stage 5.0 (TID 61) in 176 ms on 8b44f3d35cfa (executor driver) (50/200)
[2025-07-19T21:02:24.709+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 76.0 in stage 5.0 (TID 67)
[2025-07-19T21:02:24.709+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 68 (task 62, attempt 0, stage 5.0)
[2025-07-19T21:02:24.709+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 68.0 in stage 5.0 (TID 62). 9306 bytes result sent to driver
[2025-07-19T21:02:24.711+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.711+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:24.712+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.712+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:24.713+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 79.0 in stage 5.0 (TID 69) (8b44f3d35cfa, executor driver, partition 79, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.714+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 79.0 in stage 5.0 (TID 69)
[2025-07-19T21:02:24.714+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d36b8ad
[2025-07-19T21:02:24.717+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.717+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:24.718+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/74/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/74/.1.delta.f7ea0708-ecfd-48e7-9444-69dd4df9b3d5.TID65.tmp
[2025-07-19T21:02:24.719+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 68.0 in stage 5.0 (TID 62) in 172 ms on 8b44f3d35cfa (executor driver) (51/200)
[2025-07-19T21:02:24.722+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=75, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.723+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=75),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/75] for update
[2025-07-19T21:02:24.723+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.728+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@24941492
[2025-07-19T21:02:24.729+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=79, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.730+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=79),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/79] for update
[2025-07-19T21:02:24.731+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.738+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 64 (task 59, attempt 0, stage 5.0)
[2025-07-19T21:02:24.739+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/73/.1.delta.f6bd2dd6-8a5c-4648-ae06-6bdc2c169ce5.TID64.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/73/1.delta
[2025-07-19T21:02:24.740+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=73),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/73] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/73/1.delta
[2025-07-19T21:02:24.745+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 64.0 in stage 5.0 (TID 59). 9312 bytes result sent to driver
[2025-07-19T21:02:24.746+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 80.0 in stage 5.0 (TID 70) (8b44f3d35cfa, executor driver, partition 80, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.746+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b9869e4
[2025-07-19T21:02:24.747+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 73 (task 64, attempt 0, stage 5.0)
[2025-07-19T21:02:24.749+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 80.0 in stage 5.0 (TID 70)
[2025-07-19T21:02:24.749+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=76, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.749+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=76),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/76] for update
[2025-07-19T21:02:24.749+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/71/.1.delta.3ad24def-4adb-4774-af59-4f64aabdb3c1.TID63.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/71/1.delta
[2025-07-19T21:02:24.749+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=71),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/71] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/71/1.delta
[2025-07-19T21:02:24.749+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 64.0 in stage 5.0 (TID 59) in 254 ms on 8b44f3d35cfa (executor driver) (52/200)
[2025-07-19T21:02:24.749+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/75/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/75/.1.delta.4ff4c1c3-f031-428f-9768-1e568110423a.TID66.tmp
[2025-07-19T21:02:24.752+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.752+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 71 (task 63, attempt 0, stage 5.0)
[2025-07-19T21:02:24.754+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.754+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T21:02:24.761+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@375e253e
[2025-07-19T21:02:24.763+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/79/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/79/.1.delta.116d8d52-9fab-47bc-b326-f5b85adedc3c.TID69.tmp
[2025-07-19T21:02:24.763+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=77, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.763+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=77),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/77] for update
[2025-07-19T21:02:24.767+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.772+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/76/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/76/.1.delta.2dc08255-7873-4593-8fcf-a946babebfad.TID67.tmp
[2025-07-19T21:02:24.776+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 71 (task 63, attempt 0, stage 5.0)
[2025-07-19T21:02:24.777+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 71.0 in stage 5.0 (TID 63). 9300 bytes result sent to driver
[2025-07-19T21:02:24.777+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 82.0 in stage 5.0 (TID 71) (8b44f3d35cfa, executor driver, partition 82, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.779+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5128ecbf
[2025-07-19T21:02:24.780+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=80, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.781+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/74/.1.delta.f7ea0708-ecfd-48e7-9444-69dd4df9b3d5.TID65.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/74/1.delta
[2025-07-19T21:02:24.781+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=74),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/74] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/74/1.delta
[2025-07-19T21:02:24.782+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 82.0 in stage 5.0 (TID 71)
[2025-07-19T21:02:24.782+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 74 (task 65, attempt 0, stage 5.0)
[2025-07-19T21:02:24.782+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 73 (task 64, attempt 0, stage 5.0)
[2025-07-19T21:02:24.784+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=80),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/80] for update
[2025-07-19T21:02:24.785+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 73.0 in stage 5.0 (TID 64). 9312 bytes result sent to driver
[2025-07-19T21:02:24.786+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 83.0 in stage 5.0 (TID 72) (8b44f3d35cfa, executor driver, partition 83, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.786+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 83.0 in stage 5.0 (TID 72)
[2025-07-19T21:02:24.786+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 71.0 in stage 5.0 (TID 63) in 156 ms on 8b44f3d35cfa (executor driver) (53/200)
[2025-07-19T21:02:24.786+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 73.0 in stage 5.0 (TID 64) in 151 ms on 8b44f3d35cfa (executor driver) (54/200)
[2025-07-19T21:02:24.787+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.787+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:24.788+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (717.0 B) non-empty blocks including 1 (717.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.789+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:24.800+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/77/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/77/.1.delta.5cb914ed-157e-4f8f-9e02-eed3ebb15723.TID68.tmp
[2025-07-19T21:02:24.801+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@99e0136
[2025-07-19T21:02:24.802+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=82, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.803+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=82),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/82] for update
[2025-07-19T21:02:24.803+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.803+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.814+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@773da273
[2025-07-19T21:02:24.814+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=83, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.815+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=83),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/83] for update
[2025-07-19T21:02:24.815+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 74 (task 65, attempt 0, stage 5.0)
[2025-07-19T21:02:24.815+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 74.0 in stage 5.0 (TID 65). 9304 bytes result sent to driver
[2025-07-19T21:02:24.816+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 86.0 in stage 5.0 (TID 73) (8b44f3d35cfa, executor driver, partition 86, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.816+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 74.0 in stage 5.0 (TID 65) in 132 ms on 8b44f3d35cfa (executor driver) (55/200)
[2025-07-19T21:02:24.827+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 86.0 in stage 5.0 (TID 73)
[2025-07-19T21:02:24.828+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (539.0 B) non-empty blocks including 1 (539.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.829+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:24.829+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.830+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/75/.1.delta.4ff4c1c3-f031-428f-9768-1e568110423a.TID66.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/75/1.delta
[2025-07-19T21:02:24.830+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=75),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/75] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/75/1.delta
[2025-07-19T21:02:24.831+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 75 (task 66, attempt 0, stage 5.0)
[2025-07-19T21:02:24.832+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/82/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/82/.1.delta.685f523d-d8cf-43fd-9142-c138101b33d9.TID71.tmp
[2025-07-19T21:02:24.833+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/79/.1.delta.116d8d52-9fab-47bc-b326-f5b85adedc3c.TID69.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/79/1.delta
[2025-07-19T21:02:24.834+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=79),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/79] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/79/1.delta
[2025-07-19T21:02:24.835+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/80/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/80/.1.delta.fd88dcd3-d9ec-4d33-a209-d02127e5e339.TID70.tmp
[2025-07-19T21:02:24.835+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 79 (task 69, attempt 0, stage 5.0)
[2025-07-19T21:02:24.835+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/83/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/83/.1.delta.9df0fab7-5893-43fd-bc45-d61e2c272d9d.TID72.tmp
[2025-07-19T21:02:24.836+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d622461
[2025-07-19T21:02:24.837+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=86, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.837+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=86),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/86] for update
[2025-07-19T21:02:24.842+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.850+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/76/.1.delta.2dc08255-7873-4593-8fcf-a946babebfad.TID67.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/76/1.delta
[2025-07-19T21:02:24.851+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=76),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/76] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/76/1.delta
[2025-07-19T21:02:24.852+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 76 (task 67, attempt 0, stage 5.0)
[2025-07-19T21:02:24.855+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/86/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/86/.1.delta.2f8467c0-176b-496b-84ea-99cb29087ef3.TID73.tmp
[2025-07-19T21:02:24.859+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/77/.1.delta.5cb914ed-157e-4f8f-9e02-eed3ebb15723.TID68.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/77/1.delta
[2025-07-19T21:02:24.860+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=77),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/77] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/77/1.delta
[2025-07-19T21:02:24.860+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 77 (task 68, attempt 0, stage 5.0)
[2025-07-19T21:02:24.866+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 75 (task 66, attempt 0, stage 5.0)
[2025-07-19T21:02:24.866+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 79 (task 69, attempt 0, stage 5.0)
[2025-07-19T21:02:24.869+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 75.0 in stage 5.0 (TID 66). 9294 bytes result sent to driver
[2025-07-19T21:02:24.870+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 79.0 in stage 5.0 (TID 69). 9295 bytes result sent to driver
[2025-07-19T21:02:24.870+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 87.0 in stage 5.0 (TID 74) (8b44f3d35cfa, executor driver, partition 87, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.872+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 87.0 in stage 5.0 (TID 74)
[2025-07-19T21:02:24.872+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 75.0 in stage 5.0 (TID 66) in 175 ms on 8b44f3d35cfa (executor driver) (56/200)
[2025-07-19T21:02:24.877+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.878+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:24.878+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 77 (task 68, attempt 0, stage 5.0)
[2025-07-19T21:02:24.878+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 77.0 in stage 5.0 (TID 68). 9292 bytes result sent to driver
[2025-07-19T21:02:24.879+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 88.0 in stage 5.0 (TID 75) (8b44f3d35cfa, executor driver, partition 88, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.880+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 90.0 in stage 5.0 (TID 76) (8b44f3d35cfa, executor driver, partition 90, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.880+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 88.0 in stage 5.0 (TID 75)
[2025-07-19T21:02:24.880+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 90.0 in stage 5.0 (TID 76)
[2025-07-19T21:02:24.883+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.884+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:24.884+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 79.0 in stage 5.0 (TID 69) in 170 ms on 8b44f3d35cfa (executor driver) (57/200)
[2025-07-19T21:02:24.885+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 77.0 in stage 5.0 (TID 68) in 177 ms on 8b44f3d35cfa (executor driver) (58/200)
[2025-07-19T21:02:24.885+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/82/.1.delta.685f523d-d8cf-43fd-9142-c138101b33d9.TID71.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/82/1.delta
[2025-07-19T21:02:24.886+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=82),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/82] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/82/1.delta
[2025-07-19T21:02:24.886+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 82 (task 71, attempt 0, stage 5.0)
[2025-07-19T21:02:24.887+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 76 (task 67, attempt 0, stage 5.0)
[2025-07-19T21:02:24.887+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 76.0 in stage 5.0 (TID 67). 9309 bytes result sent to driver
[2025-07-19T21:02:24.888+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.889+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2025-07-19T21:02:24.890+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 92.0 in stage 5.0 (TID 77) (8b44f3d35cfa, executor driver, partition 92, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.890+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 92.0 in stage 5.0 (TID 77)
[2025-07-19T21:02:24.891+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 76.0 in stage 5.0 (TID 67) in 193 ms on 8b44f3d35cfa (executor driver) (59/200)
[2025-07-19T21:02:24.893+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@21131cb1
[2025-07-19T21:02:24.895+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=87, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.895+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/83/.1.delta.9df0fab7-5893-43fd-bc45-d61e2c272d9d.TID72.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/83/1.delta
[2025-07-19T21:02:24.895+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=83),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/83] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/83/1.delta
[2025-07-19T21:02:24.895+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=87),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/87] for update
[2025-07-19T21:02:24.896+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/80/.1.delta.fd88dcd3-d9ec-4d33-a209-d02127e5e339.TID70.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/80/1.delta
[2025-07-19T21:02:24.896+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=80),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/80] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/80/1.delta
[2025-07-19T21:02:24.896+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 80 (task 70, attempt 0, stage 5.0)
[2025-07-19T21:02:24.901+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 83 (task 72, attempt 0, stage 5.0)
[2025-07-19T21:02:24.903+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.904+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2025-07-19T21:02:24.904+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.905+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 82 (task 71, attempt 0, stage 5.0)
[2025-07-19T21:02:24.905+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 82.0 in stage 5.0 (TID 71). 9265 bytes result sent to driver
[2025-07-19T21:02:24.909+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 93.0 in stage 5.0 (TID 78) (8b44f3d35cfa, executor driver, partition 93, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.910+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 93.0 in stage 5.0 (TID 78)
[2025-07-19T21:02:24.911+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.912+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:24.914+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 82.0 in stage 5.0 (TID 71) in 136 ms on 8b44f3d35cfa (executor driver) (60/200)
[2025-07-19T21:02:24.914+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/87/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/87/.1.delta.0ead6c27-da99-4b05-b4f7-973304df64d7.TID74.tmp
[2025-07-19T21:02:24.915+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d966db1
[2025-07-19T21:02:24.916+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=90, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.916+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=90),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/90] for update
[2025-07-19T21:02:24.917+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.923+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b208e59
[2025-07-19T21:02:24.924+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=88, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.925+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=88),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/88] for update
[2025-07-19T21:02:24.927+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/86/.1.delta.2f8467c0-176b-496b-84ea-99cb29087ef3.TID73.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/86/1.delta
[2025-07-19T21:02:24.928+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=86),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/86] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/86/1.delta
[2025-07-19T21:02:24.929+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 86 (task 73, attempt 0, stage 5.0)
[2025-07-19T21:02:24.929+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.942+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 83 (task 72, attempt 0, stage 5.0)
[2025-07-19T21:02:24.943+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@525fdb6d
[2025-07-19T21:02:24.943+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=93, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.944+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=93),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/93] for update
[2025-07-19T21:02:24.945+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 83.0 in stage 5.0 (TID 72). 9308 bytes result sent to driver
[2025-07-19T21:02:24.947+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/90/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/90/.1.delta.04cc00e8-4c8b-4d4f-9cb1-543fbfbe81c1.TID76.tmp
[2025-07-19T21:02:24.947+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 96.0 in stage 5.0 (TID 79) (8b44f3d35cfa, executor driver, partition 96, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.947+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.947+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 96.0 in stage 5.0 (TID 79)
[2025-07-19T21:02:24.948+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 83.0 in stage 5.0 (TID 72) in 159 ms on 8b44f3d35cfa (executor driver) (61/200)
[2025-07-19T21:02:24.949+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 80 (task 70, attempt 0, stage 5.0)
[2025-07-19T21:02:24.951+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 80.0 in stage 5.0 (TID 70). 9306 bytes result sent to driver
[2025-07-19T21:02:24.951+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@559ee2e5
[2025-07-19T21:02:24.952+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 97.0 in stage 5.0 (TID 80) (8b44f3d35cfa, executor driver, partition 97, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.952+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 97.0 in stage 5.0 (TID 80)
[2025-07-19T21:02:24.953+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.953+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:24.953+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=92, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.953+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=92),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/92] for update
[2025-07-19T21:02:24.953+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.956+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/93/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/93/.1.delta.389a6702-4870-42ca-a8e6-52aa8e7880c6.TID78.tmp
[2025-07-19T21:02:24.957+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 80.0 in stage 5.0 (TID 70) in 207 ms on 8b44f3d35cfa (executor driver) (62/200)
[2025-07-19T21:02:24.959+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/88/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/88/.1.delta.a00cc94c-c1c8-47bc-bd89-52a128ee0283.TID75.tmp
[2025-07-19T21:02:24.961+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55c4dd7b
[2025-07-19T21:02:24.961+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=96, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.962+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=96),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/96] for update
[2025-07-19T21:02:24.967+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (539.0 B) non-empty blocks including 1 (539.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.968+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T21:02:24.968+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Committed partition 86 (task 73, attempt 0, stage 5.0)
[2025-07-19T21:02:24.968+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.969+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Finished task 86.0 in stage 5.0 (TID 73). 9315 bytes result sent to driver
[2025-07-19T21:02:24.969+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Starting task 99.0 in stage 5.0 (TID 81) (8b44f3d35cfa, executor driver, partition 99, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:24.969+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO TaskSetManager: Finished task 86.0 in stage 5.0 (TID 73) in 152 ms on 8b44f3d35cfa (executor driver) (63/200)
[2025-07-19T21:02:24.969+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO Executor: Running task 99.0 in stage 5.0 (TID 81)
[2025-07-19T21:02:24.973+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/87/.1.delta.0ead6c27-da99-4b05-b4f7-973304df64d7.TID74.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/87/1.delta
[2025-07-19T21:02:24.974+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=87),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/87] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/87/1.delta
[2025-07-19T21:02:24.975+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 87 (task 74, attempt 0, stage 5.0)
[2025-07-19T21:02:24.975+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:24.977+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:24.979+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@147b06d5
[2025-07-19T21:02:24.980+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=97, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.980+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=97),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/97] for update
[2025-07-19T21:02:24.980+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/92/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/92/.1.delta.883023ed-c0e4-4b6c-9b1e-081f8d3ca728.TID77.tmp
[2025-07-19T21:02:24.980+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:24.985+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/96/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/96/.1.delta.1521b641-b892-422c-84c6-3c6651c1ab0e.TID79.tmp
[2025-07-19T21:02:24.988+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a783bb3
[2025-07-19T21:02:24.989+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=99, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:24.989+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=99),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/99] for update
[2025-07-19T21:02:24.992+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/90/.1.delta.04cc00e8-4c8b-4d4f-9cb1-543fbfbe81c1.TID76.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/90/1.delta
[2025-07-19T21:02:24.992+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=90),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/90] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/90/1.delta
[2025-07-19T21:02:24.993+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO DataWritingSparkTask: Commit authorized for partition 90 (task 76, attempt 0, stage 5.0)
[2025-07-19T21:02:24.994+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/97/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/97/.1.delta.1021bcdd-691f-4a84-bff2-d79493554f25.TID80.tmp
[2025-07-19T21:02:24.995+0000] {subprocess.py:93} INFO - 25/07/19 21:02:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.009+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/99/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/99/.1.delta.a687cd56-b743-41d2-903d-decf730aff29.TID81.tmp
[2025-07-19T21:02:25.012+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/88/.1.delta.a00cc94c-c1c8-47bc-bd89-52a128ee0283.TID75.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/88/1.delta
[2025-07-19T21:02:25.012+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=88),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/88] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/88/1.delta
[2025-07-19T21:02:25.012+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 88 (task 75, attempt 0, stage 5.0)
[2025-07-19T21:02:25.017+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/93/.1.delta.389a6702-4870-42ca-a8e6-52aa8e7880c6.TID78.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/93/1.delta
[2025-07-19T21:02:25.017+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=93),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/93] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/93/1.delta
[2025-07-19T21:02:25.021+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 87 (task 74, attempt 0, stage 5.0)
[2025-07-19T21:02:25.021+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 87.0 in stage 5.0 (TID 74). 9310 bytes result sent to driver
[2025-07-19T21:02:25.021+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 100.0 in stage 5.0 (TID 82) (8b44f3d35cfa, executor driver, partition 100, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.021+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 93 (task 78, attempt 0, stage 5.0)
[2025-07-19T21:02:25.026+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 90 (task 76, attempt 0, stage 5.0)
[2025-07-19T21:02:25.028+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 100.0 in stage 5.0 (TID 82)
[2025-07-19T21:02:25.029+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 87.0 in stage 5.0 (TID 74) in 156 ms on 8b44f3d35cfa (executor driver) (64/200)
[2025-07-19T21:02:25.029+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 90.0 in stage 5.0 (TID 76). 9301 bytes result sent to driver
[2025-07-19T21:02:25.029+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 102.0 in stage 5.0 (TID 83) (8b44f3d35cfa, executor driver, partition 102, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.029+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 102.0 in stage 5.0 (TID 83)
[2025-07-19T21:02:25.029+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 90.0 in stage 5.0 (TID 76) in 146 ms on 8b44f3d35cfa (executor driver) (65/200)
[2025-07-19T21:02:25.030+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.030+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:25.030+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/92/.1.delta.883023ed-c0e4-4b6c-9b1e-081f8d3ca728.TID77.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/92/1.delta
[2025-07-19T21:02:25.030+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=92),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/92] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/92/1.delta
[2025-07-19T21:02:25.030+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.030+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 92 (task 77, attempt 0, stage 5.0)
[2025-07-19T21:02:25.031+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:25.037+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c8db2bd
[2025-07-19T21:02:25.038+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=100, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.039+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 88 (task 75, attempt 0, stage 5.0)
[2025-07-19T21:02:25.041+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=100),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/100] for update
[2025-07-19T21:02:25.046+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.049+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/96/.1.delta.1521b641-b892-422c-84c6-3c6651c1ab0e.TID79.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/96/1.delta
[2025-07-19T21:02:25.053+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=96),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/96] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/96/1.delta
[2025-07-19T21:02:25.054+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 96 (task 79, attempt 0, stage 5.0)
[2025-07-19T21:02:25.054+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/97/.1.delta.1021bcdd-691f-4a84-bff2-d79493554f25.TID80.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/97/1.delta
[2025-07-19T21:02:25.054+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=97),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/97] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/97/1.delta
[2025-07-19T21:02:25.054+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 97 (task 80, attempt 0, stage 5.0)
[2025-07-19T21:02:25.055+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2209f435
[2025-07-19T21:02:25.055+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=102, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.055+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=102),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/102] for update
[2025-07-19T21:02:25.055+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/99/.1.delta.a687cd56-b743-41d2-903d-decf730aff29.TID81.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/99/1.delta
[2025-07-19T21:02:25.055+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=99),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/99] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/99/1.delta
[2025-07-19T21:02:25.055+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/100/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/100/.1.delta.ce062716-ee82-4b79-bd24-db517120429d.TID82.tmp
[2025-07-19T21:02:25.058+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 88.0 in stage 5.0 (TID 75). 9304 bytes result sent to driver
[2025-07-19T21:02:25.060+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 93 (task 78, attempt 0, stage 5.0)
[2025-07-19T21:02:25.067+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 99 (task 81, attempt 0, stage 5.0)
[2025-07-19T21:02:25.067+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 103.0 in stage 5.0 (TID 84) (8b44f3d35cfa, executor driver, partition 103, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.068+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 93.0 in stage 5.0 (TID 78). 9312 bytes result sent to driver
[2025-07-19T21:02:25.068+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 103.0 in stage 5.0 (TID 84)
[2025-07-19T21:02:25.068+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 105.0 in stage 5.0 (TID 85) (8b44f3d35cfa, executor driver, partition 105, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.069+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 93.0 in stage 5.0 (TID 78) in 160 ms on 8b44f3d35cfa (executor driver) (66/200)
[2025-07-19T21:02:25.069+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 88.0 in stage 5.0 (TID 75) in 189 ms on 8b44f3d35cfa (executor driver) (67/200)
[2025-07-19T21:02:25.070+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 105.0 in stage 5.0 (TID 85)
[2025-07-19T21:02:25.071+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.072+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:25.073+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.074+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.075+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:25.081+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/102/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/102/.1.delta.531ea6b3-d5b2-4e4c-9939-39fcbcf28a40.TID83.tmp
[2025-07-19T21:02:25.085+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@477d3e9e
[2025-07-19T21:02:25.086+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=103, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.086+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=103),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/103] for update
[2025-07-19T21:02:25.087+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.087+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 97 (task 80, attempt 0, stage 5.0)
[2025-07-19T21:02:25.087+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 99 (task 81, attempt 0, stage 5.0)
[2025-07-19T21:02:25.093+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 99.0 in stage 5.0 (TID 81). 9320 bytes result sent to driver
[2025-07-19T21:02:25.094+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28861a7f
[2025-07-19T21:02:25.094+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=105, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.094+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 97.0 in stage 5.0 (TID 80). 9349 bytes result sent to driver
[2025-07-19T21:02:25.095+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=105),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/105] for update
[2025-07-19T21:02:25.099+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 106.0 in stage 5.0 (TID 86) (8b44f3d35cfa, executor driver, partition 106, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.100+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 109.0 in stage 5.0 (TID 87) (8b44f3d35cfa, executor driver, partition 109, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.100+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 106.0 in stage 5.0 (TID 86)
[2025-07-19T21:02:25.100+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 109.0 in stage 5.0 (TID 87)
[2025-07-19T21:02:25.101+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 99.0 in stage 5.0 (TID 81) in 128 ms on 8b44f3d35cfa (executor driver) (68/200)
[2025-07-19T21:02:25.101+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/103/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/103/.1.delta.4b8b1a80-20c3-45a8-90d3-ccdaf4bb621d.TID84.tmp
[2025-07-19T21:02:25.101+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.101+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:25.102+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 92 (task 77, attempt 0, stage 5.0)
[2025-07-19T21:02:25.102+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 92.0 in stage 5.0 (TID 77). 9281 bytes result sent to driver
[2025-07-19T21:02:25.103+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 110.0 in stage 5.0 (TID 88) (8b44f3d35cfa, executor driver, partition 110, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.103+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 110.0 in stage 5.0 (TID 88)
[2025-07-19T21:02:25.104+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.104+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 97.0 in stage 5.0 (TID 80) in 151 ms on 8b44f3d35cfa (executor driver) (69/200)
[2025-07-19T21:02:25.105+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.105+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:25.106+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 92.0 in stage 5.0 (TID 77) in 209 ms on 8b44f3d35cfa (executor driver) (70/200)
[2025-07-19T21:02:25.107+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.107+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:25.111+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@50a752b
[2025-07-19T21:02:25.112+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=109, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.112+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=109),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/109] for update
[2025-07-19T21:02:25.113+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/100/.1.delta.ce062716-ee82-4b79-bd24-db517120429d.TID82.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/100/1.delta
[2025-07-19T21:02:25.113+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=100),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/100] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/100/1.delta
[2025-07-19T21:02:25.113+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 100 (task 82, attempt 0, stage 5.0)
[2025-07-19T21:02:25.113+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.116+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 96 (task 79, attempt 0, stage 5.0)
[2025-07-19T21:02:25.120+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/105/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/105/.1.delta.2b803e66-9953-4fe7-9d3a-03b7f49f22ab.TID85.tmp
[2025-07-19T21:02:25.120+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 96.0 in stage 5.0 (TID 79). 9323 bytes result sent to driver
[2025-07-19T21:02:25.121+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d1d372e
[2025-07-19T21:02:25.123+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=110, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.123+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=110),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/110] for update
[2025-07-19T21:02:25.123+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 111.0 in stage 5.0 (TID 89) (8b44f3d35cfa, executor driver, partition 111, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.124+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.128+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 111.0 in stage 5.0 (TID 89)
[2025-07-19T21:02:25.128+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/102/.1.delta.531ea6b3-d5b2-4e4c-9939-39fcbcf28a40.TID83.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/102/1.delta
[2025-07-19T21:02:25.128+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=102),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/102] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/102/1.delta
[2025-07-19T21:02:25.128+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 96.0 in stage 5.0 (TID 79) in 186 ms on 8b44f3d35cfa (executor driver) (71/200)
[2025-07-19T21:02:25.129+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@550d60c6
[2025-07-19T21:02:25.130+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 102 (task 83, attempt 0, stage 5.0)
[2025-07-19T21:02:25.131+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=106, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.132+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=106),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/106] for update
[2025-07-19T21:02:25.133+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/109/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/109/.1.delta.a09bdecb-be94-424c-9987-2559d7424aa6.TID87.tmp
[2025-07-19T21:02:25.135+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.136+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:25.139+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 100 (task 82, attempt 0, stage 5.0)
[2025-07-19T21:02:25.140+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 100.0 in stage 5.0 (TID 82). 9293 bytes result sent to driver
[2025-07-19T21:02:25.141+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 112.0 in stage 5.0 (TID 90) (8b44f3d35cfa, executor driver, partition 112, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.142+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 112.0 in stage 5.0 (TID 90)
[2025-07-19T21:02:25.144+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.145+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 100.0 in stage 5.0 (TID 82) in 115 ms on 8b44f3d35cfa (executor driver) (72/200)
[2025-07-19T21:02:25.146+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.147+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:25.147+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e8c7351
[2025-07-19T21:02:25.148+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=111, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.148+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=111),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/111] for update
[2025-07-19T21:02:25.149+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.154+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ec63fd1
[2025-07-19T21:02:25.158+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=112, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.160+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=112),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/112] for update
[2025-07-19T21:02:25.161+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/110/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/110/.1.delta.5eac332c-1bf0-4aa0-8248-b271594118c5.TID88.tmp
[2025-07-19T21:02:25.161+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/103/.1.delta.4b8b1a80-20c3-45a8-90d3-ccdaf4bb621d.TID84.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/103/1.delta
[2025-07-19T21:02:25.161+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=103),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/103] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/103/1.delta
[2025-07-19T21:02:25.170+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.171+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 103 (task 84, attempt 0, stage 5.0)
[2025-07-19T21:02:25.171+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/106/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/106/.1.delta.5f4d2cab-5127-4143-9e91-316d35343ca6.TID86.tmp
[2025-07-19T21:02:25.174+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/111/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/111/.1.delta.354b47ff-46ab-4bd1-b7af-88937f13123e.TID89.tmp
[2025-07-19T21:02:25.177+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/112/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/112/.1.delta.eaf44a43-13c5-4386-8365-696e8ced8d86.TID90.tmp
[2025-07-19T21:02:25.182+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 102 (task 83, attempt 0, stage 5.0)
[2025-07-19T21:02:25.183+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 102.0 in stage 5.0 (TID 83). 9286 bytes result sent to driver
[2025-07-19T21:02:25.183+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 113.0 in stage 5.0 (TID 91) (8b44f3d35cfa, executor driver, partition 113, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.184+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 103 (task 84, attempt 0, stage 5.0)
[2025-07-19T21:02:25.186+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 102.0 in stage 5.0 (TID 83) in 159 ms on 8b44f3d35cfa (executor driver) (73/200)
[2025-07-19T21:02:25.187+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 103.0 in stage 5.0 (TID 84). 9303 bytes result sent to driver
[2025-07-19T21:02:25.188+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 113.0 in stage 5.0 (TID 91)
[2025-07-19T21:02:25.189+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 114.0 in stage 5.0 (TID 92) (8b44f3d35cfa, executor driver, partition 114, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.189+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 114.0 in stage 5.0 (TID 92)
[2025-07-19T21:02:25.189+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/105/.1.delta.2b803e66-9953-4fe7-9d3a-03b7f49f22ab.TID85.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/105/1.delta
[2025-07-19T21:02:25.190+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=105),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/105] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/105/1.delta
[2025-07-19T21:02:25.190+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 103.0 in stage 5.0 (TID 84) in 121 ms on 8b44f3d35cfa (executor driver) (74/200)
[2025-07-19T21:02:25.190+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 105 (task 85, attempt 0, stage 5.0)
[2025-07-19T21:02:25.190+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.190+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.190+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:25.203+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T21:02:25.206+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4501b5e7
[2025-07-19T21:02:25.218+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=114, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.219+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=114),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/114] for update
[2025-07-19T21:02:25.229+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/109/.1.delta.a09bdecb-be94-424c-9987-2559d7424aa6.TID87.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/109/1.delta
[2025-07-19T21:02:25.236+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=109),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/109] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/109/1.delta
[2025-07-19T21:02:25.237+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.237+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 105 (task 85, attempt 0, stage 5.0)
[2025-07-19T21:02:25.238+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 105.0 in stage 5.0 (TID 85). 9294 bytes result sent to driver
[2025-07-19T21:02:25.238+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 109 (task 87, attempt 0, stage 5.0)
[2025-07-19T21:02:25.239+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 116.0 in stage 5.0 (TID 93) (8b44f3d35cfa, executor driver, partition 116, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.239+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 105.0 in stage 5.0 (TID 85) in 161 ms on 8b44f3d35cfa (executor driver) (75/200)
[2025-07-19T21:02:25.240+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 116.0 in stage 5.0 (TID 93)
[2025-07-19T21:02:25.240+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.241+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2025-07-19T21:02:25.245+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@91bfb31
[2025-07-19T21:02:25.246+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=113, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.247+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=113),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/113] for update
[2025-07-19T21:02:25.247+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/110/.1.delta.5eac332c-1bf0-4aa0-8248-b271594118c5.TID88.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/110/1.delta
[2025-07-19T21:02:25.247+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=110),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/110] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/110/1.delta
[2025-07-19T21:02:25.248+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 110 (task 88, attempt 0, stage 5.0)
[2025-07-19T21:02:25.250+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.253+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 109 (task 87, attempt 0, stage 5.0)
[2025-07-19T21:02:25.255+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/114/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/114/.1.delta.18250130-93de-41cb-a75e-d234bdef39f3.TID92.tmp
[2025-07-19T21:02:25.257+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@548c61b9
[2025-07-19T21:02:25.258+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=116, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.262+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=116),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/116] for update
[2025-07-19T21:02:25.263+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/106/.1.delta.5f4d2cab-5127-4143-9e91-316d35343ca6.TID86.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/106/1.delta
[2025-07-19T21:02:25.263+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=106),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/106] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/106/1.delta
[2025-07-19T21:02:25.271+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 106 (task 86, attempt 0, stage 5.0)
[2025-07-19T21:02:25.272+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 109.0 in stage 5.0 (TID 87). 9306 bytes result sent to driver
[2025-07-19T21:02:25.273+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 117.0 in stage 5.0 (TID 94) (8b44f3d35cfa, executor driver, partition 117, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.273+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 117.0 in stage 5.0 (TID 94)
[2025-07-19T21:02:25.274+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 109.0 in stage 5.0 (TID 87) in 181 ms on 8b44f3d35cfa (executor driver) (76/200)
[2025-07-19T21:02:25.286+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 110 (task 88, attempt 0, stage 5.0)
[2025-07-19T21:02:25.287+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.288+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.289+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T21:02:25.290+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 110.0 in stage 5.0 (TID 88). 9305 bytes result sent to driver
[2025-07-19T21:02:25.294+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 118.0 in stage 5.0 (TID 95) (8b44f3d35cfa, executor driver, partition 118, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.295+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/112/.1.delta.eaf44a43-13c5-4386-8365-696e8ced8d86.TID90.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/112/1.delta
[2025-07-19T21:02:25.295+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=112),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/112] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/112/1.delta
[2025-07-19T21:02:25.296+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 110.0 in stage 5.0 (TID 88) in 195 ms on 8b44f3d35cfa (executor driver) (77/200)
[2025-07-19T21:02:25.297+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 118.0 in stage 5.0 (TID 95)
[2025-07-19T21:02:25.297+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/111/.1.delta.354b47ff-46ab-4bd1-b7af-88937f13123e.TID89.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/111/1.delta
[2025-07-19T21:02:25.298+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=111),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/111] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/111/1.delta
[2025-07-19T21:02:25.298+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 112 (task 90, attempt 0, stage 5.0)
[2025-07-19T21:02:25.299+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 111 (task 89, attempt 0, stage 5.0)
[2025-07-19T21:02:25.299+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/113/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/113/.1.delta.7c5788d6-9833-41b0-bcf9-6978c390d891.TID91.tmp
[2025-07-19T21:02:25.300+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.301+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:25.310+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 106 (task 86, attempt 0, stage 5.0)
[2025-07-19T21:02:25.312+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 106.0 in stage 5.0 (TID 86). 9290 bytes result sent to driver
[2025-07-19T21:02:25.313+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 119.0 in stage 5.0 (TID 96) (8b44f3d35cfa, executor driver, partition 119, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.313+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@87bcf90
[2025-07-19T21:02:25.314+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 119.0 in stage 5.0 (TID 96)
[2025-07-19T21:02:25.315+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 106.0 in stage 5.0 (TID 86) in 222 ms on 8b44f3d35cfa (executor driver) (78/200)
[2025-07-19T21:02:25.321+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 112 (task 90, attempt 0, stage 5.0)
[2025-07-19T21:02:25.324+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 112.0 in stage 5.0 (TID 90). 9296 bytes result sent to driver
[2025-07-19T21:02:25.325+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 120.0 in stage 5.0 (TID 97) (8b44f3d35cfa, executor driver, partition 120, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.326+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 120.0 in stage 5.0 (TID 97)
[2025-07-19T21:02:25.327+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 112.0 in stage 5.0 (TID 90) in 186 ms on 8b44f3d35cfa (executor driver) (79/200)
[2025-07-19T21:02:25.327+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=117, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.328+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=117),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/117] for update
[2025-07-19T21:02:25.329+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/116/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/116/.1.delta.9b1e41f4-db83-403b-9cd6-a1d028825c26.TID93.tmp
[2025-07-19T21:02:25.330+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.341+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.342+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:25.344+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6fe5f5ea
[2025-07-19T21:02:25.344+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.345+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:25.348+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=118, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.348+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=118),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/118] for update
[2025-07-19T21:02:25.349+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 111 (task 89, attempt 0, stage 5.0)
[2025-07-19T21:02:25.354+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 111.0 in stage 5.0 (TID 89). 9353 bytes result sent to driver
[2025-07-19T21:02:25.355+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 124.0 in stage 5.0 (TID 98) (8b44f3d35cfa, executor driver, partition 124, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.356+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/114/.1.delta.18250130-93de-41cb-a75e-d234bdef39f3.TID92.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/114/1.delta
[2025-07-19T21:02:25.356+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=114),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/114] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/114/1.delta
[2025-07-19T21:02:25.357+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 124.0 in stage 5.0 (TID 98)
[2025-07-19T21:02:25.357+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5381bc16
[2025-07-19T21:02:25.358+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 111.0 in stage 5.0 (TID 89) in 234 ms on 8b44f3d35cfa (executor driver) (80/200)
[2025-07-19T21:02:25.358+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=119, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.359+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=119),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/119] for update
[2025-07-19T21:02:25.360+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.360+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/113/.1.delta.7c5788d6-9833-41b0-bcf9-6978c390d891.TID91.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/113/1.delta
[2025-07-19T21:02:25.361+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=113),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/113] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/113/1.delta
[2025-07-19T21:02:25.362+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.362+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:25.363+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 114 (task 92, attempt 0, stage 5.0)
[2025-07-19T21:02:25.363+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.364+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 113 (task 91, attempt 0, stage 5.0)
[2025-07-19T21:02:25.365+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/117/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/117/.1.delta.b08c26ca-fe8d-4d27-99f9-c4ec1d559607.TID94.tmp
[2025-07-19T21:02:25.371+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/119/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/119/.1.delta.073d7996-7e42-4a08-8441-d573f2564ede.TID96.tmp
[2025-07-19T21:02:25.374+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d5f97de
[2025-07-19T21:02:25.374+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=120, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.375+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=120),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/120] for update
[2025-07-19T21:02:25.376+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/118/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/118/.1.delta.c2e09896-b593-45ff-9659-626e0385b256.TID95.tmp
[2025-07-19T21:02:25.376+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.386+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59ccda0b
[2025-07-19T21:02:25.388+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=124, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.391+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=124),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/124] for update
[2025-07-19T21:02:25.392+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 113 (task 91, attempt 0, stage 5.0)
[2025-07-19T21:02:25.392+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 113.0 in stage 5.0 (TID 91). 9284 bytes result sent to driver
[2025-07-19T21:02:25.392+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 125.0 in stage 5.0 (TID 99) (8b44f3d35cfa, executor driver, partition 125, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.393+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 125.0 in stage 5.0 (TID 99)
[2025-07-19T21:02:25.393+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 113.0 in stage 5.0 (TID 91) in 204 ms on 8b44f3d35cfa (executor driver) (81/200)
[2025-07-19T21:02:25.394+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.394+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:25.395+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.396+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/120/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/120/.1.delta.17aaa9f2-59e6-4271-9e5e-d52d41fdf6ff.TID97.tmp
[2025-07-19T21:02:25.397+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/116/.1.delta.9b1e41f4-db83-403b-9cd6-a1d028825c26.TID93.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/116/1.delta
[2025-07-19T21:02:25.398+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=116),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/116] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/116/1.delta
[2025-07-19T21:02:25.401+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 116 (task 93, attempt 0, stage 5.0)
[2025-07-19T21:02:25.403+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c2e897e
[2025-07-19T21:02:25.404+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=125, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.405+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=125),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/125] for update
[2025-07-19T21:02:25.407+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.409+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/124/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/124/.1.delta.309d69a3-478e-4c11-8c10-84ee9ff23de7.TID98.tmp
[2025-07-19T21:02:25.421+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 114 (task 92, attempt 0, stage 5.0)
[2025-07-19T21:02:25.421+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 114.0 in stage 5.0 (TID 92). 9322 bytes result sent to driver
[2025-07-19T21:02:25.422+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/117/.1.delta.b08c26ca-fe8d-4d27-99f9-c4ec1d559607.TID94.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/117/1.delta
[2025-07-19T21:02:25.425+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 126.0 in stage 5.0 (TID 100) (8b44f3d35cfa, executor driver, partition 126, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.425+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=117),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/117] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/117/1.delta
[2025-07-19T21:02:25.426+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 114.0 in stage 5.0 (TID 92) in 232 ms on 8b44f3d35cfa (executor driver) (82/200)
[2025-07-19T21:02:25.426+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 126.0 in stage 5.0 (TID 100)
[2025-07-19T21:02:25.426+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 117 (task 94, attempt 0, stage 5.0)
[2025-07-19T21:02:25.426+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.426+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:25.426+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/125/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/125/.1.delta.6d1a469c-e3a1-49e8-ba09-2c167bc04ee2.TID99.tmp
[2025-07-19T21:02:25.427+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/118/.1.delta.c2e09896-b593-45ff-9659-626e0385b256.TID95.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/118/1.delta
[2025-07-19T21:02:25.427+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=118),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/118] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/118/1.delta
[2025-07-19T21:02:25.427+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 118 (task 95, attempt 0, stage 5.0)
[2025-07-19T21:02:25.433+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/119/.1.delta.073d7996-7e42-4a08-8441-d573f2564ede.TID96.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/119/1.delta
[2025-07-19T21:02:25.434+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=119),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/119] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/119/1.delta
[2025-07-19T21:02:25.434+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@660c9704
[2025-07-19T21:02:25.435+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 119 (task 96, attempt 0, stage 5.0)
[2025-07-19T21:02:25.435+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 116 (task 93, attempt 0, stage 5.0)
[2025-07-19T21:02:25.436+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=126, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.437+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=126),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/126] for update
[2025-07-19T21:02:25.439+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 116.0 in stage 5.0 (TID 93). 9364 bytes result sent to driver
[2025-07-19T21:02:25.442+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 127.0 in stage 5.0 (TID 101) (8b44f3d35cfa, executor driver, partition 127, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.443+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 127.0 in stage 5.0 (TID 101)
[2025-07-19T21:02:25.444+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.445+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 116.0 in stage 5.0 (TID 93) in 220 ms on 8b44f3d35cfa (executor driver) (83/200)
[2025-07-19T21:02:25.451+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.453+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:25.457+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/126/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/126/.1.delta.50c87788-8283-4ec2-9849-0501b0da67cd.TID100.tmp
[2025-07-19T21:02:25.460+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 117 (task 94, attempt 0, stage 5.0)
[2025-07-19T21:02:25.461+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 119 (task 96, attempt 0, stage 5.0)
[2025-07-19T21:02:25.469+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 117.0 in stage 5.0 (TID 94). 9365 bytes result sent to driver
[2025-07-19T21:02:25.470+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 128.0 in stage 5.0 (TID 102) (8b44f3d35cfa, executor driver, partition 128, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.471+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 117.0 in stage 5.0 (TID 94) in 200 ms on 8b44f3d35cfa (executor driver) (84/200)
[2025-07-19T21:02:25.471+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3e7f434e
[2025-07-19T21:02:25.472+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 128.0 in stage 5.0 (TID 102)
[2025-07-19T21:02:25.472+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/120/.1.delta.17aaa9f2-59e6-4271-9e5e-d52d41fdf6ff.TID97.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/120/1.delta
[2025-07-19T21:02:25.472+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=127, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.473+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=127),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/127] for update
[2025-07-19T21:02:25.477+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 119.0 in stage 5.0 (TID 96). 9329 bytes result sent to driver
[2025-07-19T21:02:25.478+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=120),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/120] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/120/1.delta
[2025-07-19T21:02:25.478+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 120 (task 97, attempt 0, stage 5.0)
[2025-07-19T21:02:25.478+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 130.0 in stage 5.0 (TID 103) (8b44f3d35cfa, executor driver, partition 130, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.479+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 119.0 in stage 5.0 (TID 96) in 164 ms on 8b44f3d35cfa (executor driver) (85/200)
[2025-07-19T21:02:25.480+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 118 (task 95, attempt 0, stage 5.0)
[2025-07-19T21:02:25.480+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/124/.1.delta.309d69a3-478e-4c11-8c10-84ee9ff23de7.TID98.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/124/1.delta
[2025-07-19T21:02:25.480+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=124),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/124] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/124/1.delta
[2025-07-19T21:02:25.480+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.480+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:25.480+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 130.0 in stage 5.0 (TID 103)
[2025-07-19T21:02:25.480+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 124 (task 98, attempt 0, stage 5.0)
[2025-07-19T21:02:25.480+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.489+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3adfef9b
[2025-07-19T21:02:25.491+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.491+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:25.492+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=128, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.493+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=128),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/128] for update
[2025-07-19T21:02:25.499+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/127/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/127/.1.delta.f1bac0bf-5dce-4bdb-815d-3c22de2b8e0c.TID101.tmp
[2025-07-19T21:02:25.499+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.501+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 124 (task 98, attempt 0, stage 5.0)
[2025-07-19T21:02:25.506+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53851669
[2025-07-19T21:02:25.507+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 124.0 in stage 5.0 (TID 98). 9296 bytes result sent to driver
[2025-07-19T21:02:25.509+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 131.0 in stage 5.0 (TID 104) (8b44f3d35cfa, executor driver, partition 131, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.509+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 124.0 in stage 5.0 (TID 98) in 153 ms on 8b44f3d35cfa (executor driver) (86/200)
[2025-07-19T21:02:25.513+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=130, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.514+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=130),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/130] for update
[2025-07-19T21:02:25.526+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 131.0 in stage 5.0 (TID 104)
[2025-07-19T21:02:25.540+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/125/.1.delta.6d1a469c-e3a1-49e8-ba09-2c167bc04ee2.TID99.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/125/1.delta
[2025-07-19T21:02:25.540+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=125),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/125] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/125/1.delta
[2025-07-19T21:02:25.540+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.541+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 125 (task 99, attempt 0, stage 5.0)
[2025-07-19T21:02:25.541+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 118.0 in stage 5.0 (TID 95). 9261 bytes result sent to driver
[2025-07-19T21:02:25.541+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 120 (task 97, attempt 0, stage 5.0)
[2025-07-19T21:02:25.541+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 120.0 in stage 5.0 (TID 97). 9294 bytes result sent to driver
[2025-07-19T21:02:25.541+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.541+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
[2025-07-19T21:02:25.548+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 134.0 in stage 5.0 (TID 105) (8b44f3d35cfa, executor driver, partition 134, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.548+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 135.0 in stage 5.0 (TID 106) (8b44f3d35cfa, executor driver, partition 135, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.549+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 135.0 in stage 5.0 (TID 106)
[2025-07-19T21:02:25.549+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 134.0 in stage 5.0 (TID 105)
[2025-07-19T21:02:25.549+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 120.0 in stage 5.0 (TID 97) in 225 ms on 8b44f3d35cfa (executor driver) (87/200)
[2025-07-19T21:02:25.549+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 118.0 in stage 5.0 (TID 95) in 255 ms on 8b44f3d35cfa (executor driver) (88/200)
[2025-07-19T21:02:25.549+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/128/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/128/.1.delta.4cedc318-2145-4322-b14d-875fcf017c10.TID102.tmp
[2025-07-19T21:02:25.552+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.554+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:25.555+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@753554cd
[2025-07-19T21:02:25.556+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/130/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/130/.1.delta.d46d48ca-195d-4ada-a35f-47cd75dfae4c.TID103.tmp
[2025-07-19T21:02:25.556+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=131, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.558+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=131),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/131] for update
[2025-07-19T21:02:25.559+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 125 (task 99, attempt 0, stage 5.0)
[2025-07-19T21:02:25.565+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.566+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2025-07-19T21:02:25.566+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 125.0 in stage 5.0 (TID 99). 9335 bytes result sent to driver
[2025-07-19T21:02:25.567+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@41c9907d
[2025-07-19T21:02:25.567+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=134, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.568+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=134),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/134] for update
[2025-07-19T21:02:25.570+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.571+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.574+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 136.0 in stage 5.0 (TID 107) (8b44f3d35cfa, executor driver, partition 136, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.574+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 136.0 in stage 5.0 (TID 107)
[2025-07-19T21:02:25.575+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 125.0 in stage 5.0 (TID 99) in 187 ms on 8b44f3d35cfa (executor driver) (89/200)
[2025-07-19T21:02:25.580+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52e90003
[2025-07-19T21:02:25.582+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=135, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.582+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=135),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/135] for update
[2025-07-19T21:02:25.583+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.583+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:25.584+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.591+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/131/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/131/.1.delta.98ac6c8b-5fa2-4d43-8c75-b8238c4ea9be.TID104.tmp
[2025-07-19T21:02:25.592+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a36ced1
[2025-07-19T21:02:25.593+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=136, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.593+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=136),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/136] for update
[2025-07-19T21:02:25.594+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.594+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/127/.1.delta.f1bac0bf-5dce-4bdb-815d-3c22de2b8e0c.TID101.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/127/1.delta
[2025-07-19T21:02:25.594+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=127),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/127] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/127/1.delta
[2025-07-19T21:02:25.596+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 127 (task 101, attempt 0, stage 5.0)
[2025-07-19T21:02:25.596+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/134/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/134/.1.delta.544788f0-6299-4138-a0e6-ad0a6ca109bf.TID105.tmp
[2025-07-19T21:02:25.601+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/135/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/135/.1.delta.b77402de-7c51-43e6-b206-dc3122709981.TID106.tmp
[2025-07-19T21:02:25.602+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/126/.1.delta.50c87788-8283-4ec2-9849-0501b0da67cd.TID100.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/126/1.delta
[2025-07-19T21:02:25.602+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=126),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/126] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/126/1.delta
[2025-07-19T21:02:25.603+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 126 (task 100, attempt 0, stage 5.0)
[2025-07-19T21:02:25.616+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/128/.1.delta.4cedc318-2145-4322-b14d-875fcf017c10.TID102.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/128/1.delta
[2025-07-19T21:02:25.617+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=128),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/128] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/128/1.delta
[2025-07-19T21:02:25.617+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 128 (task 102, attempt 0, stage 5.0)
[2025-07-19T21:02:25.618+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/136/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/136/.1.delta.6e386973-f608-4a40-94ad-4bf3e68d6a71.TID107.tmp
[2025-07-19T21:02:25.620+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 126 (task 100, attempt 0, stage 5.0)
[2025-07-19T21:02:25.621+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 126.0 in stage 5.0 (TID 100). 9282 bytes result sent to driver
[2025-07-19T21:02:25.622+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 137.0 in stage 5.0 (TID 108) (8b44f3d35cfa, executor driver, partition 137, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.623+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 126.0 in stage 5.0 (TID 100) in 205 ms on 8b44f3d35cfa (executor driver) (90/200)
[2025-07-19T21:02:25.623+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 137.0 in stage 5.0 (TID 108)
[2025-07-19T21:02:25.627+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 127 (task 101, attempt 0, stage 5.0)
[2025-07-19T21:02:25.628+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 127.0 in stage 5.0 (TID 101). 9286 bytes result sent to driver
[2025-07-19T21:02:25.628+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 140.0 in stage 5.0 (TID 109) (8b44f3d35cfa, executor driver, partition 140, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.629+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 140.0 in stage 5.0 (TID 109)
[2025-07-19T21:02:25.629+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 127.0 in stage 5.0 (TID 101) in 189 ms on 8b44f3d35cfa (executor driver) (91/200)
[2025-07-19T21:02:25.635+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 128 (task 102, attempt 0, stage 5.0)
[2025-07-19T21:02:25.636+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.637+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.637+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 128.0 in stage 5.0 (TID 102). 9276 bytes result sent to driver
[2025-07-19T21:02:25.638+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T21:02:25.639+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T21:02:25.641+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 141.0 in stage 5.0 (TID 110) (8b44f3d35cfa, executor driver, partition 141, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.641+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 128.0 in stage 5.0 (TID 102) in 168 ms on 8b44f3d35cfa (executor driver) (92/200)
[2025-07-19T21:02:25.641+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 141.0 in stage 5.0 (TID 110)
[2025-07-19T21:02:25.642+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/130/.1.delta.d46d48ca-195d-4ada-a35f-47cd75dfae4c.TID103.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/130/1.delta
[2025-07-19T21:02:25.642+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.642+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:25.642+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=130),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/130] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/130/1.delta
[2025-07-19T21:02:25.642+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 130 (task 103, attempt 0, stage 5.0)
[2025-07-19T21:02:25.648+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/131/.1.delta.98ac6c8b-5fa2-4d43-8c75-b8238c4ea9be.TID104.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/131/1.delta
[2025-07-19T21:02:25.649+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=131),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/131] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/131/1.delta
[2025-07-19T21:02:25.649+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 131 (task 104, attempt 0, stage 5.0)
[2025-07-19T21:02:25.651+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2410e28b
[2025-07-19T21:02:25.654+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=137, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.655+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=137),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/137] for update
[2025-07-19T21:02:25.656+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.657+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/135/.1.delta.b77402de-7c51-43e6-b206-dc3122709981.TID106.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/135/1.delta
[2025-07-19T21:02:25.658+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=135),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/135] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/135/1.delta
[2025-07-19T21:02:25.659+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/134/.1.delta.544788f0-6299-4138-a0e6-ad0a6ca109bf.TID105.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/134/1.delta
[2025-07-19T21:02:25.660+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d3cb64d
[2025-07-19T21:02:25.661+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 135 (task 106, attempt 0, stage 5.0)
[2025-07-19T21:02:25.661+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=141, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.662+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=134),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/134] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/134/1.delta
[2025-07-19T21:02:25.662+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 134 (task 105, attempt 0, stage 5.0)
[2025-07-19T21:02:25.663+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=141),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/141] for update
[2025-07-19T21:02:25.666+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c9f1195
[2025-07-19T21:02:25.667+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=140, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.667+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=140),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/140] for update
[2025-07-19T21:02:25.667+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.668+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 131 (task 104, attempt 0, stage 5.0)
[2025-07-19T21:02:25.675+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/137/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/137/.1.delta.4b07b23b-9b89-4308-a944-ff37847a254b.TID108.tmp
[2025-07-19T21:02:25.677+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 130 (task 103, attempt 0, stage 5.0)
[2025-07-19T21:02:25.678+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 131.0 in stage 5.0 (TID 104). 9338 bytes result sent to driver
[2025-07-19T21:02:25.678+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 130.0 in stage 5.0 (TID 103). 9316 bytes result sent to driver
[2025-07-19T21:02:25.679+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.679+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 130.0 in stage 5.0 (TID 103) in 203 ms on 8b44f3d35cfa (executor driver) (93/200)
[2025-07-19T21:02:25.680+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 142.0 in stage 5.0 (TID 111) (8b44f3d35cfa, executor driver, partition 142, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.680+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 142.0 in stage 5.0 (TID 111)
[2025-07-19T21:02:25.681+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 144.0 in stage 5.0 (TID 112) (8b44f3d35cfa, executor driver, partition 144, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.682+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.683+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:25.683+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 131.0 in stage 5.0 (TID 104) in 176 ms on 8b44f3d35cfa (executor driver) (94/200)
[2025-07-19T21:02:25.684+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 144.0 in stage 5.0 (TID 112)
[2025-07-19T21:02:25.685+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/136/.1.delta.6e386973-f608-4a40-94ad-4bf3e68d6a71.TID107.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/136/1.delta
[2025-07-19T21:02:25.685+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=136),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/136] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/136/1.delta
[2025-07-19T21:02:25.685+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@46bf1ae1
[2025-07-19T21:02:25.686+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 136 (task 107, attempt 0, stage 5.0)
[2025-07-19T21:02:25.686+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=142, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.686+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=142),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/142] for update
[2025-07-19T21:02:25.688+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.690+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:25.691+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.691+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 135 (task 106, attempt 0, stage 5.0)
[2025-07-19T21:02:25.693+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 135.0 in stage 5.0 (TID 106). 9347 bytes result sent to driver
[2025-07-19T21:02:25.695+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 135.0 in stage 5.0 (TID 106) in 151 ms on 8b44f3d35cfa (executor driver) (95/200)
[2025-07-19T21:02:25.696+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 145.0 in stage 5.0 (TID 113) (8b44f3d35cfa, executor driver, partition 145, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.697+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 145.0 in stage 5.0 (TID 113)
[2025-07-19T21:02:25.701+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3586bc47
[2025-07-19T21:02:25.702+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=144, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.703+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=144),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/144] for update
[2025-07-19T21:02:25.703+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/140/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/140/.1.delta.1e9c7094-eb25-448f-bacd-9a094f644170.TID109.tmp
[2025-07-19T21:02:25.705+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.707+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/141/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/141/.1.delta.ddc56560-5d18-481c-8558-901f7f2eddfd.TID110.tmp
[2025-07-19T21:02:25.707+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.710+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/142/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/142/.1.delta.906feb7d-9b28-41da-9364-f37d5d4a227f.TID111.tmp
[2025-07-19T21:02:25.710+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:25.714+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 136 (task 107, attempt 0, stage 5.0)
[2025-07-19T21:02:25.714+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 134 (task 105, attempt 0, stage 5.0)
[2025-07-19T21:02:25.714+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 136.0 in stage 5.0 (TID 107). 9306 bytes result sent to driver
[2025-07-19T21:02:25.715+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 147.0 in stage 5.0 (TID 114) (8b44f3d35cfa, executor driver, partition 147, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.722+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 147.0 in stage 5.0 (TID 114)
[2025-07-19T21:02:25.724+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 136.0 in stage 5.0 (TID 107) in 149 ms on 8b44f3d35cfa (executor driver) (96/200)
[2025-07-19T21:02:25.724+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/144/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/144/.1.delta.7af2c227-0c70-431d-a1d5-b36e8d6fd894.TID112.tmp
[2025-07-19T21:02:25.725+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 134.0 in stage 5.0 (TID 105). 9334 bytes result sent to driver
[2025-07-19T21:02:25.726+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 148.0 in stage 5.0 (TID 115) (8b44f3d35cfa, executor driver, partition 148, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.726+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 148.0 in stage 5.0 (TID 115)
[2025-07-19T21:02:25.726+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 134.0 in stage 5.0 (TID 105) in 182 ms on 8b44f3d35cfa (executor driver) (97/200)
[2025-07-19T21:02:25.726+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.727+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:25.730+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/137/.1.delta.4b07b23b-9b89-4308-a944-ff37847a254b.TID108.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/137/1.delta
[2025-07-19T21:02:25.731+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=137),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/137] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/137/1.delta
[2025-07-19T21:02:25.731+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 137 (task 108, attempt 0, stage 5.0)
[2025-07-19T21:02:25.732+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2da2d651
[2025-07-19T21:02:25.732+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=145, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.732+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=145),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/145] for update
[2025-07-19T21:02:25.732+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.732+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:25.732+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.735+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4df186f2
[2025-07-19T21:02:25.740+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=147, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.742+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/145/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/145/.1.delta.579538a8-955d-4d49-a53f-d4cf3af060e2.TID113.tmp
[2025-07-19T21:02:25.745+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=147),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/147] for update
[2025-07-19T21:02:25.747+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.751+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 137 (task 108, attempt 0, stage 5.0)
[2025-07-19T21:02:25.752+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 137.0 in stage 5.0 (TID 108). 9302 bytes result sent to driver
[2025-07-19T21:02:25.754+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 149.0 in stage 5.0 (TID 116) (8b44f3d35cfa, executor driver, partition 149, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.755+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 149.0 in stage 5.0 (TID 116)
[2025-07-19T21:02:25.756+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 137.0 in stage 5.0 (TID 108) in 135 ms on 8b44f3d35cfa (executor driver) (98/200)
[2025-07-19T21:02:25.757+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@70a1ad28
[2025-07-19T21:02:25.757+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=148, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.757+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=148),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/148] for update
[2025-07-19T21:02:25.759+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.759+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.760+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:25.766+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/141/.1.delta.ddc56560-5d18-481c-8558-901f7f2eddfd.TID110.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/141/1.delta
[2025-07-19T21:02:25.766+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=141),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/141] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/141/1.delta
[2025-07-19T21:02:25.766+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 141 (task 110, attempt 0, stage 5.0)
[2025-07-19T21:02:25.770+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/140/.1.delta.1e9c7094-eb25-448f-bacd-9a094f644170.TID109.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/140/1.delta
[2025-07-19T21:02:25.770+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=140),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/140] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/140/1.delta
[2025-07-19T21:02:25.771+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/142/.1.delta.906feb7d-9b28-41da-9364-f37d5d4a227f.TID111.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/142/1.delta
[2025-07-19T21:02:25.771+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=142),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/142] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/142/1.delta
[2025-07-19T21:02:25.774+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@16bdf5bf
[2025-07-19T21:02:25.775+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 142 (task 111, attempt 0, stage 5.0)
[2025-07-19T21:02:25.776+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=149, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.776+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=149),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/149] for update
[2025-07-19T21:02:25.776+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/147/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/147/.1.delta.57f4c0a2-cc9f-4a71-8806-de36d4cb786d.TID114.tmp
[2025-07-19T21:02:25.776+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 140 (task 109, attempt 0, stage 5.0)
[2025-07-19T21:02:25.777+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.777+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/148/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/148/.1.delta.b05f09c8-ff97-401a-82b4-bb248a28211a.TID115.tmp
[2025-07-19T21:02:25.781+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/144/.1.delta.7af2c227-0c70-431d-a1d5-b36e8d6fd894.TID112.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/144/1.delta
[2025-07-19T21:02:25.781+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=144),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/144] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/144/1.delta
[2025-07-19T21:02:25.782+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 144 (task 112, attempt 0, stage 5.0)
[2025-07-19T21:02:25.789+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/149/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/149/.1.delta.3dece8e3-562b-4ba5-9fe2-30fff4164187.TID116.tmp
[2025-07-19T21:02:25.791+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/145/.1.delta.579538a8-955d-4d49-a53f-d4cf3af060e2.TID113.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/145/1.delta
[2025-07-19T21:02:25.792+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=145),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/145] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/145/1.delta
[2025-07-19T21:02:25.792+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 145 (task 113, attempt 0, stage 5.0)
[2025-07-19T21:02:25.801+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 141 (task 110, attempt 0, stage 5.0)
[2025-07-19T21:02:25.801+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 141.0 in stage 5.0 (TID 110). 9266 bytes result sent to driver
[2025-07-19T21:02:25.802+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 141.0 in stage 5.0 (TID 110) in 165 ms on 8b44f3d35cfa (executor driver) (99/200)
[2025-07-19T21:02:25.803+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 151.0 in stage 5.0 (TID 117) (8b44f3d35cfa, executor driver, partition 151, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.803+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 151.0 in stage 5.0 (TID 117)
[2025-07-19T21:02:25.806+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.807+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:25.810+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 140 (task 109, attempt 0, stage 5.0)
[2025-07-19T21:02:25.811+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 140.0 in stage 5.0 (TID 109). 9270 bytes result sent to driver
[2025-07-19T21:02:25.812+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 152.0 in stage 5.0 (TID 118) (8b44f3d35cfa, executor driver, partition 152, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.814+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 142 (task 111, attempt 0, stage 5.0)
[2025-07-19T21:02:25.815+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 152.0 in stage 5.0 (TID 118)
[2025-07-19T21:02:25.815+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 142.0 in stage 5.0 (TID 111). 9290 bytes result sent to driver
[2025-07-19T21:02:25.816+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 153.0 in stage 5.0 (TID 119) (8b44f3d35cfa, executor driver, partition 153, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.816+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 153.0 in stage 5.0 (TID 119)
[2025-07-19T21:02:25.817+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 140.0 in stage 5.0 (TID 109) in 182 ms on 8b44f3d35cfa (executor driver) (100/200)
[2025-07-19T21:02:25.817+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 142.0 in stage 5.0 (TID 111) in 135 ms on 8b44f3d35cfa (executor driver) (101/200)
[2025-07-19T21:02:25.818+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.819+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 144 (task 112, attempt 0, stage 5.0)
[2025-07-19T21:02:25.820+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T21:02:25.821+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.823+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:25.824+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 144.0 in stage 5.0 (TID 112). 9356 bytes result sent to driver
[2025-07-19T21:02:25.826+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 155.0 in stage 5.0 (TID 120) (8b44f3d35cfa, executor driver, partition 155, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.827+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 155.0 in stage 5.0 (TID 120)
[2025-07-19T21:02:25.828+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d772912
[2025-07-19T21:02:25.828+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=151, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.829+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=151),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/151] for update
[2025-07-19T21:02:25.829+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 144.0 in stage 5.0 (TID 112) in 143 ms on 8b44f3d35cfa (executor driver) (102/200)
[2025-07-19T21:02:25.830+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.830+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/148/.1.delta.b05f09c8-ff97-401a-82b4-bb248a28211a.TID115.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/148/1.delta
[2025-07-19T21:02:25.830+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=148),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/148] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/148/1.delta
[2025-07-19T21:02:25.830+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 148 (task 115, attempt 0, stage 5.0)
[2025-07-19T21:02:25.831+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.832+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:25.837+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1bb4d85d
[2025-07-19T21:02:25.838+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 145 (task 113, attempt 0, stage 5.0)
[2025-07-19T21:02:25.838+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/151/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/151/.1.delta.0e71ded4-99dd-4e90-9ceb-0e541fa875a6.TID117.tmp
[2025-07-19T21:02:25.844+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 145.0 in stage 5.0 (TID 113). 9338 bytes result sent to driver
[2025-07-19T21:02:25.844+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=152, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.845+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=152),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/152] for update
[2025-07-19T21:02:25.845+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/149/.1.delta.3dece8e3-562b-4ba5-9fe2-30fff4164187.TID116.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/149/1.delta
[2025-07-19T21:02:25.846+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/147/.1.delta.57f4c0a2-cc9f-4a71-8806-de36d4cb786d.TID114.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/147/1.delta
[2025-07-19T21:02:25.847+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=149),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/149] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/149/1.delta
[2025-07-19T21:02:25.847+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 156.0 in stage 5.0 (TID 121) (8b44f3d35cfa, executor driver, partition 156, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.847+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=147),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/147] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/147/1.delta
[2025-07-19T21:02:25.848+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 156.0 in stage 5.0 (TID 121)
[2025-07-19T21:02:25.849+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 145.0 in stage 5.0 (TID 113) in 149 ms on 8b44f3d35cfa (executor driver) (103/200)
[2025-07-19T21:02:25.850+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 147 (task 114, attempt 0, stage 5.0)
[2025-07-19T21:02:25.850+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.851+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.851+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:25.852+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3547c440
[2025-07-19T21:02:25.852+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=153, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.852+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=153),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/153] for update
[2025-07-19T21:02:25.853+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 149 (task 116, attempt 0, stage 5.0)
[2025-07-19T21:02:25.853+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.854+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1e29cde
[2025-07-19T21:02:25.855+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=156, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.856+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=156),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/156] for update
[2025-07-19T21:02:25.857+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.860+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 148 (task 115, attempt 0, stage 5.0)
[2025-07-19T21:02:25.860+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/152/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/152/.1.delta.23b94271-ba07-4006-81f6-d172b05ba5ed.TID118.tmp
[2025-07-19T21:02:25.862+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 148.0 in stage 5.0 (TID 115). 9306 bytes result sent to driver
[2025-07-19T21:02:25.863+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/153/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/153/.1.delta.2fb33003-2749-4fe8-a3a8-ebf0777ed9d3.TID119.tmp
[2025-07-19T21:02:25.864+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 157.0 in stage 5.0 (TID 122) (8b44f3d35cfa, executor driver, partition 157, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.868+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@acb21ee
[2025-07-19T21:02:25.868+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 157.0 in stage 5.0 (TID 122)
[2025-07-19T21:02:25.869+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 148.0 in stage 5.0 (TID 115) in 144 ms on 8b44f3d35cfa (executor driver) (104/200)
[2025-07-19T21:02:25.870+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=155, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.870+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=155),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/155] for update
[2025-07-19T21:02:25.873+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 149 (task 116, attempt 0, stage 5.0)
[2025-07-19T21:02:25.874+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/156/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/156/.1.delta.49b28b35-59a5-4d4b-bd0d-25a47fe4d593.TID121.tmp
[2025-07-19T21:02:25.875+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 149.0 in stage 5.0 (TID 116). 9307 bytes result sent to driver
[2025-07-19T21:02:25.876+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 147 (task 114, attempt 0, stage 5.0)
[2025-07-19T21:02:25.877+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 149.0 in stage 5.0 (TID 116) in 123 ms on 8b44f3d35cfa (executor driver) (105/200)
[2025-07-19T21:02:25.878+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 147.0 in stage 5.0 (TID 114). 9282 bytes result sent to driver
[2025-07-19T21:02:25.878+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.879+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:25.880+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 159.0 in stage 5.0 (TID 123) (8b44f3d35cfa, executor driver, partition 159, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.880+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 160.0 in stage 5.0 (TID 124) (8b44f3d35cfa, executor driver, partition 160, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.880+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 160.0 in stage 5.0 (TID 124)
[2025-07-19T21:02:25.880+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/151/.1.delta.0e71ded4-99dd-4e90-9ceb-0e541fa875a6.TID117.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/151/1.delta
[2025-07-19T21:02:25.881+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=151),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/151] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/151/1.delta
[2025-07-19T21:02:25.881+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 151 (task 117, attempt 0, stage 5.0)
[2025-07-19T21:02:25.884+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.885+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 147.0 in stage 5.0 (TID 114) in 169 ms on 8b44f3d35cfa (executor driver) (106/200)
[2025-07-19T21:02:25.886+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 159.0 in stage 5.0 (TID 123)
[2025-07-19T21:02:25.886+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.887+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:25.888+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2655432c
[2025-07-19T21:02:25.890+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=157, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.890+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=157),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/157] for update
[2025-07-19T21:02:25.892+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.893+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:25.895+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.895+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d07e510
[2025-07-19T21:02:25.895+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=160, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.896+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=160),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/160] for update
[2025-07-19T21:02:25.897+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.901+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/152/.1.delta.23b94271-ba07-4006-81f6-d172b05ba5ed.TID118.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/152/1.delta
[2025-07-19T21:02:25.904+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=152),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/152] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/152/1.delta
[2025-07-19T21:02:25.906+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c71f617
[2025-07-19T21:02:25.907+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/155/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/155/.1.delta.aeeaf2b5-433c-4efd-a3c5-0cece338521c.TID120.tmp
[2025-07-19T21:02:25.907+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=159, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.907+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 152 (task 118, attempt 0, stage 5.0)
[2025-07-19T21:02:25.907+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=159),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/159] for update
[2025-07-19T21:02:25.908+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 151 (task 117, attempt 0, stage 5.0)
[2025-07-19T21:02:25.909+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/153/.1.delta.2fb33003-2749-4fe8-a3a8-ebf0777ed9d3.TID119.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/153/1.delta
[2025-07-19T21:02:25.909+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=153),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/153] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/153/1.delta
[2025-07-19T21:02:25.910+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.910+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 151.0 in stage 5.0 (TID 117). 9302 bytes result sent to driver
[2025-07-19T21:02:25.912+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 153 (task 119, attempt 0, stage 5.0)
[2025-07-19T21:02:25.912+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 161.0 in stage 5.0 (TID 125) (8b44f3d35cfa, executor driver, partition 161, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.913+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/157/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/157/.1.delta.66bd312a-0e67-4b8d-a66b-7887f22abe28.TID122.tmp
[2025-07-19T21:02:25.913+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 151.0 in stage 5.0 (TID 117) in 112 ms on 8b44f3d35cfa (executor driver) (107/200)
[2025-07-19T21:02:25.914+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 161.0 in stage 5.0 (TID 125)
[2025-07-19T21:02:25.919+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/160/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/160/.1.delta.2f0724c3-943b-463f-aa16-2d86019bb074.TID124.tmp
[2025-07-19T21:02:25.924+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.925+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:25.926+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/159/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/159/.1.delta.81f2a472-1219-4f34-a92a-830a68f48894.TID123.tmp
[2025-07-19T21:02:25.933+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/156/.1.delta.49b28b35-59a5-4d4b-bd0d-25a47fe4d593.TID121.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/156/1.delta
[2025-07-19T21:02:25.933+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a3fde21
[2025-07-19T21:02:25.934+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=156),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/156] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/156/1.delta
[2025-07-19T21:02:25.934+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 156 (task 121, attempt 0, stage 5.0)
[2025-07-19T21:02:25.935+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=161, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.935+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=161),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/161] for update
[2025-07-19T21:02:25.938+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 152 (task 118, attempt 0, stage 5.0)
[2025-07-19T21:02:25.940+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.946+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 152.0 in stage 5.0 (TID 118). 9302 bytes result sent to driver
[2025-07-19T21:02:25.947+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 162.0 in stage 5.0 (TID 126) (8b44f3d35cfa, executor driver, partition 162, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.947+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 162.0 in stage 5.0 (TID 126)
[2025-07-19T21:02:25.947+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 153 (task 119, attempt 0, stage 5.0)
[2025-07-19T21:02:25.947+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 152.0 in stage 5.0 (TID 118) in 138 ms on 8b44f3d35cfa (executor driver) (108/200)
[2025-07-19T21:02:25.948+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 153.0 in stage 5.0 (TID 119). 9308 bytes result sent to driver
[2025-07-19T21:02:25.949+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 165.0 in stage 5.0 (TID 127) (8b44f3d35cfa, executor driver, partition 165, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.949+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.949+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:25.949+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 153.0 in stage 5.0 (TID 119) in 139 ms on 8b44f3d35cfa (executor driver) (109/200)
[2025-07-19T21:02:25.952+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 165.0 in stage 5.0 (TID 127)
[2025-07-19T21:02:25.954+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.955+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:25.964+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d47ba54
[2025-07-19T21:02:25.964+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=162, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.964+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=162),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/162] for update
[2025-07-19T21:02:25.966+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/155/.1.delta.aeeaf2b5-433c-4efd-a3c5-0cece338521c.TID120.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/155/1.delta
[2025-07-19T21:02:25.967+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=155),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/155] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/155/1.delta
[2025-07-19T21:02:25.967+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 155 (task 120, attempt 0, stage 5.0)
[2025-07-19T21:02:25.968+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.971+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/157/.1.delta.66bd312a-0e67-4b8d-a66b-7887f22abe28.TID122.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/157/1.delta
[2025-07-19T21:02:25.972+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=157),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/157] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/157/1.delta
[2025-07-19T21:02:25.972+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/161/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/161/.1.delta.17668431-998e-49fa-8c92-77c79823129e.TID125.tmp
[2025-07-19T21:02:25.974+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 157 (task 122, attempt 0, stage 5.0)
[2025-07-19T21:02:25.977+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@79a73990
[2025-07-19T21:02:25.978+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=165, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:25.978+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=165),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/165] for update
[2025-07-19T21:02:25.978+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 156 (task 121, attempt 0, stage 5.0)
[2025-07-19T21:02:25.978+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 156.0 in stage 5.0 (TID 121). 9305 bytes result sent to driver
[2025-07-19T21:02:25.982+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 166.0 in stage 5.0 (TID 128) (8b44f3d35cfa, executor driver, partition 166, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.984+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:25.984+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/160/.1.delta.2f0724c3-943b-463f-aa16-2d86019bb074.TID124.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/160/1.delta
[2025-07-19T21:02:25.984+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 156.0 in stage 5.0 (TID 121) in 141 ms on 8b44f3d35cfa (executor driver) (110/200)
[2025-07-19T21:02:25.984+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=160),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/160] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/160/1.delta
[2025-07-19T21:02:25.984+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Commit authorized for partition 160 (task 124, attempt 0, stage 5.0)
[2025-07-19T21:02:25.989+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 166.0 in stage 5.0 (TID 128)
[2025-07-19T21:02:25.990+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/162/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/162/.1.delta.4e4fb3f1-0b80-431e-85e2-750863ebaef6.TID126.tmp
[2025-07-19T21:02:25.991+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/165/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/165/.1.delta.b7e96d78-5579-4825-bc92-f67830829111.TID127.tmp
[2025-07-19T21:02:25.992+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:25.992+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:25.993+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 155 (task 120, attempt 0, stage 5.0)
[2025-07-19T21:02:25.997+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO DataWritingSparkTask: Committed partition 157 (task 122, attempt 0, stage 5.0)
[2025-07-19T21:02:25.999+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 155.0 in stage 5.0 (TID 120). 9319 bytes result sent to driver
[2025-07-19T21:02:25.999+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Finished task 157.0 in stage 5.0 (TID 122). 9288 bytes result sent to driver
[2025-07-19T21:02:25.999+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 168.0 in stage 5.0 (TID 129) (8b44f3d35cfa, executor driver, partition 168, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:25.999+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 168.0 in stage 5.0 (TID 129)
[2025-07-19T21:02:25.999+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Starting task 169.0 in stage 5.0 (TID 130) (8b44f3d35cfa, executor driver, partition 169, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.000+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO Executor: Running task 169.0 in stage 5.0 (TID 130)
[2025-07-19T21:02:26.001+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO TaskSetManager: Finished task 155.0 in stage 5.0 (TID 120) in 180 ms on 8b44f3d35cfa (executor driver) (111/200)
[2025-07-19T21:02:26.002+0000] {subprocess.py:93} INFO - 25/07/19 21:02:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/159/.1.delta.81f2a472-1219-4f34-a92a-830a68f48894.TID123.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/159/1.delta
[2025-07-19T21:02:26.003+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 157.0 in stage 5.0 (TID 122) in 138 ms on 8b44f3d35cfa (executor driver) (112/200)
[2025-07-19T21:02:26.003+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=159),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/159] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/159/1.delta
[2025-07-19T21:02:26.004+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 159 (task 123, attempt 0, stage 5.0)
[2025-07-19T21:02:26.004+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 160 (task 124, attempt 0, stage 5.0)
[2025-07-19T21:02:26.004+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 160.0 in stage 5.0 (TID 124). 9317 bytes result sent to driver
[2025-07-19T21:02:26.004+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.005+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.005+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.005+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.008+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 174.0 in stage 5.0 (TID 131) (8b44f3d35cfa, executor driver, partition 174, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.008+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 160.0 in stage 5.0 (TID 124) in 129 ms on 8b44f3d35cfa (executor driver) (113/200)
[2025-07-19T21:02:26.008+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 174.0 in stage 5.0 (TID 131)
[2025-07-19T21:02:26.009+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@214f623a
[2025-07-19T21:02:26.010+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=166, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.011+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=166),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/166] for update
[2025-07-19T21:02:26.011+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.012+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.015+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.022+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3aca67d9
[2025-07-19T21:02:26.023+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=168, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.023+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=168),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/168] for update
[2025-07-19T21:02:26.025+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.033+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ab697e8
[2025-07-19T21:02:26.033+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=169, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.034+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=169),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/169] for update
[2025-07-19T21:02:26.035+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/166/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/166/.1.delta.568453d5-f5f4-43c4-94ec-eb0188b183a4.TID128.tmp
[2025-07-19T21:02:26.037+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/162/.1.delta.4e4fb3f1-0b80-431e-85e2-750863ebaef6.TID126.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/162/1.delta
[2025-07-19T21:02:26.037+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=162),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/162] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/162/1.delta
[2025-07-19T21:02:26.037+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 162 (task 126, attempt 0, stage 5.0)
[2025-07-19T21:02:26.039+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 159 (task 123, attempt 0, stage 5.0)
[2025-07-19T21:02:26.040+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.040+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 159.0 in stage 5.0 (TID 123). 9300 bytes result sent to driver
[2025-07-19T21:02:26.043+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 175.0 in stage 5.0 (TID 132) (8b44f3d35cfa, executor driver, partition 175, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.043+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 159.0 in stage 5.0 (TID 123) in 164 ms on 8b44f3d35cfa (executor driver) (114/200)
[2025-07-19T21:02:26.043+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 175.0 in stage 5.0 (TID 132)
[2025-07-19T21:02:26.047+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19093d8
[2025-07-19T21:02:26.047+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=174, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.048+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=174),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/174] for update
[2025-07-19T21:02:26.051+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/168/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/168/.1.delta.0c1c2178-a6d9-46cb-b1e7-707d3241b971.TID129.tmp
[2025-07-19T21:02:26.052+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.053+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.053+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/161/.1.delta.17668431-998e-49fa-8c92-77c79823129e.TID125.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/161/1.delta
[2025-07-19T21:02:26.054+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=161),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/161] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/161/1.delta
[2025-07-19T21:02:26.054+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 161 (task 125, attempt 0, stage 5.0)
[2025-07-19T21:02:26.054+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.068+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/169/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/169/.1.delta.b79fdf66-c29b-43c7-be31-05bd3e99ca40.TID130.tmp
[2025-07-19T21:02:26.072+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2acadacc
[2025-07-19T21:02:26.073+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=175, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.074+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=175),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/175] for update
[2025-07-19T21:02:26.079+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/174/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/174/.1.delta.9929105d-4f62-436b-b04f-9c088461ad6e.TID131.tmp
[2025-07-19T21:02:26.083+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/165/.1.delta.b7e96d78-5579-4825-bc92-f67830829111.TID127.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/165/1.delta
[2025-07-19T21:02:26.083+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=165),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/165] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/165/1.delta
[2025-07-19T21:02:26.084+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.088+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 165 (task 127, attempt 0, stage 5.0)
[2025-07-19T21:02:26.091+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 162 (task 126, attempt 0, stage 5.0)
[2025-07-19T21:02:26.092+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 162.0 in stage 5.0 (TID 126). 9310 bytes result sent to driver
[2025-07-19T21:02:26.095+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 176.0 in stage 5.0 (TID 133) (8b44f3d35cfa, executor driver, partition 176, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.096+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 176.0 in stage 5.0 (TID 133)
[2025-07-19T21:02:26.097+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 162.0 in stage 5.0 (TID 126) in 150 ms on 8b44f3d35cfa (executor driver) (115/200)
[2025-07-19T21:02:26.098+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 161 (task 125, attempt 0, stage 5.0)
[2025-07-19T21:02:26.098+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 161.0 in stage 5.0 (TID 125). 9287 bytes result sent to driver
[2025-07-19T21:02:26.101+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 178.0 in stage 5.0 (TID 134) (8b44f3d35cfa, executor driver, partition 178, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.108+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 178.0 in stage 5.0 (TID 134)
[2025-07-19T21:02:26.109+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.109+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:26.109+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/175/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/175/.1.delta.fa464c4f-f6cb-4c96-8cd3-cc6159d8ef8b.TID132.tmp
[2025-07-19T21:02:26.111+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 161.0 in stage 5.0 (TID 125) in 190 ms on 8b44f3d35cfa (executor driver) (116/200)
[2025-07-19T21:02:26.116+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@26048236
[2025-07-19T21:02:26.116+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=176, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.117+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=176),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/176] for update
[2025-07-19T21:02:26.118+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.118+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.123+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.124+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/166/.1.delta.568453d5-f5f4-43c4-94ec-eb0188b183a4.TID128.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/166/1.delta
[2025-07-19T21:02:26.126+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=166),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/166] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/166/1.delta
[2025-07-19T21:02:26.128+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 166 (task 128, attempt 0, stage 5.0)
[2025-07-19T21:02:26.129+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@426fef1e
[2025-07-19T21:02:26.130+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=178, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.130+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=178),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/178] for update
[2025-07-19T21:02:26.131+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 165 (task 127, attempt 0, stage 5.0)
[2025-07-19T21:02:26.132+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 165.0 in stage 5.0 (TID 127). 9300 bytes result sent to driver
[2025-07-19T21:02:26.134+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/168/.1.delta.0c1c2178-a6d9-46cb-b1e7-707d3241b971.TID129.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/168/1.delta
[2025-07-19T21:02:26.135+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=168),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/168] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/168/1.delta
[2025-07-19T21:02:26.138+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.138+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 168 (task 129, attempt 0, stage 5.0)
[2025-07-19T21:02:26.139+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 179.0 in stage 5.0 (TID 135) (8b44f3d35cfa, executor driver, partition 179, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.140+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 165.0 in stage 5.0 (TID 127) in 188 ms on 8b44f3d35cfa (executor driver) (117/200)
[2025-07-19T21:02:26.142+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 179.0 in stage 5.0 (TID 135)
[2025-07-19T21:02:26.143+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.143+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/174/.1.delta.9929105d-4f62-436b-b04f-9c088461ad6e.TID131.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/174/1.delta
[2025-07-19T21:02:26.144+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.145+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=174),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/174] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/174/1.delta
[2025-07-19T21:02:26.147+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/169/.1.delta.b79fdf66-c29b-43c7-be31-05bd3e99ca40.TID130.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/169/1.delta
[2025-07-19T21:02:26.147+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=169),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/169] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/169/1.delta
[2025-07-19T21:02:26.147+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 169 (task 130, attempt 0, stage 5.0)
[2025-07-19T21:02:26.147+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 174 (task 131, attempt 0, stage 5.0)
[2025-07-19T21:02:26.148+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/176/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/176/.1.delta.0151ee07-3076-4cfe-b845-9b60a289e577.TID133.tmp
[2025-07-19T21:02:26.152+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/178/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/178/.1.delta.522c7536-ae31-422a-802d-e42b1ce49e42.TID134.tmp
[2025-07-19T21:02:26.155+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 166 (task 128, attempt 0, stage 5.0)
[2025-07-19T21:02:26.156+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c72c5b4
[2025-07-19T21:02:26.156+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 166.0 in stage 5.0 (TID 128). 9294 bytes result sent to driver
[2025-07-19T21:02:26.157+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=179, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.158+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=179),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/179] for update
[2025-07-19T21:02:26.158+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 182.0 in stage 5.0 (TID 136) (8b44f3d35cfa, executor driver, partition 182, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.160+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 166.0 in stage 5.0 (TID 128) in 179 ms on 8b44f3d35cfa (executor driver) (118/200)
[2025-07-19T21:02:26.161+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 182.0 in stage 5.0 (TID 136)
[2025-07-19T21:02:26.162+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.164+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/175/.1.delta.fa464c4f-f6cb-4c96-8cd3-cc6159d8ef8b.TID132.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/175/1.delta
[2025-07-19T21:02:26.164+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=175),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/175] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/175/1.delta
[2025-07-19T21:02:26.170+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 175 (task 132, attempt 0, stage 5.0)
[2025-07-19T21:02:26.176+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.177+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:26.181+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 169 (task 130, attempt 0, stage 5.0)
[2025-07-19T21:02:26.183+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 174 (task 131, attempt 0, stage 5.0)
[2025-07-19T21:02:26.184+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 169.0 in stage 5.0 (TID 130). 9300 bytes result sent to driver
[2025-07-19T21:02:26.186+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 183.0 in stage 5.0 (TID 137) (8b44f3d35cfa, executor driver, partition 183, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.186+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 174.0 in stage 5.0 (TID 131). 9348 bytes result sent to driver
[2025-07-19T21:02:26.187+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 184.0 in stage 5.0 (TID 138) (8b44f3d35cfa, executor driver, partition 184, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.188+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 174.0 in stage 5.0 (TID 131) in 179 ms on 8b44f3d35cfa (executor driver) (119/200)
[2025-07-19T21:02:26.188+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 169.0 in stage 5.0 (TID 130) in 188 ms on 8b44f3d35cfa (executor driver) (120/200)
[2025-07-19T21:02:26.189+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 183.0 in stage 5.0 (TID 137)
[2025-07-19T21:02:26.189+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 184.0 in stage 5.0 (TID 138)
[2025-07-19T21:02:26.190+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 168 (task 129, attempt 0, stage 5.0)
[2025-07-19T21:02:26.193+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 168.0 in stage 5.0 (TID 129). 9294 bytes result sent to driver
[2025-07-19T21:02:26.194+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 175 (task 132, attempt 0, stage 5.0)
[2025-07-19T21:02:26.194+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 185.0 in stage 5.0 (TID 139) (8b44f3d35cfa, executor driver, partition 185, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.194+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 175.0 in stage 5.0 (TID 132). 9287 bytes result sent to driver
[2025-07-19T21:02:26.194+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 168.0 in stage 5.0 (TID 129) in 193 ms on 8b44f3d35cfa (executor driver) (121/200)
[2025-07-19T21:02:26.195+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.195+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.196+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.197+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.198+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 185.0 in stage 5.0 (TID 139)
[2025-07-19T21:02:26.198+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 187.0 in stage 5.0 (TID 140) (8b44f3d35cfa, executor driver, partition 187, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.198+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 187.0 in stage 5.0 (TID 140)
[2025-07-19T21:02:26.199+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/179/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/179/.1.delta.0845cbcb-5d7f-4ac8-ab9f-19177f8b2b51.TID135.tmp
[2025-07-19T21:02:26.199+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 175.0 in stage 5.0 (TID 132) in 153 ms on 8b44f3d35cfa (executor driver) (122/200)
[2025-07-19T21:02:26.200+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/176/.1.delta.0151ee07-3076-4cfe-b845-9b60a289e577.TID133.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/176/1.delta
[2025-07-19T21:02:26.200+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e90720a
[2025-07-19T21:02:26.200+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=176),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/176] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/176/1.delta
[2025-07-19T21:02:26.201+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=182, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.201+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 176 (task 133, attempt 0, stage 5.0)
[2025-07-19T21:02:26.201+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=182),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/182] for update
[2025-07-19T21:02:26.201+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.201+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.201+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.201+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.202+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.207+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d7b88b
[2025-07-19T21:02:26.208+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=187, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.209+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=187),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/187] for update
[2025-07-19T21:02:26.210+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.214+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/182/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/182/.1.delta.45ae9920-f9c3-4b94-b1f1-0bc83a37952d.TID136.tmp
[2025-07-19T21:02:26.215+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@15a8acca
[2025-07-19T21:02:26.216+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=184, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.217+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=184),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/184] for update
[2025-07-19T21:02:26.217+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/178/.1.delta.522c7536-ae31-422a-802d-e42b1ce49e42.TID134.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/178/1.delta
[2025-07-19T21:02:26.218+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=178),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/178] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/178/1.delta
[2025-07-19T21:02:26.219+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 178 (task 134, attempt 0, stage 5.0)
[2025-07-19T21:02:26.219+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.219+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 176 (task 133, attempt 0, stage 5.0)
[2025-07-19T21:02:26.222+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 176.0 in stage 5.0 (TID 133). 9303 bytes result sent to driver
[2025-07-19T21:02:26.223+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/187/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/187/.1.delta.8dbb8927-06e6-4dae-bb7c-e3c9744a30f9.TID140.tmp
[2025-07-19T21:02:26.228+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 188.0 in stage 5.0 (TID 141) (8b44f3d35cfa, executor driver, partition 188, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.228+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 188.0 in stage 5.0 (TID 141)
[2025-07-19T21:02:26.229+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 176.0 in stage 5.0 (TID 133) in 133 ms on 8b44f3d35cfa (executor driver) (123/200)
[2025-07-19T21:02:26.229+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.229+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.229+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a16ef57
[2025-07-19T21:02:26.230+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=183, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.230+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=183),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/183] for update
[2025-07-19T21:02:26.233+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.234+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/184/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/184/.1.delta.5281c5e0-92f6-4085-9c6d-2525bffb26b0.TID138.tmp
[2025-07-19T21:02:26.237+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22034478
[2025-07-19T21:02:26.238+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=188, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.238+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=188),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/188] for update
[2025-07-19T21:02:26.242+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 178 (task 134, attempt 0, stage 5.0)
[2025-07-19T21:02:26.244+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 178.0 in stage 5.0 (TID 134). 9307 bytes result sent to driver
[2025-07-19T21:02:26.244+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.246+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/183/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/183/.1.delta.f1ef042c-09aa-43a9-9401-08a65d0bfd04.TID137.tmp
[2025-07-19T21:02:26.247+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 191.0 in stage 5.0 (TID 142) (8b44f3d35cfa, executor driver, partition 191, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.247+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 191.0 in stage 5.0 (TID 142)
[2025-07-19T21:02:26.251+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 178.0 in stage 5.0 (TID 134) in 145 ms on 8b44f3d35cfa (executor driver) (124/200)
[2025-07-19T21:02:26.256+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5bb9fa59
[2025-07-19T21:02:26.258+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=185, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.259+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/179/.1.delta.0845cbcb-5d7f-4ac8-ab9f-19177f8b2b51.TID135.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/179/1.delta
[2025-07-19T21:02:26.260+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=179),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/179] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/179/1.delta
[2025-07-19T21:02:26.262+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 1 (539.0 B) non-empty blocks including 1 (539.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.263+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=185),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/185] for update
[2025-07-19T21:02:26.263+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.263+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 179 (task 135, attempt 0, stage 5.0)
[2025-07-19T21:02:26.264+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.269+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53f32127
[2025-07-19T21:02:26.274+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=191, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.276+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=191),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/191] for update
[2025-07-19T21:02:26.277+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.278+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/188/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/188/.1.delta.64d63345-6093-419c-a885-51414011cf47.TID141.tmp
[2025-07-19T21:02:26.279+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/185/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/185/.1.delta.f6e684a5-d7ff-46ca-9a76-91c4cb90e5f7.TID139.tmp
[2025-07-19T21:02:26.279+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/182/.1.delta.45ae9920-f9c3-4b94-b1f1-0bc83a37952d.TID136.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/182/1.delta
[2025-07-19T21:02:26.280+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=182),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/182] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/182/1.delta
[2025-07-19T21:02:26.280+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 182 (task 136, attempt 0, stage 5.0)
[2025-07-19T21:02:26.280+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/187/.1.delta.8dbb8927-06e6-4dae-bb7c-e3c9744a30f9.TID140.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/187/1.delta
[2025-07-19T21:02:26.280+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=187),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/187] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/187/1.delta
[2025-07-19T21:02:26.280+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 187 (task 140, attempt 0, stage 5.0)
[2025-07-19T21:02:26.285+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 179 (task 135, attempt 0, stage 5.0)
[2025-07-19T21:02:26.287+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 179.0 in stage 5.0 (TID 135). 9304 bytes result sent to driver
[2025-07-19T21:02:26.288+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 194.0 in stage 5.0 (TID 143) (8b44f3d35cfa, executor driver, partition 194, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.289+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 194.0 in stage 5.0 (TID 143)
[2025-07-19T21:02:26.289+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 179.0 in stage 5.0 (TID 135) in 154 ms on 8b44f3d35cfa (executor driver) (125/200)
[2025-07-19T21:02:26.292+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.294+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.295+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/191/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/191/.1.delta.6101dc83-0b4d-4d76-a501-2c705d7b4cfa.TID142.tmp
[2025-07-19T21:02:26.300+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@14e47e7
[2025-07-19T21:02:26.303+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=194, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.304+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=194),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/194] for update
[2025-07-19T21:02:26.306+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.308+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/184/.1.delta.5281c5e0-92f6-4085-9c6d-2525bffb26b0.TID138.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/184/1.delta
[2025-07-19T21:02:26.311+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=184),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/184] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/184/1.delta
[2025-07-19T21:02:26.315+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 182 (task 136, attempt 0, stage 5.0)
[2025-07-19T21:02:26.316+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 184 (task 138, attempt 0, stage 5.0)
[2025-07-19T21:02:26.317+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 182.0 in stage 5.0 (TID 136). 9306 bytes result sent to driver
[2025-07-19T21:02:26.317+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 196.0 in stage 5.0 (TID 144) (8b44f3d35cfa, executor driver, partition 196, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.320+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 187 (task 140, attempt 0, stage 5.0)
[2025-07-19T21:02:26.322+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 187.0 in stage 5.0 (TID 140). 9300 bytes result sent to driver
[2025-07-19T21:02:26.322+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 197.0 in stage 5.0 (TID 145) (8b44f3d35cfa, executor driver, partition 197, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.323+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 196.0 in stage 5.0 (TID 144)
[2025-07-19T21:02:26.323+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 187.0 in stage 5.0 (TID 140) in 127 ms on 8b44f3d35cfa (executor driver) (126/200)
[2025-07-19T21:02:26.323+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 182.0 in stage 5.0 (TID 136) in 165 ms on 8b44f3d35cfa (executor driver) (127/200)
[2025-07-19T21:02:26.324+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 197.0 in stage 5.0 (TID 145)
[2025-07-19T21:02:26.324+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.324+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.326+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.326+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.327+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/183/.1.delta.f1ef042c-09aa-43a9-9401-08a65d0bfd04.TID137.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/183/1.delta
[2025-07-19T21:02:26.328+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=183),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/183] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/183/1.delta
[2025-07-19T21:02:26.328+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 183 (task 137, attempt 0, stage 5.0)
[2025-07-19T21:02:26.331+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/194/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/194/.1.delta.3e70d17b-532e-438f-9efc-3a3b3855a28c.TID143.tmp
[2025-07-19T21:02:26.335+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 184 (task 138, attempt 0, stage 5.0)
[2025-07-19T21:02:26.336+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@72782e83
[2025-07-19T21:02:26.336+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 184.0 in stage 5.0 (TID 138). 9291 bytes result sent to driver
[2025-07-19T21:02:26.337+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 198.0 in stage 5.0 (TID 146) (8b44f3d35cfa, executor driver, partition 198, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.339+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=196, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.339+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=196),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/196] for update
[2025-07-19T21:02:26.339+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 184.0 in stage 5.0 (TID 138) in 154 ms on 8b44f3d35cfa (executor driver) (128/200)
[2025-07-19T21:02:26.342+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.343+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/188/.1.delta.64d63345-6093-419c-a885-51414011cf47.TID141.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/188/1.delta
[2025-07-19T21:02:26.345+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 198.0 in stage 5.0 (TID 146)
[2025-07-19T21:02:26.345+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=188),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/188] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/188/1.delta
[2025-07-19T21:02:26.346+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 188 (task 141, attempt 0, stage 5.0)
[2025-07-19T21:02:26.349+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.350+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T21:02:26.353+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/185/.1.delta.f6e684a5-d7ff-46ca-9a76-91c4cb90e5f7.TID139.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/185/1.delta
[2025-07-19T21:02:26.353+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=185),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/185] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/185/1.delta
[2025-07-19T21:02:26.354+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 185 (task 139, attempt 0, stage 5.0)
[2025-07-19T21:02:26.357+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3eee53c1
[2025-07-19T21:02:26.359+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=197, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.359+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=197),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/197] for update
[2025-07-19T21:02:26.361+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.362+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/196/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/196/.1.delta.45c8ab5d-64d0-4cdf-a5f6-7ae9ac715a37.TID144.tmp
[2025-07-19T21:02:26.364+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4fbbcfe9
[2025-07-19T21:02:26.367+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 183 (task 137, attempt 0, stage 5.0)
[2025-07-19T21:02:26.367+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 183.0 in stage 5.0 (TID 137). 9291 bytes result sent to driver
[2025-07-19T21:02:26.369+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=198, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.370+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/191/.1.delta.6101dc83-0b4d-4d76-a501-2c705d7b4cfa.TID142.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/191/1.delta
[2025-07-19T21:02:26.370+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=191),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/191] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/191/1.delta
[2025-07-19T21:02:26.370+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=198),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/198] for update
[2025-07-19T21:02:26.371+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 191 (task 142, attempt 0, stage 5.0)
[2025-07-19T21:02:26.372+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 199.0 in stage 5.0 (TID 147) (8b44f3d35cfa, executor driver, partition 199, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.374+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 199.0 in stage 5.0 (TID 147)
[2025-07-19T21:02:26.375+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 183.0 in stage 5.0 (TID 137) in 188 ms on 8b44f3d35cfa (executor driver) (129/200)
[2025-07-19T21:02:26.375+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.376+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.377+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.382+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 188 (task 141, attempt 0, stage 5.0)
[2025-07-19T21:02:26.384+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 188.0 in stage 5.0 (TID 141). 9300 bytes result sent to driver
[2025-07-19T21:02:26.384+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/197/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/197/.1.delta.9fe74699-e565-4bb8-b395-9b1647bbdcd1.TID145.tmp
[2025-07-19T21:02:26.385+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 148) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.386+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 188.0 in stage 5.0 (TID 141) in 161 ms on 8b44f3d35cfa (executor driver) (130/200)
[2025-07-19T21:02:26.386+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 185 (task 139, attempt 0, stage 5.0)
[2025-07-19T21:02:26.386+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 0.0 in stage 5.0 (TID 148)
[2025-07-19T21:02:26.386+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 185.0 in stage 5.0 (TID 139). 9300 bytes result sent to driver
[2025-07-19T21:02:26.386+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 149) (8b44f3d35cfa, executor driver, partition 4, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.386+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.386+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.387+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 4.0 in stage 5.0 (TID 149)
[2025-07-19T21:02:26.387+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 185.0 in stage 5.0 (TID 139) in 196 ms on 8b44f3d35cfa (executor driver) (131/200)
[2025-07-19T21:02:26.391+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b0db79
[2025-07-19T21:02:26.392+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=199, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.392+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=199),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/199] for update
[2025-07-19T21:02:26.393+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.393+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.395+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.399+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/194/.1.delta.3e70d17b-532e-438f-9efc-3a3b3855a28c.TID143.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/194/1.delta
[2025-07-19T21:02:26.400+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=194),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/194] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/194/1.delta
[2025-07-19T21:02:26.400+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 194 (task 143, attempt 0, stage 5.0)
[2025-07-19T21:02:26.400+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/198/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/198/.1.delta.fef3ead0-1fed-4c60-8255-6dde90c53812.TID146.tmp
[2025-07-19T21:02:26.407+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 191 (task 142, attempt 0, stage 5.0)
[2025-07-19T21:02:26.409+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 191.0 in stage 5.0 (TID 142). 9306 bytes result sent to driver
[2025-07-19T21:02:26.410+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 9.0 in stage 5.0 (TID 150) (8b44f3d35cfa, executor driver, partition 9, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.412+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/199/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/199/.1.delta.d3f30737-730b-42ec-a2cf-eb7691e425a5.TID147.tmp
[2025-07-19T21:02:26.413+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 9.0 in stage 5.0 (TID 150)
[2025-07-19T21:02:26.413+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 191.0 in stage 5.0 (TID 142) in 168 ms on 8b44f3d35cfa (executor driver) (132/200)
[2025-07-19T21:02:26.415+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.416+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.417+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/196/.1.delta.45c8ab5d-64d0-4cdf-a5f6-7ae9ac715a37.TID144.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/196/1.delta
[2025-07-19T21:02:26.418+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=196),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/196] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/196/1.delta
[2025-07-19T21:02:26.418+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 196 (task 144, attempt 0, stage 5.0)
[2025-07-19T21:02:26.419+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/0/_metadata/schema using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/0/_metadata/.schema.5ef22917-e523-4f45-b7ad-5a6062b6f807.TID148.tmp
[2025-07-19T21:02:26.422+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 194 (task 143, attempt 0, stage 5.0)
[2025-07-19T21:02:26.423+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 194.0 in stage 5.0 (TID 143). 9293 bytes result sent to driver
[2025-07-19T21:02:26.424+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 21.0 in stage 5.0 (TID 151) (8b44f3d35cfa, executor driver, partition 21, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.424+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 21.0 in stage 5.0 (TID 151)
[2025-07-19T21:02:26.425+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 194.0 in stage 5.0 (TID 143) in 139 ms on 8b44f3d35cfa (executor driver) (133/200)
[2025-07-19T21:02:26.428+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.428+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.437+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/197/.1.delta.9fe74699-e565-4bb8-b395-9b1647bbdcd1.TID145.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/197/1.delta
[2025-07-19T21:02:26.438+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=197),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/197] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/197/1.delta
[2025-07-19T21:02:26.438+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 197 (task 145, attempt 0, stage 5.0)
[2025-07-19T21:02:26.441+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 196 (task 144, attempt 0, stage 5.0)
[2025-07-19T21:02:26.442+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 196.0 in stage 5.0 (TID 144). 9310 bytes result sent to driver
[2025-07-19T21:02:26.443+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 23.0 in stage 5.0 (TID 152) (8b44f3d35cfa, executor driver, partition 23, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.444+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 196.0 in stage 5.0 (TID 144) in 128 ms on 8b44f3d35cfa (executor driver) (134/200)
[2025-07-19T21:02:26.444+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 23.0 in stage 5.0 (TID 152)
[2025-07-19T21:02:26.447+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.447+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:26.448+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/0/_metadata/.schema.5ef22917-e523-4f45-b7ad-5a6062b6f807.TID148.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/0/_metadata/schema
[2025-07-19T21:02:26.449+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ec8b3ff
[2025-07-19T21:02:26.451+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=0, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.452+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/0] for update
[2025-07-19T21:02:26.452+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/198/.1.delta.fef3ead0-1fed-4c60-8255-6dde90c53812.TID146.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/198/1.delta
[2025-07-19T21:02:26.453+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=198),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/198] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/198/1.delta
[2025-07-19T21:02:26.453+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 198 (task 146, attempt 0, stage 5.0)
[2025-07-19T21:02:26.453+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.455+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 197 (task 145, attempt 0, stage 5.0)
[2025-07-19T21:02:26.455+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 197.0 in stage 5.0 (TID 145). 9296 bytes result sent to driver
[2025-07-19T21:02:26.456+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 25.0 in stage 5.0 (TID 153) (8b44f3d35cfa, executor driver, partition 25, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.457+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@51292128
[2025-07-19T21:02:26.457+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=23, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.457+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=23),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/23] for update
[2025-07-19T21:02:26.462+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 197.0 in stage 5.0 (TID 145) in 139 ms on 8b44f3d35cfa (executor driver) (135/200)
[2025-07-19T21:02:26.462+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 25.0 in stage 5.0 (TID 153)
[2025-07-19T21:02:26.462+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.463+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.463+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.463+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/199/.1.delta.d3f30737-730b-42ec-a2cf-eb7691e425a5.TID147.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/199/1.delta
[2025-07-19T21:02:26.463+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=199),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/199] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/199/1.delta
[2025-07-19T21:02:26.463+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 199 (task 147, attempt 0, stage 5.0)
[2025-07-19T21:02:26.463+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7fcd1533
[2025-07-19T21:02:26.465+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=21, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.465+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=21),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/21] for update
[2025-07-19T21:02:26.466+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.468+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/0/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/0/.1.delta.18dd87f8-9ba0-4e4a-a02a-fa0933f97dc3.TID148.tmp
[2025-07-19T21:02:26.468+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/23/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/23/.1.delta.bf6cc7b6-01d7-48d1-9d92-07ebff680e62.TID152.tmp
[2025-07-19T21:02:26.470+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 198 (task 146, attempt 0, stage 5.0)
[2025-07-19T21:02:26.470+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 198.0 in stage 5.0 (TID 146). 9302 bytes result sent to driver
[2025-07-19T21:02:26.471+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 37.0 in stage 5.0 (TID 154) (8b44f3d35cfa, executor driver, partition 37, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.475+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 37.0 in stage 5.0 (TID 154)
[2025-07-19T21:02:26.475+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 198.0 in stage 5.0 (TID 146) in 136 ms on 8b44f3d35cfa (executor driver) (136/200)
[2025-07-19T21:02:26.476+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.476+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.478+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 199 (task 147, attempt 0, stage 5.0)
[2025-07-19T21:02:26.479+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 199.0 in stage 5.0 (TID 147). 9320 bytes result sent to driver
[2025-07-19T21:02:26.479+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 38.0 in stage 5.0 (TID 155) (8b44f3d35cfa, executor driver, partition 38, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.479+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 38.0 in stage 5.0 (TID 155)
[2025-07-19T21:02:26.479+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 199.0 in stage 5.0 (TID 147) in 110 ms on 8b44f3d35cfa (executor driver) (137/200)
[2025-07-19T21:02:26.483+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.483+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63ee8f30
[2025-07-19T21:02:26.484+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.484+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=9, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.484+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/9] for update
[2025-07-19T21:02:26.486+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.487+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/21/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/21/.1.delta.c98d5bd8-1310-440b-8679-5a6c9d656116.TID151.tmp
[2025-07-19T21:02:26.489+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@44a09eb7
[2025-07-19T21:02:26.490+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=4, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.490+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/4] for update
[2025-07-19T21:02:26.492+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.499+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@44f99fa3
[2025-07-19T21:02:26.500+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=38, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.500+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=38),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/38] for update
[2025-07-19T21:02:26.501+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/23/.1.delta.bf6cc7b6-01d7-48d1-9d92-07ebff680e62.TID152.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/23/1.delta
[2025-07-19T21:02:26.501+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=23),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/23] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/23/1.delta
[2025-07-19T21:02:26.503+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 23 (task 152, attempt 0, stage 5.0)
[2025-07-19T21:02:26.504+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/9/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/9/.1.delta.21496500-5f2e-4bdf-ae4a-36e754fdd520.TID150.tmp
[2025-07-19T21:02:26.504+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e679b21
[2025-07-19T21:02:26.504+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=37, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.505+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=37),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/37] for update
[2025-07-19T21:02:26.506+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/0/.1.delta.18dd87f8-9ba0-4e4a-a02a-fa0933f97dc3.TID148.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/0/1.delta
[2025-07-19T21:02:26.506+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/0] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/0/1.delta
[2025-07-19T21:02:26.507+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 148, attempt 0, stage 5.0)
[2025-07-19T21:02:26.507+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.510+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@57380922
[2025-07-19T21:02:26.511+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=25, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.511+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=25),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/25] for update
[2025-07-19T21:02:26.512+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.512+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.513+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/4/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/4/.1.delta.07c49cd7-2698-4d70-964c-deee506c33ac.TID149.tmp
[2025-07-19T21:02:26.514+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 23 (task 152, attempt 0, stage 5.0)
[2025-07-19T21:02:26.515+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 0 (task 148, attempt 0, stage 5.0)
[2025-07-19T21:02:26.516+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 0.0 in stage 5.0 (TID 148). 6243 bytes result sent to driver
[2025-07-19T21:02:26.517+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 23.0 in stage 5.0 (TID 152). 6286 bytes result sent to driver
[2025-07-19T21:02:26.517+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/38/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/38/.1.delta.a1ed7b7e-87d4-4b56-a350-d1f73c933460.TID155.tmp
[2025-07-19T21:02:26.517+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 43.0 in stage 5.0 (TID 156) (8b44f3d35cfa, executor driver, partition 43, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.518+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 43.0 in stage 5.0 (TID 156)
[2025-07-19T21:02:26.519+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 23.0 in stage 5.0 (TID 152) in 75 ms on 8b44f3d35cfa (executor driver) (138/200)
[2025-07-19T21:02:26.520+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 45.0 in stage 5.0 (TID 157) (8b44f3d35cfa, executor driver, partition 45, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.520+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.521+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.522+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 45.0 in stage 5.0 (TID 157)
[2025-07-19T21:02:26.525+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.526+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.527+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 148) in 143 ms on 8b44f3d35cfa (executor driver) (139/200)
[2025-07-19T21:02:26.527+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/37/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/37/.1.delta.d4d42e57-d0c3-45d9-8775-449603ac0ce5.TID154.tmp
[2025-07-19T21:02:26.528+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/25/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/25/.1.delta.427903c6-1eb6-4f9b-8a2b-75b9bc07329b.TID153.tmp
[2025-07-19T21:02:26.530+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/21/.1.delta.c98d5bd8-1310-440b-8679-5a6c9d656116.TID151.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/21/1.delta
[2025-07-19T21:02:26.530+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=21),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/21] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/21/1.delta
[2025-07-19T21:02:26.531+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 21 (task 151, attempt 0, stage 5.0)
[2025-07-19T21:02:26.531+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f309306
[2025-07-19T21:02:26.533+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=43, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.533+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=43),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/43] for update
[2025-07-19T21:02:26.535+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.538+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 21 (task 151, attempt 0, stage 5.0)
[2025-07-19T21:02:26.540+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 21.0 in stage 5.0 (TID 151). 6243 bytes result sent to driver
[2025-07-19T21:02:26.541+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 50.0 in stage 5.0 (TID 158) (8b44f3d35cfa, executor driver, partition 50, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.541+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 21.0 in stage 5.0 (TID 151) in 117 ms on 8b44f3d35cfa (executor driver) (140/200)
[2025-07-19T21:02:26.541+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 50.0 in stage 5.0 (TID 158)
[2025-07-19T21:02:26.555+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/4/.1.delta.07c49cd7-2698-4d70-964c-deee506c33ac.TID149.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/4/1.delta
[2025-07-19T21:02:26.555+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/4] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/4/1.delta
[2025-07-19T21:02:26.558+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.559+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.559+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68a3e18d
[2025-07-19T21:02:26.560+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 4 (task 149, attempt 0, stage 5.0)
[2025-07-19T21:02:26.560+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=45, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.561+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=45),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/45] for update
[2025-07-19T21:02:26.561+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.562+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/43/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/43/.1.delta.6850127f-93e5-4229-ae58-2455d572149b.TID156.tmp
[2025-07-19T21:02:26.563+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/38/.1.delta.a1ed7b7e-87d4-4b56-a350-d1f73c933460.TID155.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/38/1.delta
[2025-07-19T21:02:26.563+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=38),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/38] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/38/1.delta
[2025-07-19T21:02:26.564+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@60c72fc7
[2025-07-19T21:02:26.564+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 38 (task 155, attempt 0, stage 5.0)
[2025-07-19T21:02:26.564+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 4 (task 149, attempt 0, stage 5.0)
[2025-07-19T21:02:26.564+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/9/.1.delta.21496500-5f2e-4bdf-ae4a-36e754fdd520.TID150.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/9/1.delta
[2025-07-19T21:02:26.564+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/9] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/9/1.delta
[2025-07-19T21:02:26.565+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=50, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.565+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 4.0 in stage 5.0 (TID 149). 6243 bytes result sent to driver
[2025-07-19T21:02:26.566+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 9 (task 150, attempt 0, stage 5.0)
[2025-07-19T21:02:26.566+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 52.0 in stage 5.0 (TID 159) (8b44f3d35cfa, executor driver, partition 52, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.567+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=50),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/50] for update
[2025-07-19T21:02:26.567+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 149) in 179 ms on 8b44f3d35cfa (executor driver) (141/200)
[2025-07-19T21:02:26.568+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 52.0 in stage 5.0 (TID 159)
[2025-07-19T21:02:26.568+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.570+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.571+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.572+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 38 (task 155, attempt 0, stage 5.0)
[2025-07-19T21:02:26.572+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 9 (task 150, attempt 0, stage 5.0)
[2025-07-19T21:02:26.572+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 9.0 in stage 5.0 (TID 150). 6243 bytes result sent to driver
[2025-07-19T21:02:26.572+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 38.0 in stage 5.0 (TID 155). 6243 bytes result sent to driver
[2025-07-19T21:02:26.574+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 53.0 in stage 5.0 (TID 160) (8b44f3d35cfa, executor driver, partition 53, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.575+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 53.0 in stage 5.0 (TID 160)
[2025-07-19T21:02:26.576+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 56.0 in stage 5.0 (TID 161) (8b44f3d35cfa, executor driver, partition 56, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.576+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 9.0 in stage 5.0 (TID 150) in 165 ms on 8b44f3d35cfa (executor driver) (142/200)
[2025-07-19T21:02:26.576+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 38.0 in stage 5.0 (TID 155) in 96 ms on 8b44f3d35cfa (executor driver) (143/200)
[2025-07-19T21:02:26.578+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 56.0 in stage 5.0 (TID 161)
[2025-07-19T21:02:26.583+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.584+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.584+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2fc65177
[2025-07-19T21:02:26.585+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.585+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.586+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=52, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.586+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=52),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/52] for update
[2025-07-19T21:02:26.588+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.590+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/45/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/45/.1.delta.ca2d4423-5f2e-4e64-a944-e5a89ec6cd3d.TID157.tmp
[2025-07-19T21:02:26.591+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/50/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/50/.1.delta.22753be9-a1db-4be2-85c1-0cea9a9bee2c.TID158.tmp
[2025-07-19T21:02:26.602+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53971e30
[2025-07-19T21:02:26.603+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=56, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.603+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=56),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/56] for update
[2025-07-19T21:02:26.603+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.616+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@64a13bb7
[2025-07-19T21:02:26.617+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=53, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.617+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/25/.1.delta.427903c6-1eb6-4f9b-8a2b-75b9bc07329b.TID153.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/25/1.delta
[2025-07-19T21:02:26.618+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=53),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/53] for update
[2025-07-19T21:02:26.618+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=25),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/25] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/25/1.delta
[2025-07-19T21:02:26.618+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/56/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/56/.1.delta.292e815b-c915-4954-ba24-e5aa9ac60abc.TID161.tmp
[2025-07-19T21:02:26.618+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/37/.1.delta.d4d42e57-d0c3-45d9-8775-449603ac0ce5.TID154.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/37/1.delta
[2025-07-19T21:02:26.618+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 25 (task 153, attempt 0, stage 5.0)
[2025-07-19T21:02:26.618+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/52/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/52/.1.delta.7579740d-1376-4bc3-8416-a0171fa172cb.TID159.tmp
[2025-07-19T21:02:26.618+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=37),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/37] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/37/1.delta
[2025-07-19T21:02:26.618+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 37 (task 154, attempt 0, stage 5.0)
[2025-07-19T21:02:26.619+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.620+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 25 (task 153, attempt 0, stage 5.0)
[2025-07-19T21:02:26.622+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 25.0 in stage 5.0 (TID 153). 6243 bytes result sent to driver
[2025-07-19T21:02:26.625+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 59.0 in stage 5.0 (TID 162) (8b44f3d35cfa, executor driver, partition 59, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.627+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 59.0 in stage 5.0 (TID 162)
[2025-07-19T21:02:26.628+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 25.0 in stage 5.0 (TID 153) in 173 ms on 8b44f3d35cfa (executor driver) (144/200)
[2025-07-19T21:02:26.630+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/53/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/53/.1.delta.8b2ab1b3-cb94-4a2d-a636-0f6130d519fe.TID160.tmp
[2025-07-19T21:02:26.630+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 37 (task 154, attempt 0, stage 5.0)
[2025-07-19T21:02:26.631+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/43/.1.delta.6850127f-93e5-4229-ae58-2455d572149b.TID156.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/43/1.delta
[2025-07-19T21:02:26.633+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=43),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/43] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/43/1.delta
[2025-07-19T21:02:26.634+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.635+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:26.637+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 37.0 in stage 5.0 (TID 154). 6286 bytes result sent to driver
[2025-07-19T21:02:26.637+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 43 (task 156, attempt 0, stage 5.0)
[2025-07-19T21:02:26.638+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 61.0 in stage 5.0 (TID 163) (8b44f3d35cfa, executor driver, partition 61, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.638+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 61.0 in stage 5.0 (TID 163)
[2025-07-19T21:02:26.640+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 37.0 in stage 5.0 (TID 154) in 167 ms on 8b44f3d35cfa (executor driver) (145/200)
[2025-07-19T21:02:26.641+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/45/.1.delta.ca2d4423-5f2e-4e64-a944-e5a89ec6cd3d.TID157.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/45/1.delta
[2025-07-19T21:02:26.642+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 43 (task 156, attempt 0, stage 5.0)
[2025-07-19T21:02:26.643+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.644+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:26.644+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=45),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/45] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/45/1.delta
[2025-07-19T21:02:26.644+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 43.0 in stage 5.0 (TID 156). 6243 bytes result sent to driver
[2025-07-19T21:02:26.644+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 65.0 in stage 5.0 (TID 164) (8b44f3d35cfa, executor driver, partition 65, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.645+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 45 (task 157, attempt 0, stage 5.0)
[2025-07-19T21:02:26.645+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@106e32c
[2025-07-19T21:02:26.645+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 43.0 in stage 5.0 (TID 156) in 129 ms on 8b44f3d35cfa (executor driver) (146/200)
[2025-07-19T21:02:26.646+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=59, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.646+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=59),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/59] for update
[2025-07-19T21:02:26.647+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 65.0 in stage 5.0 (TID 164)
[2025-07-19T21:02:26.649+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63311962
[2025-07-19T21:02:26.650+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=61, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.650+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=61),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/61] for update
[2025-07-19T21:02:26.652+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.652+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.652+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.652+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.658+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d2c740a
[2025-07-19T21:02:26.659+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 45 (task 157, attempt 0, stage 5.0)
[2025-07-19T21:02:26.660+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=65, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.661+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=65),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/65] for update
[2025-07-19T21:02:26.661+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/50/.1.delta.22753be9-a1db-4be2-85c1-0cea9a9bee2c.TID158.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/50/1.delta
[2025-07-19T21:02:26.661+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=50),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/50] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/50/1.delta
[2025-07-19T21:02:26.662+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/56/.1.delta.292e815b-c915-4954-ba24-e5aa9ac60abc.TID161.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/56/1.delta
[2025-07-19T21:02:26.662+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=56),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/56] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/56/1.delta
[2025-07-19T21:02:26.665+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 50 (task 158, attempt 0, stage 5.0)
[2025-07-19T21:02:26.665+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 45.0 in stage 5.0 (TID 157). 6243 bytes result sent to driver
[2025-07-19T21:02:26.665+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 56 (task 161, attempt 0, stage 5.0)
[2025-07-19T21:02:26.665+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 69.0 in stage 5.0 (TID 165) (8b44f3d35cfa, executor driver, partition 69, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.666+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 45.0 in stage 5.0 (TID 157) in 143 ms on 8b44f3d35cfa (executor driver) (147/200)
[2025-07-19T21:02:26.666+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 69.0 in stage 5.0 (TID 165)
[2025-07-19T21:02:26.666+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/61/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/61/.1.delta.dbde1ccb-1d13-42ff-86ee-025f4293f0ff.TID163.tmp
[2025-07-19T21:02:26.666+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.666+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/52/.1.delta.7579740d-1376-4bc3-8416-a0171fa172cb.TID159.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/52/1.delta
[2025-07-19T21:02:26.666+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=52),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/52] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/52/1.delta
[2025-07-19T21:02:26.666+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/59/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/59/.1.delta.0e3b0aba-9de9-4010-bb66-e20ef9218374.TID162.tmp
[2025-07-19T21:02:26.666+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 52 (task 159, attempt 0, stage 5.0)
[2025-07-19T21:02:26.669+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.669+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.669+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 56 (task 161, attempt 0, stage 5.0)
[2025-07-19T21:02:26.671+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 52 (task 159, attempt 0, stage 5.0)
[2025-07-19T21:02:26.672+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 52.0 in stage 5.0 (TID 159). 6243 bytes result sent to driver
[2025-07-19T21:02:26.672+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 56.0 in stage 5.0 (TID 161). 6243 bytes result sent to driver
[2025-07-19T21:02:26.672+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 70.0 in stage 5.0 (TID 166) (8b44f3d35cfa, executor driver, partition 70, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.673+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 70.0 in stage 5.0 (TID 166)
[2025-07-19T21:02:26.673+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 50 (task 158, attempt 0, stage 5.0)
[2025-07-19T21:02:26.673+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 72.0 in stage 5.0 (TID 167) (8b44f3d35cfa, executor driver, partition 72, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.681+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 72.0 in stage 5.0 (TID 167)
[2025-07-19T21:02:26.683+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 50.0 in stage 5.0 (TID 158). 6286 bytes result sent to driver
[2025-07-19T21:02:26.684+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 52.0 in stage 5.0 (TID 159) in 116 ms on 8b44f3d35cfa (executor driver) (148/200)
[2025-07-19T21:02:26.684+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/53/.1.delta.8b2ab1b3-cb94-4a2d-a636-0f6130d519fe.TID160.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/53/1.delta
[2025-07-19T21:02:26.685+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=53),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/53] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/53/1.delta
[2025-07-19T21:02:26.686+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6dca9441
[2025-07-19T21:02:26.688+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=69, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.690+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 78.0 in stage 5.0 (TID 168) (8b44f3d35cfa, executor driver, partition 78, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.691+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 56.0 in stage 5.0 (TID 161) in 106 ms on 8b44f3d35cfa (executor driver) (149/200)
[2025-07-19T21:02:26.691+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 50.0 in stage 5.0 (TID 158) in 140 ms on 8b44f3d35cfa (executor driver) (150/200)
[2025-07-19T21:02:26.691+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.691+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.692+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 78.0 in stage 5.0 (TID 168)
[2025-07-19T21:02:26.692+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=69),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/69] for update
[2025-07-19T21:02:26.693+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 53 (task 160, attempt 0, stage 5.0)
[2025-07-19T21:02:26.693+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.694+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.695+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.698+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.698+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e64c5ed
[2025-07-19T21:02:26.699+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/65/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/65/.1.delta.b12e9768-2221-4980-9cc9-6d75921d0385.TID164.tmp
[2025-07-19T21:02:26.700+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=70, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.700+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=70),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/70] for update
[2025-07-19T21:02:26.701+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.701+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.701+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 53 (task 160, attempt 0, stage 5.0)
[2025-07-19T21:02:26.702+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 53.0 in stage 5.0 (TID 160). 6243 bytes result sent to driver
[2025-07-19T21:02:26.702+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 81.0 in stage 5.0 (TID 169) (8b44f3d35cfa, executor driver, partition 81, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.703+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@38a4ce8a
[2025-07-19T21:02:26.703+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=72, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.704+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=72),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/72] for update
[2025-07-19T21:02:26.705+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 81.0 in stage 5.0 (TID 169)
[2025-07-19T21:02:26.705+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/70/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/70/.1.delta.911057a7-f231-43a4-888c-dce7a4423f27.TID166.tmp
[2025-07-19T21:02:26.706+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.706+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 53.0 in stage 5.0 (TID 160) in 127 ms on 8b44f3d35cfa (executor driver) (151/200)
[2025-07-19T21:02:26.708+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.708+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/69/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/69/.1.delta.2ad74c14-aa04-41df-9dd9-8c3f5d6788f6.TID165.tmp
[2025-07-19T21:02:26.709+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T21:02:26.709+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@38b4ce70
[2025-07-19T21:02:26.709+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=78, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.710+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=78),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/78] for update
[2025-07-19T21:02:26.711+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.716+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@cbcecdb
[2025-07-19T21:02:26.717+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=81, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.717+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=81),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/81] for update
[2025-07-19T21:02:26.718+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.723+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/72/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/72/.1.delta.a028db30-ba97-42b2-82bd-f1549615f56e.TID167.tmp
[2025-07-19T21:02:26.728+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/78/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/78/.1.delta.6a730b4a-a22f-48ff-9db3-acbc6d0a5be2.TID168.tmp
[2025-07-19T21:02:26.728+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/59/.1.delta.0e3b0aba-9de9-4010-bb66-e20ef9218374.TID162.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/59/1.delta
[2025-07-19T21:02:26.729+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=59),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/59] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/59/1.delta
[2025-07-19T21:02:26.729+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 59 (task 162, attempt 0, stage 5.0)
[2025-07-19T21:02:26.732+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/61/.1.delta.dbde1ccb-1d13-42ff-86ee-025f4293f0ff.TID163.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/61/1.delta
[2025-07-19T21:02:26.734+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=61),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/61] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/61/1.delta
[2025-07-19T21:02:26.734+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 61 (task 163, attempt 0, stage 5.0)
[2025-07-19T21:02:26.738+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 59 (task 162, attempt 0, stage 5.0)
[2025-07-19T21:02:26.742+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/81/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/81/.1.delta.fbb0060c-2933-4766-8b30-7c396e248f91.TID169.tmp
[2025-07-19T21:02:26.743+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/65/.1.delta.b12e9768-2221-4980-9cc9-6d75921d0385.TID164.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/65/1.delta
[2025-07-19T21:02:26.743+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=65),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/65] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/65/1.delta
[2025-07-19T21:02:26.743+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 65 (task 164, attempt 0, stage 5.0)
[2025-07-19T21:02:26.743+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 59.0 in stage 5.0 (TID 162). 6243 bytes result sent to driver
[2025-07-19T21:02:26.744+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 84.0 in stage 5.0 (TID 170) (8b44f3d35cfa, executor driver, partition 84, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.744+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 84.0 in stage 5.0 (TID 170)
[2025-07-19T21:02:26.746+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 59.0 in stage 5.0 (TID 162) in 120 ms on 8b44f3d35cfa (executor driver) (152/200)
[2025-07-19T21:02:26.746+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 61 (task 163, attempt 0, stage 5.0)
[2025-07-19T21:02:26.748+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 61.0 in stage 5.0 (TID 163). 6243 bytes result sent to driver
[2025-07-19T21:02:26.749+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.751+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.753+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 85.0 in stage 5.0 (TID 171) (8b44f3d35cfa, executor driver, partition 85, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.756+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 61.0 in stage 5.0 (TID 163) in 112 ms on 8b44f3d35cfa (executor driver) (153/200)
[2025-07-19T21:02:26.756+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 85.0 in stage 5.0 (TID 171)
[2025-07-19T21:02:26.756+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 65 (task 164, attempt 0, stage 5.0)
[2025-07-19T21:02:26.757+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 65.0 in stage 5.0 (TID 164). 6243 bytes result sent to driver
[2025-07-19T21:02:26.758+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 89.0 in stage 5.0 (TID 172) (8b44f3d35cfa, executor driver, partition 89, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.760+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 65.0 in stage 5.0 (TID 164) in 108 ms on 8b44f3d35cfa (executor driver) (154/200)
[2025-07-19T21:02:26.760+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 89.0 in stage 5.0 (TID 172)
[2025-07-19T21:02:26.760+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.761+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.761+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.763+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.764+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5bf2266d
[2025-07-19T21:02:26.764+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=84, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.764+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=84),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/84] for update
[2025-07-19T21:02:26.764+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/70/.1.delta.911057a7-f231-43a4-888c-dce7a4423f27.TID166.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/70/1.delta
[2025-07-19T21:02:26.764+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=70),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/70] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/70/1.delta
[2025-07-19T21:02:26.764+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.770+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/69/.1.delta.2ad74c14-aa04-41df-9dd9-8c3f5d6788f6.TID165.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/69/1.delta
[2025-07-19T21:02:26.772+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=69),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/69] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/69/1.delta
[2025-07-19T21:02:26.772+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 70 (task 166, attempt 0, stage 5.0)
[2025-07-19T21:02:26.773+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 69 (task 165, attempt 0, stage 5.0)
[2025-07-19T21:02:26.774+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@187dff01
[2025-07-19T21:02:26.776+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=89, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.777+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 69 (task 165, attempt 0, stage 5.0)
[2025-07-19T21:02:26.778+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=89),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/89] for update
[2025-07-19T21:02:26.779+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 69.0 in stage 5.0 (TID 165). 6243 bytes result sent to driver
[2025-07-19T21:02:26.779+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/72/.1.delta.a028db30-ba97-42b2-82bd-f1549615f56e.TID167.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/72/1.delta
[2025-07-19T21:02:26.780+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=72),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/72] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/72/1.delta
[2025-07-19T21:02:26.780+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 69.0 in stage 5.0 (TID 165) in 116 ms on 8b44f3d35cfa (executor driver) (155/200)
[2025-07-19T21:02:26.780+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 72 (task 167, attempt 0, stage 5.0)
[2025-07-19T21:02:26.781+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 91.0 in stage 5.0 (TID 173) (8b44f3d35cfa, executor driver, partition 91, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.783+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 91.0 in stage 5.0 (TID 173)
[2025-07-19T21:02:26.783+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 70 (task 166, attempt 0, stage 5.0)
[2025-07-19T21:02:26.785+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.785+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/84/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/84/.1.delta.f9220710-56a2-4771-bcd4-800ad9700f5c.TID170.tmp
[2025-07-19T21:02:26.786+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 70.0 in stage 5.0 (TID 166). 6243 bytes result sent to driver
[2025-07-19T21:02:26.787+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 94.0 in stage 5.0 (TID 174) (8b44f3d35cfa, executor driver, partition 94, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.787+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 72 (task 167, attempt 0, stage 5.0)
[2025-07-19T21:02:26.787+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 94.0 in stage 5.0 (TID 174)
[2025-07-19T21:02:26.787+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 70.0 in stage 5.0 (TID 166) in 112 ms on 8b44f3d35cfa (executor driver) (156/200)
[2025-07-19T21:02:26.787+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 72.0 in stage 5.0 (TID 167). 6243 bytes result sent to driver
[2025-07-19T21:02:26.787+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 95.0 in stage 5.0 (TID 175) (8b44f3d35cfa, executor driver, partition 95, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.787+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@674e3cec
[2025-07-19T21:02:26.787+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=85, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.787+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 95.0 in stage 5.0 (TID 175)
[2025-07-19T21:02:26.788+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=85),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/85] for update
[2025-07-19T21:02:26.790+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.792+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.792+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.794+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.796+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T21:02:26.796+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 72.0 in stage 5.0 (TID 167) in 119 ms on 8b44f3d35cfa (executor driver) (157/200)
[2025-07-19T21:02:26.796+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.796+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.797+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/78/.1.delta.6a730b4a-a22f-48ff-9db3-acbc6d0a5be2.TID168.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/78/1.delta
[2025-07-19T21:02:26.798+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=78),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/78] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/78/1.delta
[2025-07-19T21:02:26.800+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d95974
[2025-07-19T21:02:26.800+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 78 (task 168, attempt 0, stage 5.0)
[2025-07-19T21:02:26.801+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/89/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/89/.1.delta.f6468d56-da7d-40e7-8fb6-d600d37f6911.TID172.tmp
[2025-07-19T21:02:26.801+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/81/.1.delta.fbb0060c-2933-4766-8b30-7c396e248f91.TID169.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/81/1.delta
[2025-07-19T21:02:26.801+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=81),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/81] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/81/1.delta
[2025-07-19T21:02:26.801+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 81 (task 169, attempt 0, stage 5.0)
[2025-07-19T21:02:26.801+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=91, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.801+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=91),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/91] for update
[2025-07-19T21:02:26.806+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/85/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/85/.1.delta.e2d244fc-b74a-490f-b9f0-248c8b7cf167.TID171.tmp
[2025-07-19T21:02:26.808+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74f393d9
[2025-07-19T21:02:26.809+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 81 (task 169, attempt 0, stage 5.0)
[2025-07-19T21:02:26.810+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=95, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.810+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.811+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=95),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/95] for update
[2025-07-19T21:02:26.811+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 81.0 in stage 5.0 (TID 169). 6243 bytes result sent to driver
[2025-07-19T21:02:26.812+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 98.0 in stage 5.0 (TID 176) (8b44f3d35cfa, executor driver, partition 98, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.812+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 81.0 in stage 5.0 (TID 169) in 113 ms on 8b44f3d35cfa (executor driver) (158/200)
[2025-07-19T21:02:26.813+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 98.0 in stage 5.0 (TID 176)
[2025-07-19T21:02:26.813+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 78 (task 168, attempt 0, stage 5.0)
[2025-07-19T21:02:26.813+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 78.0 in stage 5.0 (TID 168). 6243 bytes result sent to driver
[2025-07-19T21:02:26.813+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 101.0 in stage 5.0 (TID 177) (8b44f3d35cfa, executor driver, partition 101, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.815+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.815+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.816+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 78.0 in stage 5.0 (TID 168) in 132 ms on 8b44f3d35cfa (executor driver) (159/200)
[2025-07-19T21:02:26.818+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 101.0 in stage 5.0 (TID 177)
[2025-07-19T21:02:26.818+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@60b705e3
[2025-07-19T21:02:26.820+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=94, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.823+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/91/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/91/.1.delta.345f88b7-3791-4a1c-b4f9-ca505088991c.TID173.tmp
[2025-07-19T21:02:26.823+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=94),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/94] for update
[2025-07-19T21:02:26.824+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.824+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.825+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.825+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T21:02:26.829+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@46c8e802
[2025-07-19T21:02:26.830+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=98, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.831+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=98),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/98] for update
[2025-07-19T21:02:26.833+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/84/.1.delta.f9220710-56a2-4771-bcd4-800ad9700f5c.TID170.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/84/1.delta
[2025-07-19T21:02:26.834+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=84),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/84] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/84/1.delta
[2025-07-19T21:02:26.834+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.836+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/94/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/94/.1.delta.b6abbb43-4036-4869-b13e-35c43f50e6df.TID174.tmp
[2025-07-19T21:02:26.837+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 84 (task 170, attempt 0, stage 5.0)
[2025-07-19T21:02:26.843+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/95/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/95/.1.delta.c008c229-032f-4fda-82b4-82b490cd625f.TID175.tmp
[2025-07-19T21:02:26.846+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ab91392
[2025-07-19T21:02:26.847+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=101, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.849+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=101),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/101] for update
[2025-07-19T21:02:26.854+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/98/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/98/.1.delta.81688004-0cc5-435d-ace5-b329a0778730.TID176.tmp
[2025-07-19T21:02:26.856+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/89/.1.delta.f6468d56-da7d-40e7-8fb6-d600d37f6911.TID172.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/89/1.delta
[2025-07-19T21:02:26.857+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=89),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/89] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/89/1.delta
[2025-07-19T21:02:26.860+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/85/.1.delta.e2d244fc-b74a-490f-b9f0-248c8b7cf167.TID171.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/85/1.delta
[2025-07-19T21:02:26.860+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=85),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/85] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/85/1.delta
[2025-07-19T21:02:26.861+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 85 (task 171, attempt 0, stage 5.0)
[2025-07-19T21:02:26.862+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.862+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 89 (task 172, attempt 0, stage 5.0)
[2025-07-19T21:02:26.867+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 89 (task 172, attempt 0, stage 5.0)
[2025-07-19T21:02:26.869+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/91/.1.delta.345f88b7-3791-4a1c-b4f9-ca505088991c.TID173.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/91/1.delta
[2025-07-19T21:02:26.870+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=91),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/91] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/91/1.delta
[2025-07-19T21:02:26.871+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 84 (task 170, attempt 0, stage 5.0)
[2025-07-19T21:02:26.871+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 85 (task 171, attempt 0, stage 5.0)
[2025-07-19T21:02:26.877+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 84.0 in stage 5.0 (TID 170). 6286 bytes result sent to driver
[2025-07-19T21:02:26.878+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 89.0 in stage 5.0 (TID 172). 6286 bytes result sent to driver
[2025-07-19T21:02:26.878+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 91 (task 173, attempt 0, stage 5.0)
[2025-07-19T21:02:26.884+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 104.0 in stage 5.0 (TID 178) (8b44f3d35cfa, executor driver, partition 104, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.885+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 85.0 in stage 5.0 (TID 171). 6286 bytes result sent to driver
[2025-07-19T21:02:26.885+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 104.0 in stage 5.0 (TID 178)
[2025-07-19T21:02:26.886+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.887+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.888+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 107.0 in stage 5.0 (TID 179) (8b44f3d35cfa, executor driver, partition 107, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.890+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 84.0 in stage 5.0 (TID 170) in 144 ms on 8b44f3d35cfa (executor driver) (160/200)
[2025-07-19T21:02:26.891+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 89.0 in stage 5.0 (TID 172) in 137 ms on 8b44f3d35cfa (executor driver) (161/200)
[2025-07-19T21:02:26.891+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 108.0 in stage 5.0 (TID 180) (8b44f3d35cfa, executor driver, partition 108, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.891+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 107.0 in stage 5.0 (TID 179)
[2025-07-19T21:02:26.891+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 85.0 in stage 5.0 (TID 171) in 142 ms on 8b44f3d35cfa (executor driver) (162/200)
[2025-07-19T21:02:26.891+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/101/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/101/.1.delta.bae55d31-181f-4098-8904-c68c7c79dc3b.TID177.tmp
[2025-07-19T21:02:26.893+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 108.0 in stage 5.0 (TID 180)
[2025-07-19T21:02:26.894+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2288d4c
[2025-07-19T21:02:26.895+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=104, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.895+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=104),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/104] for update
[2025-07-19T21:02:26.895+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.895+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.896+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/95/.1.delta.c008c229-032f-4fda-82b4-82b490cd625f.TID175.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/95/1.delta
[2025-07-19T21:02:26.898+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=95),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/95] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/95/1.delta
[2025-07-19T21:02:26.899+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 95 (task 175, attempt 0, stage 5.0)
[2025-07-19T21:02:26.900+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.900+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.901+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 91 (task 173, attempt 0, stage 5.0)
[2025-07-19T21:02:26.901+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 91.0 in stage 5.0 (TID 173). 6243 bytes result sent to driver
[2025-07-19T21:02:26.902+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:26.902+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 115.0 in stage 5.0 (TID 181) (8b44f3d35cfa, executor driver, partition 115, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.902+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 91.0 in stage 5.0 (TID 173) in 123 ms on 8b44f3d35cfa (executor driver) (163/200)
[2025-07-19T21:02:26.902+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 115.0 in stage 5.0 (TID 181)
[2025-07-19T21:02:26.906+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/94/.1.delta.b6abbb43-4036-4869-b13e-35c43f50e6df.TID174.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/94/1.delta
[2025-07-19T21:02:26.906+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=94),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/94] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/94/1.delta
[2025-07-19T21:02:26.906+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 94 (task 174, attempt 0, stage 5.0)
[2025-07-19T21:02:26.910+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@15f7478e
[2025-07-19T21:02:26.910+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=108, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.911+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=108),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/108] for update
[2025-07-19T21:02:26.911+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.912+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.912+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.913+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 95 (task 175, attempt 0, stage 5.0)
[2025-07-19T21:02:26.913+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 94 (task 174, attempt 0, stage 5.0)
[2025-07-19T21:02:26.913+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 95.0 in stage 5.0 (TID 175). 6243 bytes result sent to driver
[2025-07-19T21:02:26.913+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 94.0 in stage 5.0 (TID 174). 6243 bytes result sent to driver
[2025-07-19T21:02:26.913+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 121.0 in stage 5.0 (TID 182) (8b44f3d35cfa, executor driver, partition 121, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.914+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 122.0 in stage 5.0 (TID 183) (8b44f3d35cfa, executor driver, partition 122, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.914+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/104/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/104/.1.delta.0d2c27b4-1b93-4673-8967-6152773f53f2.TID178.tmp
[2025-07-19T21:02:26.914+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 95.0 in stage 5.0 (TID 175) in 127 ms on 8b44f3d35cfa (executor driver) (164/200)
[2025-07-19T21:02:26.914+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 121.0 in stage 5.0 (TID 182)
[2025-07-19T21:02:26.914+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 122.0 in stage 5.0 (TID 183)
[2025-07-19T21:02:26.915+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 94.0 in stage 5.0 (TID 174) in 130 ms on 8b44f3d35cfa (executor driver) (165/200)
[2025-07-19T21:02:26.917+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.917+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.918+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@36243edb
[2025-07-19T21:02:26.918+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=107, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.918+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/98/.1.delta.81688004-0cc5-435d-ace5-b329a0778730.TID176.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/98/1.delta
[2025-07-19T21:02:26.918+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=107),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/107] for update
[2025-07-19T21:02:26.918+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.919+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:26.921+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=98),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/98] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/98/1.delta
[2025-07-19T21:02:26.921+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.923+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6afb39ec
[2025-07-19T21:02:26.923+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 98 (task 176, attempt 0, stage 5.0)
[2025-07-19T21:02:26.926+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=121, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.927+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=121),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/121] for update
[2025-07-19T21:02:26.928+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/108/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/108/.1.delta.f312a264-cd4f-4742-a4cf-aca26d07d449.TID180.tmp
[2025-07-19T21:02:26.928+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.931+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 98 (task 176, attempt 0, stage 5.0)
[2025-07-19T21:02:26.932+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/101/.1.delta.bae55d31-181f-4098-8904-c68c7c79dc3b.TID177.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/101/1.delta
[2025-07-19T21:02:26.932+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=101),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/101] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/101/1.delta
[2025-07-19T21:02:26.932+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 98.0 in stage 5.0 (TID 176). 6243 bytes result sent to driver
[2025-07-19T21:02:26.933+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 101 (task 177, attempt 0, stage 5.0)
[2025-07-19T21:02:26.933+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 123.0 in stage 5.0 (TID 184) (8b44f3d35cfa, executor driver, partition 123, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.934+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/107/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/107/.1.delta.43b47133-ba6e-4991-a09d-22e2fba09ebd.TID179.tmp
[2025-07-19T21:02:26.936+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 98.0 in stage 5.0 (TID 176) in 127 ms on 8b44f3d35cfa (executor driver) (166/200)
[2025-07-19T21:02:26.937+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 123.0 in stage 5.0 (TID 184)
[2025-07-19T21:02:26.937+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1171b2a1
[2025-07-19T21:02:26.938+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=115, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.938+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=115),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/115] for update
[2025-07-19T21:02:26.939+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 101 (task 177, attempt 0, stage 5.0)
[2025-07-19T21:02:26.940+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 101.0 in stage 5.0 (TID 177). 6243 bytes result sent to driver
[2025-07-19T21:02:26.940+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.941+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.942+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.943+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/121/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/121/.1.delta.ee2cb1e0-846d-4fe7-a08d-da7acc6e3e57.TID182.tmp
[2025-07-19T21:02:26.944+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b2df12f
[2025-07-19T21:02:26.945+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=122, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.945+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 129.0 in stage 5.0 (TID 185) (8b44f3d35cfa, executor driver, partition 129, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.946+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=122),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/122] for update
[2025-07-19T21:02:26.946+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 101.0 in stage 5.0 (TID 177) in 133 ms on 8b44f3d35cfa (executor driver) (167/200)
[2025-07-19T21:02:26.947+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 129.0 in stage 5.0 (TID 185)
[2025-07-19T21:02:26.947+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.951+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.952+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.955+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@9f88e0
[2025-07-19T21:02:26.955+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=123, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.958+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=123),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/123] for update
[2025-07-19T21:02:26.959+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/104/.1.delta.0d2c27b4-1b93-4673-8967-6152773f53f2.TID178.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/104/1.delta
[2025-07-19T21:02:26.959+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=104),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/104] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/104/1.delta
[2025-07-19T21:02:26.960+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.961+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 104 (task 178, attempt 0, stage 5.0)
[2025-07-19T21:02:26.961+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/122/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/122/.1.delta.9f930370-b286-4b44-b2a0-607f209a9b22.TID183.tmp
[2025-07-19T21:02:26.963+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/115/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/115/.1.delta.753f0297-15de-460c-b505-521c1db51bfe.TID181.tmp
[2025-07-19T21:02:26.964+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74017b04
[2025-07-19T21:02:26.964+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=129, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.964+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=129),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/129] for update
[2025-07-19T21:02:26.964+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.971+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 104 (task 178, attempt 0, stage 5.0)
[2025-07-19T21:02:26.972+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 104.0 in stage 5.0 (TID 178). 6243 bytes result sent to driver
[2025-07-19T21:02:26.973+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 132.0 in stage 5.0 (TID 186) (8b44f3d35cfa, executor driver, partition 132, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.973+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 104.0 in stage 5.0 (TID 178) in 89 ms on 8b44f3d35cfa (executor driver) (168/200)
[2025-07-19T21:02:26.975+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 132.0 in stage 5.0 (TID 186)
[2025-07-19T21:02:26.980+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/123/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/123/.1.delta.995a3507-69d2-4c84-b762-e39540287dcc.TID184.tmp
[2025-07-19T21:02:26.983+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:26.984+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:26.985+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/108/.1.delta.f312a264-cd4f-4742-a4cf-aca26d07d449.TID180.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/108/1.delta
[2025-07-19T21:02:26.985+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=108),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/108] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/108/1.delta
[2025-07-19T21:02:26.985+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 108 (task 180, attempt 0, stage 5.0)
[2025-07-19T21:02:26.988+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/129/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/129/.1.delta.498ca210-c621-4c86-b0dd-35b6dc441854.TID185.tmp
[2025-07-19T21:02:26.992+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d34ce06
[2025-07-19T21:02:26.993+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Committed partition 108 (task 180, attempt 0, stage 5.0)
[2025-07-19T21:02:26.994+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Finished task 108.0 in stage 5.0 (TID 180). 6243 bytes result sent to driver
[2025-07-19T21:02:26.994+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Starting task 133.0 in stage 5.0 (TID 187) (8b44f3d35cfa, executor driver, partition 133, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:26.995+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=132, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:26.997+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=132),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/132] for update
[2025-07-19T21:02:26.998+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/107/.1.delta.43b47133-ba6e-4991-a09d-22e2fba09ebd.TID179.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/107/1.delta
[2025-07-19T21:02:26.998+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO TaskSetManager: Finished task 108.0 in stage 5.0 (TID 180) in 106 ms on 8b44f3d35cfa (executor driver) (169/200)
[2025-07-19T21:02:26.998+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=107),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/107] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/107/1.delta
[2025-07-19T21:02:26.998+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO Executor: Running task 133.0 in stage 5.0 (TID 187)
[2025-07-19T21:02:26.998+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:26.998+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO DataWritingSparkTask: Commit authorized for partition 107 (task 179, attempt 0, stage 5.0)
[2025-07-19T21:02:27.001+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/121/.1.delta.ee2cb1e0-846d-4fe7-a08d-da7acc6e3e57.TID182.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/121/1.delta
[2025-07-19T21:02:27.002+0000] {subprocess.py:93} INFO - 25/07/19 21:02:26 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=121),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/121] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/121/1.delta
[2025-07-19T21:02:27.002+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Commit authorized for partition 121 (task 182, attempt 0, stage 5.0)
[2025-07-19T21:02:27.002+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:27.002+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:27.008+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Committed partition 107 (task 179, attempt 0, stage 5.0)
[2025-07-19T21:02:27.009+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Finished task 107.0 in stage 5.0 (TID 179). 6243 bytes result sent to driver
[2025-07-19T21:02:27.010+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Starting task 138.0 in stage 5.0 (TID 188) (8b44f3d35cfa, executor driver, partition 138, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:27.011+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Finished task 107.0 in stage 5.0 (TID 179) in 122 ms on 8b44f3d35cfa (executor driver) (170/200)
[2025-07-19T21:02:27.011+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Running task 138.0 in stage 5.0 (TID 188)
[2025-07-19T21:02:27.012+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Committed partition 121 (task 182, attempt 0, stage 5.0)
[2025-07-19T21:02:27.012+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Finished task 121.0 in stage 5.0 (TID 182). 6243 bytes result sent to driver
[2025-07-19T21:02:27.013+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Starting task 139.0 in stage 5.0 (TID 189) (8b44f3d35cfa, executor driver, partition 139, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:27.014+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Running task 139.0 in stage 5.0 (TID 189)
[2025-07-19T21:02:27.015+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Finished task 121.0 in stage 5.0 (TID 182) in 99 ms on 8b44f3d35cfa (executor driver) (171/200)
[2025-07-19T21:02:27.015+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:27.015+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/132/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/132/.1.delta.60b8718b-85d9-4d94-b6b6-1c3415002149.TID186.tmp
[2025-07-19T21:02:27.015+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:27.015+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:27.015+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@42042979
[2025-07-19T21:02:27.015+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:27.015+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=133, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:27.015+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=133),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/133] for update
[2025-07-19T21:02:27.018+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:27.019+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/115/.1.delta.753f0297-15de-460c-b505-521c1db51bfe.TID181.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/115/1.delta
[2025-07-19T21:02:27.020+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=115),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/115] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/115/1.delta
[2025-07-19T21:02:27.021+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Commit authorized for partition 115 (task 181, attempt 0, stage 5.0)
[2025-07-19T21:02:27.027+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@217bc866
[2025-07-19T21:02:27.028+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=138, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:27.028+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Committed partition 115 (task 181, attempt 0, stage 5.0)
[2025-07-19T21:02:27.028+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Finished task 115.0 in stage 5.0 (TID 181). 6243 bytes result sent to driver
[2025-07-19T21:02:27.028+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=138),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/138] for update
[2025-07-19T21:02:27.032+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Starting task 143.0 in stage 5.0 (TID 190) (8b44f3d35cfa, executor driver, partition 143, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:27.033+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Finished task 115.0 in stage 5.0 (TID 181) in 134 ms on 8b44f3d35cfa (executor driver) (172/200)
[2025-07-19T21:02:27.034+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/133/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/133/.1.delta.1989ea78-1283-41e6-9482-c2c70b5c08cb.TID187.tmp
[2025-07-19T21:02:27.034+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Running task 143.0 in stage 5.0 (TID 190)
[2025-07-19T21:02:27.037+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3e009225
[2025-07-19T21:02:27.037+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:27.038+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:27.038+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:27.040+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=139, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:27.040+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=139),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/139] for update
[2025-07-19T21:02:27.041+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/122/.1.delta.9f930370-b286-4b44-b2a0-607f209a9b22.TID183.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/122/1.delta
[2025-07-19T21:02:27.041+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=122),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/122] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/122/1.delta
[2025-07-19T21:02:27.041+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Commit authorized for partition 122 (task 183, attempt 0, stage 5.0)
[2025-07-19T21:02:27.043+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:27.046+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/129/.1.delta.498ca210-c621-4c86-b0dd-35b6dc441854.TID185.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/129/1.delta
[2025-07-19T21:02:27.047+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=129),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/129] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/129/1.delta
[2025-07-19T21:02:27.047+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Commit authorized for partition 129 (task 185, attempt 0, stage 5.0)
[2025-07-19T21:02:27.047+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/123/.1.delta.995a3507-69d2-4c84-b762-e39540287dcc.TID184.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/123/1.delta
[2025-07-19T21:02:27.048+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=123),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/123] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/123/1.delta
[2025-07-19T21:02:27.049+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1efef793
[2025-07-19T21:02:27.049+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Commit authorized for partition 123 (task 184, attempt 0, stage 5.0)
[2025-07-19T21:02:27.050+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Committed partition 122 (task 183, attempt 0, stage 5.0)
[2025-07-19T21:02:27.050+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Finished task 122.0 in stage 5.0 (TID 183). 6243 bytes result sent to driver
[2025-07-19T21:02:27.051+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=143, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:27.051+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=143),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/143] for update
[2025-07-19T21:02:27.053+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Starting task 146.0 in stage 5.0 (TID 191) (8b44f3d35cfa, executor driver, partition 146, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:27.054+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Finished task 122.0 in stage 5.0 (TID 183) in 139 ms on 8b44f3d35cfa (executor driver) (173/200)
[2025-07-19T21:02:27.054+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Running task 146.0 in stage 5.0 (TID 191)
[2025-07-19T21:02:27.055+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:27.055+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/139/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/139/.1.delta.b003cc87-0c73-4981-9f5d-2b36b75ecbe2.TID189.tmp
[2025-07-19T21:02:27.056+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:27.057+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:27.058+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Committed partition 129 (task 185, attempt 0, stage 5.0)
[2025-07-19T21:02:27.059+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Finished task 129.0 in stage 5.0 (TID 185). 6243 bytes result sent to driver
[2025-07-19T21:02:27.061+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/138/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/138/.1.delta.60cf8301-56c9-4ead-be3d-23810595f987.TID188.tmp
[2025-07-19T21:02:27.062+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Finished task 129.0 in stage 5.0 (TID 185) in 117 ms on 8b44f3d35cfa (executor driver) (174/200)
[2025-07-19T21:02:27.062+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Starting task 150.0 in stage 5.0 (TID 192) (8b44f3d35cfa, executor driver, partition 150, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:27.063+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Running task 150.0 in stage 5.0 (TID 192)
[2025-07-19T21:02:27.065+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@bbd108b
[2025-07-19T21:02:27.066+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=146, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:27.066+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=146),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/146] for update
[2025-07-19T21:02:27.066+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/143/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/143/.1.delta.e33cfa1e-485c-458d-bd84-afe591302dd6.TID190.tmp
[2025-07-19T21:02:27.066+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:27.067+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:27.067+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:27.067+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Committed partition 123 (task 184, attempt 0, stage 5.0)
[2025-07-19T21:02:27.072+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/132/.1.delta.60b8718b-85d9-4d94-b6b6-1c3415002149.TID186.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/132/1.delta
[2025-07-19T21:02:27.073+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=132),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/132] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/132/1.delta
[2025-07-19T21:02:27.073+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Finished task 123.0 in stage 5.0 (TID 184). 6286 bytes result sent to driver
[2025-07-19T21:02:27.073+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Commit authorized for partition 132 (task 186, attempt 0, stage 5.0)
[2025-07-19T21:02:27.075+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73eb6bf0
[2025-07-19T21:02:27.076+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Starting task 154.0 in stage 5.0 (TID 193) (8b44f3d35cfa, executor driver, partition 154, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:27.076+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=150, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:27.077+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=150),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/150] for update
[2025-07-19T21:02:27.077+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Finished task 123.0 in stage 5.0 (TID 184) in 144 ms on 8b44f3d35cfa (executor driver) (175/200)
[2025-07-19T21:02:27.079+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:27.080+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Running task 154.0 in stage 5.0 (TID 193)
[2025-07-19T21:02:27.081+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:27.082+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/146/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/146/.1.delta.eef64490-7fcf-4f1c-b479-c34db982a802.TID191.tmp
[2025-07-19T21:02:27.083+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:27.084+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Committed partition 132 (task 186, attempt 0, stage 5.0)
[2025-07-19T21:02:27.084+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Finished task 132.0 in stage 5.0 (TID 186). 6243 bytes result sent to driver
[2025-07-19T21:02:27.084+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Starting task 158.0 in stage 5.0 (TID 194) (8b44f3d35cfa, executor driver, partition 158, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:27.085+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Running task 158.0 in stage 5.0 (TID 194)
[2025-07-19T21:02:27.086+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Finished task 132.0 in stage 5.0 (TID 186) in 114 ms on 8b44f3d35cfa (executor driver) (176/200)
[2025-07-19T21:02:27.087+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@67939f54
[2025-07-19T21:02:27.088+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/150/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/150/.1.delta.74cd9a9d-f50b-4b1e-b69e-a89daddb5da2.TID192.tmp
[2025-07-19T21:02:27.088+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:27.088+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:27.089+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/133/.1.delta.1989ea78-1283-41e6-9482-c2c70b5c08cb.TID187.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/133/1.delta
[2025-07-19T21:02:27.089+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=133),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/133] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/133/1.delta
[2025-07-19T21:02:27.090+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=154, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:27.091+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=154),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/154] for update
[2025-07-19T21:02:27.091+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Commit authorized for partition 133 (task 187, attempt 0, stage 5.0)
[2025-07-19T21:02:27.096+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Committed partition 133 (task 187, attempt 0, stage 5.0)
[2025-07-19T21:02:27.097+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Finished task 133.0 in stage 5.0 (TID 187). 6243 bytes result sent to driver
[2025-07-19T21:02:27.098+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:27.099+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Starting task 163.0 in stage 5.0 (TID 195) (8b44f3d35cfa, executor driver, partition 163, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:27.100+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f9d997b
[2025-07-19T21:02:27.100+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Finished task 133.0 in stage 5.0 (TID 187) in 105 ms on 8b44f3d35cfa (executor driver) (177/200)
[2025-07-19T21:02:27.100+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Running task 163.0 in stage 5.0 (TID 195)
[2025-07-19T21:02:27.100+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=158, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:27.101+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=158),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/158] for update
[2025-07-19T21:02:27.101+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:27.105+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/139/.1.delta.b003cc87-0c73-4981-9f5d-2b36b75ecbe2.TID189.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/139/1.delta
[2025-07-19T21:02:27.106+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=139),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/139] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/139/1.delta
[2025-07-19T21:02:27.106+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Commit authorized for partition 139 (task 189, attempt 0, stage 5.0)
[2025-07-19T21:02:27.107+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/138/.1.delta.60cf8301-56c9-4ead-be3d-23810595f987.TID188.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/138/1.delta
[2025-07-19T21:02:27.107+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=138),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/138] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/138/1.delta
[2025-07-19T21:02:27.108+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Commit authorized for partition 138 (task 188, attempt 0, stage 5.0)
[2025-07-19T21:02:27.110+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:27.110+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:27.111+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Committed partition 139 (task 189, attempt 0, stage 5.0)
[2025-07-19T21:02:27.111+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Finished task 139.0 in stage 5.0 (TID 189). 6243 bytes result sent to driver
[2025-07-19T21:02:27.113+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Committed partition 138 (task 188, attempt 0, stage 5.0)
[2025-07-19T21:02:27.114+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/143/.1.delta.e33cfa1e-485c-458d-bd84-afe591302dd6.TID190.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/143/1.delta
[2025-07-19T21:02:27.114+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=143),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/143] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/143/1.delta
[2025-07-19T21:02:27.114+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Starting task 164.0 in stage 5.0 (TID 196) (8b44f3d35cfa, executor driver, partition 164, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:27.114+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Finished task 138.0 in stage 5.0 (TID 188). 6243 bytes result sent to driver
[2025-07-19T21:02:27.115+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Commit authorized for partition 143 (task 190, attempt 0, stage 5.0)
[2025-07-19T21:02:27.115+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Finished task 139.0 in stage 5.0 (TID 189) in 105 ms on 8b44f3d35cfa (executor driver) (178/200)
[2025-07-19T21:02:27.117+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/154/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/154/.1.delta.d7f262e4-7860-4c4b-b35a-ade22e77b983.TID193.tmp
[2025-07-19T21:02:27.118+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Running task 164.0 in stage 5.0 (TID 196)
[2025-07-19T21:02:27.118+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/158/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/158/.1.delta.e91c9952-0601-4907-97ae-4850a842c7a3.TID194.tmp
[2025-07-19T21:02:27.118+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Starting task 167.0 in stage 5.0 (TID 197) (8b44f3d35cfa, executor driver, partition 167, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:27.119+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Finished task 138.0 in stage 5.0 (TID 188) in 108 ms on 8b44f3d35cfa (executor driver) (179/200)
[2025-07-19T21:02:27.119+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Running task 167.0 in stage 5.0 (TID 197)
[2025-07-19T21:02:27.120+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f722e03
[2025-07-19T21:02:27.121+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Committed partition 143 (task 190, attempt 0, stage 5.0)
[2025-07-19T21:02:27.122+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:27.123+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:27.123+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:27.123+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=163, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:27.125+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=163),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/163] for update
[2025-07-19T21:02:27.125+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:27.125+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/146/.1.delta.eef64490-7fcf-4f1c-b479-c34db982a802.TID191.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/146/1.delta
[2025-07-19T21:02:27.125+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=146),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/146] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/146/1.delta
[2025-07-19T21:02:27.125+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Commit authorized for partition 146 (task 191, attempt 0, stage 5.0)
[2025-07-19T21:02:27.125+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Finished task 143.0 in stage 5.0 (TID 190). 6243 bytes result sent to driver
[2025-07-19T21:02:27.128+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3df95ccf
[2025-07-19T21:02:27.129+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Starting task 170.0 in stage 5.0 (TID 198) (8b44f3d35cfa, executor driver, partition 170, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:27.130+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=164, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:27.130+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:27.131+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=164),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/164] for update
[2025-07-19T21:02:27.132+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Committed partition 146 (task 191, attempt 0, stage 5.0)
[2025-07-19T21:02:27.133+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Running task 170.0 in stage 5.0 (TID 198)
[2025-07-19T21:02:27.134+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Finished task 143.0 in stage 5.0 (TID 190) in 98 ms on 8b44f3d35cfa (executor driver) (180/200)
[2025-07-19T21:02:27.134+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Finished task 146.0 in stage 5.0 (TID 191). 6243 bytes result sent to driver
[2025-07-19T21:02:27.135+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Starting task 171.0 in stage 5.0 (TID 199) (8b44f3d35cfa, executor driver, partition 171, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:27.135+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:27.135+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Running task 171.0 in stage 5.0 (TID 199)
[2025-07-19T21:02:27.136+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:27.137+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:27.137+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2a82fae7
[2025-07-19T21:02:27.137+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=167, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:27.137+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=167),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/167] for update
[2025-07-19T21:02:27.138+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Finished task 146.0 in stage 5.0 (TID 191) in 85 ms on 8b44f3d35cfa (executor driver) (181/200)
[2025-07-19T21:02:27.138+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:27.143+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/163/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/163/.1.delta.12059350-ba9d-47c5-9f51-f38928c35697.TID195.tmp
[2025-07-19T21:02:27.149+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:27.151+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:27.154+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a701dcd
[2025-07-19T21:02:27.157+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=170, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:27.160+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=170),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/170] for update
[2025-07-19T21:02:27.161+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/150/.1.delta.74cd9a9d-f50b-4b1e-b69e-a89daddb5da2.TID192.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/150/1.delta
[2025-07-19T21:02:27.161+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=150),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/150] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/150/1.delta
[2025-07-19T21:02:27.162+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Commit authorized for partition 150 (task 192, attempt 0, stage 5.0)
[2025-07-19T21:02:27.162+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:27.164+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/164/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/164/.1.delta.0aaaff1d-e3e6-46c5-8791-16fc9d26cb74.TID196.tmp
[2025-07-19T21:02:27.168+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Committed partition 150 (task 192, attempt 0, stage 5.0)
[2025-07-19T21:02:27.169+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Finished task 150.0 in stage 5.0 (TID 192). 6243 bytes result sent to driver
[2025-07-19T21:02:27.170+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/167/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/167/.1.delta.a778ee67-6212-469c-995b-77baa127833d.TID197.tmp
[2025-07-19T21:02:27.173+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@17136c23
[2025-07-19T21:02:27.175+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Starting task 172.0 in stage 5.0 (TID 200) (8b44f3d35cfa, executor driver, partition 172, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:27.176+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=171, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:27.177+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Finished task 150.0 in stage 5.0 (TID 192) in 113 ms on 8b44f3d35cfa (executor driver) (182/200)
[2025-07-19T21:02:27.178+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Running task 172.0 in stage 5.0 (TID 200)
[2025-07-19T21:02:27.179+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=171),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/171] for update
[2025-07-19T21:02:27.180+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:27.180+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:27.181+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/158/.1.delta.e91c9952-0601-4907-97ae-4850a842c7a3.TID194.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/158/1.delta
[2025-07-19T21:02:27.181+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=158),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/158] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/158/1.delta
[2025-07-19T21:02:27.182+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:27.182+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Commit authorized for partition 158 (task 194, attempt 0, stage 5.0)
[2025-07-19T21:02:27.183+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/170/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/170/.1.delta.522c14f9-b6d4-42ea-a2a1-76c3248d9ef0.TID198.tmp
[2025-07-19T21:02:27.183+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/154/.1.delta.d7f262e4-7860-4c4b-b35a-ade22e77b983.TID193.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/154/1.delta
[2025-07-19T21:02:27.184+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=154),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/154] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/154/1.delta
[2025-07-19T21:02:27.184+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Commit authorized for partition 154 (task 193, attempt 0, stage 5.0)
[2025-07-19T21:02:27.187+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53b4f677
[2025-07-19T21:02:27.188+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=172, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:27.190+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=172),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/172] for update
[2025-07-19T21:02:27.191+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Committed partition 158 (task 194, attempt 0, stage 5.0)
[2025-07-19T21:02:27.192+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Finished task 158.0 in stage 5.0 (TID 194). 6243 bytes result sent to driver
[2025-07-19T21:02:27.193+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/171/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/171/.1.delta.02dceba6-fc6a-4322-b6ed-053e7e3a04f9.TID199.tmp
[2025-07-19T21:02:27.193+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Starting task 173.0 in stage 5.0 (TID 201) (8b44f3d35cfa, executor driver, partition 173, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:27.194+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Committed partition 154 (task 193, attempt 0, stage 5.0)
[2025-07-19T21:02:27.195+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Finished task 158.0 in stage 5.0 (TID 194) in 107 ms on 8b44f3d35cfa (executor driver) (183/200)
[2025-07-19T21:02:27.196+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Finished task 154.0 in stage 5.0 (TID 193). 6243 bytes result sent to driver
[2025-07-19T21:02:27.196+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Starting task 177.0 in stage 5.0 (TID 202) (8b44f3d35cfa, executor driver, partition 177, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:27.197+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Finished task 154.0 in stage 5.0 (TID 193) in 119 ms on 8b44f3d35cfa (executor driver) (184/200)
[2025-07-19T21:02:27.197+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Running task 173.0 in stage 5.0 (TID 201)
[2025-07-19T21:02:27.198+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:27.199+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Running task 177.0 in stage 5.0 (TID 202)
[2025-07-19T21:02:27.199+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/163/.1.delta.12059350-ba9d-47c5-9f51-f38928c35697.TID195.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/163/1.delta
[2025-07-19T21:02:27.200+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=163),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/163] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/163/1.delta
[2025-07-19T21:02:27.200+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Commit authorized for partition 163 (task 195, attempt 0, stage 5.0)
[2025-07-19T21:02:27.202+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:27.203+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:27.204+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:27.204+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:27.204+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/172/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/172/.1.delta.e893c639-0111-4156-b19a-43d04ea04e8e.TID200.tmp
[2025-07-19T21:02:27.208+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Committed partition 163 (task 195, attempt 0, stage 5.0)
[2025-07-19T21:02:27.208+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Finished task 163.0 in stage 5.0 (TID 195). 6243 bytes result sent to driver
[2025-07-19T21:02:27.209+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5676353
[2025-07-19T21:02:27.210+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=173, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:27.210+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Starting task 180.0 in stage 5.0 (TID 203) (8b44f3d35cfa, executor driver, partition 180, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:27.211+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Finished task 163.0 in stage 5.0 (TID 195) in 112 ms on 8b44f3d35cfa (executor driver) (185/200)
[2025-07-19T21:02:27.211+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Running task 180.0 in stage 5.0 (TID 203)
[2025-07-19T21:02:27.211+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=173),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/173] for update
[2025-07-19T21:02:27.212+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:27.212+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:27.214+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:27.218+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ce3499e
[2025-07-19T21:02:27.219+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=177, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:27.220+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=177),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/177] for update
[2025-07-19T21:02:27.220+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/164/.1.delta.0aaaff1d-e3e6-46c5-8791-16fc9d26cb74.TID196.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/164/1.delta
[2025-07-19T21:02:27.220+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=164),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/164] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/164/1.delta
[2025-07-19T21:02:27.223+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Commit authorized for partition 164 (task 196, attempt 0, stage 5.0)
[2025-07-19T21:02:27.223+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:27.223+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/173/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/173/.1.delta.8bcac391-12a7-459d-848a-afb783ba3495.TID201.tmp
[2025-07-19T21:02:27.228+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Committed partition 164 (task 196, attempt 0, stage 5.0)
[2025-07-19T21:02:27.228+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/167/.1.delta.a778ee67-6212-469c-995b-77baa127833d.TID197.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/167/1.delta
[2025-07-19T21:02:27.229+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Finished task 164.0 in stage 5.0 (TID 196). 6243 bytes result sent to driver
[2025-07-19T21:02:27.229+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/170/.1.delta.522c14f9-b6d4-42ea-a2a1-76c3248d9ef0.TID198.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/170/1.delta
[2025-07-19T21:02:27.230+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=170),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/170] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/170/1.delta
[2025-07-19T21:02:27.230+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Commit authorized for partition 170 (task 198, attempt 0, stage 5.0)
[2025-07-19T21:02:27.231+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=167),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/167] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/167/1.delta
[2025-07-19T21:02:27.231+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Commit authorized for partition 167 (task 197, attempt 0, stage 5.0)
[2025-07-19T21:02:27.231+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Starting task 181.0 in stage 5.0 (TID 204) (8b44f3d35cfa, executor driver, partition 181, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:27.232+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Finished task 164.0 in stage 5.0 (TID 196) in 118 ms on 8b44f3d35cfa (executor driver) (186/200)
[2025-07-19T21:02:27.232+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Running task 181.0 in stage 5.0 (TID 204)
[2025-07-19T21:02:27.234+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@34d46335
[2025-07-19T21:02:27.235+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:27.235+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:27.236+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=180, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:27.236+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=180),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/180] for update
[2025-07-19T21:02:27.237+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Committed partition 167 (task 197, attempt 0, stage 5.0)
[2025-07-19T21:02:27.238+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Committed partition 170 (task 198, attempt 0, stage 5.0)
[2025-07-19T21:02:27.247+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Finished task 170.0 in stage 5.0 (TID 198). 6286 bytes result sent to driver
[2025-07-19T21:02:27.247+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Finished task 167.0 in stage 5.0 (TID 197). 6286 bytes result sent to driver
[2025-07-19T21:02:27.248+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Starting task 186.0 in stage 5.0 (TID 205) (8b44f3d35cfa, executor driver, partition 186, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:27.249+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/177/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/177/.1.delta.f6d3d180-0d57-4e00-95a3-0810e20954cc.TID202.tmp
[2025-07-19T21:02:27.249+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Finished task 170.0 in stage 5.0 (TID 198) in 122 ms on 8b44f3d35cfa (executor driver) (187/200)
[2025-07-19T21:02:27.250+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Running task 186.0 in stage 5.0 (TID 205)
[2025-07-19T21:02:27.250+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:27.250+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Starting task 189.0 in stage 5.0 (TID 206) (8b44f3d35cfa, executor driver, partition 189, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:27.250+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Finished task 167.0 in stage 5.0 (TID 197) in 133 ms on 8b44f3d35cfa (executor driver) (188/200)
[2025-07-19T21:02:27.250+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Running task 189.0 in stage 5.0 (TID 206)
[2025-07-19T21:02:27.252+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/171/.1.delta.02dceba6-fc6a-4322-b6ed-053e7e3a04f9.TID199.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/171/1.delta
[2025-07-19T21:02:27.252+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=171),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/171] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/171/1.delta
[2025-07-19T21:02:27.256+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:27.257+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:27.257+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Commit authorized for partition 171 (task 199, attempt 0, stage 5.0)
[2025-07-19T21:02:27.258+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a394262
[2025-07-19T21:02:27.263+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=181, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:27.264+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=181),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/181] for update
[2025-07-19T21:02:27.264+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:27.264+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:27.264+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:27.267+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Committed partition 171 (task 199, attempt 0, stage 5.0)
[2025-07-19T21:02:27.270+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Finished task 171.0 in stage 5.0 (TID 199). 6243 bytes result sent to driver
[2025-07-19T21:02:27.274+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/180/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/180/.1.delta.3e615a14-f248-4d8a-a0d9-04080951fcc7.TID203.tmp
[2025-07-19T21:02:27.275+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/172/.1.delta.e893c639-0111-4156-b19a-43d04ea04e8e.TID200.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/172/1.delta
[2025-07-19T21:02:27.277+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=172),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/172] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/172/1.delta
[2025-07-19T21:02:27.278+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Commit authorized for partition 172 (task 200, attempt 0, stage 5.0)
[2025-07-19T21:02:27.278+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/181/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/181/.1.delta.18c6805e-3791-426c-b061-f378271c67c9.TID204.tmp
[2025-07-19T21:02:27.278+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e6338d8
[2025-07-19T21:02:27.279+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=189, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:27.279+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=189),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/189] for update
[2025-07-19T21:02:27.279+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:27.279+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Starting task 190.0 in stage 5.0 (TID 207) (8b44f3d35cfa, executor driver, partition 190, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:27.280+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Finished task 171.0 in stage 5.0 (TID 199) in 149 ms on 8b44f3d35cfa (executor driver) (189/200)
[2025-07-19T21:02:27.284+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c02886a
[2025-07-19T21:02:27.285+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Running task 190.0 in stage 5.0 (TID 207)
[2025-07-19T21:02:27.286+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Committed partition 172 (task 200, attempt 0, stage 5.0)
[2025-07-19T21:02:27.286+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=186, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:27.287+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=186),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/186] for update
[2025-07-19T21:02:27.294+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Finished task 172.0 in stage 5.0 (TID 200). 6243 bytes result sent to driver
[2025-07-19T21:02:27.295+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Starting task 192.0 in stage 5.0 (TID 208) (8b44f3d35cfa, executor driver, partition 192, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:27.296+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/173/.1.delta.8bcac391-12a7-459d-848a-afb783ba3495.TID201.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/173/1.delta
[2025-07-19T21:02:27.296+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=173),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/173] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/173/1.delta
[2025-07-19T21:02:27.296+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:27.297+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Running task 192.0 in stage 5.0 (TID 208)
[2025-07-19T21:02:27.297+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Commit authorized for partition 173 (task 201, attempt 0, stage 5.0)
[2025-07-19T21:02:27.297+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Finished task 172.0 in stage 5.0 (TID 200) in 124 ms on 8b44f3d35cfa (executor driver) (190/200)
[2025-07-19T21:02:27.300+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:27.301+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:27.302+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:27.303+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:27.303+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/189/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/189/.1.delta.4ffcc13b-b0cf-41d7-99a1-3ab1d02f9202.TID206.tmp
[2025-07-19T21:02:27.305+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@50d53a02
[2025-07-19T21:02:27.306+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=190, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:27.307+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=190),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/190] for update
[2025-07-19T21:02:27.310+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:27.312+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/177/.1.delta.f6d3d180-0d57-4e00-95a3-0810e20954cc.TID202.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/177/1.delta
[2025-07-19T21:02:27.313+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=177),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/177] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/177/1.delta
[2025-07-19T21:02:27.313+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Commit authorized for partition 177 (task 202, attempt 0, stage 5.0)
[2025-07-19T21:02:27.313+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Committed partition 173 (task 201, attempt 0, stage 5.0)
[2025-07-19T21:02:27.313+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Finished task 173.0 in stage 5.0 (TID 201). 6243 bytes result sent to driver
[2025-07-19T21:02:27.320+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/186/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/186/.1.delta.2ffc2d01-0b92-4a78-bfca-01f030f1970a.TID205.tmp
[2025-07-19T21:02:27.321+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/181/.1.delta.18c6805e-3791-426c-b061-f378271c67c9.TID204.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/181/1.delta
[2025-07-19T21:02:27.321+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=181),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/181] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/181/1.delta
[2025-07-19T21:02:27.321+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Committed partition 177 (task 202, attempt 0, stage 5.0)
[2025-07-19T21:02:27.321+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Finished task 177.0 in stage 5.0 (TID 202). 6243 bytes result sent to driver
[2025-07-19T21:02:27.324+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Starting task 193.0 in stage 5.0 (TID 209) (8b44f3d35cfa, executor driver, partition 193, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:27.325+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Running task 193.0 in stage 5.0 (TID 209)
[2025-07-19T21:02:27.325+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/190/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/190/.1.delta.01d07e2e-900d-450e-b7aa-46a4ee670b5f.TID207.tmp
[2025-07-19T21:02:27.325+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Starting task 195.0 in stage 5.0 (TID 210) (8b44f3d35cfa, executor driver, partition 195, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:27.325+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Commit authorized for partition 181 (task 204, attempt 0, stage 5.0)
[2025-07-19T21:02:27.325+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Finished task 173.0 in stage 5.0 (TID 201) in 134 ms on 8b44f3d35cfa (executor driver) (191/200)
[2025-07-19T21:02:27.326+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Finished task 177.0 in stage 5.0 (TID 202) in 133 ms on 8b44f3d35cfa (executor driver) (192/200)
[2025-07-19T21:02:27.326+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/180/.1.delta.3e615a14-f248-4d8a-a0d9-04080951fcc7.TID203.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/180/1.delta
[2025-07-19T21:02:27.326+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=180),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/180] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/180/1.delta
[2025-07-19T21:02:27.326+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7acf6447
[2025-07-19T21:02:27.326+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:27.326+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:27.327+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=192, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:27.327+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=192),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/192] for update
[2025-07-19T21:02:27.330+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Commit authorized for partition 180 (task 203, attempt 0, stage 5.0)
[2025-07-19T21:02:27.331+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:27.335+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Running task 195.0 in stage 5.0 (TID 210)
[2025-07-19T21:02:27.337+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@14a69851
[2025-07-19T21:02:27.337+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=193, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:27.337+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=193),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/193] for update
[2025-07-19T21:02:27.338+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Committed partition 181 (task 204, attempt 0, stage 5.0)
[2025-07-19T21:02:27.339+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Committed partition 180 (task 203, attempt 0, stage 5.0)
[2025-07-19T21:02:27.339+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Finished task 181.0 in stage 5.0 (TID 204). 6243 bytes result sent to driver
[2025-07-19T21:02:27.340+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Finished task 180.0 in stage 5.0 (TID 203). 6243 bytes result sent to driver
[2025-07-19T21:02:27.343+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:27.344+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:27.344+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 211) (8b44f3d35cfa, executor driver, partition 1, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:27.344+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 212) (8b44f3d35cfa, executor driver, partition 3, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:27.345+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:27.345+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Finished task 180.0 in stage 5.0 (TID 203) in 133 ms on 8b44f3d35cfa (executor driver) (193/200)
[2025-07-19T21:02:27.346+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Finished task 181.0 in stage 5.0 (TID 204) in 113 ms on 8b44f3d35cfa (executor driver) (194/200)
[2025-07-19T21:02:27.347+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/192/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/192/.1.delta.a310a2f0-0890-4829-ba18-c5eced172cfc.TID208.tmp
[2025-07-19T21:02:27.347+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Running task 3.0 in stage 1.0 (TID 212)
[2025-07-19T21:02:27.348+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Running task 1.0 in stage 1.0 (TID 211)
[2025-07-19T21:02:27.348+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/189/.1.delta.4ffcc13b-b0cf-41d7-99a1-3ab1d02f9202.TID206.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/189/1.delta
[2025-07-19T21:02:27.348+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=189),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/189] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/189/1.delta
[2025-07-19T21:02:27.349+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Commit authorized for partition 189 (task 206, attempt 0, stage 5.0)
[2025-07-19T21:02:27.355+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:27.356+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:27.356+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:27.358+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T21:02:27.359+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Committed partition 189 (task 206, attempt 0, stage 5.0)
[2025-07-19T21:02:27.360+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Finished task 189.0 in stage 5.0 (TID 206). 6243 bytes result sent to driver
[2025-07-19T21:02:27.361+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 213) (8b44f3d35cfa, executor driver, partition 4, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:27.362+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Running task 4.0 in stage 1.0 (TID 213)
[2025-07-19T21:02:27.363+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b5ecabd
[2025-07-19T21:02:27.367+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Finished task 189.0 in stage 5.0 (TID 206) in 114 ms on 8b44f3d35cfa (executor driver) (195/200)
[2025-07-19T21:02:27.368+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:27.368+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=195, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:27.368+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:27.368+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=195),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/195] for update
[2025-07-19T21:02:27.369+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/186/.1.delta.2ffc2d01-0b92-4a78-bfca-01f030f1970a.TID205.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/186/1.delta
[2025-07-19T21:02:27.370+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=186),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/186] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/186/1.delta
[2025-07-19T21:02:27.370+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Commit authorized for partition 186 (task 205, attempt 0, stage 5.0)
[2025-07-19T21:02:27.376+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/193/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/193/.1.delta.c633b400-5ad7-46ee-9746-0487a00eddf4.TID209.tmp
[2025-07-19T21:02:27.377+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/190/.1.delta.01d07e2e-900d-450e-b7aa-46a4ee670b5f.TID207.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/190/1.delta
[2025-07-19T21:02:27.378+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=190),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/190] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/190/1.delta
[2025-07-19T21:02:27.379+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Commit authorized for partition 190 (task 207, attempt 0, stage 5.0)
[2025-07-19T21:02:27.380+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Committed partition 186 (task 205, attempt 0, stage 5.0)
[2025-07-19T21:02:27.437+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:27.454+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56e6cae0
[2025-07-19T21:02:27.459+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Finished task 186.0 in stage 5.0 (TID 205). 6243 bytes result sent to driver
[2025-07-19T21:02:27.463+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 214) (8b44f3d35cfa, executor driver, partition 5, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:27.476+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Committed partition 190 (task 207, attempt 0, stage 5.0)
[2025-07-19T21:02:27.479+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=1, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:27.483+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/1] for update
[2025-07-19T21:02:27.487+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Finished task 186.0 in stage 5.0 (TID 205) in 213 ms on 8b44f3d35cfa (executor driver) (196/200)
[2025-07-19T21:02:27.497+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Running task 5.0 in stage 1.0 (TID 214)
[2025-07-19T21:02:27.500+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Finished task 190.0 in stage 5.0 (TID 207). 6200 bytes result sent to driver
[2025-07-19T21:02:27.506+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 215) (8b44f3d35cfa, executor driver, partition 6, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:27.511+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Running task 6.0 in stage 1.0 (TID 215)
[2025-07-19T21:02:27.513+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Finished task 190.0 in stage 5.0 (TID 207) in 206 ms on 8b44f3d35cfa (executor driver) (197/200)
[2025-07-19T21:02:27.514+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:27.587+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:27.615+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:27.638+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:27.638+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T21:02:27.638+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/192/.1.delta.a310a2f0-0890-4829-ba18-c5eced172cfc.TID208.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/192/1.delta
[2025-07-19T21:02:27.638+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=192),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/192] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/192/1.delta
[2025-07-19T21:02:27.639+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/195/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/195/.1.delta.41d2f51a-d00c-4ba7-9586-359e77ec24f4.TID210.tmp
[2025-07-19T21:02:27.644+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Commit authorized for partition 192 (task 208, attempt 0, stage 5.0)
[2025-07-19T21:02:27.647+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3a3d9338
[2025-07-19T21:02:27.649+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=3, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:27.650+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/3] for update
[2025-07-19T21:02:27.652+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Committed partition 192 (task 208, attempt 0, stage 5.0)
[2025-07-19T21:02:27.652+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Finished task 192.0 in stage 5.0 (TID 208). 6200 bytes result sent to driver
[2025-07-19T21:02:27.652+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 216) (8b44f3d35cfa, executor driver, partition 7, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:27.654+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Finished task 192.0 in stage 5.0 (TID 208) in 361 ms on 8b44f3d35cfa (executor driver) (198/200)
[2025-07-19T21:02:27.657+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Running task 7.0 in stage 1.0 (TID 216)
[2025-07-19T21:02:27.813+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:27.814+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:27.814+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:27.873+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@739adc07
[2025-07-19T21:02:27.877+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=6, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:27.878+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/6] for update
[2025-07-19T21:02:27.879+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:27.895+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2fb8f589
[2025-07-19T21:02:27.895+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=5, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:27.896+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/5] for update
[2025-07-19T21:02:27.899+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/193/.1.delta.c633b400-5ad7-46ee-9746-0487a00eddf4.TID209.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/193/1.delta
[2025-07-19T21:02:27.900+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=193),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/193] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/193/1.delta
[2025-07-19T21:02:27.901+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Commit authorized for partition 193 (task 209, attempt 0, stage 5.0)
[2025-07-19T21:02:27.902+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:27.909+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/6/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/6/.1.delta.0b377962-c223-4e03-bd90-aebd22c1b23a.TID215.tmp
[2025-07-19T21:02:27.912+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f24f033
[2025-07-19T21:02:27.913+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=4, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:27.914+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/4] for update
[2025-07-19T21:02:27.914+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/3/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/3/.1.delta.cd72ca73-3e41-43bc-9022-45cf6b68b068.TID212.tmp
[2025-07-19T21:02:27.914+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:27.916+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/1/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/1/.1.delta.7fe5014e-7a4c-4b62-a00d-0f5bd53fe864.TID211.tmp
[2025-07-19T21:02:27.925+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Committed partition 193 (task 209, attempt 0, stage 5.0)
[2025-07-19T21:02:27.926+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/5/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/5/.1.delta.91414dab-58bc-4da5-927d-d0b23d946f1e.TID214.tmp
[2025-07-19T21:02:27.928+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Finished task 193.0 in stage 5.0 (TID 209). 6243 bytes result sent to driver
[2025-07-19T21:02:27.930+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Finished task 193.0 in stage 5.0 (TID 209) in 609 ms on 8b44f3d35cfa (executor driver) (199/200)
[2025-07-19T21:02:27.932+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO TaskSetManager: Starting task 9.0 in stage 1.0 (TID 217) (8b44f3d35cfa, executor driver, partition 9, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:27.934+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 8b44f3d35cfa:38433 in memory (size: 15.8 KiB, free: 434.1 MiB)
[2025-07-19T21:02:27.935+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO Executor: Running task 9.0 in stage 1.0 (TID 217)
[2025-07-19T21:02:27.938+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59bbab43
[2025-07-19T21:02:27.940+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=7, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:27.941+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/7] for update
[2025-07-19T21:02:27.941+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:27.942+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:27.944+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/4/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/4/.1.delta.c5de8ebb-a573-456a-8193-d5a6957ac62d.TID213.tmp
[2025-07-19T21:02:27.945+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:27.950+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/195/.1.delta.41d2f51a-d00c-4ba7-9586-359e77ec24f4.TID210.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/195/1.delta
[2025-07-19T21:02:27.951+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=195),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/195] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/195/1.delta
[2025-07-19T21:02:27.951+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6fb74e47
[2025-07-19T21:02:27.951+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO DataWritingSparkTask: Commit authorized for partition 195 (task 210, attempt 0, stage 5.0)
[2025-07-19T21:02:27.951+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=9, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:27.952+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/9] for update
[2025-07-19T21:02:27.953+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:27.958+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 8b44f3d35cfa:38433 in memory (size: 14.6 KiB, free: 434.1 MiB)
[2025-07-19T21:02:27.967+0000] {subprocess.py:93} INFO - 25/07/19 21:02:27 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 8b44f3d35cfa:38433 in memory (size: 14.1 KiB, free: 434.2 MiB)
[2025-07-19T21:02:28.055+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Committed partition 195 (task 210, attempt 0, stage 5.0)
[2025-07-19T21:02:28.058+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Finished task 195.0 in stage 5.0 (TID 210). 6200 bytes result sent to driver
[2025-07-19T21:02:28.059+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Starting task 11.0 in stage 1.0 (TID 218) (8b44f3d35cfa, executor driver, partition 11, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:28.061+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Finished task 195.0 in stage 5.0 (TID 210) in 737 ms on 8b44f3d35cfa (executor driver) (200/200)
[2025-07-19T21:02:28.061+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/7/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/7/.1.delta.4e506466-b14d-41d4-9fe0-724dd37adffe.TID216.tmp
[2025-07-19T21:02:28.061+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Running task 11.0 in stage 1.0 (TID 218)
[2025-07-19T21:02:28.062+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2025-07-19T21:02:28.066+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DAGScheduler: ResultStage 5 (start at <unknown>:0) finished in 6.333 s
[2025-07-19T21:02:28.066+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:28.067+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:28.068+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/9/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/9/.1.delta.6018d0e4-3bb3-4df2-91f6-abb8055d5cf6.TID217.tmp
[2025-07-19T21:02:28.115+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@351c8c1c
[2025-07-19T21:02:28.116+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=11, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:28.116+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=11),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/11] for update
[2025-07-19T21:02:28.116+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:28.117+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/1/.1.delta.7fe5014e-7a4c-4b62-a00d-0f5bd53fe864.TID211.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/1/1.delta
[2025-07-19T21:02:28.117+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/1] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/1/1.delta
[2025-07-19T21:02:28.117+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-19T21:02:28.118+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
[2025-07-19T21:02:28.119+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/3/.1.delta.cd72ca73-3e41-43bc-9022-45cf6b68b068.TID212.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/3/1.delta
[2025-07-19T21:02:28.121+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/3] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/3/1.delta
[2025-07-19T21:02:28.124+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Commit authorized for partition 3 (task 212, attempt 0, stage 1.0)
[2025-07-19T21:02:28.125+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Commit authorized for partition 1 (task 211, attempt 0, stage 1.0)
[2025-07-19T21:02:28.126+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DAGScheduler: Job 0 finished: start at <unknown>:0, took 7.989222 s
[2025-07-19T21:02:28.140+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/5/.1.delta.91414dab-58bc-4da5-927d-d0b23d946f1e.TID214.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/5/1.delta
[2025-07-19T21:02:28.141+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/5] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/5/1.delta
[2025-07-19T21:02:28.143+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Commit authorized for partition 5 (task 214, attempt 0, stage 1.0)
[2025-07-19T21:02:28.144+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Checkins_raw, format=PARQUET)] is committing.
[2025-07-19T21:02:28.149+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO SparkWrite: Committing epoch 0 for query 857c6a97-8a45-4319-91e0-4d8882460008 in append mode
[2025-07-19T21:02:28.153+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/11/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/11/.1.delta.4e7bb32e-9791-4ec0-b12e-5dc494472d6c.TID218.tmp
[2025-07-19T21:02:28.164+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/6/.1.delta.0b377962-c223-4e03-bd90-aebd22c1b23a.TID215.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/6/1.delta
[2025-07-19T21:02:28.169+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/6] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/6/1.delta
[2025-07-19T21:02:28.170+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Commit authorized for partition 6 (task 215, attempt 0, stage 1.0)
[2025-07-19T21:02:28.173+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/4/.1.delta.c5de8ebb-a573-456a-8193-d5a6957ac62d.TID213.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/4/1.delta
[2025-07-19T21:02:28.174+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/4] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/4/1.delta
[2025-07-19T21:02:28.176+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/7/.1.delta.4e506466-b14d-41d4-9fe0-724dd37adffe.TID216.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/7/1.delta
[2025-07-19T21:02:28.176+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/7] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/7/1.delta
[2025-07-19T21:02:28.176+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Commit authorized for partition 4 (task 213, attempt 0, stage 1.0)
[2025-07-19T21:02:28.177+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Commit authorized for partition 7 (task 216, attempt 0, stage 1.0)
[2025-07-19T21:02:28.182+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Committed partition 1 (task 211, attempt 0, stage 1.0)
[2025-07-19T21:02:28.187+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Committed partition 3 (task 212, attempt 0, stage 1.0)
[2025-07-19T21:02:28.188+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Committed partition 5 (task 214, attempt 0, stage 1.0)
[2025-07-19T21:02:28.188+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Finished task 1.0 in stage 1.0 (TID 211). 9096 bytes result sent to driver
[2025-07-19T21:02:28.191+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Finished task 5.0 in stage 1.0 (TID 214). 9076 bytes result sent to driver
[2025-07-19T21:02:28.192+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Finished task 3.0 in stage 1.0 (TID 212). 9078 bytes result sent to driver
[2025-07-19T21:02:28.193+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/9/.1.delta.6018d0e4-3bb3-4df2-91f6-abb8055d5cf6.TID217.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/9/1.delta
[2025-07-19T21:02:28.195+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/9] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/9/1.delta
[2025-07-19T21:02:28.195+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Starting task 12.0 in stage 1.0 (TID 219) (8b44f3d35cfa, executor driver, partition 12, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:28.198+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Starting task 13.0 in stage 1.0 (TID 220) (8b44f3d35cfa, executor driver, partition 13, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:28.199+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Starting task 14.0 in stage 1.0 (TID 221) (8b44f3d35cfa, executor driver, partition 14, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:28.200+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Running task 12.0 in stage 1.0 (TID 219)
[2025-07-19T21:02:28.201+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Commit authorized for partition 9 (task 217, attempt 0, stage 1.0)
[2025-07-19T21:02:28.202+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Running task 14.0 in stage 1.0 (TID 221)
[2025-07-19T21:02:28.202+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 211) in 851 ms on 8b44f3d35cfa (executor driver) (1/200)
[2025-07-19T21:02:28.203+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Running task 13.0 in stage 1.0 (TID 220)
[2025-07-19T21:02:28.204+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 212) in 852 ms on 8b44f3d35cfa (executor driver) (2/200)
[2025-07-19T21:02:28.204+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 214) in 744 ms on 8b44f3d35cfa (executor driver) (3/200)
[2025-07-19T21:02:28.204+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:28.205+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:28.206+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO SparkWrite: Committing streaming append with 137 new data files to table my_catalog.bronze.Checkins_raw
[2025-07-19T21:02:28.207+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:28.208+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:28.208+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:28.208+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:28.209+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Committed partition 6 (task 215, attempt 0, stage 1.0)
[2025-07-19T21:02:28.209+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Finished task 6.0 in stage 1.0 (TID 215). 9035 bytes result sent to driver
[2025-07-19T21:02:28.210+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Committed partition 4 (task 213, attempt 0, stage 1.0)
[2025-07-19T21:02:28.211+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Starting task 16.0 in stage 1.0 (TID 222) (8b44f3d35cfa, executor driver, partition 16, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:28.212+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Finished task 4.0 in stage 1.0 (TID 213). 9044 bytes result sent to driver
[2025-07-19T21:02:28.213+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1bae249a
[2025-07-19T21:02:28.213+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Running task 16.0 in stage 1.0 (TID 222)
[2025-07-19T21:02:28.213+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Finished task 6.0 in stage 1.0 (TID 215) in 733 ms on 8b44f3d35cfa (executor driver) (4/200)
[2025-07-19T21:02:28.214+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=14, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:28.214+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Starting task 18.0 in stage 1.0 (TID 223) (8b44f3d35cfa, executor driver, partition 18, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:28.215+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 213) in 852 ms on 8b44f3d35cfa (executor driver) (5/200)
[2025-07-19T21:02:28.215+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:28.216+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=14),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/14] for update
[2025-07-19T21:02:28.217+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:28.217+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Running task 18.0 in stage 1.0 (TID 223)
[2025-07-19T21:02:28.218+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:28.218+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:28.219+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:28.219+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74403981
[2025-07-19T21:02:28.221+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=13, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:28.221+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Committed partition 9 (task 217, attempt 0, stage 1.0)
[2025-07-19T21:02:28.222+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=13),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/13] for update
[2025-07-19T21:02:28.224+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Finished task 9.0 in stage 1.0 (TID 217). 9043 bytes result sent to driver
[2025-07-19T21:02:28.225+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Starting task 19.0 in stage 1.0 (TID 224) (8b44f3d35cfa, executor driver, partition 19, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:28.226+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Running task 19.0 in stage 1.0 (TID 224)
[2025-07-19T21:02:28.226+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Finished task 9.0 in stage 1.0 (TID 217) in 294 ms on 8b44f3d35cfa (executor driver) (6/200)
[2025-07-19T21:02:28.229+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/14/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/14/.1.delta.3c652640-9423-4fb6-8359-49134f7d7e29.TID221.tmp
[2025-07-19T21:02:28.231+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c0affcd
[2025-07-19T21:02:28.232+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/11/.1.delta.4e7bb32e-9791-4ec0-b12e-5dc494472d6c.TID218.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/11/1.delta
[2025-07-19T21:02:28.234+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=11),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/11] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/11/1.delta
[2025-07-19T21:02:28.235+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=12, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:28.235+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=12),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/12] for update
[2025-07-19T21:02:28.236+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:28.237+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Committed partition 7 (task 216, attempt 0, stage 1.0)
[2025-07-19T21:02:28.238+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:28.238+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:28.241+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Finished task 7.0 in stage 1.0 (TID 216). 9034 bytes result sent to driver
[2025-07-19T21:02:28.242+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Commit authorized for partition 11 (task 218, attempt 0, stage 1.0)
[2025-07-19T21:02:28.242+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Starting task 20.0 in stage 1.0 (TID 225) (8b44f3d35cfa, executor driver, partition 20, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:28.243+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:28.243+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Running task 20.0 in stage 1.0 (TID 225)
[2025-07-19T21:02:28.244+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Finished task 7.0 in stage 1.0 (TID 216) in 590 ms on 8b44f3d35cfa (executor driver) (7/200)
[2025-07-19T21:02:28.247+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56f7464d
[2025-07-19T21:02:28.250+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:28.251+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:28.251+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=18, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:28.252+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=18),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/18] for update
[2025-07-19T21:02:28.256+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/13/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/13/.1.delta.4fe38f29-ad41-42ee-8f48-c4246622f6af.TID220.tmp
[2025-07-19T21:02:28.257+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/12/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/12/.1.delta.f2e89604-20ae-4bee-a186-149ba2844004.TID219.tmp
[2025-07-19T21:02:28.260+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:28.261+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Committed partition 11 (task 218, attempt 0, stage 1.0)
[2025-07-19T21:02:28.262+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Finished task 11.0 in stage 1.0 (TID 218). 9061 bytes result sent to driver
[2025-07-19T21:02:28.263+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Starting task 21.0 in stage 1.0 (TID 226) (8b44f3d35cfa, executor driver, partition 21, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:28.264+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Running task 21.0 in stage 1.0 (TID 226)
[2025-07-19T21:02:28.265+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f58e325
[2025-07-19T21:02:28.267+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Finished task 11.0 in stage 1.0 (TID 218) in 206 ms on 8b44f3d35cfa (executor driver) (8/200)
[2025-07-19T21:02:28.268+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=16, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:28.269+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=16),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/16] for update
[2025-07-19T21:02:28.272+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:28.278+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/18/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/18/.1.delta.854188cd-e094-4d1a-b2df-17609c1366d4.TID223.tmp
[2025-07-19T21:02:28.281+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:28.281+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:28.287+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@45b0c922
[2025-07-19T21:02:28.288+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=20, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:28.289+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=20),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/20] for update
[2025-07-19T21:02:28.291+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:28.295+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e1812ae
[2025-07-19T21:02:28.297+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=19, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:28.301+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=19),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/19] for update
[2025-07-19T21:02:28.302+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:28.305+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/20/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/20/.1.delta.e612dfa1-1f21-4139-b465-7681e698f42f.TID225.tmp
[2025-07-19T21:02:28.306+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/16/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/16/.1.delta.e82bd727-7ff0-44a8-9692-9da78b527382.TID222.tmp
[2025-07-19T21:02:28.310+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/14/.1.delta.3c652640-9423-4fb6-8359-49134f7d7e29.TID221.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/14/1.delta
[2025-07-19T21:02:28.311+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=14),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/14] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/14/1.delta
[2025-07-19T21:02:28.313+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d6a8876
[2025-07-19T21:02:28.316+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Commit authorized for partition 14 (task 221, attempt 0, stage 1.0)
[2025-07-19T21:02:28.317+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=21, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:28.318+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=21),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/21] for update
[2025-07-19T21:02:28.319+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:28.327+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/19/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/19/.1.delta.58a22f7e-fd61-4b17-a5d0-ccbcfcf2edd4.TID224.tmp
[2025-07-19T21:02:28.342+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/21/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/21/.1.delta.12528ba1-3bd2-4591-a8ab-ebc95814d3a7.TID226.tmp
[2025-07-19T21:02:28.343+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Committed partition 14 (task 221, attempt 0, stage 1.0)
[2025-07-19T21:02:28.345+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/13/.1.delta.4fe38f29-ad41-42ee-8f48-c4246622f6af.TID220.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/13/1.delta
[2025-07-19T21:02:28.346+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=13),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/13] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/13/1.delta
[2025-07-19T21:02:28.347+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Finished task 14.0 in stage 1.0 (TID 221). 9098 bytes result sent to driver
[2025-07-19T21:02:28.348+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Starting task 22.0 in stage 1.0 (TID 227) (8b44f3d35cfa, executor driver, partition 22, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:28.350+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Commit authorized for partition 13 (task 220, attempt 0, stage 1.0)
[2025-07-19T21:02:28.351+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Finished task 14.0 in stage 1.0 (TID 221) in 156 ms on 8b44f3d35cfa (executor driver) (9/200)
[2025-07-19T21:02:28.352+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Running task 22.0 in stage 1.0 (TID 227)
[2025-07-19T21:02:28.354+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:28.355+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:28.360+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/12/.1.delta.f2e89604-20ae-4bee-a186-149ba2844004.TID219.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/12/1.delta
[2025-07-19T21:02:28.362+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=12),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/12] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/12/1.delta
[2025-07-19T21:02:28.365+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Commit authorized for partition 12 (task 219, attempt 0, stage 1.0)
[2025-07-19T21:02:28.374+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/18/.1.delta.854188cd-e094-4d1a-b2df-17609c1366d4.TID223.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/18/1.delta
[2025-07-19T21:02:28.376+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=18),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/18] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/18/1.delta
[2025-07-19T21:02:28.378+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Commit authorized for partition 18 (task 223, attempt 0, stage 1.0)
[2025-07-19T21:02:28.382+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@fd7de06
[2025-07-19T21:02:28.383+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=22, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:28.385+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=22),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/22] for update
[2025-07-19T21:02:28.386+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:28.388+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/20/.1.delta.e612dfa1-1f21-4139-b465-7681e698f42f.TID225.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/20/1.delta
[2025-07-19T21:02:28.391+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=20),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/20] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/20/1.delta
[2025-07-19T21:02:28.393+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/16/.1.delta.e82bd727-7ff0-44a8-9692-9da78b527382.TID222.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/16/1.delta
[2025-07-19T21:02:28.395+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Commit authorized for partition 20 (task 225, attempt 0, stage 1.0)
[2025-07-19T21:02:28.395+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=16),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/16] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/16/1.delta
[2025-07-19T21:02:28.396+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Commit authorized for partition 16 (task 222, attempt 0, stage 1.0)
[2025-07-19T21:02:28.401+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/22/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/22/.1.delta.79be1009-e4b0-4668-aca4-d0a4aec35de9.TID227.tmp
[2025-07-19T21:02:28.402+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/19/.1.delta.58a22f7e-fd61-4b17-a5d0-ccbcfcf2edd4.TID224.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/19/1.delta
[2025-07-19T21:02:28.403+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=19),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/19] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/19/1.delta
[2025-07-19T21:02:28.420+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Commit authorized for partition 19 (task 224, attempt 0, stage 1.0)
[2025-07-19T21:02:28.425+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Committed partition 13 (task 220, attempt 0, stage 1.0)
[2025-07-19T21:02:28.425+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Committed partition 12 (task 219, attempt 0, stage 1.0)
[2025-07-19T21:02:28.427+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Committed partition 18 (task 223, attempt 0, stage 1.0)
[2025-07-19T21:02:28.445+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Finished task 13.0 in stage 1.0 (TID 220). 9078 bytes result sent to driver
[2025-07-19T21:02:28.446+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Finished task 18.0 in stage 1.0 (TID 223). 9119 bytes result sent to driver
[2025-07-19T21:02:28.448+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Starting task 23.0 in stage 1.0 (TID 228) (8b44f3d35cfa, executor driver, partition 23, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:28.449+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Finished task 12.0 in stage 1.0 (TID 219). 9140 bytes result sent to driver
[2025-07-19T21:02:28.450+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Finished task 13.0 in stage 1.0 (TID 220) in 250 ms on 8b44f3d35cfa (executor driver) (10/200)
[2025-07-19T21:02:28.450+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Starting task 24.0 in stage 1.0 (TID 229) (8b44f3d35cfa, executor driver, partition 24, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:28.451+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Starting task 25.0 in stage 1.0 (TID 230) (8b44f3d35cfa, executor driver, partition 25, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:28.452+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Running task 24.0 in stage 1.0 (TID 229)
[2025-07-19T21:02:28.453+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Running task 23.0 in stage 1.0 (TID 228)
[2025-07-19T21:02:28.453+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Getting 1 (251.0 B) non-empty blocks including 1 (251.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:28.453+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Running task 25.0 in stage 1.0 (TID 230)
[2025-07-19T21:02:28.454+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:28.454+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Finished task 18.0 in stage 1.0 (TID 223) in 238 ms on 8b44f3d35cfa (executor driver) (11/200)
[2025-07-19T21:02:28.455+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Finished task 12.0 in stage 1.0 (TID 219) in 259 ms on 8b44f3d35cfa (executor driver) (12/200)
[2025-07-19T21:02:28.458+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:28.484+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:28.493+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/21/.1.delta.12528ba1-3bd2-4591-a8ab-ebc95814d3a7.TID226.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/21/1.delta
[2025-07-19T21:02:28.510+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=21),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/21] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/21/1.delta
[2025-07-19T21:02:28.515+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Commit authorized for partition 21 (task 226, attempt 0, stage 1.0)
[2025-07-19T21:02:28.536+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Committed partition 20 (task 225, attempt 0, stage 1.0)
[2025-07-19T21:02:28.564+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Finished task 20.0 in stage 1.0 (TID 225). 9087 bytes result sent to driver
[2025-07-19T21:02:28.574+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Starting task 26.0 in stage 1.0 (TID 231) (8b44f3d35cfa, executor driver, partition 26, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:28.582+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1899d43e
[2025-07-19T21:02:28.583+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:28.584+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:28.584+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Committed partition 19 (task 224, attempt 0, stage 1.0)
[2025-07-19T21:02:28.584+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Finished task 19.0 in stage 1.0 (TID 224). 9097 bytes result sent to driver
[2025-07-19T21:02:28.585+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Finished task 19.0 in stage 1.0 (TID 224) in 281 ms on 8b44f3d35cfa (executor driver) (13/200)
[2025-07-19T21:02:28.585+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Starting task 29.0 in stage 1.0 (TID 232) (8b44f3d35cfa, executor driver, partition 29, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:28.585+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=24, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:28.586+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=24),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/24] for update
[2025-07-19T21:02:28.586+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Running task 26.0 in stage 1.0 (TID 231)
[2025-07-19T21:02:28.586+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Running task 29.0 in stage 1.0 (TID 232)
[2025-07-19T21:02:28.586+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:28.587+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:28.587+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Finished task 20.0 in stage 1.0 (TID 225) in 328 ms on 8b44f3d35cfa (executor driver) (14/200)
[2025-07-19T21:02:28.587+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:28.587+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Committed partition 16 (task 222, attempt 0, stage 1.0)
[2025-07-19T21:02:28.587+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Finished task 16.0 in stage 1.0 (TID 222). 9080 bytes result sent to driver
[2025-07-19T21:02:28.587+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:28.593+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Starting task 30.0 in stage 1.0 (TID 233) (8b44f3d35cfa, executor driver, partition 30, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:28.594+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Finished task 16.0 in stage 1.0 (TID 222) in 382 ms on 8b44f3d35cfa (executor driver) (15/200)
[2025-07-19T21:02:28.595+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Committed partition 21 (task 226, attempt 0, stage 1.0)
[2025-07-19T21:02:28.596+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Running task 30.0 in stage 1.0 (TID 233)
[2025-07-19T21:02:28.596+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T21:02:28.597+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Finished task 21.0 in stage 1.0 (TID 226). 9083 bytes result sent to driver
[2025-07-19T21:02:28.597+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Starting task 32.0 in stage 1.0 (TID 234) (8b44f3d35cfa, executor driver, partition 32, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:28.597+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/24/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/24/.1.delta.2a153dfa-41f0-4698-b03e-06250e80d7ca.TID229.tmp
[2025-07-19T21:02:28.598+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Finished task 21.0 in stage 1.0 (TID 226) in 334 ms on 8b44f3d35cfa (executor driver) (16/200)
[2025-07-19T21:02:28.598+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Running task 32.0 in stage 1.0 (TID 234)
[2025-07-19T21:02:28.599+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@219c5342
[2025-07-19T21:02:28.600+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=23, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:28.600+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=23),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/23] for update
[2025-07-19T21:02:28.605+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:28.606+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:28.607+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:28.607+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:28.607+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:28.612+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3e249a47
[2025-07-19T21:02:28.612+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=25, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:28.613+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=25),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/25] for update
[2025-07-19T21:02:28.624+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/22/.1.delta.79be1009-e4b0-4668-aca4-d0a4aec35de9.TID227.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/22/1.delta
[2025-07-19T21:02:28.624+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=22),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/22] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/22/1.delta
[2025-07-19T21:02:28.625+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:28.638+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Commit authorized for partition 22 (task 227, attempt 0, stage 1.0)
[2025-07-19T21:02:28.640+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d09a9bb
[2025-07-19T21:02:28.641+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=30, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:28.642+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=30),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/30] for update
[2025-07-19T21:02:28.642+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:28.645+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/23/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/23/.1.delta.c6f13846-d078-48ef-bf11-e32a204d8a30.TID228.tmp
[2025-07-19T21:02:28.650+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3b356f66
[2025-07-19T21:02:28.650+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=32, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:28.651+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=32),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/32] for update
[2025-07-19T21:02:28.656+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/30/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/30/.1.delta.d25d8262-2143-41c7-968e-df324fa4e43b.TID233.tmp
[2025-07-19T21:02:28.657+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:28.661+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/25/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/25/.1.delta.d1aed9d6-8c8f-447f-a9f3-60acbfdf4d7c.TID230.tmp
[2025-07-19T21:02:28.665+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Committed partition 22 (task 227, attempt 0, stage 1.0)
[2025-07-19T21:02:28.667+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23350ec8
[2025-07-19T21:02:28.669+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Finished task 22.0 in stage 1.0 (TID 227). 9129 bytes result sent to driver
[2025-07-19T21:02:28.669+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=26, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:28.670+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=26),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/26] for update
[2025-07-19T21:02:28.670+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Starting task 35.0 in stage 1.0 (TID 235) (8b44f3d35cfa, executor driver, partition 35, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:28.670+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Finished task 22.0 in stage 1.0 (TID 227) in 323 ms on 8b44f3d35cfa (executor driver) (17/200)
[2025-07-19T21:02:28.676+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d953912
[2025-07-19T21:02:28.677+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=29, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:28.677+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=29),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/29] for update
[2025-07-19T21:02:28.677+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:28.678+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/32/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/32/.1.delta.933f3223-8cd6-4512-bde5-4ff9580f56f0.TID234.tmp
[2025-07-19T21:02:28.682+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:28.687+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/24/.1.delta.2a153dfa-41f0-4698-b03e-06250e80d7ca.TID229.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/24/1.delta
[2025-07-19T21:02:28.688+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=24),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/24] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/24/1.delta
[2025-07-19T21:02:28.688+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Commit authorized for partition 24 (task 229, attempt 0, stage 1.0)
[2025-07-19T21:02:28.688+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Running task 35.0 in stage 1.0 (TID 235)
[2025-07-19T21:02:28.714+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:28.718+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms
[2025-07-19T21:02:28.744+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6fdb409a
[2025-07-19T21:02:28.745+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/26/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/26/.1.delta.3e5ddc64-f558-4500-bf92-caf7e8759e1f.TID231.tmp
[2025-07-19T21:02:28.745+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=35, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:28.746+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=35),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/35] for update
[2025-07-19T21:02:28.747+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Committed partition 24 (task 229, attempt 0, stage 1.0)
[2025-07-19T21:02:28.747+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Finished task 24.0 in stage 1.0 (TID 229). 9093 bytes result sent to driver
[2025-07-19T21:02:28.747+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Starting task 37.0 in stage 1.0 (TID 236) (8b44f3d35cfa, executor driver, partition 37, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:28.748+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Running task 37.0 in stage 1.0 (TID 236)
[2025-07-19T21:02:28.750+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Finished task 24.0 in stage 1.0 (TID 229) in 308 ms on 8b44f3d35cfa (executor driver) (18/200)
[2025-07-19T21:02:28.752+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:28.753+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:28.762+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:28.763+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 8b44f3d35cfa:38433 in memory (size: 19.9 KiB, free: 434.2 MiB)
[2025-07-19T21:02:28.764+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@191c685c
[2025-07-19T21:02:28.765+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=37, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:28.766+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=37),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/37] for update
[2025-07-19T21:02:28.773+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:28.775+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/29/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/29/.1.delta.7dca9248-1a52-42b2-8c37-4d958a976769.TID232.tmp
[2025-07-19T21:02:28.776+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/23/.1.delta.c6f13846-d078-48ef-bf11-e32a204d8a30.TID228.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/23/1.delta
[2025-07-19T21:02:28.776+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=23),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/23] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/23/1.delta
[2025-07-19T21:02:28.777+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Commit authorized for partition 23 (task 228, attempt 0, stage 1.0)
[2025-07-19T21:02:28.777+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/35/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/35/.1.delta.ae54c091-97dd-4b16-9a1a-d8134b992b3f.TID235.tmp
[2025-07-19T21:02:28.792+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/37/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/37/.1.delta.a3134fb6-4364-42e0-944f-3000739fd6ca.TID236.tmp
[2025-07-19T21:02:28.801+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/25/.1.delta.d1aed9d6-8c8f-447f-a9f3-60acbfdf4d7c.TID230.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/25/1.delta
[2025-07-19T21:02:28.803+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=25),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/25] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/25/1.delta
[2025-07-19T21:02:28.803+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Commit authorized for partition 25 (task 230, attempt 0, stage 1.0)
[2025-07-19T21:02:28.807+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Committed partition 23 (task 228, attempt 0, stage 1.0)
[2025-07-19T21:02:28.812+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Finished task 23.0 in stage 1.0 (TID 228). 9082 bytes result sent to driver
[2025-07-19T21:02:28.812+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Starting task 38.0 in stage 1.0 (TID 237) (8b44f3d35cfa, executor driver, partition 38, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:28.813+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Finished task 23.0 in stage 1.0 (TID 228) in 375 ms on 8b44f3d35cfa (executor driver) (19/200)
[2025-07-19T21:02:28.814+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Running task 38.0 in stage 1.0 (TID 237)
[2025-07-19T21:02:28.818+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:28.818+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:28.826+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Committed partition 25 (task 230, attempt 0, stage 1.0)
[2025-07-19T21:02:28.826+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Finished task 25.0 in stage 1.0 (TID 230). 9098 bytes result sent to driver
[2025-07-19T21:02:28.827+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Starting task 39.0 in stage 1.0 (TID 238) (8b44f3d35cfa, executor driver, partition 39, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:28.828+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/30/.1.delta.d25d8262-2143-41c7-968e-df324fa4e43b.TID233.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/30/1.delta
[2025-07-19T21:02:28.829+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=30),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/30] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/30/1.delta
[2025-07-19T21:02:28.830+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Running task 39.0 in stage 1.0 (TID 238)
[2025-07-19T21:02:28.830+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Commit authorized for partition 30 (task 233, attempt 0, stage 1.0)
[2025-07-19T21:02:28.830+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/26/.1.delta.3e5ddc64-f558-4500-bf92-caf7e8759e1f.TID231.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/26/1.delta
[2025-07-19T21:02:28.830+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Finished task 25.0 in stage 1.0 (TID 230) in 387 ms on 8b44f3d35cfa (executor driver) (20/200)
[2025-07-19T21:02:28.831+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=26),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/26] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/26/1.delta
[2025-07-19T21:02:28.833+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Commit authorized for partition 26 (task 231, attempt 0, stage 1.0)
[2025-07-19T21:02:28.840+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/29/.1.delta.7dca9248-1a52-42b2-8c37-4d958a976769.TID232.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/29/1.delta
[2025-07-19T21:02:28.842+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=29),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/29] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/29/1.delta
[2025-07-19T21:02:28.843+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Commit authorized for partition 29 (task 232, attempt 0, stage 1.0)
[2025-07-19T21:02:28.843+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/35/.1.delta.ae54c091-97dd-4b16-9a1a-d8134b992b3f.TID235.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/35/1.delta
[2025-07-19T21:02:28.843+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=35),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/35] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/35/1.delta
[2025-07-19T21:02:28.843+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63aceb1
[2025-07-19T21:02:28.843+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:28.844+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T21:02:28.845+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=38, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:28.846+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Commit authorized for partition 35 (task 235, attempt 0, stage 1.0)
[2025-07-19T21:02:28.847+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=38),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/38] for update
[2025-07-19T21:02:28.849+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:28.854+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/32/.1.delta.933f3223-8cd6-4512-bde5-4ff9580f56f0.TID234.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/32/1.delta
[2025-07-19T21:02:28.855+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=32),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/32] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/32/1.delta
[2025-07-19T21:02:28.855+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@26b5c237
[2025-07-19T21:02:28.856+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Commit authorized for partition 32 (task 234, attempt 0, stage 1.0)
[2025-07-19T21:02:28.857+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=39, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:28.859+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=39),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/39] for update
[2025-07-19T21:02:28.861+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Committed partition 29 (task 232, attempt 0, stage 1.0)
[2025-07-19T21:02:28.862+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Finished task 29.0 in stage 1.0 (TID 232). 9068 bytes result sent to driver
[2025-07-19T21:02:28.865+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Committed partition 30 (task 233, attempt 0, stage 1.0)
[2025-07-19T21:02:28.867+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Starting task 41.0 in stage 1.0 (TID 239) (8b44f3d35cfa, executor driver, partition 41, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:28.868+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Committed partition 26 (task 231, attempt 0, stage 1.0)
[2025-07-19T21:02:28.868+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Finished task 26.0 in stage 1.0 (TID 231). 9073 bytes result sent to driver
[2025-07-19T21:02:28.868+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Finished task 29.0 in stage 1.0 (TID 232) in 359 ms on 8b44f3d35cfa (executor driver) (21/200)
[2025-07-19T21:02:28.869+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Starting task 43.0 in stage 1.0 (TID 240) (8b44f3d35cfa, executor driver, partition 43, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:28.869+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Running task 43.0 in stage 1.0 (TID 240)
[2025-07-19T21:02:28.869+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Finished task 26.0 in stage 1.0 (TID 231) in 406 ms on 8b44f3d35cfa (executor driver) (22/200)
[2025-07-19T21:02:28.869+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Running task 41.0 in stage 1.0 (TID 239)
[2025-07-19T21:02:28.869+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/37/.1.delta.a3134fb6-4364-42e0-944f-3000739fd6ca.TID236.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/37/1.delta
[2025-07-19T21:02:28.869+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=37),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/37] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/37/1.delta
[2025-07-19T21:02:28.869+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Finished task 30.0 in stage 1.0 (TID 233). 9121 bytes result sent to driver
[2025-07-19T21:02:28.869+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Starting task 45.0 in stage 1.0 (TID 241) (8b44f3d35cfa, executor driver, partition 45, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:28.873+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:28.874+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:28.875+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/38/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/38/.1.delta.b222e06f-8d66-47af-aebf-f48039b9645f.TID237.tmp
[2025-07-19T21:02:28.875+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:28.875+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:28.875+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Commit authorized for partition 37 (task 236, attempt 0, stage 1.0)
[2025-07-19T21:02:28.876+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Finished task 30.0 in stage 1.0 (TID 233) in 286 ms on 8b44f3d35cfa (executor driver) (23/200)
[2025-07-19T21:02:28.876+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:28.876+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Running task 45.0 in stage 1.0 (TID 241)
[2025-07-19T21:02:28.882+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e31be56
[2025-07-19T21:02:28.883+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:28.883+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:28.884+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=43, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:28.884+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=43),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/43] for update
[2025-07-19T21:02:28.888+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:28.892+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/39/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/39/.1.delta.91127cdc-5f7e-4143-8ff0-2d339c40ad59.TID238.tmp
[2025-07-19T21:02:28.893+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Committed partition 35 (task 235, attempt 0, stage 1.0)
[2025-07-19T21:02:28.894+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Committed partition 32 (task 234, attempt 0, stage 1.0)
[2025-07-19T21:02:28.895+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58a65c34
[2025-07-19T21:02:28.896+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=41, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:28.896+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Finished task 35.0 in stage 1.0 (TID 235). 9046 bytes result sent to driver
[2025-07-19T21:02:28.896+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Starting task 46.0 in stage 1.0 (TID 242) (8b44f3d35cfa, executor driver, partition 46, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:28.897+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=41),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/41] for update
[2025-07-19T21:02:28.898+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Finished task 35.0 in stage 1.0 (TID 235) in 229 ms on 8b44f3d35cfa (executor driver) (24/200)
[2025-07-19T21:02:28.899+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Finished task 32.0 in stage 1.0 (TID 234). 9123 bytes result sent to driver
[2025-07-19T21:02:28.899+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Starting task 47.0 in stage 1.0 (TID 243) (8b44f3d35cfa, executor driver, partition 47, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:28.900+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Finished task 32.0 in stage 1.0 (TID 234) in 304 ms on 8b44f3d35cfa (executor driver) (25/200)
[2025-07-19T21:02:28.901+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Running task 47.0 in stage 1.0 (TID 243)
[2025-07-19T21:02:28.901+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Running task 46.0 in stage 1.0 (TID 242)
[2025-07-19T21:02:28.902+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Committed partition 37 (task 236, attempt 0, stage 1.0)
[2025-07-19T21:02:28.903+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Finished task 37.0 in stage 1.0 (TID 236). 9043 bytes result sent to driver
[2025-07-19T21:02:28.904+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:28.904+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:28.906+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Starting task 48.0 in stage 1.0 (TID 244) (8b44f3d35cfa, executor driver, partition 48, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:28.906+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Finished task 37.0 in stage 1.0 (TID 236) in 159 ms on 8b44f3d35cfa (executor driver) (26/200)
[2025-07-19T21:02:28.907+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Running task 48.0 in stage 1.0 (TID 244)
[2025-07-19T21:02:28.910+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/43/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/43/.1.delta.69df385f-164f-49ee-9d94-49da60de1acf.TID240.tmp
[2025-07-19T21:02:28.912+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35e9348
[2025-07-19T21:02:28.913+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:28.913+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=45, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:28.914+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=45),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/45] for update
[2025-07-19T21:02:28.914+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:28.915+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:28.915+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:28.916+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:28.917+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:28.917+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65e952b2
[2025-07-19T21:02:28.918+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=46, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:28.919+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=46),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/46] for update
[2025-07-19T21:02:28.920+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/41/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/41/.1.delta.30dee920-c805-40ae-b6a5-a279933c8484.TID239.tmp
[2025-07-19T21:02:28.923+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/45/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/45/.1.delta.589e4655-0a38-4a65-b488-91a69033337f.TID241.tmp
[2025-07-19T21:02:28.925+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:28.927+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ac2cd19
[2025-07-19T21:02:28.927+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=47, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:28.928+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=47),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/47] for update
[2025-07-19T21:02:28.929+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:28.932+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/38/.1.delta.b222e06f-8d66-47af-aebf-f48039b9645f.TID237.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/38/1.delta
[2025-07-19T21:02:28.934+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=38),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/38] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/38/1.delta
[2025-07-19T21:02:28.934+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Commit authorized for partition 38 (task 237, attempt 0, stage 1.0)
[2025-07-19T21:02:28.934+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@12380eb2
[2025-07-19T21:02:28.937+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=48, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:28.938+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=48),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/48] for update
[2025-07-19T21:02:28.938+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/46/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/46/.1.delta.dedc1b32-c00f-474c-a8f2-c346d95d3e68.TID242.tmp
[2025-07-19T21:02:28.940+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/47/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/47/.1.delta.dc169619-9874-4e59-b8b4-d5117656d8c6.TID243.tmp
[2025-07-19T21:02:28.942+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:28.943+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/39/.1.delta.91127cdc-5f7e-4143-8ff0-2d339c40ad59.TID238.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/39/1.delta
[2025-07-19T21:02:28.943+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=39),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/39] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/39/1.delta
[2025-07-19T21:02:28.943+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Commit authorized for partition 39 (task 238, attempt 0, stage 1.0)
[2025-07-19T21:02:28.958+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/43/.1.delta.69df385f-164f-49ee-9d94-49da60de1acf.TID240.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/43/1.delta
[2025-07-19T21:02:28.959+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=43),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/43] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/43/1.delta
[2025-07-19T21:02:28.959+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/48/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/48/.1.delta.ae13cc6a-8d80-4439-bf46-d86f43a4877a.TID244.tmp
[2025-07-19T21:02:28.961+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Commit authorized for partition 43 (task 240, attempt 0, stage 1.0)
[2025-07-19T21:02:28.962+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Committed partition 39 (task 238, attempt 0, stage 1.0)
[2025-07-19T21:02:28.964+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Finished task 39.0 in stage 1.0 (TID 238). 9025 bytes result sent to driver
[2025-07-19T21:02:28.965+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Starting task 51.0 in stage 1.0 (TID 245) (8b44f3d35cfa, executor driver, partition 51, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:28.967+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Running task 51.0 in stage 1.0 (TID 245)
[2025-07-19T21:02:28.968+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Finished task 39.0 in stage 1.0 (TID 238) in 137 ms on 8b44f3d35cfa (executor driver) (27/200)
[2025-07-19T21:02:28.972+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:28.973+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:28.973+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Committed partition 38 (task 237, attempt 0, stage 1.0)
[2025-07-19T21:02:28.983+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Finished task 38.0 in stage 1.0 (TID 237). 9031 bytes result sent to driver
[2025-07-19T21:02:28.984+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/45/.1.delta.589e4655-0a38-4a65-b488-91a69033337f.TID241.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/45/1.delta
[2025-07-19T21:02:28.985+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=45),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/45] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/45/1.delta
[2025-07-19T21:02:28.986+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Starting task 52.0 in stage 1.0 (TID 246) (8b44f3d35cfa, executor driver, partition 52, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:28.986+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@18ba65e8
[2025-07-19T21:02:28.986+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Commit authorized for partition 45 (task 241, attempt 0, stage 1.0)
[2025-07-19T21:02:28.987+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=51, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:28.987+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO Executor: Running task 52.0 in stage 1.0 (TID 246)
[2025-07-19T21:02:28.987+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=51),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/51] for update
[2025-07-19T21:02:28.990+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO TaskSetManager: Finished task 38.0 in stage 1.0 (TID 237) in 174 ms on 8b44f3d35cfa (executor driver) (28/200)
[2025-07-19T21:02:28.991+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:28.991+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/41/.1.delta.30dee920-c805-40ae-b6a5-a279933c8484.TID239.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/41/1.delta
[2025-07-19T21:02:28.991+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=41),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/41] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/41/1.delta
[2025-07-19T21:02:28.991+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Commit authorized for partition 41 (task 239, attempt 0, stage 1.0)
[2025-07-19T21:02:28.997+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Committed partition 43 (task 240, attempt 0, stage 1.0)
[2025-07-19T21:02:29.000+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/46/.1.delta.dedc1b32-c00f-474c-a8f2-c346d95d3e68.TID242.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/46/1.delta
[2025-07-19T21:02:29.001+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=46),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/46] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/46/1.delta
[2025-07-19T21:02:29.001+0000] {subprocess.py:93} INFO - 25/07/19 21:02:28 INFO DataWritingSparkTask: Commit authorized for partition 46 (task 242, attempt 0, stage 1.0)
[2025-07-19T21:02:29.002+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 43.0 in stage 1.0 (TID 240). 9033 bytes result sent to driver
[2025-07-19T21:02:29.008+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/48/.1.delta.ae13cc6a-8d80-4439-bf46-d86f43a4877a.TID244.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/48/1.delta
[2025-07-19T21:02:29.010+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=48),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/48] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/48/1.delta
[2025-07-19T21:02:29.013+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 48 (task 244, attempt 0, stage 1.0)
[2025-07-19T21:02:29.013+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/51/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/51/.1.delta.58c8bf50-34f7-4d84-b101-5580bc6d9aad.TID245.tmp
[2025-07-19T21:02:29.014+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 45 (task 241, attempt 0, stage 1.0)
[2025-07-19T21:02:29.014+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 53.0 in stage 1.0 (TID 247) (8b44f3d35cfa, executor driver, partition 53, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.014+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 45.0 in stage 1.0 (TID 241). 9043 bytes result sent to driver
[2025-07-19T21:02:29.015+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.016+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
[2025-07-19T21:02:29.016+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 56.0 in stage 1.0 (TID 248) (8b44f3d35cfa, executor driver, partition 56, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.018+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 43.0 in stage 1.0 (TID 240) in 145 ms on 8b44f3d35cfa (executor driver) (29/200)
[2025-07-19T21:02:29.019+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 56.0 in stage 1.0 (TID 248)
[2025-07-19T21:02:29.019+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 45.0 in stage 1.0 (TID 241) in 143 ms on 8b44f3d35cfa (executor driver) (30/200)
[2025-07-19T21:02:29.020+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 53.0 in stage 1.0 (TID 247)
[2025-07-19T21:02:29.021+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/47/.1.delta.dc169619-9874-4e59-b8b4-d5117656d8c6.TID243.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/47/1.delta
[2025-07-19T21:02:29.022+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=47),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/47] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/47/1.delta
[2025-07-19T21:02:29.022+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 41 (task 239, attempt 0, stage 1.0)
[2025-07-19T21:02:29.023+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 47 (task 243, attempt 0, stage 1.0)
[2025-07-19T21:02:29.024+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 41.0 in stage 1.0 (TID 239). 9033 bytes result sent to driver
[2025-07-19T21:02:29.024+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.025+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:29.026+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 57.0 in stage 1.0 (TID 249) (8b44f3d35cfa, executor driver, partition 57, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.026+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 41.0 in stage 1.0 (TID 239) in 157 ms on 8b44f3d35cfa (executor driver) (31/200)
[2025-07-19T21:02:29.027+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.028+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:29.029+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@295d1571
[2025-07-19T21:02:29.029+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 57.0 in stage 1.0 (TID 249)
[2025-07-19T21:02:29.030+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=52, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.031+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=52),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/52] for update
[2025-07-19T21:02:29.031+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 46 (task 242, attempt 0, stage 1.0)
[2025-07-19T21:02:29.031+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 46.0 in stage 1.0 (TID 242). 9054 bytes result sent to driver
[2025-07-19T21:02:29.032+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.032+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:29.032+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 58.0 in stage 1.0 (TID 250) (8b44f3d35cfa, executor driver, partition 58, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.033+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.033+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 58.0 in stage 1.0 (TID 250)
[2025-07-19T21:02:29.037+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 47 (task 243, attempt 0, stage 1.0)
[2025-07-19T21:02:29.038+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 46.0 in stage 1.0 (TID 242) in 140 ms on 8b44f3d35cfa (executor driver) (32/200)
[2025-07-19T21:02:29.038+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 47.0 in stage 1.0 (TID 243). 9042 bytes result sent to driver
[2025-07-19T21:02:29.039+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 59.0 in stage 1.0 (TID 251) (8b44f3d35cfa, executor driver, partition 59, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.040+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 47.0 in stage 1.0 (TID 243) in 141 ms on 8b44f3d35cfa (executor driver) (33/200)
[2025-07-19T21:02:29.043+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.043+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/52/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/52/.1.delta.d23709d4-e6e4-49bc-97df-17b772fb3659.TID246.tmp
[2025-07-19T21:02:29.044+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T21:02:29.045+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e97c003
[2025-07-19T21:02:29.046+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=53, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.047+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=53),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/53] for update
[2025-07-19T21:02:29.048+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 59.0 in stage 1.0 (TID 251)
[2025-07-19T21:02:29.048+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.049+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.049+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:29.057+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d6b211d
[2025-07-19T21:02:29.057+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=56, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.058+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=56),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/56] for update
[2025-07-19T21:02:29.058+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.062+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/53/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/53/.1.delta.a6a37814-3e22-4e49-b73f-fbb9a6edf94d.TID247.tmp
[2025-07-19T21:02:29.063+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/51/.1.delta.58c8bf50-34f7-4d84-b101-5580bc6d9aad.TID245.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/51/1.delta
[2025-07-19T21:02:29.064+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=51),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/51] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/51/1.delta
[2025-07-19T21:02:29.065+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 51 (task 245, attempt 0, stage 1.0)
[2025-07-19T21:02:29.066+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d3f28bf
[2025-07-19T21:02:29.066+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=59, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.066+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=59),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/59] for update
[2025-07-19T21:02:29.071+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.072+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 48 (task 244, attempt 0, stage 1.0)
[2025-07-19T21:02:29.073+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 48.0 in stage 1.0 (TID 244). 9044 bytes result sent to driver
[2025-07-19T21:02:29.077+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/56/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/56/.1.delta.8d58f983-da76-411b-af3b-b6854742632d.TID248.tmp
[2025-07-19T21:02:29.077+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 60.0 in stage 1.0 (TID 252) (8b44f3d35cfa, executor driver, partition 60, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.077+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2475b946
[2025-07-19T21:02:29.077+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=58, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.077+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 48.0 in stage 1.0 (TID 244) in 171 ms on 8b44f3d35cfa (executor driver) (34/200)
[2025-07-19T21:02:29.077+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=58),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/58] for update
[2025-07-19T21:02:29.078+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 60.0 in stage 1.0 (TID 252)
[2025-07-19T21:02:29.078+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.084+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/59/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/59/.1.delta.7402a3ae-e6f6-4f8c-84af-86f3b6ba3536.TID251.tmp
[2025-07-19T21:02:29.084+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.085+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:29.088+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@db53651
[2025-07-19T21:02:29.089+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/52/.1.delta.d23709d4-e6e4-49bc-97df-17b772fb3659.TID246.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/52/1.delta
[2025-07-19T21:02:29.090+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=52),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/52] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/52/1.delta
[2025-07-19T21:02:29.091+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/58/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/58/.1.delta.28cb1e7a-7feb-4441-aeda-25b8709895cd.TID250.tmp
[2025-07-19T21:02:29.092+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 52 (task 246, attempt 0, stage 1.0)
[2025-07-19T21:02:29.093+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=57, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.093+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=57),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/57] for update
[2025-07-19T21:02:29.094+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 51 (task 245, attempt 0, stage 1.0)
[2025-07-19T21:02:29.095+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 51.0 in stage 1.0 (TID 245). 9035 bytes result sent to driver
[2025-07-19T21:02:29.099+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 62.0 in stage 1.0 (TID 253) (8b44f3d35cfa, executor driver, partition 62, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.100+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 62.0 in stage 1.0 (TID 253)
[2025-07-19T21:02:29.101+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 51.0 in stage 1.0 (TID 245) in 135 ms on 8b44f3d35cfa (executor driver) (35/200)
[2025-07-19T21:02:29.104+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.106+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f812380
[2025-07-19T21:02:29.106+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=60, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.106+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=60),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/60] for update
[2025-07-19T21:02:29.107+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.107+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:29.107+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.113+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2cfe0cc9
[2025-07-19T21:02:29.115+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 52 (task 246, attempt 0, stage 1.0)
[2025-07-19T21:02:29.116+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/53/.1.delta.a6a37814-3e22-4e49-b73f-fbb9a6edf94d.TID247.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/53/1.delta
[2025-07-19T21:02:29.116+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 52.0 in stage 1.0 (TID 246). 9027 bytes result sent to driver
[2025-07-19T21:02:29.116+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=53),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/53] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/53/1.delta
[2025-07-19T21:02:29.117+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 63.0 in stage 1.0 (TID 254) (8b44f3d35cfa, executor driver, partition 63, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.117+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=62, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.118+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=62),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/62] for update
[2025-07-19T21:02:29.119+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 53 (task 247, attempt 0, stage 1.0)
[2025-07-19T21:02:29.119+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.120+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 63.0 in stage 1.0 (TID 254)
[2025-07-19T21:02:29.121+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 52.0 in stage 1.0 (TID 246) in 139 ms on 8b44f3d35cfa (executor driver) (36/200)
[2025-07-19T21:02:29.122+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/57/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/57/.1.delta.6085f7c0-8ec5-4a81-9637-42d962c3666d.TID249.tmp
[2025-07-19T21:02:29.124+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.125+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:29.125+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/60/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/60/.1.delta.1cbb7537-9d8b-4bd9-9b6c-9af6b93701cf.TID252.tmp
[2025-07-19T21:02:29.136+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/62/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/62/.1.delta.05b2aaec-d0fe-49ab-aa32-83e5f8e3d83a.TID253.tmp
[2025-07-19T21:02:29.136+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a69a31
[2025-07-19T21:02:29.136+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=63, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.137+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/56/.1.delta.8d58f983-da76-411b-af3b-b6854742632d.TID248.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/56/1.delta
[2025-07-19T21:02:29.137+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=56),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/56] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/56/1.delta
[2025-07-19T21:02:29.137+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=63),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/63] for update
[2025-07-19T21:02:29.137+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.139+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 56 (task 248, attempt 0, stage 1.0)
[2025-07-19T21:02:29.141+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/58/.1.delta.28cb1e7a-7feb-4441-aeda-25b8709895cd.TID250.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/58/1.delta
[2025-07-19T21:02:29.141+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=58),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/58] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/58/1.delta
[2025-07-19T21:02:29.143+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 58 (task 250, attempt 0, stage 1.0)
[2025-07-19T21:02:29.165+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/59/.1.delta.7402a3ae-e6f6-4f8c-84af-86f3b6ba3536.TID251.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/59/1.delta
[2025-07-19T21:02:29.166+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=59),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/59] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/59/1.delta
[2025-07-19T21:02:29.166+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 59 (task 251, attempt 0, stage 1.0)
[2025-07-19T21:02:29.166+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/63/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/63/.1.delta.a7712b0b-71bb-41b5-9c55-bcecdfbec47c.TID254.tmp
[2025-07-19T21:02:29.167+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 53 (task 247, attempt 0, stage 1.0)
[2025-07-19T21:02:29.171+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 53.0 in stage 1.0 (TID 247). 9051 bytes result sent to driver
[2025-07-19T21:02:29.175+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 64.0 in stage 1.0 (TID 255) (8b44f3d35cfa, executor driver, partition 64, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.176+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 64.0 in stage 1.0 (TID 255)
[2025-07-19T21:02:29.177+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 53.0 in stage 1.0 (TID 247) in 165 ms on 8b44f3d35cfa (executor driver) (37/200)
[2025-07-19T21:02:29.180+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 56 (task 248, attempt 0, stage 1.0)
[2025-07-19T21:02:29.181+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 58 (task 250, attempt 0, stage 1.0)
[2025-07-19T21:02:29.184+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.186+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:29.187+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 56.0 in stage 1.0 (TID 248). 9050 bytes result sent to driver
[2025-07-19T21:02:29.188+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 65.0 in stage 1.0 (TID 256) (8b44f3d35cfa, executor driver, partition 65, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.189+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 58.0 in stage 1.0 (TID 250). 9047 bytes result sent to driver
[2025-07-19T21:02:29.190+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 65.0 in stage 1.0 (TID 256)
[2025-07-19T21:02:29.192+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 56.0 in stage 1.0 (TID 248) in 175 ms on 8b44f3d35cfa (executor driver) (38/200)
[2025-07-19T21:02:29.192+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/62/.1.delta.05b2aaec-d0fe-49ab-aa32-83e5f8e3d83a.TID253.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/62/1.delta
[2025-07-19T21:02:29.192+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=62),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/62] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/62/1.delta
[2025-07-19T21:02:29.193+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 66.0 in stage 1.0 (TID 257) (8b44f3d35cfa, executor driver, partition 66, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.193+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 62 (task 253, attempt 0, stage 1.0)
[2025-07-19T21:02:29.194+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 59 (task 251, attempt 0, stage 1.0)
[2025-07-19T21:02:29.195+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.196+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:29.196+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 59.0 in stage 1.0 (TID 251). 9048 bytes result sent to driver
[2025-07-19T21:02:29.197+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 66.0 in stage 1.0 (TID 257)
[2025-07-19T21:02:29.200+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 68.0 in stage 1.0 (TID 258) (8b44f3d35cfa, executor driver, partition 68, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.201+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 68.0 in stage 1.0 (TID 258)
[2025-07-19T21:02:29.202+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 58.0 in stage 1.0 (TID 250) in 171 ms on 8b44f3d35cfa (executor driver) (39/200)
[2025-07-19T21:02:29.203+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@760d7bb6
[2025-07-19T21:02:29.204+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/60/.1.delta.1cbb7537-9d8b-4bd9-9b6c-9af6b93701cf.TID252.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/60/1.delta
[2025-07-19T21:02:29.206+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=60),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/60] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/60/1.delta
[2025-07-19T21:02:29.207+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 59.0 in stage 1.0 (TID 251) in 165 ms on 8b44f3d35cfa (executor driver) (40/200)
[2025-07-19T21:02:29.207+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.207+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:29.207+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.208+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:29.208+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=64, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.208+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=64),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/64] for update
[2025-07-19T21:02:29.208+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.209+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 60 (task 252, attempt 0, stage 1.0)
[2025-07-19T21:02:29.209+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/57/.1.delta.6085f7c0-8ec5-4a81-9637-42d962c3666d.TID249.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/57/1.delta
[2025-07-19T21:02:29.209+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=57),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/57] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/57/1.delta
[2025-07-19T21:02:29.210+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 57 (task 249, attempt 0, stage 1.0)
[2025-07-19T21:02:29.212+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@595f0d00
[2025-07-19T21:02:29.212+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=68, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.212+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=68),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/68] for update
[2025-07-19T21:02:29.217+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.219+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/64/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/64/.1.delta.f533fd34-3fce-4965-aa2b-25af3870af93.TID255.tmp
[2025-07-19T21:02:29.221+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HadoopTableOperations: Committed a new metadata file s3a://warehouse/bronze/Checkins_raw/metadata/v128.metadata.json
[2025-07-19T21:02:29.221+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 62 (task 253, attempt 0, stage 1.0)
[2025-07-19T21:02:29.225+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 62.0 in stage 1.0 (TID 253). 9043 bytes result sent to driver
[2025-07-19T21:02:29.236+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@14e4c8b7
[2025-07-19T21:02:29.237+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/68/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/68/.1.delta.6dc84786-616f-4dcf-bc17-efe89181e585.TID258.tmp
[2025-07-19T21:02:29.237+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=66, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.238+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=66),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/66] for update
[2025-07-19T21:02:29.238+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 69.0 in stage 1.0 (TID 259) (8b44f3d35cfa, executor driver, partition 69, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.239+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 69.0 in stage 1.0 (TID 259)
[2025-07-19T21:02:29.239+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.242+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 62.0 in stage 1.0 (TID 253) in 142 ms on 8b44f3d35cfa (executor driver) (41/200)
[2025-07-19T21:02:29.243+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/63/.1.delta.a7712b0b-71bb-41b5-9c55-bcecdfbec47c.TID254.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/63/1.delta
[2025-07-19T21:02:29.243+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=63),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/63] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/63/1.delta
[2025-07-19T21:02:29.243+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 63 (task 254, attempt 0, stage 1.0)
[2025-07-19T21:02:29.244+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.244+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@695e835a
[2025-07-19T21:02:29.244+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:29.245+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=65, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.245+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 57 (task 249, attempt 0, stage 1.0)
[2025-07-19T21:02:29.245+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 57.0 in stage 1.0 (TID 249). 9090 bytes result sent to driver
[2025-07-19T21:02:29.246+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=65),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/65] for update
[2025-07-19T21:02:29.248+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 71.0 in stage 1.0 (TID 260) (8b44f3d35cfa, executor driver, partition 71, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.249+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 57.0 in stage 1.0 (TID 249) in 225 ms on 8b44f3d35cfa (executor driver) (42/200)
[2025-07-19T21:02:29.250+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.251+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 71.0 in stage 1.0 (TID 260)
[2025-07-19T21:02:29.251+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3a62df93
[2025-07-19T21:02:29.253+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.254+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:29.255+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 60 (task 252, attempt 0, stage 1.0)
[2025-07-19T21:02:29.256+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 60.0 in stage 1.0 (TID 252). 9080 bytes result sent to driver
[2025-07-19T21:02:29.256+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/66/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/66/.1.delta.50222d17-bd0e-4602-8462-37a8b31ab243.TID257.tmp
[2025-07-19T21:02:29.257+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 72.0 in stage 1.0 (TID 261) (8b44f3d35cfa, executor driver, partition 72, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.257+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 72.0 in stage 1.0 (TID 261)
[2025-07-19T21:02:29.260+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 60.0 in stage 1.0 (TID 252) in 184 ms on 8b44f3d35cfa (executor driver) (43/200)
[2025-07-19T21:02:29.261+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=69, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.261+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=69),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/69] for update
[2025-07-19T21:02:29.261+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.265+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/65/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/65/.1.delta.ad475c2d-25d4-4516-b835-e6e7bf4c5cbe.TID256.tmp
[2025-07-19T21:02:29.268+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.269+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 63 (task 254, attempt 0, stage 1.0)
[2025-07-19T21:02:29.271+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T21:02:29.275+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@46f3635f
[2025-07-19T21:02:29.276+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 63.0 in stage 1.0 (TID 254). 9076 bytes result sent to driver
[2025-07-19T21:02:29.277+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=71, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.277+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=71),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/71] for update
[2025-07-19T21:02:29.278+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 73.0 in stage 1.0 (TID 262) (8b44f3d35cfa, executor driver, partition 73, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.278+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 73.0 in stage 1.0 (TID 262)
[2025-07-19T21:02:29.279+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 63.0 in stage 1.0 (TID 254) in 159 ms on 8b44f3d35cfa (executor driver) (44/200)
[2025-07-19T21:02:29.279+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.280+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/69/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/69/.1.delta.52f5ace0-9488-4692-bfce-56894159573e.TID259.tmp
[2025-07-19T21:02:29.281+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4913aa47
[2025-07-19T21:02:29.284+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=72, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.286+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.286+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:29.287+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=72),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/72] for update
[2025-07-19T21:02:29.290+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.308+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/64/.1.delta.f533fd34-3fce-4965-aa2b-25af3870af93.TID255.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/64/1.delta
[2025-07-19T21:02:29.308+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=64),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/64] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/64/1.delta
[2025-07-19T21:02:29.314+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 64 (task 255, attempt 0, stage 1.0)
[2025-07-19T21:02:29.314+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/68/.1.delta.6dc84786-616f-4dcf-bc17-efe89181e585.TID258.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/68/1.delta
[2025-07-19T21:02:29.314+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=68),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/68] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/68/1.delta
[2025-07-19T21:02:29.315+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/71/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/71/.1.delta.1c73febf-86d5-4b22-8664-837adb3fd49a.TID260.tmp
[2025-07-19T21:02:29.321+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 68 (task 258, attempt 0, stage 1.0)
[2025-07-19T21:02:29.322+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/72/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/72/.1.delta.548d9230-c5ba-4ebe-80b7-f451d8572994.TID261.tmp
[2025-07-19T21:02:29.323+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f738f35
[2025-07-19T21:02:29.327+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=73, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.328+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=73),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/73] for update
[2025-07-19T21:02:29.329+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.342+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/65/.1.delta.ad475c2d-25d4-4516-b835-e6e7bf4c5cbe.TID256.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/65/1.delta
[2025-07-19T21:02:29.343+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=65),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/65] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/65/1.delta
[2025-07-19T21:02:29.343+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 65 (task 256, attempt 0, stage 1.0)
[2025-07-19T21:02:29.347+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/66/.1.delta.50222d17-bd0e-4602-8462-37a8b31ab243.TID257.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/66/1.delta
[2025-07-19T21:02:29.348+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=66),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/66] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/66/1.delta
[2025-07-19T21:02:29.348+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 66 (task 257, attempt 0, stage 1.0)
[2025-07-19T21:02:29.348+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 64 (task 255, attempt 0, stage 1.0)
[2025-07-19T21:02:29.354+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO SnapshotProducer: Committed snapshot 8093862157344045911 (FastAppend)
[2025-07-19T21:02:29.356+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/73/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/73/.1.delta.84ae16f2-2cb5-4917-be85-295219f0ec87.TID262.tmp
[2025-07-19T21:02:29.356+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 64.0 in stage 1.0 (TID 255). 9093 bytes result sent to driver
[2025-07-19T21:02:29.356+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 75.0 in stage 1.0 (TID 263) (8b44f3d35cfa, executor driver, partition 75, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.357+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 75.0 in stage 1.0 (TID 263)
[2025-07-19T21:02:29.358+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 64.0 in stage 1.0 (TID 255) in 187 ms on 8b44f3d35cfa (executor driver) (45/200)
[2025-07-19T21:02:29.359+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/69/.1.delta.52f5ace0-9488-4692-bfce-56894159573e.TID259.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/69/1.delta
[2025-07-19T21:02:29.359+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=69),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/69] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/69/1.delta
[2025-07-19T21:02:29.360+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 69 (task 259, attempt 0, stage 1.0)
[2025-07-19T21:02:29.362+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.363+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:29.368+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 66 (task 257, attempt 0, stage 1.0)
[2025-07-19T21:02:29.375+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 66.0 in stage 1.0 (TID 257). 9103 bytes result sent to driver
[2025-07-19T21:02:29.377+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 77.0 in stage 1.0 (TID 264) (8b44f3d35cfa, executor driver, partition 77, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.377+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 68 (task 258, attempt 0, stage 1.0)
[2025-07-19T21:02:29.377+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 77.0 in stage 1.0 (TID 264)
[2025-07-19T21:02:29.377+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a0498e5
[2025-07-19T21:02:29.378+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 66.0 in stage 1.0 (TID 257) in 183 ms on 8b44f3d35cfa (executor driver) (46/200)
[2025-07-19T21:02:29.378+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=75, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.378+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 68.0 in stage 1.0 (TID 258). 9072 bytes result sent to driver
[2025-07-19T21:02:29.378+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=75),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/75] for update
[2025-07-19T21:02:29.378+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 78.0 in stage 1.0 (TID 265) (8b44f3d35cfa, executor driver, partition 78, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.378+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.378+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 68.0 in stage 1.0 (TID 258) in 177 ms on 8b44f3d35cfa (executor driver) (47/200)
[2025-07-19T21:02:29.384+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.384+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:29.387+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 78.0 in stage 1.0 (TID 265)
[2025-07-19T21:02:29.388+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/75/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/75/.1.delta.1993ca3a-5abb-4432-9e89-4b3b1df9b0ee.TID263.tmp
[2025-07-19T21:02:29.394+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/72/.1.delta.548d9230-c5ba-4ebe-80b7-f451d8572994.TID261.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/72/1.delta
[2025-07-19T21:02:29.394+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=72),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/72] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/72/1.delta
[2025-07-19T21:02:29.399+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 69 (task 259, attempt 0, stage 1.0)
[2025-07-19T21:02:29.400+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 69.0 in stage 1.0 (TID 259). 9066 bytes result sent to driver
[2025-07-19T21:02:29.403+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 72 (task 261, attempt 0, stage 1.0)
[2025-07-19T21:02:29.404+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 79.0 in stage 1.0 (TID 266) (8b44f3d35cfa, executor driver, partition 79, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.405+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 79.0 in stage 1.0 (TID 266)
[2025-07-19T21:02:29.405+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.405+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
[2025-07-19T21:02:29.405+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/71/.1.delta.1c73febf-86d5-4b22-8664-837adb3fd49a.TID260.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/71/1.delta
[2025-07-19T21:02:29.405+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=71),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/71] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/71/1.delta
[2025-07-19T21:02:29.406+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 65 (task 256, attempt 0, stage 1.0)
[2025-07-19T21:02:29.406+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@50ec94a4
[2025-07-19T21:02:29.406+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 69.0 in stage 1.0 (TID 259) in 180 ms on 8b44f3d35cfa (executor driver) (48/200)
[2025-07-19T21:02:29.432+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=77, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.435+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=77),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/77] for update
[2025-07-19T21:02:29.436+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.436+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 71 (task 260, attempt 0, stage 1.0)
[2025-07-19T21:02:29.436+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 65.0 in stage 1.0 (TID 256). 9129 bytes result sent to driver
[2025-07-19T21:02:29.436+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 82.0 in stage 1.0 (TID 267) (8b44f3d35cfa, executor driver, partition 82, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.437+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 65.0 in stage 1.0 (TID 256) in 251 ms on 8b44f3d35cfa (executor driver) (49/200)
[2025-07-19T21:02:29.439+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/73/.1.delta.84ae16f2-2cb5-4917-be85-295219f0ec87.TID262.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/73/1.delta
[2025-07-19T21:02:29.439+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=73),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/73] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/73/1.delta
[2025-07-19T21:02:29.442+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 73 (task 262, attempt 0, stage 1.0)
[2025-07-19T21:02:29.442+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 82.0 in stage 1.0 (TID 267)
[2025-07-19T21:02:29.444+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.445+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:29.446+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7e3e8250
[2025-07-19T21:02:29.446+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.446+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:29.447+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=78, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.447+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=78),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/78] for update
[2025-07-19T21:02:29.447+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.456+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/77/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/77/.1.delta.03d67911-365d-47b6-9a25-8824e29d7738.TID264.tmp
[2025-07-19T21:02:29.457+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 71 (task 260, attempt 0, stage 1.0)
[2025-07-19T21:02:29.458+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 71.0 in stage 1.0 (TID 260). 9074 bytes result sent to driver
[2025-07-19T21:02:29.460+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@77cd6f0a
[2025-07-19T21:02:29.460+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 83.0 in stage 1.0 (TID 268) (8b44f3d35cfa, executor driver, partition 83, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.463+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 83.0 in stage 1.0 (TID 268)
[2025-07-19T21:02:29.464+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 71.0 in stage 1.0 (TID 260) in 219 ms on 8b44f3d35cfa (executor driver) (50/200)
[2025-07-19T21:02:29.464+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=79, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.465+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=79),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/79] for update
[2025-07-19T21:02:29.472+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 72 (task 261, attempt 0, stage 1.0)
[2025-07-19T21:02:29.473+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/78/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/78/.1.delta.05c44bae-33b5-4b4e-9cc3-332dcac98dbd.TID265.tmp
[2025-07-19T21:02:29.478+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@247362dd
[2025-07-19T21:02:29.479+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=82, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.479+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=82),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/82] for update
[2025-07-19T21:02:29.479+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 73 (task 262, attempt 0, stage 1.0)
[2025-07-19T21:02:29.479+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 73.0 in stage 1.0 (TID 262). 9095 bytes result sent to driver
[2025-07-19T21:02:29.479+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 72.0 in stage 1.0 (TID 261). 9113 bytes result sent to driver
[2025-07-19T21:02:29.479+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.479+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.480+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 85.0 in stage 1.0 (TID 269) (8b44f3d35cfa, executor driver, partition 85, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.480+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 86.0 in stage 1.0 (TID 270) (8b44f3d35cfa, executor driver, partition 86, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.480+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.481+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:29.481+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 72.0 in stage 1.0 (TID 261) in 222 ms on 8b44f3d35cfa (executor driver) (51/200)
[2025-07-19T21:02:29.481+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 85.0 in stage 1.0 (TID 269)
[2025-07-19T21:02:29.481+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 73.0 in stage 1.0 (TID 262) in 207 ms on 8b44f3d35cfa (executor driver) (52/200)
[2025-07-19T21:02:29.481+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.481+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:29.481+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 86.0 in stage 1.0 (TID 270)
[2025-07-19T21:02:29.485+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.486+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:29.487+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4562463f
[2025-07-19T21:02:29.488+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/75/.1.delta.1993ca3a-5abb-4432-9e89-4b3b1df9b0ee.TID263.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/75/1.delta
[2025-07-19T21:02:29.490+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=75),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/75] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/75/1.delta
[2025-07-19T21:02:29.491+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 75 (task 263, attempt 0, stage 1.0)
[2025-07-19T21:02:29.491+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=83, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.492+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=83),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/83] for update
[2025-07-19T21:02:29.493+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.494+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/82/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/82/.1.delta.c2a9441b-ccba-4f55-b6bb-b696c86ac0e5.TID267.tmp
[2025-07-19T21:02:29.499+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/79/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/79/.1.delta.173c6d69-5ed0-43f8-863d-d131935ced82.TID266.tmp
[2025-07-19T21:02:29.499+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO LoggingMetricsReporter: Received metrics report: CommitReport{tableName=my_catalog.bronze.Checkins_raw, snapshotId=8093862157344045911, sequenceNumber=127, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT1.271110418S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=CounterResult{unit=COUNT, value=137}, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=6255}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=CounterResult{unit=COUNT, value=234}, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=8928}, addedFilesSizeInBytes=CounterResult{unit=BYTES, value=446424}, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=20262697}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}}, metadata={engine-version=3.5.6, app-id=local-1752958935081, engine-name=spark, iceberg-version=Apache Iceberg 1.4.0 (commit 10367c380098c2e06a49521a33681ac7f6c64b2c)}}
[2025-07-19T21:02:29.499+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO SparkWrite: Committed in 1295 ms
[2025-07-19T21:02:29.500+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@36cdd5fb
[2025-07-19T21:02:29.500+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Checkins_raw, format=PARQUET)] committed.
[2025-07-19T21:02:29.500+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=86, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.500+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=86),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/86] for update
[2025-07-19T21:02:29.503+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.507+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO WatermarkTracker: Updating event-time watermark from 0 to 1752784740000 ms
[2025-07-19T21:02:29.507+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/83/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/83/.1.delta.e817bc42-cd83-4e05-8c7f-4715182fe855.TID268.tmp
[2025-07-19T21:02:29.511+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@18b86b60
[2025-07-19T21:02:29.513+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 75 (task 263, attempt 0, stage 1.0)
[2025-07-19T21:02:29.513+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=85, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.514+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 75.0 in stage 1.0 (TID 263). 9033 bytes result sent to driver
[2025-07-19T21:02:29.515+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=85),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/85] for update
[2025-07-19T21:02:29.515+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 87.0 in stage 1.0 (TID 271) (8b44f3d35cfa, executor driver, partition 87, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.515+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 75.0 in stage 1.0 (TID 263) in 162 ms on 8b44f3d35cfa (executor driver) (53/200)
[2025-07-19T21:02:29.515+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 87.0 in stage 1.0 (TID 271)
[2025-07-19T21:02:29.517+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.523+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/commits/0 using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/commits/.0.79e8c773-d765-427c-9ed7-c7c5e72e8f15.tmp
[2025-07-19T21:02:29.524+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.524+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:29.525+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/86/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/86/.1.delta.57746ce9-be07-47a1-a571-a541cb901a17.TID270.tmp
[2025-07-19T21:02:29.534+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/77/.1.delta.03d67911-365d-47b6-9a25-8824e29d7738.TID264.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/77/1.delta
[2025-07-19T21:02:29.537+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=77),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/77] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/77/1.delta
[2025-07-19T21:02:29.538+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 77 (task 264, attempt 0, stage 1.0)
[2025-07-19T21:02:29.539+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/85/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/85/.1.delta.10545620-d18c-467f-be9a-6ff9c5b19679.TID269.tmp
[2025-07-19T21:02:29.539+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@fe3c1a3
[2025-07-19T21:02:29.542+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=87, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.543+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=87),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/87] for update
[2025-07-19T21:02:29.543+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.551+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/78/.1.delta.05c44bae-33b5-4b4e-9cc3-332dcac98dbd.TID265.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/78/1.delta
[2025-07-19T21:02:29.552+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=78),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/78] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/78/1.delta
[2025-07-19T21:02:29.554+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 78 (task 265, attempt 0, stage 1.0)
[2025-07-19T21:02:29.555+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/82/.1.delta.c2a9441b-ccba-4f55-b6bb-b696c86ac0e5.TID267.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/82/1.delta
[2025-07-19T21:02:29.555+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=82),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/82] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/82/1.delta
[2025-07-19T21:02:29.560+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 82 (task 267, attempt 0, stage 1.0)
[2025-07-19T21:02:29.565+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/87/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/87/.1.delta.bdaa591a-5291-4532-ac27-22b4fdc5a76a.TID271.tmp
[2025-07-19T21:02:29.570+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 77 (task 264, attempt 0, stage 1.0)
[2025-07-19T21:02:29.571+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 77.0 in stage 1.0 (TID 264). 9037 bytes result sent to driver
[2025-07-19T21:02:29.578+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 78 (task 265, attempt 0, stage 1.0)
[2025-07-19T21:02:29.578+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 89.0 in stage 1.0 (TID 272) (8b44f3d35cfa, executor driver, partition 89, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.579+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 89.0 in stage 1.0 (TID 272)
[2025-07-19T21:02:29.580+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 78.0 in stage 1.0 (TID 265). 9046 bytes result sent to driver
[2025-07-19T21:02:29.580+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 92.0 in stage 1.0 (TID 273) (8b44f3d35cfa, executor driver, partition 92, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.581+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 92.0 in stage 1.0 (TID 273)
[2025-07-19T21:02:29.584+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 77.0 in stage 1.0 (TID 264) in 211 ms on 8b44f3d35cfa (executor driver) (54/200)
[2025-07-19T21:02:29.585+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.587+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:29.587+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/79/.1.delta.173c6d69-5ed0-43f8-863d-d131935ced82.TID266.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/79/1.delta
[2025-07-19T21:02:29.588+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=79),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/79] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/79/1.delta
[2025-07-19T21:02:29.589+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.590+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:29.590+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 78.0 in stage 1.0 (TID 265) in 213 ms on 8b44f3d35cfa (executor driver) (55/200)
[2025-07-19T21:02:29.590+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 79 (task 266, attempt 0, stage 1.0)
[2025-07-19T21:02:29.591+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 82 (task 267, attempt 0, stage 1.0)
[2025-07-19T21:02:29.591+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 82.0 in stage 1.0 (TID 267). 9039 bytes result sent to driver
[2025-07-19T21:02:29.592+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 94.0 in stage 1.0 (TID 274) (8b44f3d35cfa, executor driver, partition 94, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.592+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 94.0 in stage 1.0 (TID 274)
[2025-07-19T21:02:29.592+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 82.0 in stage 1.0 (TID 267) in 162 ms on 8b44f3d35cfa (executor driver) (56/200)
[2025-07-19T21:02:29.593+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/85/.1.delta.10545620-d18c-467f-be9a-6ff9c5b19679.TID269.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/85/1.delta
[2025-07-19T21:02:29.593+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=85),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/85] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/85/1.delta
[2025-07-19T21:02:29.595+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 85 (task 269, attempt 0, stage 1.0)
[2025-07-19T21:02:29.596+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.596+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:29.602+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@b5ef329
[2025-07-19T21:02:29.602+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=89, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.602+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=89),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/89] for update
[2025-07-19T21:02:29.605+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/86/.1.delta.57746ce9-be07-47a1-a571-a541cb901a17.TID270.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/86/1.delta
[2025-07-19T21:02:29.607+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=86),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/86] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/86/1.delta
[2025-07-19T21:02:29.607+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/83/.1.delta.e817bc42-cd83-4e05-8c7f-4715182fe855.TID268.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/83/1.delta
[2025-07-19T21:02:29.608+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 86 (task 270, attempt 0, stage 1.0)
[2025-07-19T21:02:29.608+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=83),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/83] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/83/1.delta
[2025-07-19T21:02:29.608+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 83 (task 268, attempt 0, stage 1.0)
[2025-07-19T21:02:29.608+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.610+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 79 (task 266, attempt 0, stage 1.0)
[2025-07-19T21:02:29.611+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 85 (task 269, attempt 0, stage 1.0)
[2025-07-19T21:02:29.612+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@60c4228f
[2025-07-19T21:02:29.613+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 85.0 in stage 1.0 (TID 269). 9048 bytes result sent to driver
[2025-07-19T21:02:29.615+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 95.0 in stage 1.0 (TID 275) (8b44f3d35cfa, executor driver, partition 95, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.615+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=92, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.616+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=92),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/92] for update
[2025-07-19T21:02:29.616+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 95.0 in stage 1.0 (TID 275)
[2025-07-19T21:02:29.617+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 79.0 in stage 1.0 (TID 266). 9039 bytes result sent to driver
[2025-07-19T21:02:29.618+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.619+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 96.0 in stage 1.0 (TID 276) (8b44f3d35cfa, executor driver, partition 96, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.619+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 85.0 in stage 1.0 (TID 269) in 139 ms on 8b44f3d35cfa (executor driver) (57/200)
[2025-07-19T21:02:29.620+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 79.0 in stage 1.0 (TID 266) in 215 ms on 8b44f3d35cfa (executor driver) (58/200)
[2025-07-19T21:02:29.621+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 96.0 in stage 1.0 (TID 276)
[2025-07-19T21:02:29.626+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/commits/.0.79e8c773-d765-427c-9ed7-c7c5e72e8f15.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/commits/0
[2025-07-19T21:02:29.628+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6405f8ad
[2025-07-19T21:02:29.630+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=94, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.634+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=94),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/94] for update
[2025-07-19T21:02:29.637+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.639+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:29.640+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.640+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/87/.1.delta.bdaa591a-5291-4532-ac27-22b4fdc5a76a.TID271.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/87/1.delta
[2025-07-19T21:02:29.641+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=87),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/87] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/87/1.delta
[2025-07-19T21:02:29.641+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 86 (task 270, attempt 0, stage 1.0)
[2025-07-19T21:02:29.642+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 86.0 in stage 1.0 (TID 270). 9051 bytes result sent to driver
[2025-07-19T21:02:29.643+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 87 (task 271, attempt 0, stage 1.0)
[2025-07-19T21:02:29.644+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/89/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/89/.1.delta.3a54a4ed-61e2-4646-b59d-04792b0619a7.TID272.tmp
[2025-07-19T21:02:29.644+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.644+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:29.645+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 97.0 in stage 1.0 (TID 277) (8b44f3d35cfa, executor driver, partition 97, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.645+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 83 (task 268, attempt 0, stage 1.0)
[2025-07-19T21:02:29.645+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 86.0 in stage 1.0 (TID 270) in 157 ms on 8b44f3d35cfa (executor driver) (59/200)
[2025-07-19T21:02:29.646+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6f6fd989
[2025-07-19T21:02:29.646+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 83.0 in stage 1.0 (TID 268). 9038 bytes result sent to driver
[2025-07-19T21:02:29.647+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 97.0 in stage 1.0 (TID 277)
[2025-07-19T21:02:29.647+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=96, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.647+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=96),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/96] for update
[2025-07-19T21:02:29.647+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 98.0 in stage 1.0 (TID 278) (8b44f3d35cfa, executor driver, partition 98, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.648+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 98.0 in stage 1.0 (TID 278)
[2025-07-19T21:02:29.648+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 83.0 in stage 1.0 (TID 268) in 176 ms on 8b44f3d35cfa (executor driver) (60/200)
[2025-07-19T21:02:29.648+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/94/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/94/.1.delta.231faf34-78f3-488d-9248-61a7b57f222d.TID274.tmp
[2025-07-19T21:02:29.648+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.649+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/92/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/92/.1.delta.06042ff0-8e12-40a6-a091-766a0e3f4992.TID273.tmp
[2025-07-19T21:02:29.649+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a8df87e
[2025-07-19T21:02:29.649+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=95, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.650+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=95),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/95] for update
[2025-07-19T21:02:29.650+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.657+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.657+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:29.658+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.658+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:29.662+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1053edb6
[2025-07-19T21:02:29.664+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=97, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.665+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=97),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/97] for update
[2025-07-19T21:02:29.665+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/96/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/96/.1.delta.a75c0177-a770-468e-af3f-4fa6565b35a1.TID276.tmp
[2025-07-19T21:02:29.666+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.667+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/95/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/95/.1.delta.2d4cd5a7-9307-4113-a146-badfddae1680.TID275.tmp
[2025-07-19T21:02:29.667+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 87 (task 271, attempt 0, stage 1.0)
[2025-07-19T21:02:29.668+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e2ee74d
[2025-07-19T21:02:29.672+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=98, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.674+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=98),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/98] for update
[2025-07-19T21:02:29.674+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.675+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/89/.1.delta.3a54a4ed-61e2-4646-b59d-04792b0619a7.TID272.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/89/1.delta
[2025-07-19T21:02:29.675+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=89),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/89] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/89/1.delta
[2025-07-19T21:02:29.676+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 87.0 in stage 1.0 (TID 271). 9051 bytes result sent to driver
[2025-07-19T21:02:29.677+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 99.0 in stage 1.0 (TID 279) (8b44f3d35cfa, executor driver, partition 99, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.678+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 87.0 in stage 1.0 (TID 271) in 163 ms on 8b44f3d35cfa (executor driver) (61/200)
[2025-07-19T21:02:29.680+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 89 (task 272, attempt 0, stage 1.0)
[2025-07-19T21:02:29.684+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 99.0 in stage 1.0 (TID 279)
[2025-07-19T21:02:29.685+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/97/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/97/.1.delta.63d61a10-86c9-4934-8ac4-a3f6fef1d30b.TID277.tmp
[2025-07-19T21:02:29.689+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/98/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/98/.1.delta.6278e5a5-76c7-4c35-8b42-6bff24f944fd.TID278.tmp
[2025-07-19T21:02:29.694+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.695+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:29.695+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/92/.1.delta.06042ff0-8e12-40a6-a091-766a0e3f4992.TID273.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/92/1.delta
[2025-07-19T21:02:29.696+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=92),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/92] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/92/1.delta
[2025-07-19T21:02:29.696+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 92 (task 273, attempt 0, stage 1.0)
[2025-07-19T21:02:29.701+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@27f79270
[2025-07-19T21:02:29.701+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=99, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.701+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=99),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/99] for update
[2025-07-19T21:02:29.703+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/94/.1.delta.231faf34-78f3-488d-9248-61a7b57f222d.TID274.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/94/1.delta
[2025-07-19T21:02:29.705+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=94),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/94] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/94/1.delta
[2025-07-19T21:02:29.706+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.706+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 94 (task 274, attempt 0, stage 1.0)
[2025-07-19T21:02:29.706+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 89 (task 272, attempt 0, stage 1.0)
[2025-07-19T21:02:29.706+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 89.0 in stage 1.0 (TID 272). 9035 bytes result sent to driver
[2025-07-19T21:02:29.711+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 100.0 in stage 1.0 (TID 280) (8b44f3d35cfa, executor driver, partition 100, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.712+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 100.0 in stage 1.0 (TID 280)
[2025-07-19T21:02:29.714+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 89.0 in stage 1.0 (TID 272) in 138 ms on 8b44f3d35cfa (executor driver) (62/200)
[2025-07-19T21:02:29.715+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.715+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:29.718+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 92 (task 273, attempt 0, stage 1.0)
[2025-07-19T21:02:29.719+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO MicroBatchExecution: Streaming query made progress: {
[2025-07-19T21:02:29.720+0000] {subprocess.py:93} INFO -   "id" : "857c6a97-8a45-4319-91e0-4d8882460008",
[2025-07-19T21:02:29.720+0000] {subprocess.py:93} INFO -   "runId" : "fe455bb9-f78f-4c5d-a439-a7e861a32bf0",
[2025-07-19T21:02:29.721+0000] {subprocess.py:93} INFO -   "name" : null,
[2025-07-19T21:02:29.722+0000] {subprocess.py:93} INFO -   "timestamp" : "2025-07-19T21:02:18.260Z",
[2025-07-19T21:02:29.723+0000] {subprocess.py:93} INFO -   "batchId" : 0,
[2025-07-19T21:02:29.723+0000] {subprocess.py:93} INFO -   "numInputRows" : 234,
[2025-07-19T21:02:29.724+0000] {subprocess.py:93} INFO -   "inputRowsPerSecond" : 0.0,
[2025-07-19T21:02:29.726+0000] {subprocess.py:93} INFO -   "processedRowsPerSecond" : 20.600404965225813,
[2025-07-19T21:02:29.726+0000] {subprocess.py:93} INFO -   "durationMs" : {
[2025-07-19T21:02:29.727+0000] {subprocess.py:93} INFO -     "addBatch" : 10127,
[2025-07-19T21:02:29.728+0000] {subprocess.py:93} INFO -     "commitOffsets" : 113,
[2025-07-19T21:02:29.728+0000] {subprocess.py:93} INFO -     "getBatch" : 24,
[2025-07-19T21:02:29.729+0000] {subprocess.py:93} INFO -     "latestOffset" : 546,
[2025-07-19T21:02:29.730+0000] {subprocess.py:93} INFO -     "queryPlanning" : 439,
[2025-07-19T21:02:29.730+0000] {subprocess.py:93} INFO -     "triggerExecution" : 11359,
[2025-07-19T21:02:29.730+0000] {subprocess.py:93} INFO -     "walCommit" : 96
[2025-07-19T21:02:29.730+0000] {subprocess.py:93} INFO -   },
[2025-07-19T21:02:29.731+0000] {subprocess.py:93} INFO -   "eventTime" : {
[2025-07-19T21:02:29.732+0000] {subprocess.py:93} INFO -     "avg" : "2025-07-19T18:13:04.871Z",
[2025-07-19T21:02:29.732+0000] {subprocess.py:93} INFO -     "max" : "2025-07-19T20:39:00.000Z",
[2025-07-19T21:02:29.733+0000] {subprocess.py:93} INFO -     "min" : "2025-07-19T16:04:00.000Z",
[2025-07-19T21:02:29.733+0000] {subprocess.py:93} INFO -     "watermark" : "1970-01-01T00:00:00.000Z"
[2025-07-19T21:02:29.733+0000] {subprocess.py:93} INFO -   },
[2025-07-19T21:02:29.733+0000] {subprocess.py:93} INFO -   "stateOperators" : [ {
[2025-07-19T21:02:29.733+0000] {subprocess.py:93} INFO -     "operatorName" : "dedupe",
[2025-07-19T21:02:29.733+0000] {subprocess.py:93} INFO -     "numRowsTotal" : 234,
[2025-07-19T21:02:29.733+0000] {subprocess.py:93} INFO -     "numRowsUpdated" : 234,
[2025-07-19T21:02:29.733+0000] {subprocess.py:93} INFO -     "allUpdatesTimeMs" : 4300,
[2025-07-19T21:02:29.733+0000] {subprocess.py:93} INFO -     "numRowsRemoved" : 0,
[2025-07-19T21:02:29.733+0000] {subprocess.py:93} INFO -     "allRemovalsTimeMs" : 391,
[2025-07-19T21:02:29.734+0000] {subprocess.py:93} INFO -     "commitTimeMs" : 17426,
[2025-07-19T21:02:29.734+0000] {subprocess.py:93} INFO -     "memoryUsedBytes" : 102016,
[2025-07-19T21:02:29.734+0000] {subprocess.py:93} INFO -     "numRowsDroppedByWatermark" : 0,
[2025-07-19T21:02:29.734+0000] {subprocess.py:93} INFO -     "numShufflePartitions" : 200,
[2025-07-19T21:02:29.734+0000] {subprocess.py:93} INFO -     "numStateStoreInstances" : 200,
[2025-07-19T21:02:29.734+0000] {subprocess.py:93} INFO -     "customMetrics" : {
[2025-07-19T21:02:29.734+0000] {subprocess.py:93} INFO -       "loadedMapCacheHitCount" : 0,
[2025-07-19T21:02:29.734+0000] {subprocess.py:93} INFO -       "loadedMapCacheMissCount" : 0,
[2025-07-19T21:02:29.734+0000] {subprocess.py:93} INFO -       "numDroppedDuplicateRows" : 0,
[2025-07-19T21:02:29.734+0000] {subprocess.py:93} INFO -       "stateOnCurrentVersionSizeBytes" : 73216
[2025-07-19T21:02:29.735+0000] {subprocess.py:93} INFO -     }
[2025-07-19T21:02:29.735+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T21:02:29.735+0000] {subprocess.py:93} INFO -   "sources" : [ {
[2025-07-19T21:02:29.735+0000] {subprocess.py:93} INFO -     "description" : "KafkaV2[Subscribe[checkins]]",
[2025-07-19T21:02:29.735+0000] {subprocess.py:93} INFO -     "startOffset" : null,
[2025-07-19T21:02:29.735+0000] {subprocess.py:93} INFO -     "endOffset" : {
[2025-07-19T21:02:29.735+0000] {subprocess.py:93} INFO -       "checkins" : {
[2025-07-19T21:02:29.735+0000] {subprocess.py:93} INFO -         "0" : 234
[2025-07-19T21:02:29.735+0000] {subprocess.py:93} INFO -       }
[2025-07-19T21:02:29.735+0000] {subprocess.py:93} INFO -     },
[2025-07-19T21:02:29.735+0000] {subprocess.py:93} INFO -     "latestOffset" : {
[2025-07-19T21:02:29.736+0000] {subprocess.py:93} INFO -       "checkins" : {
[2025-07-19T21:02:29.736+0000] {subprocess.py:93} INFO -         "0" : 234
[2025-07-19T21:02:29.736+0000] {subprocess.py:93} INFO -       }
[2025-07-19T21:02:29.736+0000] {subprocess.py:93} INFO -     },
[2025-07-19T21:02:29.736+0000] {subprocess.py:93} INFO -     "numInputRows" : 234,
[2025-07-19T21:02:29.736+0000] {subprocess.py:93} INFO -     "inputRowsPerSecond" : 0.0,
[2025-07-19T21:02:29.736+0000] {subprocess.py:93} INFO -     "processedRowsPerSecond" : 20.600404965225813,
[2025-07-19T21:02:29.736+0000] {subprocess.py:93} INFO -     "metrics" : {
[2025-07-19T21:02:29.737+0000] {subprocess.py:93} INFO -       "avgOffsetsBehindLatest" : "0.0",
[2025-07-19T21:02:29.737+0000] {subprocess.py:93} INFO -       "maxOffsetsBehindLatest" : "0",
[2025-07-19T21:02:29.737+0000] {subprocess.py:93} INFO -       "minOffsetsBehindLatest" : "0"
[2025-07-19T21:02:29.737+0000] {subprocess.py:93} INFO -     }
[2025-07-19T21:02:29.737+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T21:02:29.738+0000] {subprocess.py:93} INFO -   "sink" : {
[2025-07-19T21:02:29.738+0000] {subprocess.py:93} INFO -     "description" : "my_catalog.bronze.Checkins_raw",
[2025-07-19T21:02:29.739+0000] {subprocess.py:93} INFO -     "numOutputRows" : 234
[2025-07-19T21:02:29.739+0000] {subprocess.py:93} INFO -   }
[2025-07-19T21:02:29.741+0000] {subprocess.py:93} INFO - }
[2025-07-19T21:02:29.742+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 92.0 in stage 1.0 (TID 273). 9035 bytes result sent to driver
[2025-07-19T21:02:29.742+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 102.0 in stage 1.0 (TID 281) (8b44f3d35cfa, executor driver, partition 102, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.743+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/99/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/99/.1.delta.5640e708-f09b-4830-bdb9-2e055d5dea55.TID279.tmp
[2025-07-19T21:02:29.743+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@de457d0
[2025-07-19T21:02:29.743+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=100, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.743+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 92.0 in stage 1.0 (TID 273) in 145 ms on 8b44f3d35cfa (executor driver) (63/200)
[2025-07-19T21:02:29.744+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 102.0 in stage 1.0 (TID 281)
[2025-07-19T21:02:29.744+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=100),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/100] for update
[2025-07-19T21:02:29.744+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.744+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.745+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:29.745+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/95/.1.delta.2d4cd5a7-9307-4113-a146-badfddae1680.TID275.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/95/1.delta
[2025-07-19T21:02:29.747+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=95),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/95] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/95/1.delta
[2025-07-19T21:02:29.748+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 95 (task 275, attempt 0, stage 1.0)
[2025-07-19T21:02:29.749+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/97/.1.delta.63d61a10-86c9-4934-8ac4-a3f6fef1d30b.TID277.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/97/1.delta
[2025-07-19T21:02:29.750+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=97),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/97] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/97/1.delta
[2025-07-19T21:02:29.750+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 97 (task 277, attempt 0, stage 1.0)
[2025-07-19T21:02:29.751+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6263a092
[2025-07-19T21:02:29.751+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=102, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.752+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=102),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/102] for update
[2025-07-19T21:02:29.752+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/100/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/100/.1.delta.ca7ef67d-8aff-4247-b47d-12fe80c04c0d.TID280.tmp
[2025-07-19T21:02:29.753+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 94 (task 274, attempt 0, stage 1.0)
[2025-07-19T21:02:29.753+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/96/.1.delta.a75c0177-a770-468e-af3f-4fa6565b35a1.TID276.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/96/1.delta
[2025-07-19T21:02:29.753+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=96),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/96] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/96/1.delta
[2025-07-19T21:02:29.754+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 96 (task 276, attempt 0, stage 1.0)
[2025-07-19T21:02:29.755+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/98/.1.delta.6278e5a5-76c7-4c35-8b42-6bff24f944fd.TID278.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/98/1.delta
[2025-07-19T21:02:29.755+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=98),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/98] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/98/1.delta
[2025-07-19T21:02:29.756+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 98 (task 278, attempt 0, stage 1.0)
[2025-07-19T21:02:29.757+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 94.0 in stage 1.0 (TID 274). 9049 bytes result sent to driver
[2025-07-19T21:02:29.758+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 104.0 in stage 1.0 (TID 282) (8b44f3d35cfa, executor driver, partition 104, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.759+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 104.0 in stage 1.0 (TID 282)
[2025-07-19T21:02:29.762+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.766+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 94.0 in stage 1.0 (TID 274) in 161 ms on 8b44f3d35cfa (executor driver) (64/200)
[2025-07-19T21:02:29.768+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.775+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:29.777+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@61e19f21
[2025-07-19T21:02:29.778+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=104, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.778+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=104),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/104] for update
[2025-07-19T21:02:29.779+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/offsets/1 using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/offsets/.1.39955d2c-834e-4453-8792-23512ea5688b.tmp
[2025-07-19T21:02:29.782+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/102/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/102/.1.delta.60a6c6de-6722-482f-9ee6-eef38f3c5eaa.TID281.tmp
[2025-07-19T21:02:29.782+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.787+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/99/.1.delta.5640e708-f09b-4830-bdb9-2e055d5dea55.TID279.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/99/1.delta
[2025-07-19T21:02:29.788+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=99),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/99] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/99/1.delta
[2025-07-19T21:02:29.789+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 99 (task 279, attempt 0, stage 1.0)
[2025-07-19T21:02:29.789+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/104/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/104/.1.delta.2ca54003-6c55-4b2f-a43b-a8bdf4e267da.TID282.tmp
[2025-07-19T21:02:29.793+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 95 (task 275, attempt 0, stage 1.0)
[2025-07-19T21:02:29.794+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 95.0 in stage 1.0 (TID 275). 9037 bytes result sent to driver
[2025-07-19T21:02:29.795+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 96 (task 276, attempt 0, stage 1.0)
[2025-07-19T21:02:29.796+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 98 (task 278, attempt 0, stage 1.0)
[2025-07-19T21:02:29.796+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 105.0 in stage 1.0 (TID 283) (8b44f3d35cfa, executor driver, partition 105, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.797+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 105.0 in stage 1.0 (TID 283)
[2025-07-19T21:02:29.798+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 98.0 in stage 1.0 (TID 278). 9029 bytes result sent to driver
[2025-07-19T21:02:29.801+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 97 (task 277, attempt 0, stage 1.0)
[2025-07-19T21:02:29.802+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 106.0 in stage 1.0 (TID 284) (8b44f3d35cfa, executor driver, partition 106, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.804+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 97.0 in stage 1.0 (TID 277). 9037 bytes result sent to driver
[2025-07-19T21:02:29.805+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 107.0 in stage 1.0 (TID 285) (8b44f3d35cfa, executor driver, partition 107, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.806+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 107.0 in stage 1.0 (TID 285)
[2025-07-19T21:02:29.806+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.807+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:29.808+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 106.0 in stage 1.0 (TID 284)
[2025-07-19T21:02:29.808+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 98.0 in stage 1.0 (TID 278) in 166 ms on 8b44f3d35cfa (executor driver) (65/200)
[2025-07-19T21:02:29.808+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 96.0 in stage 1.0 (TID 276). 9075 bytes result sent to driver
[2025-07-19T21:02:29.809+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 97.0 in stage 1.0 (TID 277) in 171 ms on 8b44f3d35cfa (executor driver) (66/200)
[2025-07-19T21:02:29.809+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 109.0 in stage 1.0 (TID 286) (8b44f3d35cfa, executor driver, partition 109, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.811+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 95.0 in stage 1.0 (TID 275) in 190 ms on 8b44f3d35cfa (executor driver) (67/200)
[2025-07-19T21:02:29.811+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.812+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.812+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:29.812+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 109.0 in stage 1.0 (TID 286)
[2025-07-19T21:02:29.813+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:29.813+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 96.0 in stage 1.0 (TID 276) in 190 ms on 8b44f3d35cfa (executor driver) (68/200)
[2025-07-19T21:02:29.813+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.813+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:29.813+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1cec8183
[2025-07-19T21:02:29.813+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=105, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.813+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=105),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/105] for update
[2025-07-19T21:02:29.813+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.816+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f882db5
[2025-07-19T21:02:29.817+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=109, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.820+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=109),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/109] for update
[2025-07-19T21:02:29.820+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 99 (task 279, attempt 0, stage 1.0)
[2025-07-19T21:02:29.820+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 99.0 in stage 1.0 (TID 279). 9037 bytes result sent to driver
[2025-07-19T21:02:29.823+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.825+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 110.0 in stage 1.0 (TID 287) (8b44f3d35cfa, executor driver, partition 110, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.825+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 110.0 in stage 1.0 (TID 287)
[2025-07-19T21:02:29.826+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/100/.1.delta.ca7ef67d-8aff-4247-b47d-12fe80c04c0d.TID280.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/100/1.delta
[2025-07-19T21:02:29.826+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=100),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/100] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/100/1.delta
[2025-07-19T21:02:29.827+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/105/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/105/.1.delta.221a0c99-7be2-4fb3-afa4-1073a96e30d0.TID283.tmp
[2025-07-19T21:02:29.828+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 99.0 in stage 1.0 (TID 279) in 148 ms on 8b44f3d35cfa (executor driver) (69/200)
[2025-07-19T21:02:29.829+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/offsets/.1.39955d2c-834e-4453-8792-23512ea5688b.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/offsets/1
[2025-07-19T21:02:29.829+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/102/.1.delta.60a6c6de-6722-482f-9ee6-eef38f3c5eaa.TID281.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/102/1.delta
[2025-07-19T21:02:29.831+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 100 (task 280, attempt 0, stage 1.0)
[2025-07-19T21:02:29.832+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=102),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/102] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/102/1.delta
[2025-07-19T21:02:29.832+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO MicroBatchExecution: Committed offsets for batch 1. Metadata OffsetSeqMetadata(1752784740000,1752958949732,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.optimizer.pruneFiltersCanPruneStreamingSubplan -> false, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2025-07-19T21:02:29.832+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 102 (task 281, attempt 0, stage 1.0)
[2025-07-19T21:02:29.833+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.833+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:29.834+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7fd9ec17
[2025-07-19T21:02:29.834+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=107, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.834+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=107),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/107] for update
[2025-07-19T21:02:29.839+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.840+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@67bda99e
[2025-07-19T21:02:29.842+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=106, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.843+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=106),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/106] for update
[2025-07-19T21:02:29.843+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/109/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/109/.1.delta.c22cbb0a-5072-4eb4-94bf-60c057106dc6.TID286.tmp
[2025-07-19T21:02:29.844+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.845+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7e70cfc3
[2025-07-19T21:02:29.850+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=110, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.852+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/104/.1.delta.2ca54003-6c55-4b2f-a43b-a8bdf4e267da.TID282.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/104/1.delta
[2025-07-19T21:02:29.853+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=110),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/110] for update
[2025-07-19T21:02:29.854+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=104),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/104] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/104/1.delta
[2025-07-19T21:02:29.854+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 102 (task 281, attempt 0, stage 1.0)
[2025-07-19T21:02:29.856+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 104 (task 282, attempt 0, stage 1.0)
[2025-07-19T21:02:29.858+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.859+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 102.0 in stage 1.0 (TID 281). 9037 bytes result sent to driver
[2025-07-19T21:02:29.859+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 111.0 in stage 1.0 (TID 288) (8b44f3d35cfa, executor driver, partition 111, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.859+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 111.0 in stage 1.0 (TID 288)
[2025-07-19T21:02:29.859+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 100 (task 280, attempt 0, stage 1.0)
[2025-07-19T21:02:29.860+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 100.0 in stage 1.0 (TID 280). 9045 bytes result sent to driver
[2025-07-19T21:02:29.868+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/106/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/106/.1.delta.7896b900-5aea-48bc-8f21-8aefa634a089.TID284.tmp
[2025-07-19T21:02:29.869+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 113.0 in stage 1.0 (TID 289) (8b44f3d35cfa, executor driver, partition 113, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.873+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.874+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:29.874+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 100.0 in stage 1.0 (TID 280) in 158 ms on 8b44f3d35cfa (executor driver) (70/200)
[2025-07-19T21:02:29.875+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 113.0 in stage 1.0 (TID 289)
[2025-07-19T21:02:29.875+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.875+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:29.876+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 102.0 in stage 1.0 (TID 281) in 151 ms on 8b44f3d35cfa (executor driver) (71/200)
[2025-07-19T21:02:29.876+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/107/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/107/.1.delta.5125660b-cbf9-4882-ae80-7051329bc1c0.TID285.tmp
[2025-07-19T21:02:29.877+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Checkins_raw
[2025-07-19T21:02:29.877+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Checkins_raw
[2025-07-19T21:02:29.877+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Checkins_raw
[2025-07-19T21:02:29.882+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/110/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/110/.1.delta.2075b4e1-347a-4606-94c1-fabb322c82be.TID287.tmp
[2025-07-19T21:02:29.884+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d6b3043
[2025-07-19T21:02:29.885+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=111, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.888+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=111),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/111] for update
[2025-07-19T21:02:29.888+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.891+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/105/.1.delta.221a0c99-7be2-4fb3-afa4-1073a96e30d0.TID283.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/105/1.delta
[2025-07-19T21:02:29.893+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=105),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/105] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/105/1.delta
[2025-07-19T21:02:29.894+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 105 (task 283, attempt 0, stage 1.0)
[2025-07-19T21:02:29.894+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 104 (task 282, attempt 0, stage 1.0)
[2025-07-19T21:02:29.894+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 104.0 in stage 1.0 (TID 282). 9085 bytes result sent to driver
[2025-07-19T21:02:29.895+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 117.0 in stage 1.0 (TID 290) (8b44f3d35cfa, executor driver, partition 117, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.895+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 104.0 in stage 1.0 (TID 282) in 146 ms on 8b44f3d35cfa (executor driver) (72/200)
[2025-07-19T21:02:29.897+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 117.0 in stage 1.0 (TID 290)
[2025-07-19T21:02:29.900+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.901+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:29.902+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@725df04b
[2025-07-19T21:02:29.904+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=113, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.904+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=113),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/113] for update
[2025-07-19T21:02:29.905+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.906+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/111/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/111/.1.delta.f991e64a-9a90-4584-b320-15abe5bcc419.TID288.tmp
[2025-07-19T21:02:29.909+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4db9c17d
[2025-07-19T21:02:29.911+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=117, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.911+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=117),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/117] for update
[2025-07-19T21:02:29.912+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Checkins_raw
[2025-07-19T21:02:29.912+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Checkins_raw
[2025-07-19T21:02:29.913+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Checkins_raw
[2025-07-19T21:02:29.914+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.914+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 105 (task 283, attempt 0, stage 1.0)
[2025-07-19T21:02:29.915+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 105.0 in stage 1.0 (TID 283). 9086 bytes result sent to driver
[2025-07-19T21:02:29.917+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 118.0 in stage 1.0 (TID 291) (8b44f3d35cfa, executor driver, partition 118, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.918+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 105.0 in stage 1.0 (TID 283) in 121 ms on 8b44f3d35cfa (executor driver) (73/200)
[2025-07-19T21:02:29.921+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 118.0 in stage 1.0 (TID 291)
[2025-07-19T21:02:29.922+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/113/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/113/.1.delta.651c5b09-65c4-45ac-b1fc-2dfb16095a71.TID289.tmp
[2025-07-19T21:02:29.922+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.922+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:29.923+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/109/.1.delta.c22cbb0a-5072-4eb4-94bf-60c057106dc6.TID286.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/109/1.delta
[2025-07-19T21:02:29.924+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=109),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/109] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/109/1.delta
[2025-07-19T21:02:29.924+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 109 (task 286, attempt 0, stage 1.0)
[2025-07-19T21:02:29.928+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/117/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/117/.1.delta.2ff9b89e-4c21-49a4-8198-146af4420bbd.TID290.tmp
[2025-07-19T21:02:29.941+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/107/.1.delta.5125660b-cbf9-4882-ae80-7051329bc1c0.TID285.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/107/1.delta
[2025-07-19T21:02:29.942+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=107),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/107] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/107/1.delta
[2025-07-19T21:02:29.942+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Checkins_raw
[2025-07-19T21:02:29.942+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@66c84e36
[2025-07-19T21:02:29.942+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Checkins_raw
[2025-07-19T21:02:29.942+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Checkins_raw
[2025-07-19T21:02:29.942+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=118, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.942+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/106/.1.delta.7896b900-5aea-48bc-8f21-8aefa634a089.TID284.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/106/1.delta
[2025-07-19T21:02:29.943+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=106),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/106] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/106/1.delta
[2025-07-19T21:02:29.943+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 106 (task 284, attempt 0, stage 1.0)
[2025-07-19T21:02:29.943+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=118),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/118] for update
[2025-07-19T21:02:29.944+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 107 (task 285, attempt 0, stage 1.0)
[2025-07-19T21:02:29.944+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/110/.1.delta.2075b4e1-347a-4606-94c1-fabb322c82be.TID287.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/110/1.delta
[2025-07-19T21:02:29.944+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=110),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/110] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/110/1.delta
[2025-07-19T21:02:29.944+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.949+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 110 (task 287, attempt 0, stage 1.0)
[2025-07-19T21:02:29.966+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 109 (task 286, attempt 0, stage 1.0)
[2025-07-19T21:02:29.966+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/118/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/118/.1.delta.72242455-b161-4cf4-bc92-40a423583694.TID291.tmp
[2025-07-19T21:02:29.975+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 109.0 in stage 1.0 (TID 286). 9080 bytes result sent to driver
[2025-07-19T21:02:29.976+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 107 (task 285, attempt 0, stage 1.0)
[2025-07-19T21:02:29.977+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 119.0 in stage 1.0 (TID 292) (8b44f3d35cfa, executor driver, partition 119, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.977+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 107.0 in stage 1.0 (TID 285). 9127 bytes result sent to driver
[2025-07-19T21:02:29.978+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 120.0 in stage 1.0 (TID 293) (8b44f3d35cfa, executor driver, partition 120, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.982+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 119.0 in stage 1.0 (TID 292)
[2025-07-19T21:02:29.983+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 120.0 in stage 1.0 (TID 293)
[2025-07-19T21:02:29.984+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 107.0 in stage 1.0 (TID 285) in 175 ms on 8b44f3d35cfa (executor driver) (74/200)
[2025-07-19T21:02:29.984+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 109.0 in stage 1.0 (TID 286) in 171 ms on 8b44f3d35cfa (executor driver) (75/200)
[2025-07-19T21:02:29.984+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 110 (task 287, attempt 0, stage 1.0)
[2025-07-19T21:02:29.985+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/111/.1.delta.f991e64a-9a90-4584-b320-15abe5bcc419.TID288.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/111/1.delta
[2025-07-19T21:02:29.985+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=111),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/111] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/111/1.delta
[2025-07-19T21:02:29.987+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.988+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:29.988+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.988+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:29.988+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 110.0 in stage 1.0 (TID 287). 9061 bytes result sent to driver
[2025-07-19T21:02:29.988+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 111 (task 288, attempt 0, stage 1.0)
[2025-07-19T21:02:29.989+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Starting task 121.0 in stage 1.0 (TID 294) (8b44f3d35cfa, executor driver, partition 121, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:29.989+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Running task 121.0 in stage 1.0 (TID 294)
[2025-07-19T21:02:29.989+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO TaskSetManager: Finished task 110.0 in stage 1.0 (TID 287) in 157 ms on 8b44f3d35cfa (executor driver) (76/200)
[2025-07-19T21:02:29.989+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:29.989+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:29.989+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4797518b
[2025-07-19T21:02:29.991+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=119, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:29.991+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=119),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/119] for update
[2025-07-19T21:02:29.991+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:29.992+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 209.0 KiB, free 433.2 MiB)
[2025-07-19T21:02:29.992+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/117/.1.delta.2ff9b89e-4c21-49a4-8198-146af4420bbd.TID290.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/117/1.delta
[2025-07-19T21:02:29.992+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=117),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/117] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/117/1.delta
[2025-07-19T21:02:29.992+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Commit authorized for partition 117 (task 290, attempt 0, stage 1.0)
[2025-07-19T21:02:30.000+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO DataWritingSparkTask: Committed partition 106 (task 284, attempt 0, stage 1.0)
[2025-07-19T21:02:30.001+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO Executor: Finished task 106.0 in stage 1.0 (TID 284). 9078 bytes result sent to driver
[2025-07-19T21:02:30.004+0000] {subprocess.py:93} INFO - 25/07/19 21:02:29 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47b67137
[2025-07-19T21:02:30.005+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 122.0 in stage 1.0 (TID 295) (8b44f3d35cfa, executor driver, partition 122, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.006+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/113/.1.delta.651c5b09-65c4-45ac-b1fc-2dfb16095a71.TID289.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/113/1.delta
[2025-07-19T21:02:30.007+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=113),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/113] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/113/1.delta
[2025-07-19T21:02:30.008+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=120, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.009+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=120),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/120] for update
[2025-07-19T21:02:30.010+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 113 (task 289, attempt 0, stage 1.0)
[2025-07-19T21:02:30.011+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 122.0 in stage 1.0 (TID 295)
[2025-07-19T21:02:30.012+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 106.0 in stage 1.0 (TID 284) in 204 ms on 8b44f3d35cfa (executor driver) (77/200)
[2025-07-19T21:02:30.013+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.015+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/119/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/119/.1.delta.41bb1794-9209-4056-84ee-1d49fd4cf2ee.TID292.tmp
[2025-07-19T21:02:30.016+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.2 MiB)
[2025-07-19T21:02:30.017+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 8b44f3d35cfa:38433 (size: 35.4 KiB, free: 434.1 MiB)
[2025-07-19T21:02:30.017+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO SparkContext: Created broadcast 12 from start at <unknown>:0
[2025-07-19T21:02:30.018+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 111 (task 288, attempt 0, stage 1.0)
[2025-07-19T21:02:30.019+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.020+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 111.0 in stage 1.0 (TID 288). 9103 bytes result sent to driver
[2025-07-19T21:02:30.021+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 32.0 KiB, free 433.1 MiB)
[2025-07-19T21:02:30.022+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T21:02:30.022+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 123.0 in stage 1.0 (TID 296) (8b44f3d35cfa, executor driver, partition 123, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.022+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a5510a3
[2025-07-19T21:02:30.022+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 123.0 in stage 1.0 (TID 296)
[2025-07-19T21:02:30.022+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/120/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/120/.1.delta.4d7e66d1-b4e9-44fd-a002-187e9b90bec7.TID293.tmp
[2025-07-19T21:02:30.024+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=121, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.024+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=121),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/121] for update
[2025-07-19T21:02:30.025+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 111.0 in stage 1.0 (TID 288) in 162 ms on 8b44f3d35cfa (executor driver) (78/200)
[2025-07-19T21:02:30.025+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 117 (task 290, attempt 0, stage 1.0)
[2025-07-19T21:02:30.025+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 433.1 MiB)
[2025-07-19T21:02:30.025+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 117.0 in stage 1.0 (TID 290). 9078 bytes result sent to driver
[2025-07-19T21:02:30.025+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.025+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:30.032+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 127.0 in stage 1.0 (TID 297) (8b44f3d35cfa, executor driver, partition 127, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.033+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 127.0 in stage 1.0 (TID 297)
[2025-07-19T21:02:30.034+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 8b44f3d35cfa:38433 (size: 29.5 KiB, free: 434.1 MiB)
[2025-07-19T21:02:30.035+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 117.0 in stage 1.0 (TID 290) in 138 ms on 8b44f3d35cfa (executor driver) (79/200)
[2025-07-19T21:02:30.036+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO SparkContext: Created broadcast 13 from start at <unknown>:0
[2025-07-19T21:02:30.037+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6f14c24f
[2025-07-19T21:02:30.038+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=122, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.038+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=122),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/122] for update
[2025-07-19T21:02:30.038+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO WriteToDataSourceV2Exec: Start processing data source write support: MicroBatchWrite[epoch: 1, writer: IcebergStreamingWrite(table=my_catalog.bronze.Checkins_raw, format=PARQUET)]. The input RDD has 200 partitions.
[2025-07-19T21:02:30.038+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.038+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.039+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.039+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.040+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO SparkContext: Starting job: start at <unknown>:0
[2025-07-19T21:02:30.041+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 113 (task 289, attempt 0, stage 1.0)
[2025-07-19T21:02:30.042+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/118/.1.delta.72242455-b161-4cf4-bc92-40a423583694.TID291.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/118/1.delta
[2025-07-19T21:02:30.042+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=118),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/118] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/118/1.delta
[2025-07-19T21:02:30.043+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 113.0 in stage 1.0 (TID 289). 9095 bytes result sent to driver
[2025-07-19T21:02:30.046+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DAGScheduler: Registering RDD 27 (start at <unknown>:0) as input to shuffle 3
[2025-07-19T21:02:30.047+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DAGScheduler: Got job 3 (start at <unknown>:0) with 200 output partitions
[2025-07-19T21:02:30.049+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DAGScheduler: Final stage: ResultStage 7 (start at <unknown>:0)
[2025-07-19T21:02:30.050+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
[2025-07-19T21:02:30.051+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DAGScheduler: Missing parents: List()
[2025-07-19T21:02:30.051+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DAGScheduler: Submitting ResultStage 7 (StateStoreRDD[29] at start at <unknown>:0), which has no missing parents
[2025-07-19T21:02:30.051+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 128.0 in stage 1.0 (TID 298) (8b44f3d35cfa, executor driver, partition 128, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.051+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 128.0 in stage 1.0 (TID 298)
[2025-07-19T21:02:30.052+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@87c7d01
[2025-07-19T21:02:30.052+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.052+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.052+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=123, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.052+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 118 (task 291, attempt 0, stage 1.0)
[2025-07-19T21:02:30.053+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=123),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/123] for update
[2025-07-19T21:02:30.053+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/121/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/121/.1.delta.739780db-1ff9-480f-9db5-76cdf3f73a2e.TID294.tmp
[2025-07-19T21:02:30.053+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.055+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 113.0 in stage 1.0 (TID 289) in 189 ms on 8b44f3d35cfa (executor driver) (80/200)
[2025-07-19T21:02:30.056+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/122/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/122/.1.delta.951baf6f-2037-4f53-8459-5a6afcca897f.TID295.tmp
[2025-07-19T21:02:30.062+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/123/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/123/.1.delta.27cd9837-a8e6-40e4-9d6f-f66bcb086b52.TID296.tmp
[2025-07-19T21:02:30.064+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 8b44f3d35cfa:38433 in memory (size: 35.4 KiB, free: 434.1 MiB)
[2025-07-19T21:02:30.064+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/119/.1.delta.41bb1794-9209-4056-84ee-1d49fd4cf2ee.TID292.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/119/1.delta
[2025-07-19T21:02:30.065+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=119),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/119] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/119/1.delta
[2025-07-19T21:02:30.065+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 119 (task 292, attempt 0, stage 1.0)
[2025-07-19T21:02:30.066+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71aafdf8
[2025-07-19T21:02:30.067+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=128, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.068+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=128),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/128] for update
[2025-07-19T21:02:30.071+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 8b44f3d35cfa:38433 in memory (size: 29.6 KiB, free: 434.2 MiB)
[2025-07-19T21:02:30.072+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.073+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@589a450c
[2025-07-19T21:02:30.077+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=127, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.077+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=127),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/127] for update
[2025-07-19T21:02:30.081+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.085+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/120/.1.delta.4d7e66d1-b4e9-44fd-a002-187e9b90bec7.TID293.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/120/1.delta
[2025-07-19T21:02:30.085+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=120),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/120] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/120/1.delta
[2025-07-19T21:02:30.086+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 120 (task 293, attempt 0, stage 1.0)
[2025-07-19T21:02:30.089+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 118 (task 291, attempt 0, stage 1.0)
[2025-07-19T21:02:30.090+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/121/.1.delta.739780db-1ff9-480f-9db5-76cdf3f73a2e.TID294.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/121/1.delta
[2025-07-19T21:02:30.091+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/128/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/128/.1.delta.4e689a44-6336-4e1e-b55e-bc1c996af0a6.TID298.tmp
[2025-07-19T21:02:30.091+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=121),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/121] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/121/1.delta
[2025-07-19T21:02:30.091+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 118.0 in stage 1.0 (TID 291). 9078 bytes result sent to driver
[2025-07-19T21:02:30.091+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 119 (task 292, attempt 0, stage 1.0)
[2025-07-19T21:02:30.093+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 121 (task 294, attempt 0, stage 1.0)
[2025-07-19T21:02:30.094+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 129.0 in stage 1.0 (TID 299) (8b44f3d35cfa, executor driver, partition 129, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.095+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 129.0 in stage 1.0 (TID 299)
[2025-07-19T21:02:30.096+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/127/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/127/.1.delta.6762405e-50af-4f35-94c6-762a450b3a35.TID297.tmp
[2025-07-19T21:02:30.096+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 118.0 in stage 1.0 (TID 291) in 177 ms on 8b44f3d35cfa (executor driver) (81/200)
[2025-07-19T21:02:30.096+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (251.0 B) non-empty blocks including 1 (251.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.097+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.098+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 119.0 in stage 1.0 (TID 292). 9080 bytes result sent to driver
[2025-07-19T21:02:30.098+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 130.0 in stage 1.0 (TID 300) (8b44f3d35cfa, executor driver, partition 130, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.100+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 130.0 in stage 1.0 (TID 300)
[2025-07-19T21:02:30.100+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 119.0 in stage 1.0 (TID 292) in 128 ms on 8b44f3d35cfa (executor driver) (82/200)
[2025-07-19T21:02:30.102+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.103+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.105+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1cf4dfed
[2025-07-19T21:02:30.106+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=129, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.108+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=129),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/129] for update
[2025-07-19T21:02:30.109+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/122/.1.delta.951baf6f-2037-4f53-8459-5a6afcca897f.TID295.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/122/1.delta
[2025-07-19T21:02:30.110+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.110+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=122),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/122] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/122/1.delta
[2025-07-19T21:02:30.113+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 122 (task 295, attempt 0, stage 1.0)
[2025-07-19T21:02:30.116+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/123/.1.delta.27cd9837-a8e6-40e4-9d6f-f66bcb086b52.TID296.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/123/1.delta
[2025-07-19T21:02:30.116+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=123),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/123] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/123/1.delta
[2025-07-19T21:02:30.117+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 123 (task 296, attempt 0, stage 1.0)
[2025-07-19T21:02:30.118+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/129/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/129/.1.delta.a2f82e61-a361-47ef-91b3-eb6a8509fcca.TID299.tmp
[2025-07-19T21:02:30.121+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 120 (task 293, attempt 0, stage 1.0)
[2025-07-19T21:02:30.121+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 121 (task 294, attempt 0, stage 1.0)
[2025-07-19T21:02:30.122+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 120.0 in stage 1.0 (TID 293). 9037 bytes result sent to driver
[2025-07-19T21:02:30.122+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 131.0 in stage 1.0 (TID 301) (8b44f3d35cfa, executor driver, partition 131, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.122+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 120.0 in stage 1.0 (TID 293) in 150 ms on 8b44f3d35cfa (executor driver) (83/200)
[2025-07-19T21:02:30.123+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f3807b5
[2025-07-19T21:02:30.124+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 121.0 in stage 1.0 (TID 294). 9033 bytes result sent to driver
[2025-07-19T21:02:30.125+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/128/.1.delta.4e689a44-6336-4e1e-b55e-bc1c996af0a6.TID298.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/128/1.delta
[2025-07-19T21:02:30.126+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=128),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/128] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/128/1.delta
[2025-07-19T21:02:30.127+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=130, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.127+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=130),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/130] for update
[2025-07-19T21:02:30.127+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 122 (task 295, attempt 0, stage 1.0)
[2025-07-19T21:02:30.128+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 122.0 in stage 1.0 (TID 295). 9018 bytes result sent to driver
[2025-07-19T21:02:30.128+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.130+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 128 (task 298, attempt 0, stage 1.0)
[2025-07-19T21:02:30.130+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 133.0 in stage 1.0 (TID 302) (8b44f3d35cfa, executor driver, partition 133, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.130+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 135.0 in stage 1.0 (TID 303) (8b44f3d35cfa, executor driver, partition 135, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.131+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 133.0 in stage 1.0 (TID 302)
[2025-07-19T21:02:30.131+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 122.0 in stage 1.0 (TID 295) in 129 ms on 8b44f3d35cfa (executor driver) (84/200)
[2025-07-19T21:02:30.132+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 131.0 in stage 1.0 (TID 301)
[2025-07-19T21:02:30.133+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 121.0 in stage 1.0 (TID 294) in 155 ms on 8b44f3d35cfa (executor driver) (85/200)
[2025-07-19T21:02:30.134+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 135.0 in stage 1.0 (TID 303)
[2025-07-19T21:02:30.134+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.135+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.135+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.136+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/127/.1.delta.6762405e-50af-4f35-94c6-762a450b3a35.TID297.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/127/1.delta
[2025-07-19T21:02:30.136+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=127),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/127] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/127/1.delta
[2025-07-19T21:02:30.137+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.140+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.140+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 127 (task 297, attempt 0, stage 1.0)
[2025-07-19T21:02:30.142+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T21:02:30.142+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 123 (task 296, attempt 0, stage 1.0)
[2025-07-19T21:02:30.142+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 123.0 in stage 1.0 (TID 296). 9029 bytes result sent to driver
[2025-07-19T21:02:30.142+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 136.0 in stage 1.0 (TID 304) (8b44f3d35cfa, executor driver, partition 136, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.143+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 136.0 in stage 1.0 (TID 304)
[2025-07-19T21:02:30.145+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/130/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/130/.1.delta.143a52ba-613a-40d7-9dce-fdb28b2f6457.TID300.tmp
[2025-07-19T21:02:30.146+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 123.0 in stage 1.0 (TID 296) in 126 ms on 8b44f3d35cfa (executor driver) (86/200)
[2025-07-19T21:02:30.146+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 32.0 KiB, free 433.4 MiB)
[2025-07-19T21:02:30.147+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 15.9 KiB, free 433.3 MiB)
[2025-07-19T21:02:30.147+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 8b44f3d35cfa:38433 (size: 15.9 KiB, free: 434.2 MiB)
[2025-07-19T21:02:30.147+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2a66bb8f
[2025-07-19T21:02:30.147+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1611
[2025-07-19T21:02:30.148+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=131, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.148+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=131),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/131] for update
[2025-07-19T21:02:30.148+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 7 (StateStoreRDD[29] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-07-19T21:02:30.148+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSchedulerImpl: Adding task set 7.0 with 200 tasks resource profile 0
[2025-07-19T21:02:30.150+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 128 (task 298, attempt 0, stage 1.0)
[2025-07-19T21:02:30.151+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.156+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.157+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.158+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 128.0 in stage 1.0 (TID 298). 9068 bytes result sent to driver
[2025-07-19T21:02:30.159+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@67700218
[2025-07-19T21:02:30.160+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 137.0 in stage 1.0 (TID 305) (8b44f3d35cfa, executor driver, partition 137, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.160+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=135, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.160+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 137.0 in stage 1.0 (TID 305)
[2025-07-19T21:02:30.160+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=135),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/135] for update
[2025-07-19T21:02:30.161+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.162+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.163+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 127 (task 297, attempt 0, stage 1.0)
[2025-07-19T21:02:30.163+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 128.0 in stage 1.0 (TID 298) in 113 ms on 8b44f3d35cfa (executor driver) (87/200)
[2025-07-19T21:02:30.163+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 127.0 in stage 1.0 (TID 297). 9025 bytes result sent to driver
[2025-07-19T21:02:30.163+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/129/.1.delta.a2f82e61-a361-47ef-91b3-eb6a8509fcca.TID299.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/129/1.delta
[2025-07-19T21:02:30.163+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=129),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/129] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/129/1.delta
[2025-07-19T21:02:30.164+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 138.0 in stage 1.0 (TID 306) (8b44f3d35cfa, executor driver, partition 138, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.164+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 129 (task 299, attempt 0, stage 1.0)
[2025-07-19T21:02:30.164+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 138.0 in stage 1.0 (TID 306)
[2025-07-19T21:02:30.164+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56e69f21
[2025-07-19T21:02:30.164+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=133, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.164+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=133),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/133] for update
[2025-07-19T21:02:30.165+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 127.0 in stage 1.0 (TID 297) in 129 ms on 8b44f3d35cfa (executor driver) (88/200)
[2025-07-19T21:02:30.165+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/131/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/131/.1.delta.fd5117dd-4bb5-44d6-b6fc-8e92297fcf6a.TID301.tmp
[2025-07-19T21:02:30.165+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.165+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.165+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.165+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.171+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/135/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/135/.1.delta.edd0db32-c6ba-419b-9974-dd0b80ade0bb.TID303.tmp
[2025-07-19T21:02:30.171+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/133/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/133/.1.delta.da9e0266-2d48-4742-85df-22d068ae30db.TID302.tmp
[2025-07-19T21:02:30.175+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@48332a1
[2025-07-19T21:02:30.177+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=137, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.178+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=137),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/137] for update
[2025-07-19T21:02:30.179+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 129 (task 299, attempt 0, stage 1.0)
[2025-07-19T21:02:30.180+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.181+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 129.0 in stage 1.0 (TID 299). 9044 bytes result sent to driver
[2025-07-19T21:02:30.182+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 139.0 in stage 1.0 (TID 307) (8b44f3d35cfa, executor driver, partition 139, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.182+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 139.0 in stage 1.0 (TID 307)
[2025-07-19T21:02:30.182+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 129.0 in stage 1.0 (TID 299) in 86 ms on 8b44f3d35cfa (executor driver) (89/200)
[2025-07-19T21:02:30.185+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.186+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.187+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a34734c
[2025-07-19T21:02:30.188+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=136, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.188+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=136),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/136] for update
[2025-07-19T21:02:30.189+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.189+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/137/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/137/.1.delta.b43f087a-099d-42a7-8f29-e6efd702067f.TID305.tmp
[2025-07-19T21:02:30.190+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/130/.1.delta.143a52ba-613a-40d7-9dce-fdb28b2f6457.TID300.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/130/1.delta
[2025-07-19T21:02:30.190+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=130),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/130] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/130/1.delta
[2025-07-19T21:02:30.190+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 130 (task 300, attempt 0, stage 1.0)
[2025-07-19T21:02:30.200+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@99d4db
[2025-07-19T21:02:30.202+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=139, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.203+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=139),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/139] for update
[2025-07-19T21:02:30.207+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.210+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/131/.1.delta.fd5117dd-4bb5-44d6-b6fc-8e92297fcf6a.TID301.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/131/1.delta
[2025-07-19T21:02:30.211+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=131),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/131] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/131/1.delta
[2025-07-19T21:02:30.212+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 131 (task 301, attempt 0, stage 1.0)
[2025-07-19T21:02:30.213+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/136/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/136/.1.delta.0289aacf-f84e-425c-865f-39c379e383a6.TID304.tmp
[2025-07-19T21:02:30.213+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@527f357
[2025-07-19T21:02:30.214+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=138, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.215+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=138),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/138] for update
[2025-07-19T21:02:30.215+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 130 (task 300, attempt 0, stage 1.0)
[2025-07-19T21:02:30.215+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.216+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 130.0 in stage 1.0 (TID 300). 9049 bytes result sent to driver
[2025-07-19T21:02:30.218+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 140.0 in stage 1.0 (TID 308) (8b44f3d35cfa, executor driver, partition 140, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.219+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 140.0 in stage 1.0 (TID 308)
[2025-07-19T21:02:30.220+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 130.0 in stage 1.0 (TID 300) in 121 ms on 8b44f3d35cfa (executor driver) (90/200)
[2025-07-19T21:02:30.222+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.223+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.229+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/139/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/139/.1.delta.a0a70f4c-369f-41e5-87f1-d323f6fdd2af.TID307.tmp
[2025-07-19T21:02:30.235+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/138/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/138/.1.delta.7c94732e-b116-4ff3-836e-01866b812005.TID306.tmp
[2025-07-19T21:02:30.237+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68712751
[2025-07-19T21:02:30.242+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=140, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.244+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=140),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/140] for update
[2025-07-19T21:02:30.245+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 131 (task 301, attempt 0, stage 1.0)
[2025-07-19T21:02:30.245+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.247+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/135/.1.delta.edd0db32-c6ba-419b-9974-dd0b80ade0bb.TID303.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/135/1.delta
[2025-07-19T21:02:30.248+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=135),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/135] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/135/1.delta
[2025-07-19T21:02:30.249+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 131.0 in stage 1.0 (TID 301). 9046 bytes result sent to driver
[2025-07-19T21:02:30.249+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 135 (task 303, attempt 0, stage 1.0)
[2025-07-19T21:02:30.252+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 144.0 in stage 1.0 (TID 309) (8b44f3d35cfa, executor driver, partition 144, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.252+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/133/.1.delta.da9e0266-2d48-4742-85df-22d068ae30db.TID302.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/133/1.delta
[2025-07-19T21:02:30.252+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=133),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/133] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/133/1.delta
[2025-07-19T21:02:30.253+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 133 (task 302, attempt 0, stage 1.0)
[2025-07-19T21:02:30.253+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 131.0 in stage 1.0 (TID 301) in 124 ms on 8b44f3d35cfa (executor driver) (91/200)
[2025-07-19T21:02:30.254+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 144.0 in stage 1.0 (TID 309)
[2025-07-19T21:02:30.255+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.256+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.257+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@594166f1
[2025-07-19T21:02:30.257+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/140/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/140/.1.delta.e5c08c63-61a5-4385-b3e0-3de580842c14.TID308.tmp
[2025-07-19T21:02:30.258+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=144, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.258+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=144),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/144] for update
[2025-07-19T21:02:30.258+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/137/.1.delta.b43f087a-099d-42a7-8f29-e6efd702067f.TID305.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/137/1.delta
[2025-07-19T21:02:30.258+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=137),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/137] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/137/1.delta
[2025-07-19T21:02:30.259+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 137 (task 305, attempt 0, stage 1.0)
[2025-07-19T21:02:30.262+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.267+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 133 (task 302, attempt 0, stage 1.0)
[2025-07-19T21:02:30.268+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 133.0 in stage 1.0 (TID 302). 9045 bytes result sent to driver
[2025-07-19T21:02:30.268+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/136/.1.delta.0289aacf-f84e-425c-865f-39c379e383a6.TID304.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/136/1.delta
[2025-07-19T21:02:30.270+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=136),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/136] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/136/1.delta
[2025-07-19T21:02:30.272+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 145.0 in stage 1.0 (TID 310) (8b44f3d35cfa, executor driver, partition 145, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.272+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 136 (task 304, attempt 0, stage 1.0)
[2025-07-19T21:02:30.272+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 135 (task 303, attempt 0, stage 1.0)
[2025-07-19T21:02:30.276+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 135.0 in stage 1.0 (TID 303). 9037 bytes result sent to driver
[2025-07-19T21:02:30.278+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 133.0 in stage 1.0 (TID 302) in 140 ms on 8b44f3d35cfa (executor driver) (92/200)
[2025-07-19T21:02:30.279+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 145.0 in stage 1.0 (TID 310)
[2025-07-19T21:02:30.279+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 149.0 in stage 1.0 (TID 311) (8b44f3d35cfa, executor driver, partition 149, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.279+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 135.0 in stage 1.0 (TID 303) in 145 ms on 8b44f3d35cfa (executor driver) (93/200)
[2025-07-19T21:02:30.281+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 137 (task 305, attempt 0, stage 1.0)
[2025-07-19T21:02:30.282+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 137.0 in stage 1.0 (TID 305). 9052 bytes result sent to driver
[2025-07-19T21:02:30.282+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 149.0 in stage 1.0 (TID 311)
[2025-07-19T21:02:30.282+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/144/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/144/.1.delta.e693c306-f371-43bb-b4bd-ca9eedf65226.TID309.tmp
[2025-07-19T21:02:30.282+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 150.0 in stage 1.0 (TID 312) (8b44f3d35cfa, executor driver, partition 150, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.282+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 150.0 in stage 1.0 (TID 312)
[2025-07-19T21:02:30.282+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 137.0 in stage 1.0 (TID 305) in 125 ms on 8b44f3d35cfa (executor driver) (94/200)
[2025-07-19T21:02:30.282+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.282+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.287+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.288+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T21:02:30.288+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a5787b1
[2025-07-19T21:02:30.292+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=150, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.293+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=150),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/150] for update
[2025-07-19T21:02:30.294+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.294+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:30.295+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/138/.1.delta.7c94732e-b116-4ff3-836e-01866b812005.TID306.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/138/1.delta
[2025-07-19T21:02:30.295+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=138),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/138] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/138/1.delta
[2025-07-19T21:02:30.296+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 138 (task 306, attempt 0, stage 1.0)
[2025-07-19T21:02:30.296+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.297+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 136 (task 304, attempt 0, stage 1.0)
[2025-07-19T21:02:30.297+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 136.0 in stage 1.0 (TID 304). 9035 bytes result sent to driver
[2025-07-19T21:02:30.297+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/139/.1.delta.a0a70f4c-369f-41e5-87f1-d323f6fdd2af.TID307.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/139/1.delta
[2025-07-19T21:02:30.298+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=139),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/139] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/139/1.delta
[2025-07-19T21:02:30.299+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 153.0 in stage 1.0 (TID 313) (8b44f3d35cfa, executor driver, partition 153, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.300+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 136.0 in stage 1.0 (TID 304) in 158 ms on 8b44f3d35cfa (executor driver) (95/200)
[2025-07-19T21:02:30.301+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a20bf40
[2025-07-19T21:02:30.301+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 139 (task 307, attempt 0, stage 1.0)
[2025-07-19T21:02:30.302+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 153.0 in stage 1.0 (TID 313)
[2025-07-19T21:02:30.302+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=145, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.306+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=145),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/145] for update
[2025-07-19T21:02:30.309+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/150/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/150/.1.delta.20c44ef7-b2f4-47e7-b81a-87b4bd5f04b2.TID312.tmp
[2025-07-19T21:02:30.311+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/140/.1.delta.e5c08c63-61a5-4385-b3e0-3de580842c14.TID308.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/140/1.delta
[2025-07-19T21:02:30.312+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=140),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/140] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/140/1.delta
[2025-07-19T21:02:30.313+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 140 (task 308, attempt 0, stage 1.0)
[2025-07-19T21:02:30.314+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.316+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 138 (task 306, attempt 0, stage 1.0)
[2025-07-19T21:02:30.316+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@105ce19f
[2025-07-19T21:02:30.317+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 138.0 in stage 1.0 (TID 306). 9044 bytes result sent to driver
[2025-07-19T21:02:30.318+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.318+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=149, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.319+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:30.319+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=149),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/149] for update
[2025-07-19T21:02:30.320+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 154.0 in stage 1.0 (TID 314) (8b44f3d35cfa, executor driver, partition 154, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.320+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 138.0 in stage 1.0 (TID 306) in 156 ms on 8b44f3d35cfa (executor driver) (96/200)
[2025-07-19T21:02:30.320+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.321+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 154.0 in stage 1.0 (TID 314)
[2025-07-19T21:02:30.321+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.321+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.323+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@763d9582
[2025-07-19T21:02:30.325+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=153, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.326+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/149/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/149/.1.delta.16d3267c-43ac-432c-94f9-61cbb3ca9159.TID311.tmp
[2025-07-19T21:02:30.326+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=153),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/153] for update
[2025-07-19T21:02:30.328+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 140 (task 308, attempt 0, stage 1.0)
[2025-07-19T21:02:30.331+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 140.0 in stage 1.0 (TID 308). 9039 bytes result sent to driver
[2025-07-19T21:02:30.331+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 155.0 in stage 1.0 (TID 315) (8b44f3d35cfa, executor driver, partition 155, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.332+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 155.0 in stage 1.0 (TID 315)
[2025-07-19T21:02:30.332+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.333+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 140.0 in stage 1.0 (TID 308) in 114 ms on 8b44f3d35cfa (executor driver) (97/200)
[2025-07-19T21:02:30.333+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/145/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/145/.1.delta.e1813154-d8a4-4d52-9db3-15565d9e730d.TID310.tmp
[2025-07-19T21:02:30.335+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 139 (task 307, attempt 0, stage 1.0)
[2025-07-19T21:02:30.336+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.337+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.337+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 139.0 in stage 1.0 (TID 307). 9039 bytes result sent to driver
[2025-07-19T21:02:30.337+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 158.0 in stage 1.0 (TID 316) (8b44f3d35cfa, executor driver, partition 158, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.337+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 158.0 in stage 1.0 (TID 316)
[2025-07-19T21:02:30.338+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 139.0 in stage 1.0 (TID 307) in 159 ms on 8b44f3d35cfa (executor driver) (98/200)
[2025-07-19T21:02:30.340+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.343+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@62fcb068
[2025-07-19T21:02:30.344+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:30.344+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=154, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.345+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=154),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/154] for update
[2025-07-19T21:02:30.346+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.346+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/144/.1.delta.e693c306-f371-43bb-b4bd-ca9eedf65226.TID309.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/144/1.delta
[2025-07-19T21:02:30.347+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=144),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/144] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/144/1.delta
[2025-07-19T21:02:30.349+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/153/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/153/.1.delta.ec537fd3-f7b0-4017-b556-21315ec570be.TID313.tmp
[2025-07-19T21:02:30.350+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 144 (task 309, attempt 0, stage 1.0)
[2025-07-19T21:02:30.356+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33c231a6
[2025-07-19T21:02:30.356+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=158, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.357+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=158),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/158] for update
[2025-07-19T21:02:30.359+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.359+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/154/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/154/.1.delta.bafcef2a-6cf1-45e6-8573-80392bb97b15.TID314.tmp
[2025-07-19T21:02:30.364+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 144 (task 309, attempt 0, stage 1.0)
[2025-07-19T21:02:30.365+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 144.0 in stage 1.0 (TID 309). 9031 bytes result sent to driver
[2025-07-19T21:02:30.366+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7cbf1614
[2025-07-19T21:02:30.367+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=155, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.368+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 159.0 in stage 1.0 (TID 317) (8b44f3d35cfa, executor driver, partition 159, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.369+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 159.0 in stage 1.0 (TID 317)
[2025-07-19T21:02:30.370+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=155),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/155] for update
[2025-07-19T21:02:30.370+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 144.0 in stage 1.0 (TID 309) in 127 ms on 8b44f3d35cfa (executor driver) (99/200)
[2025-07-19T21:02:30.371+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/158/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/158/.1.delta.e319479e-8b1c-47ab-bfbc-4b49d4ea4941.TID316.tmp
[2025-07-19T21:02:30.372+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.382+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/150/.1.delta.20c44ef7-b2f4-47e7-b81a-87b4bd5f04b2.TID312.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/150/1.delta
[2025-07-19T21:02:30.382+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=150),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/150] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/150/1.delta
[2025-07-19T21:02:30.385+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 150 (task 312, attempt 0, stage 1.0)
[2025-07-19T21:02:30.386+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.388+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T21:02:30.391+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/155/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/155/.1.delta.167d4209-321f-4d80-aa4a-2248d74ec925.TID315.tmp
[2025-07-19T21:02:30.393+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ba90bdf
[2025-07-19T21:02:30.394+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=159, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.394+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=159),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/159] for update
[2025-07-19T21:02:30.395+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.399+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/145/.1.delta.e1813154-d8a4-4d52-9db3-15565d9e730d.TID310.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/145/1.delta
[2025-07-19T21:02:30.400+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=145),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/145] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/145/1.delta
[2025-07-19T21:02:30.400+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/149/.1.delta.16d3267c-43ac-432c-94f9-61cbb3ca9159.TID311.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/149/1.delta
[2025-07-19T21:02:30.401+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=149),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/149] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/149/1.delta
[2025-07-19T21:02:30.402+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 150 (task 312, attempt 0, stage 1.0)
[2025-07-19T21:02:30.403+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 150.0 in stage 1.0 (TID 312). 9083 bytes result sent to driver
[2025-07-19T21:02:30.403+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 145 (task 310, attempt 0, stage 1.0)
[2025-07-19T21:02:30.404+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 160.0 in stage 1.0 (TID 318) (8b44f3d35cfa, executor driver, partition 160, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.404+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 160.0 in stage 1.0 (TID 318)
[2025-07-19T21:02:30.405+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 150.0 in stage 1.0 (TID 312) in 124 ms on 8b44f3d35cfa (executor driver) (100/200)
[2025-07-19T21:02:30.405+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 149 (task 311, attempt 0, stage 1.0)
[2025-07-19T21:02:30.405+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/159/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/159/.1.delta.e5235f27-c975-40af-af35-2efc5d1fb272.TID317.tmp
[2025-07-19T21:02:30.406+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.407+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.410+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/153/.1.delta.ec537fd3-f7b0-4017-b556-21315ec570be.TID313.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/153/1.delta
[2025-07-19T21:02:30.410+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=153),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/153] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/153/1.delta
[2025-07-19T21:02:30.411+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 153 (task 313, attempt 0, stage 1.0)
[2025-07-19T21:02:30.415+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d22d230
[2025-07-19T21:02:30.416+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=160, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.417+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=160),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/160] for update
[2025-07-19T21:02:30.420+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 145 (task 310, attempt 0, stage 1.0)
[2025-07-19T21:02:30.421+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/154/.1.delta.bafcef2a-6cf1-45e6-8573-80392bb97b15.TID314.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/154/1.delta
[2025-07-19T21:02:30.422+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=154),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/154] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/154/1.delta
[2025-07-19T21:02:30.422+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 145.0 in stage 1.0 (TID 310). 9091 bytes result sent to driver
[2025-07-19T21:02:30.423+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 154 (task 314, attempt 0, stage 1.0)
[2025-07-19T21:02:30.424+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 149 (task 311, attempt 0, stage 1.0)
[2025-07-19T21:02:30.424+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 149.0 in stage 1.0 (TID 311). 9099 bytes result sent to driver
[2025-07-19T21:02:30.424+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 161.0 in stage 1.0 (TID 319) (8b44f3d35cfa, executor driver, partition 161, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.425+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 161.0 in stage 1.0 (TID 319)
[2025-07-19T21:02:30.426+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.426+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.426+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.427+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 162.0 in stage 1.0 (TID 320) (8b44f3d35cfa, executor driver, partition 162, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.427+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 162.0 in stage 1.0 (TID 320)
[2025-07-19T21:02:30.427+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 149.0 in stage 1.0 (TID 311) in 149 ms on 8b44f3d35cfa (executor driver) (101/200)
[2025-07-19T21:02:30.428+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 145.0 in stage 1.0 (TID 310) in 155 ms on 8b44f3d35cfa (executor driver) (102/200)
[2025-07-19T21:02:30.428+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.433+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T21:02:30.434+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/158/.1.delta.e319479e-8b1c-47ab-bfbc-4b49d4ea4941.TID316.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/158/1.delta
[2025-07-19T21:02:30.435+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=158),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/158] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/158/1.delta
[2025-07-19T21:02:30.435+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@67b10e2d
[2025-07-19T21:02:30.435+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 153 (task 313, attempt 0, stage 1.0)
[2025-07-19T21:02:30.435+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=161, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.435+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 158 (task 316, attempt 0, stage 1.0)
[2025-07-19T21:02:30.435+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=161),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/161] for update
[2025-07-19T21:02:30.442+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.443+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 153.0 in stage 1.0 (TID 313). 9125 bytes result sent to driver
[2025-07-19T21:02:30.444+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 163.0 in stage 1.0 (TID 321) (8b44f3d35cfa, executor driver, partition 163, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.446+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 163.0 in stage 1.0 (TID 321)
[2025-07-19T21:02:30.448+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 154 (task 314, attempt 0, stage 1.0)
[2025-07-19T21:02:30.448+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@45124976
[2025-07-19T21:02:30.450+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/160/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/160/.1.delta.3273abec-0b48-4c7e-9e18-9587cbb2bff4.TID318.tmp
[2025-07-19T21:02:30.451+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 154.0 in stage 1.0 (TID 314). 9099 bytes result sent to driver
[2025-07-19T21:02:30.454+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=162, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.455+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 153.0 in stage 1.0 (TID 313) in 147 ms on 8b44f3d35cfa (executor driver) (103/200)
[2025-07-19T21:02:30.457+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 165.0 in stage 1.0 (TID 322) (8b44f3d35cfa, executor driver, partition 165, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.457+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 165.0 in stage 1.0 (TID 322)
[2025-07-19T21:02:30.458+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 154.0 in stage 1.0 (TID 314) in 137 ms on 8b44f3d35cfa (executor driver) (104/200)
[2025-07-19T21:02:30.458+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=162),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/162] for update
[2025-07-19T21:02:30.459+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (251.0 B) non-empty blocks including 1 (251.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.459+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:30.459+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.460+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/155/.1.delta.167d4209-321f-4d80-aa4a-2248d74ec925.TID315.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/155/1.delta
[2025-07-19T21:02:30.461+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=155),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/155] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/155/1.delta
[2025-07-19T21:02:30.462+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 155 (task 315, attempt 0, stage 1.0)
[2025-07-19T21:02:30.462+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/161/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/161/.1.delta.5a8759a4-537c-4fd8-990b-50e64e6ac87b.TID319.tmp
[2025-07-19T21:02:30.462+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.462+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 158 (task 316, attempt 0, stage 1.0)
[2025-07-19T21:02:30.462+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.462+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@485e9f0f
[2025-07-19T21:02:30.462+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=163, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.462+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=163),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/163] for update
[2025-07-19T21:02:30.462+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 158.0 in stage 1.0 (TID 316). 9128 bytes result sent to driver
[2025-07-19T21:02:30.463+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 169.0 in stage 1.0 (TID 323) (8b44f3d35cfa, executor driver, partition 169, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.463+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 169.0 in stage 1.0 (TID 323)
[2025-07-19T21:02:30.463+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 158.0 in stage 1.0 (TID 316) in 128 ms on 8b44f3d35cfa (executor driver) (105/200)
[2025-07-19T21:02:30.465+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.466+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/159/.1.delta.e5235f27-c975-40af-af35-2efc5d1fb272.TID317.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/159/1.delta
[2025-07-19T21:02:30.466+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=159),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/159] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/159/1.delta
[2025-07-19T21:02:30.468+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 159 (task 317, attempt 0, stage 1.0)
[2025-07-19T21:02:30.470+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1bcedc72
[2025-07-19T21:02:30.471+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.472+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=165, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.473+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.474+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=165),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/165] for update
[2025-07-19T21:02:30.477+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.479+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/162/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/162/.1.delta.4f8ced91-c0e7-4775-9386-a6a71c0f00aa.TID320.tmp
[2025-07-19T21:02:30.480+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/163/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/163/.1.delta.04a85cb4-6974-4636-9041-221127f87da4.TID321.tmp
[2025-07-19T21:02:30.482+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 155 (task 315, attempt 0, stage 1.0)
[2025-07-19T21:02:30.483+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 155.0 in stage 1.0 (TID 315). 9093 bytes result sent to driver
[2025-07-19T21:02:30.484+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 170.0 in stage 1.0 (TID 324) (8b44f3d35cfa, executor driver, partition 170, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.485+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/165/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/165/.1.delta.7628bb88-02e6-4078-93c9-369b24de0254.TID322.tmp
[2025-07-19T21:02:30.486+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 170.0 in stage 1.0 (TID 324)
[2025-07-19T21:02:30.487+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 155.0 in stage 1.0 (TID 315) in 156 ms on 8b44f3d35cfa (executor driver) (106/200)
[2025-07-19T21:02:30.487+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@16c28c63
[2025-07-19T21:02:30.487+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=169, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.488+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=169),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/169] for update
[2025-07-19T21:02:30.488+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.496+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.496+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.497+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 159 (task 317, attempt 0, stage 1.0)
[2025-07-19T21:02:30.498+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 159.0 in stage 1.0 (TID 317). 9080 bytes result sent to driver
[2025-07-19T21:02:30.499+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 172.0 in stage 1.0 (TID 325) (8b44f3d35cfa, executor driver, partition 172, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.499+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 172.0 in stage 1.0 (TID 325)
[2025-07-19T21:02:30.512+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 159.0 in stage 1.0 (TID 317) in 143 ms on 8b44f3d35cfa (executor driver) (107/200)
[2025-07-19T21:02:30.516+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.517+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.517+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/169/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/169/.1.delta.723ad67d-f1e3-40e4-bfcb-4acf48dd1f23.TID323.tmp
[2025-07-19T21:02:30.517+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f4799c0
[2025-07-19T21:02:30.517+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=170, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.517+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=170),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/170] for update
[2025-07-19T21:02:30.517+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.518+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/160/.1.delta.3273abec-0b48-4c7e-9e18-9587cbb2bff4.TID318.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/160/1.delta
[2025-07-19T21:02:30.518+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=160),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/160] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/160/1.delta
[2025-07-19T21:02:30.518+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 160 (task 318, attempt 0, stage 1.0)
[2025-07-19T21:02:30.526+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d8372c9
[2025-07-19T21:02:30.530+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=172, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.530+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=172),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/172] for update
[2025-07-19T21:02:30.530+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.536+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/170/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/170/.1.delta.9275bb8f-ff90-4a2b-b3d4-3f581a0109bf.TID324.tmp
[2025-07-19T21:02:30.537+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/161/.1.delta.5a8759a4-537c-4fd8-990b-50e64e6ac87b.TID319.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/161/1.delta
[2025-07-19T21:02:30.538+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=161),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/161] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/161/1.delta
[2025-07-19T21:02:30.539+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 161 (task 319, attempt 0, stage 1.0)
[2025-07-19T21:02:30.540+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/163/.1.delta.04a85cb4-6974-4636-9041-221127f87da4.TID321.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/163/1.delta
[2025-07-19T21:02:30.540+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=163),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/163] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/163/1.delta
[2025-07-19T21:02:30.541+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 163 (task 321, attempt 0, stage 1.0)
[2025-07-19T21:02:30.544+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/172/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/172/.1.delta.cc3eef21-3fe6-4117-87d0-7953776f3a17.TID325.tmp
[2025-07-19T21:02:30.545+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 160 (task 318, attempt 0, stage 1.0)
[2025-07-19T21:02:30.547+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/162/.1.delta.4f8ced91-c0e7-4775-9386-a6a71c0f00aa.TID320.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/162/1.delta
[2025-07-19T21:02:30.548+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=162),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/162] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/162/1.delta
[2025-07-19T21:02:30.549+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 162 (task 320, attempt 0, stage 1.0)
[2025-07-19T21:02:30.550+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 160.0 in stage 1.0 (TID 318). 9083 bytes result sent to driver
[2025-07-19T21:02:30.550+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 174.0 in stage 1.0 (TID 326) (8b44f3d35cfa, executor driver, partition 174, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.553+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 174.0 in stage 1.0 (TID 326)
[2025-07-19T21:02:30.554+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 160.0 in stage 1.0 (TID 318) in 148 ms on 8b44f3d35cfa (executor driver) (108/200)
[2025-07-19T21:02:30.554+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.554+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.555+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 161 (task 319, attempt 0, stage 1.0)
[2025-07-19T21:02:30.556+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 161.0 in stage 1.0 (TID 319). 9078 bytes result sent to driver
[2025-07-19T21:02:30.557+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 175.0 in stage 1.0 (TID 327) (8b44f3d35cfa, executor driver, partition 175, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.558+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 163 (task 321, attempt 0, stage 1.0)
[2025-07-19T21:02:30.559+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 161.0 in stage 1.0 (TID 319) in 139 ms on 8b44f3d35cfa (executor driver) (109/200)
[2025-07-19T21:02:30.559+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/165/.1.delta.7628bb88-02e6-4078-93c9-369b24de0254.TID322.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/165/1.delta
[2025-07-19T21:02:30.559+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=165),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/165] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/165/1.delta
[2025-07-19T21:02:30.560+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 163.0 in stage 1.0 (TID 321). 9050 bytes result sent to driver
[2025-07-19T21:02:30.560+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 177.0 in stage 1.0 (TID 328) (8b44f3d35cfa, executor driver, partition 177, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.560+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 175.0 in stage 1.0 (TID 327)
[2025-07-19T21:02:30.560+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 163.0 in stage 1.0 (TID 321) in 119 ms on 8b44f3d35cfa (executor driver) (110/200)
[2025-07-19T21:02:30.560+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 177.0 in stage 1.0 (TID 328)
[2025-07-19T21:02:30.562+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 165 (task 322, attempt 0, stage 1.0)
[2025-07-19T21:02:30.563+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/169/.1.delta.723ad67d-f1e3-40e4-bfcb-4acf48dd1f23.TID323.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/169/1.delta
[2025-07-19T21:02:30.564+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=169),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/169] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/169/1.delta
[2025-07-19T21:02:30.564+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.564+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 169 (task 323, attempt 0, stage 1.0)
[2025-07-19T21:02:30.564+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.566+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.566+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@42aea25d
[2025-07-19T21:02:30.567+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:30.567+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=174, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.568+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=174),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/174] for update
[2025-07-19T21:02:30.571+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.573+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20dbac8b
[2025-07-19T21:02:30.573+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 162 (task 320, attempt 0, stage 1.0)
[2025-07-19T21:02:30.574+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=177, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.575+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 162.0 in stage 1.0 (TID 320). 9076 bytes result sent to driver
[2025-07-19T21:02:30.576+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=177),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/177] for update
[2025-07-19T21:02:30.580+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/174/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/174/.1.delta.d20661bc-678d-4219-8a59-327f905c4116.TID326.tmp
[2025-07-19T21:02:30.585+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 178.0 in stage 1.0 (TID 329) (8b44f3d35cfa, executor driver, partition 178, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.586+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 178.0 in stage 1.0 (TID 329)
[2025-07-19T21:02:30.586+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e9c4939
[2025-07-19T21:02:30.587+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 162.0 in stage 1.0 (TID 320) in 164 ms on 8b44f3d35cfa (executor driver) (111/200)
[2025-07-19T21:02:30.587+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=175, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.587+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=175),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/175] for update
[2025-07-19T21:02:30.588+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.589+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:30.589+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.589+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/170/.1.delta.9275bb8f-ff90-4a2b-b3d4-3f581a0109bf.TID324.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/170/1.delta
[2025-07-19T21:02:30.590+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=170),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/170] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/170/1.delta
[2025-07-19T21:02:30.590+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 165 (task 322, attempt 0, stage 1.0)
[2025-07-19T21:02:30.591+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 170 (task 324, attempt 0, stage 1.0)
[2025-07-19T21:02:30.591+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 165.0 in stage 1.0 (TID 322). 9030 bytes result sent to driver
[2025-07-19T21:02:30.591+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 179.0 in stage 1.0 (TID 330) (8b44f3d35cfa, executor driver, partition 179, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.591+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 179.0 in stage 1.0 (TID 330)
[2025-07-19T21:02:30.592+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 165.0 in stage 1.0 (TID 322) in 140 ms on 8b44f3d35cfa (executor driver) (112/200)
[2025-07-19T21:02:30.592+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.592+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.592+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.597+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 169 (task 323, attempt 0, stage 1.0)
[2025-07-19T21:02:30.599+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 169.0 in stage 1.0 (TID 323). 9010 bytes result sent to driver
[2025-07-19T21:02:30.601+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ddad6cf
[2025-07-19T21:02:30.602+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=178, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.602+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=178),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/178] for update
[2025-07-19T21:02:30.602+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/175/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/175/.1.delta.002a5e1d-f19c-4679-b956-fe9e9d50ed6e.TID327.tmp
[2025-07-19T21:02:30.603+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 180.0 in stage 1.0 (TID 331) (8b44f3d35cfa, executor driver, partition 180, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.604+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 180.0 in stage 1.0 (TID 331)
[2025-07-19T21:02:30.605+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 169.0 in stage 1.0 (TID 323) in 140 ms on 8b44f3d35cfa (executor driver) (113/200)
[2025-07-19T21:02:30.605+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.606+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.606+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.611+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@64bbfe34
[2025-07-19T21:02:30.611+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=179, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.612+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=179),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/179] for update
[2025-07-19T21:02:30.612+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.615+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/172/.1.delta.cc3eef21-3fe6-4117-87d0-7953776f3a17.TID325.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/172/1.delta
[2025-07-19T21:02:30.616+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=172),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/172] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/172/1.delta
[2025-07-19T21:02:30.616+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 170 (task 324, attempt 0, stage 1.0)
[2025-07-19T21:02:30.617+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 170.0 in stage 1.0 (TID 324). 9039 bytes result sent to driver
[2025-07-19T21:02:30.617+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 172 (task 325, attempt 0, stage 1.0)
[2025-07-19T21:02:30.617+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/177/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/177/.1.delta.70742e44-b9cf-4d91-8c3c-332604c31e3c.TID328.tmp
[2025-07-19T21:02:30.623+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/178/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/178/.1.delta.7971f956-ec25-41be-85aa-cf9b5c78965b.TID329.tmp
[2025-07-19T21:02:30.624+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6be926cf
[2025-07-19T21:02:30.625+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 181.0 in stage 1.0 (TID 332) (8b44f3d35cfa, executor driver, partition 181, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.625+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=180, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.625+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=180),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/180] for update
[2025-07-19T21:02:30.625+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 170.0 in stage 1.0 (TID 324) in 138 ms on 8b44f3d35cfa (executor driver) (114/200)
[2025-07-19T21:02:30.626+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 181.0 in stage 1.0 (TID 332)
[2025-07-19T21:02:30.626+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.629+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/179/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/179/.1.delta.0df5b81e-595b-4171-9a20-07922ec814c5.TID330.tmp
[2025-07-19T21:02:30.630+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/174/.1.delta.d20661bc-678d-4219-8a59-327f905c4116.TID326.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/174/1.delta
[2025-07-19T21:02:30.631+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=174),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/174] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/174/1.delta
[2025-07-19T21:02:30.631+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 174 (task 326, attempt 0, stage 1.0)
[2025-07-19T21:02:30.633+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.633+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:30.637+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@547cd38f
[2025-07-19T21:02:30.637+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/180/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/180/.1.delta.65c1f8f5-fd72-4138-85ae-cec4b041525f.TID331.tmp
[2025-07-19T21:02:30.638+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 172 (task 325, attempt 0, stage 1.0)
[2025-07-19T21:02:30.640+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=181, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.640+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 172.0 in stage 1.0 (TID 325). 9043 bytes result sent to driver
[2025-07-19T21:02:30.640+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=181),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/181] for update
[2025-07-19T21:02:30.640+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 182.0 in stage 1.0 (TID 333) (8b44f3d35cfa, executor driver, partition 182, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.640+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 182.0 in stage 1.0 (TID 333)
[2025-07-19T21:02:30.640+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.640+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 172.0 in stage 1.0 (TID 325) in 141 ms on 8b44f3d35cfa (executor driver) (115/200)
[2025-07-19T21:02:30.644+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.645+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.648+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/181/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/181/.1.delta.1063a6c9-ad41-4c63-bb77-c7a1492339d5.TID332.tmp
[2025-07-19T21:02:30.651+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74100e1d
[2025-07-19T21:02:30.652+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 174 (task 326, attempt 0, stage 1.0)
[2025-07-19T21:02:30.652+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=182, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.652+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=182),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/182] for update
[2025-07-19T21:02:30.653+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 174.0 in stage 1.0 (TID 326). 9029 bytes result sent to driver
[2025-07-19T21:02:30.654+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.657+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 183.0 in stage 1.0 (TID 334) (8b44f3d35cfa, executor driver, partition 183, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.657+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 183.0 in stage 1.0 (TID 334)
[2025-07-19T21:02:30.658+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 174.0 in stage 1.0 (TID 326) in 107 ms on 8b44f3d35cfa (executor driver) (116/200)
[2025-07-19T21:02:30.659+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.659+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.660+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/175/.1.delta.002a5e1d-f19c-4679-b956-fe9e9d50ed6e.TID327.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/175/1.delta
[2025-07-19T21:02:30.660+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=175),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/175] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/175/1.delta
[2025-07-19T21:02:30.661+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 175 (task 327, attempt 0, stage 1.0)
[2025-07-19T21:02:30.669+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2bf9afef
[2025-07-19T21:02:30.670+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=183, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.670+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=183),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/183] for update
[2025-07-19T21:02:30.671+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/182/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/182/.1.delta.c97d178b-93fc-4544-ab92-2f5bded0eb26.TID333.tmp
[2025-07-19T21:02:30.671+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.671+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/179/.1.delta.0df5b81e-595b-4171-9a20-07922ec814c5.TID330.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/179/1.delta
[2025-07-19T21:02:30.672+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=179),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/179] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/179/1.delta
[2025-07-19T21:02:30.672+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 179 (task 330, attempt 0, stage 1.0)
[2025-07-19T21:02:30.674+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/178/.1.delta.7971f956-ec25-41be-85aa-cf9b5c78965b.TID329.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/178/1.delta
[2025-07-19T21:02:30.675+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/177/.1.delta.70742e44-b9cf-4d91-8c3c-332604c31e3c.TID328.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/177/1.delta
[2025-07-19T21:02:30.675+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=178),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/178] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/178/1.delta
[2025-07-19T21:02:30.675+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=177),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/177] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/177/1.delta
[2025-07-19T21:02:30.675+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 178 (task 329, attempt 0, stage 1.0)
[2025-07-19T21:02:30.675+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 177 (task 328, attempt 0, stage 1.0)
[2025-07-19T21:02:30.677+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/183/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/183/.1.delta.9eea91f1-0bb3-4689-9610-de4dfd5f2b6e.TID334.tmp
[2025-07-19T21:02:30.678+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 175 (task 327, attempt 0, stage 1.0)
[2025-07-19T21:02:30.680+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 175.0 in stage 1.0 (TID 327). 9027 bytes result sent to driver
[2025-07-19T21:02:30.680+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 185.0 in stage 1.0 (TID 335) (8b44f3d35cfa, executor driver, partition 185, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.682+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 175.0 in stage 1.0 (TID 327) in 125 ms on 8b44f3d35cfa (executor driver) (117/200)
[2025-07-19T21:02:30.690+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 185.0 in stage 1.0 (TID 335)
[2025-07-19T21:02:30.693+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/180/.1.delta.65c1f8f5-fd72-4138-85ae-cec4b041525f.TID331.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/180/1.delta
[2025-07-19T21:02:30.695+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=180),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/180] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/180/1.delta
[2025-07-19T21:02:30.696+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 180 (task 331, attempt 0, stage 1.0)
[2025-07-19T21:02:30.696+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 179 (task 330, attempt 0, stage 1.0)
[2025-07-19T21:02:30.697+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.698+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.698+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 179.0 in stage 1.0 (TID 330). 9053 bytes result sent to driver
[2025-07-19T21:02:30.698+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 186.0 in stage 1.0 (TID 336) (8b44f3d35cfa, executor driver, partition 186, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.698+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 186.0 in stage 1.0 (TID 336)
[2025-07-19T21:02:30.698+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 179.0 in stage 1.0 (TID 330) in 108 ms on 8b44f3d35cfa (executor driver) (118/200)
[2025-07-19T21:02:30.698+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.699+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.704+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/181/.1.delta.1063a6c9-ad41-4c63-bb77-c7a1492339d5.TID332.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/181/1.delta
[2025-07-19T21:02:30.705+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=181),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/181] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/181/1.delta
[2025-07-19T21:02:30.705+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 177 (task 328, attempt 0, stage 1.0)
[2025-07-19T21:02:30.706+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 181 (task 332, attempt 0, stage 1.0)
[2025-07-19T21:02:30.706+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 177.0 in stage 1.0 (TID 328). 9044 bytes result sent to driver
[2025-07-19T21:02:30.707+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 180 (task 331, attempt 0, stage 1.0)
[2025-07-19T21:02:30.708+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 180.0 in stage 1.0 (TID 331). 9057 bytes result sent to driver
[2025-07-19T21:02:30.708+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c0b8978
[2025-07-19T21:02:30.709+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 187.0 in stage 1.0 (TID 337) (8b44f3d35cfa, executor driver, partition 187, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.709+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=185, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.710+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=185),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/185] for update
[2025-07-19T21:02:30.711+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 178 (task 329, attempt 0, stage 1.0)
[2025-07-19T21:02:30.711+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 188.0 in stage 1.0 (TID 338) (8b44f3d35cfa, executor driver, partition 188, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.713+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 188.0 in stage 1.0 (TID 338)
[2025-07-19T21:02:30.714+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 187.0 in stage 1.0 (TID 337)
[2025-07-19T21:02:30.714+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 177.0 in stage 1.0 (TID 328) in 154 ms on 8b44f3d35cfa (executor driver) (119/200)
[2025-07-19T21:02:30.717+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 178.0 in stage 1.0 (TID 329). 9029 bytes result sent to driver
[2025-07-19T21:02:30.717+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 190.0 in stage 1.0 (TID 339) (8b44f3d35cfa, executor driver, partition 190, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.718+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 190.0 in stage 1.0 (TID 339)
[2025-07-19T21:02:30.719+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 180.0 in stage 1.0 (TID 331) in 118 ms on 8b44f3d35cfa (executor driver) (120/200)
[2025-07-19T21:02:30.720+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7bd4ddb0
[2025-07-19T21:02:30.720+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 178.0 in stage 1.0 (TID 329) in 137 ms on 8b44f3d35cfa (executor driver) (121/200)
[2025-07-19T21:02:30.720+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.724+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.728+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:30.728+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.728+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T21:02:30.729+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.730+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T21:02:30.732+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=186, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.733+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/182/.1.delta.c97d178b-93fc-4544-ab92-2f5bded0eb26.TID333.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/182/1.delta
[2025-07-19T21:02:30.734+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=182),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/182] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/182/1.delta
[2025-07-19T21:02:30.734+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 182 (task 333, attempt 0, stage 1.0)
[2025-07-19T21:02:30.734+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=186),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/186] for update
[2025-07-19T21:02:30.736+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.737+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/183/.1.delta.9eea91f1-0bb3-4689-9610-de4dfd5f2b6e.TID334.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/183/1.delta
[2025-07-19T21:02:30.737+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=183),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/183] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/183/1.delta
[2025-07-19T21:02:30.737+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 183 (task 334, attempt 0, stage 1.0)
[2025-07-19T21:02:30.738+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ab75adb
[2025-07-19T21:02:30.739+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 181 (task 332, attempt 0, stage 1.0)
[2025-07-19T21:02:30.740+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=188, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.740+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=188),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/188] for update
[2025-07-19T21:02:30.741+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 181.0 in stage 1.0 (TID 332). 9037 bytes result sent to driver
[2025-07-19T21:02:30.742+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 192.0 in stage 1.0 (TID 340) (8b44f3d35cfa, executor driver, partition 192, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.742+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/185/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/185/.1.delta.75ae3055-84ba-48a1-826b-9ab236878d0f.TID335.tmp
[2025-07-19T21:02:30.743+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 192.0 in stage 1.0 (TID 340)
[2025-07-19T21:02:30.743+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 181.0 in stage 1.0 (TID 332) in 116 ms on 8b44f3d35cfa (executor driver) (122/200)
[2025-07-19T21:02:30.744+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.744+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.745+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.745+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/186/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/186/.1.delta.fc384304-36e9-40a9-b664-c114bc890edf.TID336.tmp
[2025-07-19T21:02:30.745+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7fdae99d
[2025-07-19T21:02:30.746+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=187, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.746+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=187),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/187] for update
[2025-07-19T21:02:30.746+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.748+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6b71396a
[2025-07-19T21:02:30.749+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/188/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/188/.1.delta.428001c1-d990-462a-886f-29058d9517f5.TID338.tmp
[2025-07-19T21:02:30.749+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=190, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.749+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=190),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/190] for update
[2025-07-19T21:02:30.752+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.754+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/187/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/187/.1.delta.b0177615-459c-45b5-b9ea-bf7ec5e83a44.TID337.tmp
[2025-07-19T21:02:30.755+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 182 (task 333, attempt 0, stage 1.0)
[2025-07-19T21:02:30.755+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 183 (task 334, attempt 0, stage 1.0)
[2025-07-19T21:02:30.755+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 183.0 in stage 1.0 (TID 334). 9049 bytes result sent to driver
[2025-07-19T21:02:30.756+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 182.0 in stage 1.0 (TID 333). 9031 bytes result sent to driver
[2025-07-19T21:02:30.757+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 195.0 in stage 1.0 (TID 341) (8b44f3d35cfa, executor driver, partition 195, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.758+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 199.0 in stage 1.0 (TID 342) (8b44f3d35cfa, executor driver, partition 199, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.759+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 195.0 in stage 1.0 (TID 341)
[2025-07-19T21:02:30.759+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 199.0 in stage 1.0 (TID 342)
[2025-07-19T21:02:30.760+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6aa11bd
[2025-07-19T21:02:30.760+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 183.0 in stage 1.0 (TID 334) in 104 ms on 8b44f3d35cfa (executor driver) (123/200)
[2025-07-19T21:02:30.761+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.762+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.763+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 182.0 in stage 1.0 (TID 333) in 120 ms on 8b44f3d35cfa (executor driver) (124/200)
[2025-07-19T21:02:30.763+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.764+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=192, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.764+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=192),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/192] for update
[2025-07-19T21:02:30.765+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.765+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:30.765+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/190/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/190/.1.delta.b817761d-ab5e-473e-a367-07ec7be2f66f.TID339.tmp
[2025-07-19T21:02:30.771+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1db54cc7
[2025-07-19T21:02:30.772+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=195, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.772+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=195),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/195] for update
[2025-07-19T21:02:30.773+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.774+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/186/.1.delta.fc384304-36e9-40a9-b664-c114bc890edf.TID336.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/186/1.delta
[2025-07-19T21:02:30.774+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=186),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/186] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/186/1.delta
[2025-07-19T21:02:30.775+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 186 (task 336, attempt 0, stage 1.0)
[2025-07-19T21:02:30.775+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/185/.1.delta.75ae3055-84ba-48a1-826b-9ab236878d0f.TID335.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/185/1.delta
[2025-07-19T21:02:30.775+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=185),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/185] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/185/1.delta
[2025-07-19T21:02:30.776+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/192/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/192/.1.delta.196e8f5a-3645-4bb4-9419-25891f7e4621.TID340.tmp
[2025-07-19T21:02:30.776+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 185 (task 335, attempt 0, stage 1.0)
[2025-07-19T21:02:30.781+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@26e3c272
[2025-07-19T21:02:30.781+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=199, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.781+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=199),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/199] for update
[2025-07-19T21:02:30.781+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.785+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/195/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/195/.1.delta.b25a5eda-937c-4ddf-922d-4e893576d9fa.TID341.tmp
[2025-07-19T21:02:30.792+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 186 (task 336, attempt 0, stage 1.0)
[2025-07-19T21:02:30.793+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 186.0 in stage 1.0 (TID 336). 9024 bytes result sent to driver
[2025-07-19T21:02:30.795+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 343) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.795+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 0.0 in stage 1.0 (TID 343)
[2025-07-19T21:02:30.795+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 186.0 in stage 1.0 (TID 336) in 98 ms on 8b44f3d35cfa (executor driver) (125/200)
[2025-07-19T21:02:30.796+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.796+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.797+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/190/.1.delta.b817761d-ab5e-473e-a367-07ec7be2f66f.TID339.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/190/1.delta
[2025-07-19T21:02:30.797+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=190),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/190] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/190/1.delta
[2025-07-19T21:02:30.797+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/199/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/199/.1.delta.19c09a0b-c1f1-4f99-b15d-fede31704c13.TID342.tmp
[2025-07-19T21:02:30.797+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 190 (task 339, attempt 0, stage 1.0)
[2025-07-19T21:02:30.798+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/188/.1.delta.428001c1-d990-462a-886f-29058d9517f5.TID338.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/188/1.delta
[2025-07-19T21:02:30.798+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=188),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/188] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/188/1.delta
[2025-07-19T21:02:30.798+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 188 (task 338, attempt 0, stage 1.0)
[2025-07-19T21:02:30.798+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/187/.1.delta.b0177615-459c-45b5-b9ea-bf7ec5e83a44.TID337.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/187/1.delta
[2025-07-19T21:02:30.799+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=187),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/187] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/187/1.delta
[2025-07-19T21:02:30.799+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 187 (task 337, attempt 0, stage 1.0)
[2025-07-19T21:02:30.807+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 190 (task 339, attempt 0, stage 1.0)
[2025-07-19T21:02:30.807+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 190.0 in stage 1.0 (TID 339). 9048 bytes result sent to driver
[2025-07-19T21:02:30.808+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 344) (8b44f3d35cfa, executor driver, partition 2, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.809+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 190.0 in stage 1.0 (TID 339) in 91 ms on 8b44f3d35cfa (executor driver) (126/200)
[2025-07-19T21:02:30.809+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 2.0 in stage 1.0 (TID 344)
[2025-07-19T21:02:30.811+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.811+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.811+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/0/_metadata/schema using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/0/_metadata/.schema.317899d3-c213-497a-bccc-52d5f4ee5dfa.TID343.tmp
[2025-07-19T21:02:30.815+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/195/.1.delta.b25a5eda-937c-4ddf-922d-4e893576d9fa.TID341.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/195/1.delta
[2025-07-19T21:02:30.816+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=195),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/195] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/195/1.delta
[2025-07-19T21:02:30.816+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 195 (task 341, attempt 0, stage 1.0)
[2025-07-19T21:02:30.817+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 187 (task 337, attempt 0, stage 1.0)
[2025-07-19T21:02:30.817+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 187.0 in stage 1.0 (TID 337). 9055 bytes result sent to driver
[2025-07-19T21:02:30.817+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 188 (task 338, attempt 0, stage 1.0)
[2025-07-19T21:02:30.818+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 188.0 in stage 1.0 (TID 338). 9052 bytes result sent to driver
[2025-07-19T21:02:30.819+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 187.0 in stage 1.0 (TID 337) in 110 ms on 8b44f3d35cfa (executor driver) (127/200)
[2025-07-19T21:02:30.820+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 8.0 in stage 1.0 (TID 345) (8b44f3d35cfa, executor driver, partition 8, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.821+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/192/.1.delta.196e8f5a-3645-4bb4-9419-25891f7e4621.TID340.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/192/1.delta
[2025-07-19T21:02:30.821+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 10.0 in stage 1.0 (TID 346) (8b44f3d35cfa, executor driver, partition 10, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.822+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=192),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/192] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/192/1.delta
[2025-07-19T21:02:30.822+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 8.0 in stage 1.0 (TID 345)
[2025-07-19T21:02:30.822+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 185 (task 335, attempt 0, stage 1.0)
[2025-07-19T21:02:30.825+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 10.0 in stage 1.0 (TID 346)
[2025-07-19T21:02:30.826+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 185.0 in stage 1.0 (TID 335). 9025 bytes result sent to driver
[2025-07-19T21:02:30.827+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.828+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 15.0 in stage 1.0 (TID 347) (8b44f3d35cfa, executor driver, partition 15, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.828+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 192 (task 340, attempt 0, stage 1.0)
[2025-07-19T21:02:30.828+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 188.0 in stage 1.0 (TID 338) in 112 ms on 8b44f3d35cfa (executor driver) (128/200)
[2025-07-19T21:02:30.828+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:30.828+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 185.0 in stage 1.0 (TID 335) in 144 ms on 8b44f3d35cfa (executor driver) (129/200)
[2025-07-19T21:02:30.828+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 15.0 in stage 1.0 (TID 347)
[2025-07-19T21:02:30.828+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.828+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.828+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.828+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.831+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 195 (task 341, attempt 0, stage 1.0)
[2025-07-19T21:02:30.832+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 195.0 in stage 1.0 (TID 341). 9037 bytes result sent to driver
[2025-07-19T21:02:30.833+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/199/.1.delta.19c09a0b-c1f1-4f99-b15d-fede31704c13.TID342.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/199/1.delta
[2025-07-19T21:02:30.833+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 17.0 in stage 1.0 (TID 348) (8b44f3d35cfa, executor driver, partition 17, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.833+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=199),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/199] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/199/1.delta
[2025-07-19T21:02:30.835+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 195.0 in stage 1.0 (TID 341) in 77 ms on 8b44f3d35cfa (executor driver) (130/200)
[2025-07-19T21:02:30.835+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 199 (task 342, attempt 0, stage 1.0)
[2025-07-19T21:02:30.841+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 192 (task 340, attempt 0, stage 1.0)
[2025-07-19T21:02:30.842+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 192.0 in stage 1.0 (TID 340). 9043 bytes result sent to driver
[2025-07-19T21:02:30.843+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/0/_metadata/.schema.317899d3-c213-497a-bccc-52d5f4ee5dfa.TID343.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/0/_metadata/schema
[2025-07-19T21:02:30.843+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 17.0 in stage 1.0 (TID 348)
[2025-07-19T21:02:30.844+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 27.0 in stage 1.0 (TID 349) (8b44f3d35cfa, executor driver, partition 27, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.844+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 192.0 in stage 1.0 (TID 340) in 107 ms on 8b44f3d35cfa (executor driver) (131/200)
[2025-07-19T21:02:30.846+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.846+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.847+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@76be5ffc
[2025-07-19T21:02:30.847+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=0, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.847+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 27.0 in stage 1.0 (TID 349)
[2025-07-19T21:02:30.847+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/0] for update
[2025-07-19T21:02:30.847+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.847+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.847+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.850+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71a686f5
[2025-07-19T21:02:30.853+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=17, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.854+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=17),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/17] for update
[2025-07-19T21:02:30.854+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 199 (task 342, attempt 0, stage 1.0)
[2025-07-19T21:02:30.855+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 199.0 in stage 1.0 (TID 342). 9027 bytes result sent to driver
[2025-07-19T21:02:30.855+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.855+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 199.0 in stage 1.0 (TID 342) in 98 ms on 8b44f3d35cfa (executor driver) (132/200)
[2025-07-19T21:02:30.856+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 28.0 in stage 1.0 (TID 350) (8b44f3d35cfa, executor driver, partition 28, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.856+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/0/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/0/.1.delta.01fcc420-2f2b-49c6-8304-c6e4580e4fd2.TID343.tmp
[2025-07-19T21:02:30.857+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 28.0 in stage 1.0 (TID 350)
[2025-07-19T21:02:30.857+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54899de8
[2025-07-19T21:02:30.858+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=15, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.858+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.858+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.859+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=15),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/15] for update
[2025-07-19T21:02:30.863+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.864+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@42e588fe
[2025-07-19T21:02:30.869+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=28, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.869+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=28),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/28] for update
[2025-07-19T21:02:30.870+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.874+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/17/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/17/.1.delta.03b5110a-aa3b-43b8-8cfa-ba90aea79525.TID348.tmp
[2025-07-19T21:02:30.875+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b9a9cfa
[2025-07-19T21:02:30.875+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=10, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.878+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=10),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/10] for update
[2025-07-19T21:02:30.878+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/15/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/15/.1.delta.9a51bfa8-48c1-40bc-b9b2-73a2c0f96ef9.TID347.tmp
[2025-07-19T21:02:30.879+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.879+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/28/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/28/.1.delta.577ce6b9-1011-4ba0-91f4-76ea82429901.TID350.tmp
[2025-07-19T21:02:30.881+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d25d6cc
[2025-07-19T21:02:30.882+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=8, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.883+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/8] for update
[2025-07-19T21:02:30.884+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.889+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/8/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/8/.1.delta.e101acd2-c112-494e-886a-ccab096842ac.TID345.tmp
[2025-07-19T21:02:30.892+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/10/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/10/.1.delta.82b1e449-09be-4c92-ad1c-56d4fea2206b.TID346.tmp
[2025-07-19T21:02:30.893+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c0bdf24
[2025-07-19T21:02:30.893+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=2, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.893+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/2] for update
[2025-07-19T21:02:30.895+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.899+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/0/.1.delta.01fcc420-2f2b-49c6-8304-c6e4580e4fd2.TID343.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/0/1.delta
[2025-07-19T21:02:30.901+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/0] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/0/1.delta
[2025-07-19T21:02:30.902+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 343, attempt 0, stage 1.0)
[2025-07-19T21:02:30.902+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7058aa51
[2025-07-19T21:02:30.904+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=27, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.904+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=27),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/27] for update
[2025-07-19T21:02:30.904+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/2/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/2/.1.delta.254b951b-5344-4807-999c-7eecf3405ad3.TID344.tmp
[2025-07-19T21:02:30.904+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.907+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 0 (task 343, attempt 0, stage 1.0)
[2025-07-19T21:02:30.908+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 0.0 in stage 1.0 (TID 343). 6243 bytes result sent to driver
[2025-07-19T21:02:30.909+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 31.0 in stage 1.0 (TID 351) (8b44f3d35cfa, executor driver, partition 31, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.910+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 343) in 119 ms on 8b44f3d35cfa (executor driver) (133/200)
[2025-07-19T21:02:30.911+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/28/.1.delta.577ce6b9-1011-4ba0-91f4-76ea82429901.TID350.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/28/1.delta
[2025-07-19T21:02:30.912+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=28),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/28] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/28/1.delta
[2025-07-19T21:02:30.912+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 28 (task 350, attempt 0, stage 1.0)
[2025-07-19T21:02:30.912+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 31.0 in stage 1.0 (TID 351)
[2025-07-19T21:02:30.913+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/17/.1.delta.03b5110a-aa3b-43b8-8cfa-ba90aea79525.TID348.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/17/1.delta
[2025-07-19T21:02:30.913+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=17),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/17] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/17/1.delta
[2025-07-19T21:02:30.914+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/15/.1.delta.9a51bfa8-48c1-40bc-b9b2-73a2c0f96ef9.TID347.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/15/1.delta
[2025-07-19T21:02:30.915+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=15),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/15] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/15/1.delta
[2025-07-19T21:02:30.916+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 17 (task 348, attempt 0, stage 1.0)
[2025-07-19T21:02:30.917+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 15 (task 347, attempt 0, stage 1.0)
[2025-07-19T21:02:30.918+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.918+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.919+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 28 (task 350, attempt 0, stage 1.0)
[2025-07-19T21:02:30.920+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 15 (task 347, attempt 0, stage 1.0)
[2025-07-19T21:02:30.920+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 17 (task 348, attempt 0, stage 1.0)
[2025-07-19T21:02:30.920+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 17.0 in stage 1.0 (TID 348). 6243 bytes result sent to driver
[2025-07-19T21:02:30.920+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 28.0 in stage 1.0 (TID 350). 6243 bytes result sent to driver
[2025-07-19T21:02:30.921+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/27/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/27/.1.delta.463dd536-81e7-4276-bf9e-3016fe2f4d8d.TID349.tmp
[2025-07-19T21:02:30.921+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 33.0 in stage 1.0 (TID 352) (8b44f3d35cfa, executor driver, partition 33, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.921+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 17.0 in stage 1.0 (TID 348) in 85 ms on 8b44f3d35cfa (executor driver) (134/200)
[2025-07-19T21:02:30.921+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 33.0 in stage 1.0 (TID 352)
[2025-07-19T21:02:30.921+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 34.0 in stage 1.0 (TID 353) (8b44f3d35cfa, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.921+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 28.0 in stage 1.0 (TID 350) in 63 ms on 8b44f3d35cfa (executor driver) (135/200)
[2025-07-19T21:02:30.921+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 15.0 in stage 1.0 (TID 347). 6243 bytes result sent to driver
[2025-07-19T21:02:30.921+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 34.0 in stage 1.0 (TID 353)
[2025-07-19T21:02:30.921+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.922+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.922+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 36.0 in stage 1.0 (TID 354) (8b44f3d35cfa, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.923+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 36.0 in stage 1.0 (TID 354)
[2025-07-19T21:02:30.923+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 15.0 in stage 1.0 (TID 347) in 101 ms on 8b44f3d35cfa (executor driver) (136/200)
[2025-07-19T21:02:30.924+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/10/.1.delta.82b1e449-09be-4c92-ad1c-56d4fea2206b.TID346.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/10/1.delta
[2025-07-19T21:02:30.924+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=10),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/10] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/10/1.delta
[2025-07-19T21:02:30.925+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 10 (task 346, attempt 0, stage 1.0)
[2025-07-19T21:02:30.925+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.925+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.926+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.927+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.928+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ce100b1
[2025-07-19T21:02:30.928+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=31, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.928+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=31),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/31] for update
[2025-07-19T21:02:30.935+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/8/.1.delta.e101acd2-c112-494e-886a-ccab096842ac.TID345.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/8/1.delta
[2025-07-19T21:02:30.935+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/8] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/8/1.delta
[2025-07-19T21:02:30.936+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.936+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 10 (task 346, attempt 0, stage 1.0)
[2025-07-19T21:02:30.936+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 8 (task 345, attempt 0, stage 1.0)
[2025-07-19T21:02:30.941+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/2/.1.delta.254b951b-5344-4807-999c-7eecf3405ad3.TID344.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/2/1.delta
[2025-07-19T21:02:30.943+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/2] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/2/1.delta
[2025-07-19T21:02:30.944+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@643f30bf
[2025-07-19T21:02:30.944+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 10.0 in stage 1.0 (TID 346). 6286 bytes result sent to driver
[2025-07-19T21:02:30.944+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 2 (task 344, attempt 0, stage 1.0)
[2025-07-19T21:02:30.945+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=36, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.946+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=36),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/36] for update
[2025-07-19T21:02:30.947+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 8 (task 345, attempt 0, stage 1.0)
[2025-07-19T21:02:30.947+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.948+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 8.0 in stage 1.0 (TID 345). 6243 bytes result sent to driver
[2025-07-19T21:02:30.948+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 40.0 in stage 1.0 (TID 355) (8b44f3d35cfa, executor driver, partition 40, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.948+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 42.0 in stage 1.0 (TID 356) (8b44f3d35cfa, executor driver, partition 42, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.948+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 10.0 in stage 1.0 (TID 346) in 126 ms on 8b44f3d35cfa (executor driver) (137/200)
[2025-07-19T21:02:30.948+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 8.0 in stage 1.0 (TID 345) in 127 ms on 8b44f3d35cfa (executor driver) (138/200)
[2025-07-19T21:02:30.948+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 42.0 in stage 1.0 (TID 356)
[2025-07-19T21:02:30.948+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 2 (task 344, attempt 0, stage 1.0)
[2025-07-19T21:02:30.948+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 2.0 in stage 1.0 (TID 344). 6243 bytes result sent to driver
[2025-07-19T21:02:30.950+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@76bc2f0f
[2025-07-19T21:02:30.951+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 44.0 in stage 1.0 (TID 357) (8b44f3d35cfa, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.952+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/31/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/31/.1.delta.86162a14-8701-42cc-82e1-2a72e22d504a.TID351.tmp
[2025-07-19T21:02:30.952+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 40.0 in stage 1.0 (TID 355)
[2025-07-19T21:02:30.952+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=33, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.954+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=33),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/33] for update
[2025-07-19T21:02:30.955+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.956+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:30.957+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 344) in 147 ms on 8b44f3d35cfa (executor driver) (139/200)
[2025-07-19T21:02:30.957+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.957+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.957+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.958+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 44.0 in stage 1.0 (TID 357)
[2025-07-19T21:02:30.958+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/36/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/36/.1.delta.1bc46f6b-f932-41d7-8fc6-b2f9e4fc735d.TID354.tmp
[2025-07-19T21:02:30.960+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40a70dda
[2025-07-19T21:02:30.961+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=34, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.961+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=34),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/34] for update
[2025-07-19T21:02:30.961+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.962+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.962+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.963+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20947613
[2025-07-19T21:02:30.964+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=42, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.966+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=42),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/42] for update
[2025-07-19T21:02:30.968+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.968+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/27/.1.delta.463dd536-81e7-4276-bf9e-3016fe2f4d8d.TID349.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/27/1.delta
[2025-07-19T21:02:30.968+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=27),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/27] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/27/1.delta
[2025-07-19T21:02:30.969+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Commit authorized for partition 27 (task 349, attempt 0, stage 1.0)
[2025-07-19T21:02:30.973+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/34/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/34/.1.delta.3796f3b4-868b-47f8-b860-c4c21814fb7c.TID353.tmp
[2025-07-19T21:02:30.975+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5be3a2a8
[2025-07-19T21:02:30.975+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/33/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/33/.1.delta.d9359b48-da00-4038-8e10-d22c5840559d.TID352.tmp
[2025-07-19T21:02:30.976+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=40, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.976+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=40),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/40] for update
[2025-07-19T21:02:30.976+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:30.978+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO DataWritingSparkTask: Committed partition 27 (task 349, attempt 0, stage 1.0)
[2025-07-19T21:02:30.978+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Finished task 27.0 in stage 1.0 (TID 349). 6243 bytes result sent to driver
[2025-07-19T21:02:30.980+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Starting task 49.0 in stage 1.0 (TID 358) (8b44f3d35cfa, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:30.980+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO TaskSetManager: Finished task 27.0 in stage 1.0 (TID 349) in 140 ms on 8b44f3d35cfa (executor driver) (140/200)
[2025-07-19T21:02:30.981+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO Executor: Running task 49.0 in stage 1.0 (TID 358)
[2025-07-19T21:02:30.983+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:30.984+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:30.985+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56619c20
[2025-07-19T21:02:30.987+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/42/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/42/.1.delta.6331a778-af45-439d-a0ed-6f280169d0ad.TID356.tmp
[2025-07-19T21:02:30.987+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=44, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:30.988+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=44),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/44] for update
[2025-07-19T21:02:30.991+0000] {subprocess.py:93} INFO - 25/07/19 21:02:30 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.006+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/40/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/40/.1.delta.bf920906-3e52-4f8a-a417-2c0be692b9d3.TID355.tmp
[2025-07-19T21:02:31.010+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73c479fc
[2025-07-19T21:02:31.011+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=49, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.011+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=49),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/49] for update
[2025-07-19T21:02:31.011+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/44/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/44/.1.delta.21bd0b60-1146-44b7-871d-5edd3497ce77.TID357.tmp
[2025-07-19T21:02:31.011+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.011+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/31/.1.delta.86162a14-8701-42cc-82e1-2a72e22d504a.TID351.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/31/1.delta
[2025-07-19T21:02:31.011+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=31),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/31] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/31/1.delta
[2025-07-19T21:02:31.013+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 31 (task 351, attempt 0, stage 1.0)
[2025-07-19T21:02:31.018+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 31 (task 351, attempt 0, stage 1.0)
[2025-07-19T21:02:31.019+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 31.0 in stage 1.0 (TID 351). 6243 bytes result sent to driver
[2025-07-19T21:02:31.023+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/49/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/49/.1.delta.3e060d11-8831-4cfe-9fc9-2b87d35399bd.TID358.tmp
[2025-07-19T21:02:31.026+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 50.0 in stage 1.0 (TID 359) (8b44f3d35cfa, executor driver, partition 50, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.026+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 31.0 in stage 1.0 (TID 351) in 115 ms on 8b44f3d35cfa (executor driver) (141/200)
[2025-07-19T21:02:31.028+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/36/.1.delta.1bc46f6b-f932-41d7-8fc6-b2f9e4fc735d.TID354.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/36/1.delta
[2025-07-19T21:02:31.029+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=36),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/36] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/36/1.delta
[2025-07-19T21:02:31.029+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 36 (task 354, attempt 0, stage 1.0)
[2025-07-19T21:02:31.029+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 50.0 in stage 1.0 (TID 359)
[2025-07-19T21:02:31.030+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/34/.1.delta.3796f3b4-868b-47f8-b860-c4c21814fb7c.TID353.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/34/1.delta
[2025-07-19T21:02:31.030+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=34),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/34] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/34/1.delta
[2025-07-19T21:02:31.033+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 34 (task 353, attempt 0, stage 1.0)
[2025-07-19T21:02:31.033+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/33/.1.delta.d9359b48-da00-4038-8e10-d22c5840559d.TID352.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/33/1.delta
[2025-07-19T21:02:31.033+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=33),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/33] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/33/1.delta
[2025-07-19T21:02:31.036+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.037+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.038+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 34 (task 353, attempt 0, stage 1.0)
[2025-07-19T21:02:31.038+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 36 (task 354, attempt 0, stage 1.0)
[2025-07-19T21:02:31.038+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 36.0 in stage 1.0 (TID 354). 6243 bytes result sent to driver
[2025-07-19T21:02:31.039+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 34.0 in stage 1.0 (TID 353). 6243 bytes result sent to driver
[2025-07-19T21:02:31.039+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 54.0 in stage 1.0 (TID 360) (8b44f3d35cfa, executor driver, partition 54, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.039+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 55.0 in stage 1.0 (TID 361) (8b44f3d35cfa, executor driver, partition 55, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.039+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 34.0 in stage 1.0 (TID 353) in 121 ms on 8b44f3d35cfa (executor driver) (142/200)
[2025-07-19T21:02:31.040+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 55.0 in stage 1.0 (TID 361)
[2025-07-19T21:02:31.040+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 54.0 in stage 1.0 (TID 360)
[2025-07-19T21:02:31.040+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 36.0 in stage 1.0 (TID 354) in 116 ms on 8b44f3d35cfa (executor driver) (143/200)
[2025-07-19T21:02:31.040+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.040+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.040+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.040+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.041+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@766345d2
[2025-07-19T21:02:31.041+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=50, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.041+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=50),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/50] for update
[2025-07-19T21:02:31.043+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 33 (task 352, attempt 0, stage 1.0)
[2025-07-19T21:02:31.045+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.045+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/42/.1.delta.6331a778-af45-439d-a0ed-6f280169d0ad.TID356.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/42/1.delta
[2025-07-19T21:02:31.045+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=42),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/42] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/42/1.delta
[2025-07-19T21:02:31.045+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 42 (task 356, attempt 0, stage 1.0)
[2025-07-19T21:02:31.046+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f0a143f
[2025-07-19T21:02:31.047+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 33 (task 352, attempt 0, stage 1.0)
[2025-07-19T21:02:31.047+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 33.0 in stage 1.0 (TID 352). 6243 bytes result sent to driver
[2025-07-19T21:02:31.051+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=54, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.053+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=54),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/54] for update
[2025-07-19T21:02:31.054+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 61.0 in stage 1.0 (TID 362) (8b44f3d35cfa, executor driver, partition 61, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.054+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 61.0 in stage 1.0 (TID 362)
[2025-07-19T21:02:31.055+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 42 (task 356, attempt 0, stage 1.0)
[2025-07-19T21:02:31.055+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 42.0 in stage 1.0 (TID 356). 6243 bytes result sent to driver
[2025-07-19T21:02:31.055+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 33.0 in stage 1.0 (TID 352) in 135 ms on 8b44f3d35cfa (executor driver) (144/200)
[2025-07-19T21:02:31.055+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 67.0 in stage 1.0 (TID 363) (8b44f3d35cfa, executor driver, partition 67, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.055+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.055+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 42.0 in stage 1.0 (TID 356) in 108 ms on 8b44f3d35cfa (executor driver) (145/200)
[2025-07-19T21:02:31.056+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 67.0 in stage 1.0 (TID 363)
[2025-07-19T21:02:31.057+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.057+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:31.058+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.058+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.058+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/40/.1.delta.bf920906-3e52-4f8a-a417-2c0be692b9d3.TID355.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/40/1.delta
[2025-07-19T21:02:31.058+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=40),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/40] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/40/1.delta
[2025-07-19T21:02:31.058+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 40 (task 355, attempt 0, stage 1.0)
[2025-07-19T21:02:31.059+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/50/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/50/.1.delta.75eae7cc-c8ef-42dd-b5c9-ae670428c6c1.TID359.tmp
[2025-07-19T21:02:31.060+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74f00c82
[2025-07-19T21:02:31.061+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/44/.1.delta.21bd0b60-1146-44b7-871d-5edd3497ce77.TID357.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/44/1.delta
[2025-07-19T21:02:31.061+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=55, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.061+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=44),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/44] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/44/1.delta
[2025-07-19T21:02:31.061+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 44 (task 357, attempt 0, stage 1.0)
[2025-07-19T21:02:31.061+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=55),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/55] for update
[2025-07-19T21:02:31.064+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 40 (task 355, attempt 0, stage 1.0)
[2025-07-19T21:02:31.065+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 40.0 in stage 1.0 (TID 355). 6200 bytes result sent to driver
[2025-07-19T21:02:31.065+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.066+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 70.0 in stage 1.0 (TID 364) (8b44f3d35cfa, executor driver, partition 70, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.066+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 40.0 in stage 1.0 (TID 355) in 124 ms on 8b44f3d35cfa (executor driver) (146/200)
[2025-07-19T21:02:31.066+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 44 (task 357, attempt 0, stage 1.0)
[2025-07-19T21:02:31.067+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 70.0 in stage 1.0 (TID 364)
[2025-07-19T21:02:31.069+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/54/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/54/.1.delta.81568703-7c3d-4e40-a022-50909f23bc15.TID360.tmp
[2025-07-19T21:02:31.069+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 44.0 in stage 1.0 (TID 357). 6243 bytes result sent to driver
[2025-07-19T21:02:31.069+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.069+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.072+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@395933dc
[2025-07-19T21:02:31.072+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 74.0 in stage 1.0 (TID 365) (8b44f3d35cfa, executor driver, partition 74, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.074+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 74.0 in stage 1.0 (TID 365)
[2025-07-19T21:02:31.075+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=67, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.075+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=67),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/67] for update
[2025-07-19T21:02:31.075+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 44.0 in stage 1.0 (TID 357) in 124 ms on 8b44f3d35cfa (executor driver) (147/200)
[2025-07-19T21:02:31.076+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.077+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.077+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/49/.1.delta.3e060d11-8831-4cfe-9fc9-2b87d35399bd.TID358.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/49/1.delta
[2025-07-19T21:02:31.077+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/55/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/55/.1.delta.4eb847f3-2f9a-4816-a3e1-baf74b643d63.TID361.tmp
[2025-07-19T21:02:31.078+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:31.078+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=49),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/49] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/49/1.delta
[2025-07-19T21:02:31.078+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 49 (task 358, attempt 0, stage 1.0)
[2025-07-19T21:02:31.080+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@253cafa5
[2025-07-19T21:02:31.081+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 49 (task 358, attempt 0, stage 1.0)
[2025-07-19T21:02:31.081+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=61, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.081+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=61),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/61] for update
[2025-07-19T21:02:31.082+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 49.0 in stage 1.0 (TID 358). 6200 bytes result sent to driver
[2025-07-19T21:02:31.082+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 76.0 in stage 1.0 (TID 366) (8b44f3d35cfa, executor driver, partition 76, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.083+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 49.0 in stage 1.0 (TID 358) in 105 ms on 8b44f3d35cfa (executor driver) (148/200)
[2025-07-19T21:02:31.084+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.085+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 76.0 in stage 1.0 (TID 366)
[2025-07-19T21:02:31.085+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/67/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/67/.1.delta.5c76045a-8002-44d5-b2d6-53afd379ee44.TID363.tmp
[2025-07-19T21:02:31.088+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.088+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.089+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5aff62d5
[2025-07-19T21:02:31.089+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=74, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.089+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=74),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/74] for update
[2025-07-19T21:02:31.091+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.093+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23f12f67
[2025-07-19T21:02:31.094+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=70, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.094+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=70),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/70] for update
[2025-07-19T21:02:31.097+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.099+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/61/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/61/.1.delta.21ad7e63-fdd3-40eb-87e0-2ed5064b509a.TID362.tmp
[2025-07-19T21:02:31.099+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/50/.1.delta.75eae7cc-c8ef-42dd-b5c9-ae670428c6c1.TID359.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/50/1.delta
[2025-07-19T21:02:31.099+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=50),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/50] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/50/1.delta
[2025-07-19T21:02:31.099+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 50 (task 359, attempt 0, stage 1.0)
[2025-07-19T21:02:31.103+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/74/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/74/.1.delta.5e9186c1-e83c-4e4b-a173-a56d014d70af.TID365.tmp
[2025-07-19T21:02:31.104+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 50 (task 359, attempt 0, stage 1.0)
[2025-07-19T21:02:31.107+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 50.0 in stage 1.0 (TID 359). 6200 bytes result sent to driver
[2025-07-19T21:02:31.108+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 50.0 in stage 1.0 (TID 359) in 82 ms on 8b44f3d35cfa (executor driver) (149/200)
[2025-07-19T21:02:31.109+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 80.0 in stage 1.0 (TID 367) (8b44f3d35cfa, executor driver, partition 80, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.110+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 80.0 in stage 1.0 (TID 367)
[2025-07-19T21:02:31.110+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c4789
[2025-07-19T21:02:31.112+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/54/.1.delta.81568703-7c3d-4e40-a022-50909f23bc15.TID360.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/54/1.delta
[2025-07-19T21:02:31.112+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=54),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/54] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/54/1.delta
[2025-07-19T21:02:31.113+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.114+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.114+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=76, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.114+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=76),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/76] for update
[2025-07-19T21:02:31.115+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 54 (task 360, attempt 0, stage 1.0)
[2025-07-19T21:02:31.115+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 54 (task 360, attempt 0, stage 1.0)
[2025-07-19T21:02:31.115+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.117+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 54.0 in stage 1.0 (TID 360). 6200 bytes result sent to driver
[2025-07-19T21:02:31.118+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/70/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/70/.1.delta.8d4c0fc9-6e8b-4bb7-9f21-d76b2520d4a1.TID364.tmp
[2025-07-19T21:02:31.118+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/55/.1.delta.4eb847f3-2f9a-4816-a3e1-baf74b643d63.TID361.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/55/1.delta
[2025-07-19T21:02:31.118+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=55),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/55] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/55/1.delta
[2025-07-19T21:02:31.120+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 81.0 in stage 1.0 (TID 368) (8b44f3d35cfa, executor driver, partition 81, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.121+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 55 (task 361, attempt 0, stage 1.0)
[2025-07-19T21:02:31.121+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 54.0 in stage 1.0 (TID 360) in 82 ms on 8b44f3d35cfa (executor driver) (150/200)
[2025-07-19T21:02:31.121+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d07b716
[2025-07-19T21:02:31.122+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 81.0 in stage 1.0 (TID 368)
[2025-07-19T21:02:31.122+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=80, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.123+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=80),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/80] for update
[2025-07-19T21:02:31.123+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.124+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.125+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/76/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/76/.1.delta.27988862-8566-4fd8-acd6-22038397a1cb.TID366.tmp
[2025-07-19T21:02:31.126+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.127+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/67/.1.delta.5c76045a-8002-44d5-b2d6-53afd379ee44.TID363.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/67/1.delta
[2025-07-19T21:02:31.127+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=67),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/67] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/67/1.delta
[2025-07-19T21:02:31.128+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 67 (task 363, attempt 0, stage 1.0)
[2025-07-19T21:02:31.129+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 55 (task 361, attempt 0, stage 1.0)
[2025-07-19T21:02:31.133+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f03c7cd
[2025-07-19T21:02:31.134+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 55.0 in stage 1.0 (TID 361). 6200 bytes result sent to driver
[2025-07-19T21:02:31.134+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=81, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.134+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=81),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/81] for update
[2025-07-19T21:02:31.135+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 67 (task 363, attempt 0, stage 1.0)
[2025-07-19T21:02:31.136+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 67.0 in stage 1.0 (TID 363). 6200 bytes result sent to driver
[2025-07-19T21:02:31.136+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 55.0 in stage 1.0 (TID 361) in 95 ms on 8b44f3d35cfa (executor driver) (151/200)
[2025-07-19T21:02:31.136+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.136+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 84.0 in stage 1.0 (TID 369) (8b44f3d35cfa, executor driver, partition 84, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.137+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/80/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/80/.1.delta.7ebf3169-3d7d-4d26-a37c-dd3d21e41414.TID367.tmp
[2025-07-19T21:02:31.137+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 84.0 in stage 1.0 (TID 369)
[2025-07-19T21:02:31.138+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 88.0 in stage 1.0 (TID 370) (8b44f3d35cfa, executor driver, partition 88, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.138+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 67.0 in stage 1.0 (TID 363) in 84 ms on 8b44f3d35cfa (executor driver) (152/200)
[2025-07-19T21:02:31.138+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 88.0 in stage 1.0 (TID 370)
[2025-07-19T21:02:31.139+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.139+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.141+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.142+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.147+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4dd554c8
[2025-07-19T21:02:31.147+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=84, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.148+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=84),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/84] for update
[2025-07-19T21:02:31.148+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/74/.1.delta.5e9186c1-e83c-4e4b-a173-a56d014d70af.TID365.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/74/1.delta
[2025-07-19T21:02:31.149+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=74),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/74] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/74/1.delta
[2025-07-19T21:02:31.149+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 74 (task 365, attempt 0, stage 1.0)
[2025-07-19T21:02:31.150+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/61/.1.delta.21ad7e63-fdd3-40eb-87e0-2ed5064b509a.TID362.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/61/1.delta
[2025-07-19T21:02:31.150+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=61),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/61] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/61/1.delta
[2025-07-19T21:02:31.150+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 61 (task 362, attempt 0, stage 1.0)
[2025-07-19T21:02:31.151+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/81/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/81/.1.delta.d4116f74-160c-47a7-a904-5c5b7dc88ea0.TID368.tmp
[2025-07-19T21:02:31.152+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.153+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/70/.1.delta.8d4c0fc9-6e8b-4bb7-9f21-d76b2520d4a1.TID364.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/70/1.delta
[2025-07-19T21:02:31.154+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=70),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/70] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/70/1.delta
[2025-07-19T21:02:31.154+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 70 (task 364, attempt 0, stage 1.0)
[2025-07-19T21:02:31.155+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 61 (task 362, attempt 0, stage 1.0)
[2025-07-19T21:02:31.156+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 61.0 in stage 1.0 (TID 362). 6200 bytes result sent to driver
[2025-07-19T21:02:31.157+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 90.0 in stage 1.0 (TID 371) (8b44f3d35cfa, executor driver, partition 90, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.157+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71a89d3
[2025-07-19T21:02:31.157+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 74 (task 365, attempt 0, stage 1.0)
[2025-07-19T21:02:31.157+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=88, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.157+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 74.0 in stage 1.0 (TID 365). 6200 bytes result sent to driver
[2025-07-19T21:02:31.157+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=88),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/88] for update
[2025-07-19T21:02:31.157+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 90.0 in stage 1.0 (TID 371)
[2025-07-19T21:02:31.157+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 91.0 in stage 1.0 (TID 372) (8b44f3d35cfa, executor driver, partition 91, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.157+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 61.0 in stage 1.0 (TID 362) in 108 ms on 8b44f3d35cfa (executor driver) (153/200)
[2025-07-19T21:02:31.157+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 74.0 in stage 1.0 (TID 365) in 87 ms on 8b44f3d35cfa (executor driver) (154/200)
[2025-07-19T21:02:31.161+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 70 (task 364, attempt 0, stage 1.0)
[2025-07-19T21:02:31.162+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.162+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.162+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.162+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 70.0 in stage 1.0 (TID 364). 6200 bytes result sent to driver
[2025-07-19T21:02:31.162+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 91.0 in stage 1.0 (TID 372)
[2025-07-19T21:02:31.168+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.168+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:31.168+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/88/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/88/.1.delta.1f168301-eab1-43ce-a137-1a13f5b83410.TID370.tmp
[2025-07-19T21:02:31.168+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 93.0 in stage 1.0 (TID 373) (8b44f3d35cfa, executor driver, partition 93, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.169+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 70.0 in stage 1.0 (TID 364) in 102 ms on 8b44f3d35cfa (executor driver) (155/200)
[2025-07-19T21:02:31.169+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d83e9b5
[2025-07-19T21:02:31.169+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 93.0 in stage 1.0 (TID 373)
[2025-07-19T21:02:31.169+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/84/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/84/.1.delta.0c92f941-fde1-49d1-a70a-9803b8479c11.TID369.tmp
[2025-07-19T21:02:31.169+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/76/.1.delta.27988862-8566-4fd8-acd6-22038397a1cb.TID366.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/76/1.delta
[2025-07-19T21:02:31.169+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=90, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.169+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=76),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/76] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/76/1.delta
[2025-07-19T21:02:31.169+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=90),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/90] for update
[2025-07-19T21:02:31.169+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 76 (task 366, attempt 0, stage 1.0)
[2025-07-19T21:02:31.170+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.172+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.172+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.173+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/80/.1.delta.7ebf3169-3d7d-4d26-a37c-dd3d21e41414.TID367.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/80/1.delta
[2025-07-19T21:02:31.174+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=80),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/80] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/80/1.delta
[2025-07-19T21:02:31.174+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 76 (task 366, attempt 0, stage 1.0)
[2025-07-19T21:02:31.175+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 80 (task 367, attempt 0, stage 1.0)
[2025-07-19T21:02:31.176+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 76.0 in stage 1.0 (TID 366). 6200 bytes result sent to driver
[2025-07-19T21:02:31.177+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@bc7b3c7
[2025-07-19T21:02:31.177+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=91, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.178+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=91),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/91] for update
[2025-07-19T21:02:31.178+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 101.0 in stage 1.0 (TID 374) (8b44f3d35cfa, executor driver, partition 101, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.179+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 101.0 in stage 1.0 (TID 374)
[2025-07-19T21:02:31.180+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 76.0 in stage 1.0 (TID 366) in 98 ms on 8b44f3d35cfa (executor driver) (156/200)
[2025-07-19T21:02:31.181+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/90/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/90/.1.delta.a9944b07-5806-47fd-b3bf-36a953fad8e5.TID371.tmp
[2025-07-19T21:02:31.182+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.184+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 80 (task 367, attempt 0, stage 1.0)
[2025-07-19T21:02:31.188+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/81/.1.delta.d4116f74-160c-47a7-a904-5c5b7dc88ea0.TID368.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/81/1.delta
[2025-07-19T21:02:31.191+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 80.0 in stage 1.0 (TID 367). 6200 bytes result sent to driver
[2025-07-19T21:02:31.191+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=81),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/81] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/81/1.delta
[2025-07-19T21:02:31.192+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 81 (task 368, attempt 0, stage 1.0)
[2025-07-19T21:02:31.192+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 103.0 in stage 1.0 (TID 375) (8b44f3d35cfa, executor driver, partition 103, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.192+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@693a7f82
[2025-07-19T21:02:31.193+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=93, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.194+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 80.0 in stage 1.0 (TID 367) in 81 ms on 8b44f3d35cfa (executor driver) (157/200)
[2025-07-19T21:02:31.194+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=93),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/93] for update
[2025-07-19T21:02:31.195+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.195+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.196+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T21:02:31.196+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 103.0 in stage 1.0 (TID 375)
[2025-07-19T21:02:31.196+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 81 (task 368, attempt 0, stage 1.0)
[2025-07-19T21:02:31.196+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 81.0 in stage 1.0 (TID 368). 6200 bytes result sent to driver
[2025-07-19T21:02:31.196+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 81.0 in stage 1.0 (TID 368) in 73 ms on 8b44f3d35cfa (executor driver) (158/200)
[2025-07-19T21:02:31.196+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 108.0 in stage 1.0 (TID 376) (8b44f3d35cfa, executor driver, partition 108, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.196+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 108.0 in stage 1.0 (TID 376)
[2025-07-19T21:02:31.196+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.197+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.197+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.197+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.198+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@295ad659
[2025-07-19T21:02:31.198+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=101, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.198+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=101),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/101] for update
[2025-07-19T21:02:31.202+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.202+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/91/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/91/.1.delta.d67d0400-5695-4d0b-b80a-0946ce61b984.TID372.tmp
[2025-07-19T21:02:31.203+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/93/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/93/.1.delta.041aac8e-2337-480c-a2bd-cbf85c29c81d.TID373.tmp
[2025-07-19T21:02:31.208+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6592da5d
[2025-07-19T21:02:31.208+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=103, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.209+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=103),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/103] for update
[2025-07-19T21:02:31.212+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.213+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/101/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/101/.1.delta.d699cded-c6af-4886-91e7-cb1da0ede23f.TID374.tmp
[2025-07-19T21:02:31.213+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/88/.1.delta.1f168301-eab1-43ce-a137-1a13f5b83410.TID370.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/88/1.delta
[2025-07-19T21:02:31.213+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=88),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/88] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/88/1.delta
[2025-07-19T21:02:31.214+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/84/.1.delta.0c92f941-fde1-49d1-a70a-9803b8479c11.TID369.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/84/1.delta
[2025-07-19T21:02:31.215+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=84),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/84] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/84/1.delta
[2025-07-19T21:02:31.215+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 84 (task 369, attempt 0, stage 1.0)
[2025-07-19T21:02:31.215+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 88 (task 370, attempt 0, stage 1.0)
[2025-07-19T21:02:31.218+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c3aa163
[2025-07-19T21:02:31.219+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=108, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.219+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=108),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/108] for update
[2025-07-19T21:02:31.222+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 88 (task 370, attempt 0, stage 1.0)
[2025-07-19T21:02:31.223+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/90/.1.delta.a9944b07-5806-47fd-b3bf-36a953fad8e5.TID371.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/90/1.delta
[2025-07-19T21:02:31.224+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=90),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/90] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/90/1.delta
[2025-07-19T21:02:31.225+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.226+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/103/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/103/.1.delta.7562b281-48fd-4402-acab-85e2e9338616.TID375.tmp
[2025-07-19T21:02:31.226+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 90 (task 371, attempt 0, stage 1.0)
[2025-07-19T21:02:31.227+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 88.0 in stage 1.0 (TID 370). 6200 bytes result sent to driver
[2025-07-19T21:02:31.227+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 84 (task 369, attempt 0, stage 1.0)
[2025-07-19T21:02:31.229+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 84.0 in stage 1.0 (TID 369). 6200 bytes result sent to driver
[2025-07-19T21:02:31.229+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 112.0 in stage 1.0 (TID 377) (8b44f3d35cfa, executor driver, partition 112, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.230+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 88.0 in stage 1.0 (TID 370) in 90 ms on 8b44f3d35cfa (executor driver) (159/200)
[2025-07-19T21:02:31.230+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 112.0 in stage 1.0 (TID 377)
[2025-07-19T21:02:31.231+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 114.0 in stage 1.0 (TID 378) (8b44f3d35cfa, executor driver, partition 114, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.231+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 84.0 in stage 1.0 (TID 369) in 93 ms on 8b44f3d35cfa (executor driver) (160/200)
[2025-07-19T21:02:31.231+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 114.0 in stage 1.0 (TID 378)
[2025-07-19T21:02:31.232+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.232+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.232+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.233+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.233+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 90 (task 371, attempt 0, stage 1.0)
[2025-07-19T21:02:31.234+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 90.0 in stage 1.0 (TID 371). 6200 bytes result sent to driver
[2025-07-19T21:02:31.240+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/108/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/108/.1.delta.5c6a04a6-78b6-4624-8aae-365b35695945.TID376.tmp
[2025-07-19T21:02:31.241+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4138a509
[2025-07-19T21:02:31.242+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 115.0 in stage 1.0 (TID 379) (8b44f3d35cfa, executor driver, partition 115, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.242+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=114, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.242+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=114),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/114] for update
[2025-07-19T21:02:31.243+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 90.0 in stage 1.0 (TID 371) in 82 ms on 8b44f3d35cfa (executor driver) (161/200)
[2025-07-19T21:02:31.243+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/93/.1.delta.041aac8e-2337-480c-a2bd-cbf85c29c81d.TID373.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/93/1.delta
[2025-07-19T21:02:31.245+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=93),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/93] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/93/1.delta
[2025-07-19T21:02:31.245+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.245+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 115.0 in stage 1.0 (TID 379)
[2025-07-19T21:02:31.245+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.245+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.245+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 93 (task 373, attempt 0, stage 1.0)
[2025-07-19T21:02:31.247+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/91/.1.delta.d67d0400-5695-4d0b-b80a-0946ce61b984.TID372.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/91/1.delta
[2025-07-19T21:02:31.247+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=91),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/91] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/91/1.delta
[2025-07-19T21:02:31.248+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 91 (task 372, attempt 0, stage 1.0)
[2025-07-19T21:02:31.249+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 93 (task 373, attempt 0, stage 1.0)
[2025-07-19T21:02:31.251+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 93.0 in stage 1.0 (TID 373). 6200 bytes result sent to driver
[2025-07-19T21:02:31.254+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 116.0 in stage 1.0 (TID 380) (8b44f3d35cfa, executor driver, partition 116, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.255+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/114/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/114/.1.delta.9ef7411f-a33f-43cc-97c3-618031c0c7f1.TID378.tmp
[2025-07-19T21:02:31.258+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 91 (task 372, attempt 0, stage 1.0)
[2025-07-19T21:02:31.259+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 91.0 in stage 1.0 (TID 372). 6200 bytes result sent to driver
[2025-07-19T21:02:31.260+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 93.0 in stage 1.0 (TID 373) in 90 ms on 8b44f3d35cfa (executor driver) (162/200)
[2025-07-19T21:02:31.260+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 116.0 in stage 1.0 (TID 380)
[2025-07-19T21:02:31.261+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 124.0 in stage 1.0 (TID 381) (8b44f3d35cfa, executor driver, partition 124, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.261+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1fcae1a6
[2025-07-19T21:02:31.262+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 91.0 in stage 1.0 (TID 372) in 99 ms on 8b44f3d35cfa (executor driver) (163/200)
[2025-07-19T21:02:31.262+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=112, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.262+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=112),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/112] for update
[2025-07-19T21:02:31.262+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 124.0 in stage 1.0 (TID 381)
[2025-07-19T21:02:31.262+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.263+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.263+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.263+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/101/.1.delta.d699cded-c6af-4886-91e7-cb1da0ede23f.TID374.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/101/1.delta
[2025-07-19T21:02:31.263+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=101),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/101] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/101/1.delta
[2025-07-19T21:02:31.264+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.264+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.264+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 101 (task 374, attempt 0, stage 1.0)
[2025-07-19T21:02:31.266+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 101 (task 374, attempt 0, stage 1.0)
[2025-07-19T21:02:31.267+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@457376c6
[2025-07-19T21:02:31.268+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 101.0 in stage 1.0 (TID 374). 6200 bytes result sent to driver
[2025-07-19T21:02:31.268+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 125.0 in stage 1.0 (TID 382) (8b44f3d35cfa, executor driver, partition 125, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.268+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=115, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.268+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=115),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/115] for update
[2025-07-19T21:02:31.268+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 125.0 in stage 1.0 (TID 382)
[2025-07-19T21:02:31.268+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 101.0 in stage 1.0 (TID 374) in 89 ms on 8b44f3d35cfa (executor driver) (164/200)
[2025-07-19T21:02:31.270+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.271+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/103/.1.delta.7562b281-48fd-4402-acab-85e2e9338616.TID375.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/103/1.delta
[2025-07-19T21:02:31.273+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/112/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/112/.1.delta.e7426d79-c42a-4717-a09f-e4f78a64d537.TID377.tmp
[2025-07-19T21:02:31.274+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=103),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/103] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/103/1.delta
[2025-07-19T21:02:31.275+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.275+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.275+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 103 (task 375, attempt 0, stage 1.0)
[2025-07-19T21:02:31.276+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@12f2ba59
[2025-07-19T21:02:31.276+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=116, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.276+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=116),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/116] for update
[2025-07-19T21:02:31.279+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.281+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 103 (task 375, attempt 0, stage 1.0)
[2025-07-19T21:02:31.281+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 103.0 in stage 1.0 (TID 375). 6200 bytes result sent to driver
[2025-07-19T21:02:31.282+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 126.0 in stage 1.0 (TID 383) (8b44f3d35cfa, executor driver, partition 126, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.283+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 103.0 in stage 1.0 (TID 375) in 98 ms on 8b44f3d35cfa (executor driver) (165/200)
[2025-07-19T21:02:31.283+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 126.0 in stage 1.0 (TID 383)
[2025-07-19T21:02:31.285+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/108/.1.delta.5c6a04a6-78b6-4624-8aae-365b35695945.TID376.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/108/1.delta
[2025-07-19T21:02:31.285+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=108),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/108] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/108/1.delta
[2025-07-19T21:02:31.286+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/115/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/115/.1.delta.4a2c09b0-47b8-48d2-ac4c-1a04b8cb62d9.TID379.tmp
[2025-07-19T21:02:31.287+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 108 (task 376, attempt 0, stage 1.0)
[2025-07-19T21:02:31.287+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@277db1ab
[2025-07-19T21:02:31.288+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=124, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.288+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=124),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/124] for update
[2025-07-19T21:02:31.288+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.289+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.289+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.294+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 108 (task 376, attempt 0, stage 1.0)
[2025-07-19T21:02:31.295+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 108.0 in stage 1.0 (TID 376). 6200 bytes result sent to driver
[2025-07-19T21:02:31.296+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 108.0 in stage 1.0 (TID 376) in 100 ms on 8b44f3d35cfa (executor driver) (166/200)
[2025-07-19T21:02:31.296+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 132.0 in stage 1.0 (TID 384) (8b44f3d35cfa, executor driver, partition 132, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.296+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 132.0 in stage 1.0 (TID 384)
[2025-07-19T21:02:31.296+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.296+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.297+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@21ba630d
[2025-07-19T21:02:31.298+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=126, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.299+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=126),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/126] for update
[2025-07-19T21:02:31.299+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/114/.1.delta.9ef7411f-a33f-43cc-97c3-618031c0c7f1.TID378.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/114/1.delta
[2025-07-19T21:02:31.300+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=114),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/114] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/114/1.delta
[2025-07-19T21:02:31.300+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.301+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 114 (task 378, attempt 0, stage 1.0)
[2025-07-19T21:02:31.301+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/116/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/116/.1.delta.1cb01485-f6d2-417d-82f2-25190ded257f.TID380.tmp
[2025-07-19T21:02:31.305+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/124/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/124/.1.delta.82e4aeba-0eb2-4ea4-8b2e-4ebf39293146.TID381.tmp
[2025-07-19T21:02:31.307+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a140fcc
[2025-07-19T21:02:31.308+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 114 (task 378, attempt 0, stage 1.0)
[2025-07-19T21:02:31.308+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=125, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.309+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=125),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/125] for update
[2025-07-19T21:02:31.309+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 114.0 in stage 1.0 (TID 378). 6157 bytes result sent to driver
[2025-07-19T21:02:31.310+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 134.0 in stage 1.0 (TID 385) (8b44f3d35cfa, executor driver, partition 134, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.311+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 114.0 in stage 1.0 (TID 378) in 83 ms on 8b44f3d35cfa (executor driver) (167/200)
[2025-07-19T21:02:31.311+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 134.0 in stage 1.0 (TID 385)
[2025-07-19T21:02:31.311+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.314+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.315+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.323+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/126/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/126/.1.delta.99fcce8c-11e3-4fe8-8bff-dc3f66fc9626.TID383.tmp
[2025-07-19T21:02:31.324+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3b2b0ed3
[2025-07-19T21:02:31.324+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=132, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.324+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=132),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/132] for update
[2025-07-19T21:02:31.324+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.328+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/125/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/125/.1.delta.3af4cdf1-30b5-40d5-831b-b7e7e07f8966.TID382.tmp
[2025-07-19T21:02:31.329+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/112/.1.delta.e7426d79-c42a-4717-a09f-e4f78a64d537.TID377.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/112/1.delta
[2025-07-19T21:02:31.329+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=112),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/112] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/112/1.delta
[2025-07-19T21:02:31.329+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 112 (task 377, attempt 0, stage 1.0)
[2025-07-19T21:02:31.331+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 112 (task 377, attempt 0, stage 1.0)
[2025-07-19T21:02:31.332+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 112.0 in stage 1.0 (TID 377). 6243 bytes result sent to driver
[2025-07-19T21:02:31.333+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 141.0 in stage 1.0 (TID 386) (8b44f3d35cfa, executor driver, partition 141, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.333+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 112.0 in stage 1.0 (TID 377) in 109 ms on 8b44f3d35cfa (executor driver) (168/200)
[2025-07-19T21:02:31.333+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c8fa1ce
[2025-07-19T21:02:31.334+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 141.0 in stage 1.0 (TID 386)
[2025-07-19T21:02:31.334+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=134, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.334+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=134),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/134] for update
[2025-07-19T21:02:31.337+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/115/.1.delta.4a2c09b0-47b8-48d2-ac4c-1a04b8cb62d9.TID379.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/115/1.delta
[2025-07-19T21:02:31.337+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=115),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/115] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/115/1.delta
[2025-07-19T21:02:31.338+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 115 (task 379, attempt 0, stage 1.0)
[2025-07-19T21:02:31.338+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.341+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 115 (task 379, attempt 0, stage 1.0)
[2025-07-19T21:02:31.343+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/132/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/132/.1.delta.87ab659b-c7ec-41e6-adcd-2d18f28ad151.TID384.tmp
[2025-07-19T21:02:31.343+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 115.0 in stage 1.0 (TID 379). 6243 bytes result sent to driver
[2025-07-19T21:02:31.344+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 142.0 in stage 1.0 (TID 387) (8b44f3d35cfa, executor driver, partition 142, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.344+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 142.0 in stage 1.0 (TID 387)
[2025-07-19T21:02:31.345+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 115.0 in stage 1.0 (TID 379) in 105 ms on 8b44f3d35cfa (executor driver) (169/200)
[2025-07-19T21:02:31.345+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.345+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.349+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/116/.1.delta.1cb01485-f6d2-417d-82f2-25190ded257f.TID380.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/116/1.delta
[2025-07-19T21:02:31.350+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=116),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/116] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/116/1.delta
[2025-07-19T21:02:31.351+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 116 (task 380, attempt 0, stage 1.0)
[2025-07-19T21:02:31.351+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/124/.1.delta.82e4aeba-0eb2-4ea4-8b2e-4ebf39293146.TID381.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/124/1.delta
[2025-07-19T21:02:31.352+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=124),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/124] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/124/1.delta
[2025-07-19T21:02:31.354+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3106622b
[2025-07-19T21:02:31.354+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=142, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.354+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=142),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/142] for update
[2025-07-19T21:02:31.354+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 124 (task 381, attempt 0, stage 1.0)
[2025-07-19T21:02:31.358+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/126/.1.delta.99fcce8c-11e3-4fe8-8bff-dc3f66fc9626.TID383.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/126/1.delta
[2025-07-19T21:02:31.358+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=126),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/126] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/126/1.delta
[2025-07-19T21:02:31.359+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 126 (task 383, attempt 0, stage 1.0)
[2025-07-19T21:02:31.364+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/132/.1.delta.87ab659b-c7ec-41e6-adcd-2d18f28ad151.TID384.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/132/1.delta
[2025-07-19T21:02:31.366+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=132),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/132] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/132/1.delta
[2025-07-19T21:02:31.367+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 132 (task 384, attempt 0, stage 1.0)
[2025-07-19T21:02:31.367+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.368+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 28 ms
[2025-07-19T21:02:31.368+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 116 (task 380, attempt 0, stage 1.0)
[2025-07-19T21:02:31.368+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 116.0 in stage 1.0 (TID 380). 6243 bytes result sent to driver
[2025-07-19T21:02:31.368+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 143.0 in stage 1.0 (TID 388) (8b44f3d35cfa, executor driver, partition 143, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.368+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.373+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@713f22fe
[2025-07-19T21:02:31.375+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 116.0 in stage 1.0 (TID 380) in 117 ms on 8b44f3d35cfa (executor driver) (170/200)
[2025-07-19T21:02:31.376+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 143.0 in stage 1.0 (TID 388)
[2025-07-19T21:02:31.376+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 124 (task 381, attempt 0, stage 1.0)
[2025-07-19T21:02:31.377+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 132 (task 384, attempt 0, stage 1.0)
[2025-07-19T21:02:31.378+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 126 (task 383, attempt 0, stage 1.0)
[2025-07-19T21:02:31.378+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.379+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=141, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.380+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=141),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/141] for update
[2025-07-19T21:02:31.381+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 124.0 in stage 1.0 (TID 381). 6243 bytes result sent to driver
[2025-07-19T21:02:31.382+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.382+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 132.0 in stage 1.0 (TID 384). 6243 bytes result sent to driver
[2025-07-19T21:02:31.382+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 146.0 in stage 1.0 (TID 389) (8b44f3d35cfa, executor driver, partition 146, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.383+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:31.383+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 124.0 in stage 1.0 (TID 381) in 121 ms on 8b44f3d35cfa (executor driver) (171/200)
[2025-07-19T21:02:31.383+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 146.0 in stage 1.0 (TID 389)
[2025-07-19T21:02:31.383+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 126.0 in stage 1.0 (TID 383). 6243 bytes result sent to driver
[2025-07-19T21:02:31.384+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/134/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/134/.1.delta.f779f035-a6f8-4ffb-b61b-6e42d5b4a9ec.TID385.tmp
[2025-07-19T21:02:31.385+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.386+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.386+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 147.0 in stage 1.0 (TID 390) (8b44f3d35cfa, executor driver, partition 147, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.386+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 148.0 in stage 1.0 (TID 391) (8b44f3d35cfa, executor driver, partition 148, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.386+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 147.0 in stage 1.0 (TID 390)
[2025-07-19T21:02:31.386+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 132.0 in stage 1.0 (TID 384) in 88 ms on 8b44f3d35cfa (executor driver) (172/200)
[2025-07-19T21:02:31.386+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 126.0 in stage 1.0 (TID 383) in 97 ms on 8b44f3d35cfa (executor driver) (173/200)
[2025-07-19T21:02:31.386+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 148.0 in stage 1.0 (TID 391)
[2025-07-19T21:02:31.386+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.387+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.387+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.387+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.388+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/142/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/142/.1.delta.dc6d7b3e-3c3f-40f9-95cd-5e67385039de.TID387.tmp
[2025-07-19T21:02:31.388+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74893fa8
[2025-07-19T21:02:31.388+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/125/.1.delta.3af4cdf1-30b5-40d5-831b-b7e7e07f8966.TID382.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/125/1.delta
[2025-07-19T21:02:31.389+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=125),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/125] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/125/1.delta
[2025-07-19T21:02:31.389+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 125 (task 382, attempt 0, stage 1.0)
[2025-07-19T21:02:31.389+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=143, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.389+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=143),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/143] for update
[2025-07-19T21:02:31.397+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/141/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/141/.1.delta.e4e78663-d084-41a3-845b-a47b26c5ec01.TID386.tmp
[2025-07-19T21:02:31.397+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 125 (task 382, attempt 0, stage 1.0)
[2025-07-19T21:02:31.404+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.405+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 125.0 in stage 1.0 (TID 382). 6286 bytes result sent to driver
[2025-07-19T21:02:31.405+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 151.0 in stage 1.0 (TID 392) (8b44f3d35cfa, executor driver, partition 151, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.406+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@17b3b799
[2025-07-19T21:02:31.406+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 151.0 in stage 1.0 (TID 392)
[2025-07-19T21:02:31.406+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=148, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.406+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=148),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/148] for update
[2025-07-19T21:02:31.407+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.407+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 125.0 in stage 1.0 (TID 382) in 141 ms on 8b44f3d35cfa (executor driver) (174/200)
[2025-07-19T21:02:31.409+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.410+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.411+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a5193b3
[2025-07-19T21:02:31.411+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=147, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.411+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=147),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/147] for update
[2025-07-19T21:02:31.414+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.418+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/148/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/148/.1.delta.7d8713d2-16e6-4026-9ef9-373847db49ca.TID391.tmp
[2025-07-19T21:02:31.422+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/143/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/143/.1.delta.5c313d47-2e79-43c3-a69a-4fb539f54618.TID388.tmp
[2025-07-19T21:02:31.423+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1fd1084
[2025-07-19T21:02:31.424+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=146, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.424+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=146),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/146] for update
[2025-07-19T21:02:31.426+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/147/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/147/.1.delta.09c5f293-9830-4fe6-a7fb-9ba62b2e916e.TID390.tmp
[2025-07-19T21:02:31.426+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.433+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4fa52693
[2025-07-19T21:02:31.434+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=151, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.434+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=151),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/151] for update
[2025-07-19T21:02:31.435+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.440+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/146/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/146/.1.delta.42534de5-5bf4-4cd1-b575-efd11a723851.TID389.tmp
[2025-07-19T21:02:31.455+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/151/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/151/.1.delta.d3e19b1e-0d42-4fac-a837-27482a992867.TID392.tmp
[2025-07-19T21:02:31.457+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/134/.1.delta.f779f035-a6f8-4ffb-b61b-6e42d5b4a9ec.TID385.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/134/1.delta
[2025-07-19T21:02:31.457+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=134),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/134] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/134/1.delta
[2025-07-19T21:02:31.457+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 134 (task 385, attempt 0, stage 1.0)
[2025-07-19T21:02:31.467+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/141/.1.delta.e4e78663-d084-41a3-845b-a47b26c5ec01.TID386.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/141/1.delta
[2025-07-19T21:02:31.467+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 134 (task 385, attempt 0, stage 1.0)
[2025-07-19T21:02:31.467+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 134.0 in stage 1.0 (TID 385). 6243 bytes result sent to driver
[2025-07-19T21:02:31.468+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 152.0 in stage 1.0 (TID 393) (8b44f3d35cfa, executor driver, partition 152, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.468+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 134.0 in stage 1.0 (TID 385) in 159 ms on 8b44f3d35cfa (executor driver) (175/200)
[2025-07-19T21:02:31.469+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 152.0 in stage 1.0 (TID 393)
[2025-07-19T21:02:31.470+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=141),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/141] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/141/1.delta
[2025-07-19T21:02:31.471+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 141 (task 386, attempt 0, stage 1.0)
[2025-07-19T21:02:31.472+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/143/.1.delta.5c313d47-2e79-43c3-a69a-4fb539f54618.TID388.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/143/1.delta
[2025-07-19T21:02:31.472+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=143),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/143] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/143/1.delta
[2025-07-19T21:02:31.472+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/142/.1.delta.dc6d7b3e-3c3f-40f9-95cd-5e67385039de.TID387.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/142/1.delta
[2025-07-19T21:02:31.473+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=142),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/142] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/142/1.delta
[2025-07-19T21:02:31.473+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 143 (task 388, attempt 0, stage 1.0)
[2025-07-19T21:02:31.473+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 142 (task 387, attempt 0, stage 1.0)
[2025-07-19T21:02:31.476+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 143 (task 388, attempt 0, stage 1.0)
[2025-07-19T21:02:31.476+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 141 (task 386, attempt 0, stage 1.0)
[2025-07-19T21:02:31.476+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 143.0 in stage 1.0 (TID 388). 6243 bytes result sent to driver
[2025-07-19T21:02:31.476+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 141.0 in stage 1.0 (TID 386). 6243 bytes result sent to driver
[2025-07-19T21:02:31.476+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.476+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:31.477+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 142 (task 387, attempt 0, stage 1.0)
[2025-07-19T21:02:31.477+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 142.0 in stage 1.0 (TID 387). 6243 bytes result sent to driver
[2025-07-19T21:02:31.477+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 156.0 in stage 1.0 (TID 394) (8b44f3d35cfa, executor driver, partition 156, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.477+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 156.0 in stage 1.0 (TID 394)
[2025-07-19T21:02:31.478+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 157.0 in stage 1.0 (TID 395) (8b44f3d35cfa, executor driver, partition 157, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.478+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 164.0 in stage 1.0 (TID 396) (8b44f3d35cfa, executor driver, partition 164, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.478+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 157.0 in stage 1.0 (TID 395)
[2025-07-19T21:02:31.479+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 143.0 in stage 1.0 (TID 388) in 111 ms on 8b44f3d35cfa (executor driver) (176/200)
[2025-07-19T21:02:31.479+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 142.0 in stage 1.0 (TID 387) in 136 ms on 8b44f3d35cfa (executor driver) (177/200)
[2025-07-19T21:02:31.479+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 141.0 in stage 1.0 (TID 386) in 144 ms on 8b44f3d35cfa (executor driver) (178/200)
[2025-07-19T21:02:31.479+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 164.0 in stage 1.0 (TID 396)
[2025-07-19T21:02:31.479+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.479+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.481+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.482+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.482+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@619e39
[2025-07-19T21:02:31.483+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=152, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.484+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=152),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/152] for update
[2025-07-19T21:02:31.484+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.485+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.485+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.485+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/148/.1.delta.7d8713d2-16e6-4026-9ef9-373847db49ca.TID391.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/148/1.delta
[2025-07-19T21:02:31.486+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=148),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/148] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/148/1.delta
[2025-07-19T21:02:31.487+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 148 (task 391, attempt 0, stage 1.0)
[2025-07-19T21:02:31.488+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39c5741
[2025-07-19T21:02:31.488+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/147/.1.delta.09c5f293-9830-4fe6-a7fb-9ba62b2e916e.TID390.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/147/1.delta
[2025-07-19T21:02:31.488+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=147),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/147] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/147/1.delta
[2025-07-19T21:02:31.488+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 147 (task 390, attempt 0, stage 1.0)
[2025-07-19T21:02:31.489+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=164, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.489+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=164),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/164] for update
[2025-07-19T21:02:31.490+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.495+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/146/.1.delta.42534de5-5bf4-4cd1-b575-efd11a723851.TID389.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/146/1.delta
[2025-07-19T21:02:31.495+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=146),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/146] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/146/1.delta
[2025-07-19T21:02:31.496+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 146 (task 389, attempt 0, stage 1.0)
[2025-07-19T21:02:31.497+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 148 (task 391, attempt 0, stage 1.0)
[2025-07-19T21:02:31.498+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 148.0 in stage 1.0 (TID 391). 6243 bytes result sent to driver
[2025-07-19T21:02:31.499+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 147 (task 390, attempt 0, stage 1.0)
[2025-07-19T21:02:31.500+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 147.0 in stage 1.0 (TID 390). 6243 bytes result sent to driver
[2025-07-19T21:02:31.502+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 166.0 in stage 1.0 (TID 397) (8b44f3d35cfa, executor driver, partition 166, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.502+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 167.0 in stage 1.0 (TID 398) (8b44f3d35cfa, executor driver, partition 167, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.503+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 167.0 in stage 1.0 (TID 398)
[2025-07-19T21:02:31.504+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 166.0 in stage 1.0 (TID 397)
[2025-07-19T21:02:31.505+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 148.0 in stage 1.0 (TID 391) in 116 ms on 8b44f3d35cfa (executor driver) (179/200)
[2025-07-19T21:02:31.505+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 147.0 in stage 1.0 (TID 390) in 118 ms on 8b44f3d35cfa (executor driver) (180/200)
[2025-07-19T21:02:31.505+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7258438e
[2025-07-19T21:02:31.506+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=156, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.506+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 146 (task 389, attempt 0, stage 1.0)
[2025-07-19T21:02:31.506+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=156),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/156] for update
[2025-07-19T21:02:31.507+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/151/.1.delta.d3e19b1e-0d42-4fac-a837-27482a992867.TID392.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/151/1.delta
[2025-07-19T21:02:31.507+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=151),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/151] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/151/1.delta
[2025-07-19T21:02:31.507+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.507+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.507+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:31.507+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 151 (task 392, attempt 0, stage 1.0)
[2025-07-19T21:02:31.507+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.508+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 146.0 in stage 1.0 (TID 389). 6243 bytes result sent to driver
[2025-07-19T21:02:31.508+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 168.0 in stage 1.0 (TID 399) (8b44f3d35cfa, executor driver, partition 168, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.508+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 168.0 in stage 1.0 (TID 399)
[2025-07-19T21:02:31.508+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 146.0 in stage 1.0 (TID 389) in 132 ms on 8b44f3d35cfa (executor driver) (181/200)
[2025-07-19T21:02:31.508+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2025-07-19T21:02:31.510+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/164/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/164/.1.delta.df7b6c14-8965-4f42-9bd5-3aa05a46ad3d.TID396.tmp
[2025-07-19T21:02:31.511+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 151 (task 392, attempt 0, stage 1.0)
[2025-07-19T21:02:31.512+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 151.0 in stage 1.0 (TID 392). 6200 bytes result sent to driver
[2025-07-19T21:02:31.512+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.513+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.513+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 171.0 in stage 1.0 (TID 400) (8b44f3d35cfa, executor driver, partition 171, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.515+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 151.0 in stage 1.0 (TID 392) in 108 ms on 8b44f3d35cfa (executor driver) (182/200)
[2025-07-19T21:02:31.516+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/152/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/152/.1.delta.4439811a-c5a5-4d90-83b7-f57ee3705093.TID393.tmp
[2025-07-19T21:02:31.516+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@241cb109
[2025-07-19T21:02:31.516+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=157, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.516+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=157),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/157] for update
[2025-07-19T21:02:31.516+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.517+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/156/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/156/.1.delta.b3a74482-4611-4942-8487-af7d276b0899.TID394.tmp
[2025-07-19T21:02:31.518+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 171.0 in stage 1.0 (TID 400)
[2025-07-19T21:02:31.518+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@36fdedaa
[2025-07-19T21:02:31.519+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=168, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.519+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=168),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/168] for update
[2025-07-19T21:02:31.520+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.522+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.522+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.522+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/157/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/157/.1.delta.05ab6814-b54e-433f-8981-1660c5df666c.TID395.tmp
[2025-07-19T21:02:31.524+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@45b5d129
[2025-07-19T21:02:31.524+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=167, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.524+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=167),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/167] for update
[2025-07-19T21:02:31.526+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.530+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f5dbe38
[2025-07-19T21:02:31.531+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=166, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.531+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/168/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/168/.1.delta.fefe2986-64d7-4184-b507-aed6f71ebf5d.TID399.tmp
[2025-07-19T21:02:31.531+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=166),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/166] for update
[2025-07-19T21:02:31.532+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.533+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/167/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/167/.1.delta.b257de3a-1dd2-443e-b494-d566bd5a6cd4.TID398.tmp
[2025-07-19T21:02:31.535+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a60eb62
[2025-07-19T21:02:31.536+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=171, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.536+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=171),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/171] for update
[2025-07-19T21:02:31.537+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.542+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/152/.1.delta.4439811a-c5a5-4d90-83b7-f57ee3705093.TID393.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/152/1.delta
[2025-07-19T21:02:31.542+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=152),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/152] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/152/1.delta
[2025-07-19T21:02:31.542+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 152 (task 393, attempt 0, stage 1.0)
[2025-07-19T21:02:31.543+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/166/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/166/.1.delta.91c01ed1-4b77-4596-a507-88e6108441a2.TID397.tmp
[2025-07-19T21:02:31.546+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/164/.1.delta.df7b6c14-8965-4f42-9bd5-3aa05a46ad3d.TID396.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/164/1.delta
[2025-07-19T21:02:31.546+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=164),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/164] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/164/1.delta
[2025-07-19T21:02:31.547+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 164 (task 396, attempt 0, stage 1.0)
[2025-07-19T21:02:31.548+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 152 (task 393, attempt 0, stage 1.0)
[2025-07-19T21:02:31.549+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 152.0 in stage 1.0 (TID 393). 6200 bytes result sent to driver
[2025-07-19T21:02:31.550+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/171/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/171/.1.delta.3148003c-e10e-4c3c-8999-ea95f69ef742.TID400.tmp
[2025-07-19T21:02:31.551+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/156/.1.delta.b3a74482-4611-4942-8487-af7d276b0899.TID394.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/156/1.delta
[2025-07-19T21:02:31.551+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=156),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/156] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/156/1.delta
[2025-07-19T21:02:31.551+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 173.0 in stage 1.0 (TID 401) (8b44f3d35cfa, executor driver, partition 173, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.553+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 173.0 in stage 1.0 (TID 401)
[2025-07-19T21:02:31.553+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 152.0 in stage 1.0 (TID 393) in 84 ms on 8b44f3d35cfa (executor driver) (183/200)
[2025-07-19T21:02:31.553+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 156 (task 394, attempt 0, stage 1.0)
[2025-07-19T21:02:31.553+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 164 (task 396, attempt 0, stage 1.0)
[2025-07-19T21:02:31.553+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.554+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.554+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 164.0 in stage 1.0 (TID 396). 6200 bytes result sent to driver
[2025-07-19T21:02:31.555+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 176.0 in stage 1.0 (TID 402) (8b44f3d35cfa, executor driver, partition 176, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.555+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 176.0 in stage 1.0 (TID 402)
[2025-07-19T21:02:31.556+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 164.0 in stage 1.0 (TID 396) in 79 ms on 8b44f3d35cfa (executor driver) (184/200)
[2025-07-19T21:02:31.557+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40544e25
[2025-07-19T21:02:31.557+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=173, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.557+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=173),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/173] for update
[2025-07-19T21:02:31.559+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.561+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 156 (task 394, attempt 0, stage 1.0)
[2025-07-19T21:02:31.562+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 156.0 in stage 1.0 (TID 394). 6200 bytes result sent to driver
[2025-07-19T21:02:31.563+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 184.0 in stage 1.0 (TID 403) (8b44f3d35cfa, executor driver, partition 184, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.564+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.566+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.567+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 184.0 in stage 1.0 (TID 403)
[2025-07-19T21:02:31.568+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 156.0 in stage 1.0 (TID 394) in 87 ms on 8b44f3d35cfa (executor driver) (185/200)
[2025-07-19T21:02:31.568+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/157/.1.delta.05ab6814-b54e-433f-8981-1660c5df666c.TID395.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/157/1.delta
[2025-07-19T21:02:31.568+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=157),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/157] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/157/1.delta
[2025-07-19T21:02:31.570+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/168/.1.delta.fefe2986-64d7-4184-b507-aed6f71ebf5d.TID399.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/168/1.delta
[2025-07-19T21:02:31.571+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=168),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/168] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/168/1.delta
[2025-07-19T21:02:31.574+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.574+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.575+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 157 (task 395, attempt 0, stage 1.0)
[2025-07-19T21:02:31.575+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 168 (task 399, attempt 0, stage 1.0)
[2025-07-19T21:02:31.575+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6280f61d
[2025-07-19T21:02:31.575+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=176, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.575+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=176),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/176] for update
[2025-07-19T21:02:31.575+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/167/.1.delta.b257de3a-1dd2-443e-b494-d566bd5a6cd4.TID398.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/167/1.delta
[2025-07-19T21:02:31.576+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=167),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/167] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/167/1.delta
[2025-07-19T21:02:31.576+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 167 (task 398, attempt 0, stage 1.0)
[2025-07-19T21:02:31.576+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 157 (task 395, attempt 0, stage 1.0)
[2025-07-19T21:02:31.577+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 168 (task 399, attempt 0, stage 1.0)
[2025-07-19T21:02:31.577+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/173/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/173/.1.delta.77cfc08e-cb66-4bcb-b735-72080d27ce23.TID401.tmp
[2025-07-19T21:02:31.577+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 168.0 in stage 1.0 (TID 399). 6200 bytes result sent to driver
[2025-07-19T21:02:31.578+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.578+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 189.0 in stage 1.0 (TID 404) (8b44f3d35cfa, executor driver, partition 189, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.578+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 157.0 in stage 1.0 (TID 395). 6200 bytes result sent to driver
[2025-07-19T21:02:31.579+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 168.0 in stage 1.0 (TID 399) in 66 ms on 8b44f3d35cfa (executor driver) (186/200)
[2025-07-19T21:02:31.580+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 167 (task 398, attempt 0, stage 1.0)
[2025-07-19T21:02:31.580+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 189.0 in stage 1.0 (TID 404)
[2025-07-19T21:02:31.580+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 167.0 in stage 1.0 (TID 398). 6200 bytes result sent to driver
[2025-07-19T21:02:31.580+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 191.0 in stage 1.0 (TID 405) (8b44f3d35cfa, executor driver, partition 191, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.581+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 191.0 in stage 1.0 (TID 405)
[2025-07-19T21:02:31.581+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.581+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.582+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 193.0 in stage 1.0 (TID 406) (8b44f3d35cfa, executor driver, partition 193, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.582+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 193.0 in stage 1.0 (TID 406)
[2025-07-19T21:02:31.582+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 167.0 in stage 1.0 (TID 398) in 79 ms on 8b44f3d35cfa (executor driver) (187/200)
[2025-07-19T21:02:31.583+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 157.0 in stage 1.0 (TID 395) in 98 ms on 8b44f3d35cfa (executor driver) (188/200)
[2025-07-19T21:02:31.584+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@405eeffb
[2025-07-19T21:02:31.585+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.585+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.586+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=184, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.586+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=184),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/184] for update
[2025-07-19T21:02:31.588+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.588+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.589+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.590+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/176/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/176/.1.delta.6fae3365-d6e3-4e06-9dd7-8dda8cf127b0.TID402.tmp
[2025-07-19T21:02:31.590+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/166/.1.delta.91c01ed1-4b77-4596-a507-88e6108441a2.TID397.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/166/1.delta
[2025-07-19T21:02:31.590+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=166),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/166] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/166/1.delta
[2025-07-19T21:02:31.590+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f372896
[2025-07-19T21:02:31.590+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 166 (task 397, attempt 0, stage 1.0)
[2025-07-19T21:02:31.590+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=193, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.590+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=193),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/193] for update
[2025-07-19T21:02:31.590+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.591+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/184/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/184/.1.delta.97f11332-2120-4555-862f-6a8a0775e42c.TID403.tmp
[2025-07-19T21:02:31.592+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 166 (task 397, attempt 0, stage 1.0)
[2025-07-19T21:02:31.594+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@582f5685
[2025-07-19T21:02:31.595+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 166.0 in stage 1.0 (TID 397). 6200 bytes result sent to driver
[2025-07-19T21:02:31.596+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=189, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.596+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=189),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/189] for update
[2025-07-19T21:02:31.596+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 194.0 in stage 1.0 (TID 407) (8b44f3d35cfa, executor driver, partition 194, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.597+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 194.0 in stage 1.0 (TID 407)
[2025-07-19T21:02:31.597+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 166.0 in stage 1.0 (TID 397) in 96 ms on 8b44f3d35cfa (executor driver) (189/200)
[2025-07-19T21:02:31.597+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.598+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52199061
[2025-07-19T21:02:31.598+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=191, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.599+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=191),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/191] for update
[2025-07-19T21:02:31.600+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.600+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.600+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.600+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/193/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/193/.1.delta.5bfe0be0-6330-4e68-8ad1-b593f6c086cd.TID406.tmp
[2025-07-19T21:02:31.603+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/173/.1.delta.77cfc08e-cb66-4bcb-b735-72080d27ce23.TID401.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/173/1.delta
[2025-07-19T21:02:31.604+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=173),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/173] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/173/1.delta
[2025-07-19T21:02:31.605+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/171/.1.delta.3148003c-e10e-4c3c-8999-ea95f69ef742.TID400.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/171/1.delta
[2025-07-19T21:02:31.607+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=171),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/171] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/171/1.delta
[2025-07-19T21:02:31.607+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 173 (task 401, attempt 0, stage 1.0)
[2025-07-19T21:02:31.607+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 171 (task 400, attempt 0, stage 1.0)
[2025-07-19T21:02:31.607+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/189/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/189/.1.delta.6a74836e-6b44-4ec9-9b1a-c3722de017c2.TID404.tmp
[2025-07-19T21:02:31.609+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6f30ccc3
[2025-07-19T21:02:31.609+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=194, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.609+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=194),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/194] for update
[2025-07-19T21:02:31.610+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/191/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/191/.1.delta.61dd3968-5fa4-48a7-8bd1-2c95e3ee427d.TID405.tmp
[2025-07-19T21:02:31.610+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 171 (task 400, attempt 0, stage 1.0)
[2025-07-19T21:02:31.610+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 171.0 in stage 1.0 (TID 400). 6200 bytes result sent to driver
[2025-07-19T21:02:31.611+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.611+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 196.0 in stage 1.0 (TID 408) (8b44f3d35cfa, executor driver, partition 196, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.611+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 173 (task 401, attempt 0, stage 1.0)
[2025-07-19T21:02:31.611+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 173.0 in stage 1.0 (TID 401). 6200 bytes result sent to driver
[2025-07-19T21:02:31.612+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 197.0 in stage 1.0 (TID 409) (8b44f3d35cfa, executor driver, partition 197, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.613+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 196.0 in stage 1.0 (TID 408)
[2025-07-19T21:02:31.613+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 197.0 in stage 1.0 (TID 409)
[2025-07-19T21:02:31.614+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 173.0 in stage 1.0 (TID 401) in 60 ms on 8b44f3d35cfa (executor driver) (190/200)
[2025-07-19T21:02:31.614+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 171.0 in stage 1.0 (TID 400) in 99 ms on 8b44f3d35cfa (executor driver) (191/200)
[2025-07-19T21:02:31.614+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.615+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.615+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.615+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:31.618+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@337d31d7
[2025-07-19T21:02:31.619+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/194/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/194/.1.delta.5f216aba-51df-48b5-a974-bd7dc31a9a0a.TID407.tmp
[2025-07-19T21:02:31.620+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/176/.1.delta.6fae3365-d6e3-4e06-9dd7-8dda8cf127b0.TID402.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/176/1.delta
[2025-07-19T21:02:31.620+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=176),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/176] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/176/1.delta
[2025-07-19T21:02:31.620+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=197, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.621+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=197),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/197] for update
[2025-07-19T21:02:31.621+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 176 (task 402, attempt 0, stage 1.0)
[2025-07-19T21:02:31.621+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/184/.1.delta.97f11332-2120-4555-862f-6a8a0775e42c.TID403.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/184/1.delta
[2025-07-19T21:02:31.623+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=184),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/184] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/184/1.delta
[2025-07-19T21:02:31.624+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.625+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 184 (task 403, attempt 0, stage 1.0)
[2025-07-19T21:02:31.626+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 184 (task 403, attempt 0, stage 1.0)
[2025-07-19T21:02:31.626+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 176 (task 402, attempt 0, stage 1.0)
[2025-07-19T21:02:31.627+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 176.0 in stage 1.0 (TID 402). 6200 bytes result sent to driver
[2025-07-19T21:02:31.628+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@b3bfdff
[2025-07-19T21:02:31.629+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 184.0 in stage 1.0 (TID 403). 6200 bytes result sent to driver
[2025-07-19T21:02:31.629+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=196, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.630+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 198.0 in stage 1.0 (TID 410) (8b44f3d35cfa, executor driver, partition 198, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.630+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=196),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/196] for update
[2025-07-19T21:02:31.630+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 176.0 in stage 1.0 (TID 402) in 70 ms on 8b44f3d35cfa (executor driver) (192/200)
[2025-07-19T21:02:31.630+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 198.0 in stage 1.0 (TID 410)
[2025-07-19T21:02:31.630+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.630+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 10.0 in stage 3.0 (TID 411) (8b44f3d35cfa, executor driver, partition 10, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.631+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 10.0 in stage 3.0 (TID 411)
[2025-07-19T21:02:31.631+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 184.0 in stage 1.0 (TID 403) in 68 ms on 8b44f3d35cfa (executor driver) (193/200)
[2025-07-19T21:02:31.632+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.632+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.632+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.632+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.632+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/197/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/197/.1.delta.d8911e7e-4687-465e-ac42-0bf17be8611a.TID409.tmp
[2025-07-19T21:02:31.634+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/196/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/196/.1.delta.551fae6b-7e6e-4921-88bb-297b3b0d91ae.TID408.tmp
[2025-07-19T21:02:31.636+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/193/.1.delta.5bfe0be0-6330-4e68-8ad1-b593f6c086cd.TID406.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/193/1.delta
[2025-07-19T21:02:31.637+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=193),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/193] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/193/1.delta
[2025-07-19T21:02:31.637+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 193 (task 406, attempt 0, stage 1.0)
[2025-07-19T21:02:31.641+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/191/.1.delta.61dd3968-5fa4-48a7-8bd1-2c95e3ee427d.TID405.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/191/1.delta
[2025-07-19T21:02:31.642+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=191),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/191] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/191/1.delta
[2025-07-19T21:02:31.642+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 191 (task 405, attempt 0, stage 1.0)
[2025-07-19T21:02:31.642+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 193 (task 406, attempt 0, stage 1.0)
[2025-07-19T21:02:31.642+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 193.0 in stage 1.0 (TID 406). 6200 bytes result sent to driver
[2025-07-19T21:02:31.645+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 11.0 in stage 3.0 (TID 412) (8b44f3d35cfa, executor driver, partition 11, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.645+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/189/.1.delta.6a74836e-6b44-4ec9-9b1a-c3722de017c2.TID404.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/189/1.delta
[2025-07-19T21:02:31.646+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=189),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/189] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/189/1.delta
[2025-07-19T21:02:31.647+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4432288b
[2025-07-19T21:02:31.647+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 11.0 in stage 3.0 (TID 412)
[2025-07-19T21:02:31.648+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 189 (task 404, attempt 0, stage 1.0)
[2025-07-19T21:02:31.649+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=198, storeName=default ],40450798-f492-4fd3-9974-3406c234d637) is active
[2025-07-19T21:02:31.651+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=198),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/198] for update
[2025-07-19T21:02:31.651+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 191 (task 405, attempt 0, stage 1.0)
[2025-07-19T21:02:31.652+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 191.0 in stage 1.0 (TID 405). 6200 bytes result sent to driver
[2025-07-19T21:02:31.652+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.652+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.652+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 193.0 in stage 1.0 (TID 406) in 77 ms on 8b44f3d35cfa (executor driver) (194/200)
[2025-07-19T21:02:31.653+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.654+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 191.0 in stage 1.0 (TID 405) in 78 ms on 8b44f3d35cfa (executor driver) (195/200)
[2025-07-19T21:02:31.655+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 12.0 in stage 3.0 (TID 413) (8b44f3d35cfa, executor driver, partition 12, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.655+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 12.0 in stage 3.0 (TID 413)
[2025-07-19T21:02:31.655+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 189 (task 404, attempt 0, stage 1.0)
[2025-07-19T21:02:31.656+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 189.0 in stage 1.0 (TID 404). 6200 bytes result sent to driver
[2025-07-19T21:02:31.659+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/194/.1.delta.5f216aba-51df-48b5-a974-bd7dc31a9a0a.TID407.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/194/1.delta
[2025-07-19T21:02:31.660+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=194),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/194] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/194/1.delta
[2025-07-19T21:02:31.660+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.660+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:31.661+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 194 (task 407, attempt 0, stage 1.0)
[2025-07-19T21:02:31.662+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 13.0 in stage 3.0 (TID 414) (8b44f3d35cfa, executor driver, partition 13, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.663+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47e92a21
[2025-07-19T21:02:31.664+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 13.0 in stage 3.0 (TID 414)
[2025-07-19T21:02:31.664+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 189.0 in stage 1.0 (TID 404) in 92 ms on 8b44f3d35cfa (executor driver) (196/200)
[2025-07-19T21:02:31.665+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=10, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:31.665+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=10),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/10] for update
[2025-07-19T21:02:31.665+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.666+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.666+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.667+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/198/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/198/.1.delta.183ec629-2f75-42fe-a2d2-45d27800deab.TID410.tmp
[2025-07-19T21:02:31.668+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 194 (task 407, attempt 0, stage 1.0)
[2025-07-19T21:02:31.669+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 194.0 in stage 1.0 (TID 407). 6200 bytes result sent to driver
[2025-07-19T21:02:31.670+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/197/.1.delta.d8911e7e-4687-465e-ac42-0bf17be8611a.TID409.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/197/1.delta
[2025-07-19T21:02:31.670+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=197),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/197] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/197/1.delta
[2025-07-19T21:02:31.671+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a2401d9
[2025-07-19T21:02:31.671+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=12, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:31.672+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 197 (task 409, attempt 0, stage 1.0)
[2025-07-19T21:02:31.673+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 14.0 in stage 3.0 (TID 415) (8b44f3d35cfa, executor driver, partition 14, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.674+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=12),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/12] for update
[2025-07-19T21:02:31.674+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 14.0 in stage 3.0 (TID 415)
[2025-07-19T21:02:31.675+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 194.0 in stage 1.0 (TID 407) in 81 ms on 8b44f3d35cfa (executor driver) (197/200)
[2025-07-19T21:02:31.675+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.675+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 197 (task 409, attempt 0, stage 1.0)
[2025-07-19T21:02:31.676+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 197.0 in stage 1.0 (TID 409). 6200 bytes result sent to driver
[2025-07-19T21:02:31.676+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 15.0 in stage 3.0 (TID 416) (8b44f3d35cfa, executor driver, partition 15, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.676+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.676+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.677+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 15.0 in stage 3.0 (TID 416)
[2025-07-19T21:02:31.677+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 197.0 in stage 1.0 (TID 409) in 67 ms on 8b44f3d35cfa (executor driver) (198/200)
[2025-07-19T21:02:31.678+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.678+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.680+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/10/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/10/.1.delta.2a73a6a2-5692-432d-aff6-685a5185ae49.TID411.tmp
[2025-07-19T21:02:31.681+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@12c49554
[2025-07-19T21:02:31.682+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=11, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:31.682+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=11),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/11] for update
[2025-07-19T21:02:31.683+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/196/.1.delta.551fae6b-7e6e-4921-88bb-297b3b0d91ae.TID408.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/196/1.delta
[2025-07-19T21:02:31.683+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=196),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/196] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/196/1.delta
[2025-07-19T21:02:31.683+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 196 (task 408, attempt 0, stage 1.0)
[2025-07-19T21:02:31.684+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.688+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/12/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/12/.1.delta.314db553-dcc2-44a7-9e08-b7bf5dca703a.TID413.tmp
[2025-07-19T21:02:31.690+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c90f893
[2025-07-19T21:02:31.690+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 196 (task 408, attempt 0, stage 1.0)
[2025-07-19T21:02:31.690+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 196.0 in stage 1.0 (TID 408). 6157 bytes result sent to driver
[2025-07-19T21:02:31.691+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=15, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:31.691+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=15),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/15] for update
[2025-07-19T21:02:31.692+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 16.0 in stage 3.0 (TID 417) (8b44f3d35cfa, executor driver, partition 16, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.692+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 196.0 in stage 1.0 (TID 408) in 83 ms on 8b44f3d35cfa (executor driver) (199/200)
[2025-07-19T21:02:31.693+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 16.0 in stage 3.0 (TID 417)
[2025-07-19T21:02:31.693+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.694+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.695+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.695+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/11/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/11/.1.delta.b93c0779-9930-44e5-828c-14da6e685e8e.TID412.tmp
[2025-07-19T21:02:31.696+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c6b3f42
[2025-07-19T21:02:31.702+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=14, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:31.702+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=14),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/14] for update
[2025-07-19T21:02:31.703+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.704+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/15/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/15/.1.delta.071a2853-1c3e-4f12-8f56-159cdb21bc06.TID416.tmp
[2025-07-19T21:02:31.707+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@37df5e8d
[2025-07-19T21:02:31.709+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=13, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:31.709+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=13),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/13] for update
[2025-07-19T21:02:31.710+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.715+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@30d8709
[2025-07-19T21:02:31.716+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=16, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:31.716+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=16),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/16] for update
[2025-07-19T21:02:31.718+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.729+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/13/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/13/.1.delta.1d9d1ed5-e341-44ea-ac98-d4b1c72168f4.TID414.tmp
[2025-07-19T21:02:31.729+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/198/.1.delta.183ec629-2f75-42fe-a2d2-45d27800deab.TID410.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/198/1.delta
[2025-07-19T21:02:31.729+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=198),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/198] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/state/0/198/1.delta
[2025-07-19T21:02:31.730+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 198 (task 410, attempt 0, stage 1.0)
[2025-07-19T21:02:31.731+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/14/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/14/.1.delta.475e1410-bb4f-4ead-b1b2-7dc340feebb8.TID415.tmp
[2025-07-19T21:02:31.734+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/12/.1.delta.314db553-dcc2-44a7-9e08-b7bf5dca703a.TID413.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/12/1.delta
[2025-07-19T21:02:31.737+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=12),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/12] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/12/1.delta
[2025-07-19T21:02:31.737+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 12 (task 413, attempt 0, stage 3.0)
[2025-07-19T21:02:31.737+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/10/.1.delta.2a73a6a2-5692-432d-aff6-685a5185ae49.TID411.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/10/1.delta
[2025-07-19T21:02:31.738+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=10),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/10] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/10/1.delta
[2025-07-19T21:02:31.738+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 10 (task 411, attempt 0, stage 3.0)
[2025-07-19T21:02:31.738+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 198 (task 410, attempt 0, stage 1.0)
[2025-07-19T21:02:31.738+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/16/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/16/.1.delta.2c0751fc-1e8c-4cfc-af4f-8424a7600b2e.TID417.tmp
[2025-07-19T21:02:31.739+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 198.0 in stage 1.0 (TID 410). 6200 bytes result sent to driver
[2025-07-19T21:02:31.742+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 18.0 in stage 3.0 (TID 418) (8b44f3d35cfa, executor driver, partition 18, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.743+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 18.0 in stage 3.0 (TID 418)
[2025-07-19T21:02:31.743+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 198.0 in stage 1.0 (TID 410) in 116 ms on 8b44f3d35cfa (executor driver) (200/200)
[2025-07-19T21:02:31.744+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
[2025-07-19T21:02:31.744+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DAGScheduler: ResultStage 1 (start at <unknown>:0) finished in 10.101 s
[2025-07-19T21:02:31.744+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-19T21:02:31.745+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
[2025-07-19T21:02:31.745+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DAGScheduler: Job 1 finished: start at <unknown>:0, took 11.613602 s
[2025-07-19T21:02:31.746+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Reservations_raw, format=PARQUET)] is committing.
[2025-07-19T21:02:31.746+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO SparkWrite: Committing epoch 0 for query 73830d4c-ed35-482d-8a53-860d8476043f in append mode
[2025-07-19T21:02:31.747+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.748+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.748+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/11/.1.delta.b93c0779-9930-44e5-828c-14da6e685e8e.TID412.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/11/1.delta
[2025-07-19T21:02:31.748+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=11),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/11] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/11/1.delta
[2025-07-19T21:02:31.749+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 11 (task 412, attempt 0, stage 3.0)
[2025-07-19T21:02:31.754+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@412255e1
[2025-07-19T21:02:31.755+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=18, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:31.755+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=18),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/18] for update
[2025-07-19T21:02:31.756+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.771+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 12 (task 413, attempt 0, stage 3.0)
[2025-07-19T21:02:31.772+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 12.0 in stage 3.0 (TID 413). 9170 bytes result sent to driver
[2025-07-19T21:02:31.774+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 20.0 in stage 3.0 (TID 419) (8b44f3d35cfa, executor driver, partition 20, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.778+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 20.0 in stage 3.0 (TID 419)
[2025-07-19T21:02:31.779+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 12.0 in stage 3.0 (TID 413) in 123 ms on 8b44f3d35cfa (executor driver) (9/200)
[2025-07-19T21:02:31.779+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 10 (task 411, attempt 0, stage 3.0)
[2025-07-19T21:02:31.779+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 11 (task 412, attempt 0, stage 3.0)
[2025-07-19T21:02:31.780+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 11.0 in stage 3.0 (TID 412). 9149 bytes result sent to driver
[2025-07-19T21:02:31.780+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 10.0 in stage 3.0 (TID 411). 9157 bytes result sent to driver
[2025-07-19T21:02:31.780+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.781+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 22.0 in stage 3.0 (TID 420) (8b44f3d35cfa, executor driver, partition 22, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.781+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.782+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 22.0 in stage 3.0 (TID 420)
[2025-07-19T21:02:31.782+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.782+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.783+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 11.0 in stage 3.0 (TID 412) in 135 ms on 8b44f3d35cfa (executor driver) (10/200)
[2025-07-19T21:02:31.783+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 23.0 in stage 3.0 (TID 421) (8b44f3d35cfa, executor driver, partition 23, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.785+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO SparkWrite: Committing streaming append with 132 new data files to table my_catalog.bronze.Reservations_raw
[2025-07-19T21:02:31.786+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 10.0 in stage 3.0 (TID 411) in 155 ms on 8b44f3d35cfa (executor driver) (11/200)
[2025-07-19T21:02:31.786+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@769599ef
[2025-07-19T21:02:31.787+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 23.0 in stage 3.0 (TID 421)
[2025-07-19T21:02:31.788+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/18/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/18/.1.delta.9c3f2d82-3053-47b6-a13f-66dcd38c7342.TID418.tmp
[2025-07-19T21:02:31.788+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/15/.1.delta.071a2853-1c3e-4f12-8f56-159cdb21bc06.TID416.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/15/1.delta
[2025-07-19T21:02:31.789+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=15),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/15] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/15/1.delta
[2025-07-19T21:02:31.789+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 15 (task 416, attempt 0, stage 3.0)
[2025-07-19T21:02:31.789+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=20, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:31.789+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=20),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/20] for update
[2025-07-19T21:02:31.789+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.790+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.790+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T21:02:31.792+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53c8e3a5
[2025-07-19T21:02:31.794+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=22, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:31.795+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=22),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/22] for update
[2025-07-19T21:02:31.795+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/13/.1.delta.1d9d1ed5-e341-44ea-ac98-d4b1c72168f4.TID414.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/13/1.delta
[2025-07-19T21:02:31.795+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=13),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/13] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/13/1.delta
[2025-07-19T21:02:31.796+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.797+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 13 (task 414, attempt 0, stage 3.0)
[2025-07-19T21:02:31.802+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/20/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/20/.1.delta.819a16f1-ac79-4c47-9e44-682a8c284f64.TID419.tmp
[2025-07-19T21:02:31.804+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@183f5886
[2025-07-19T21:02:31.805+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/14/.1.delta.475e1410-bb4f-4ead-b1b2-7dc340feebb8.TID415.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/14/1.delta
[2025-07-19T21:02:31.806+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=14),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/14] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/14/1.delta
[2025-07-19T21:02:31.807+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 15 (task 416, attempt 0, stage 3.0)
[2025-07-19T21:02:31.807+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 14 (task 415, attempt 0, stage 3.0)
[2025-07-19T21:02:31.807+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=23, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:31.809+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/22/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/22/.1.delta.2be34c9c-982a-4c34-9c59-560fb80ce253.TID420.tmp
[2025-07-19T21:02:31.810+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=23),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/23] for update
[2025-07-19T21:02:31.810+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/16/.1.delta.2c0751fc-1e8c-4cfc-af4f-8424a7600b2e.TID417.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/16/1.delta
[2025-07-19T21:02:31.810+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=16),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/16] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/16/1.delta
[2025-07-19T21:02:31.810+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 16 (task 417, attempt 0, stage 3.0)
[2025-07-19T21:02:31.813+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 15.0 in stage 3.0 (TID 416). 9200 bytes result sent to driver
[2025-07-19T21:02:31.813+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.817+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 26.0 in stage 3.0 (TID 422) (8b44f3d35cfa, executor driver, partition 26, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.822+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 26.0 in stage 3.0 (TID 422)
[2025-07-19T21:02:31.823+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 15.0 in stage 3.0 (TID 416) in 147 ms on 8b44f3d35cfa (executor driver) (12/200)
[2025-07-19T21:02:31.829+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/23/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/23/.1.delta.6aa4c3b8-edf2-40e8-836b-5229fced8ae1.TID421.tmp
[2025-07-19T21:02:31.830+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.830+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:31.838+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 13 (task 414, attempt 0, stage 3.0)
[2025-07-19T21:02:31.839+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 13.0 in stage 3.0 (TID 414). 9172 bytes result sent to driver
[2025-07-19T21:02:31.840+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 14 (task 415, attempt 0, stage 3.0)
[2025-07-19T21:02:31.843+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 14.0 in stage 3.0 (TID 415). 9150 bytes result sent to driver
[2025-07-19T21:02:31.845+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f69962
[2025-07-19T21:02:31.847+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 27.0 in stage 3.0 (TID 423) (8b44f3d35cfa, executor driver, partition 27, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.849+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 28.0 in stage 3.0 (TID 424) (8b44f3d35cfa, executor driver, partition 28, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.851+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 13.0 in stage 3.0 (TID 414) in 182 ms on 8b44f3d35cfa (executor driver) (13/200)
[2025-07-19T21:02:31.852+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 14.0 in stage 3.0 (TID 415) in 173 ms on 8b44f3d35cfa (executor driver) (14/200)
[2025-07-19T21:02:31.852+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 28.0 in stage 3.0 (TID 424)
[2025-07-19T21:02:31.853+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=26, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:31.853+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=26),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/26] for update
[2025-07-19T21:02:31.853+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 16 (task 417, attempt 0, stage 3.0)
[2025-07-19T21:02:31.854+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 16.0 in stage 3.0 (TID 417). 9184 bytes result sent to driver
[2025-07-19T21:02:31.855+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 30.0 in stage 3.0 (TID 425) (8b44f3d35cfa, executor driver, partition 30, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.856+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.856+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 16.0 in stage 3.0 (TID 417) in 157 ms on 8b44f3d35cfa (executor driver) (15/200)
[2025-07-19T21:02:31.857+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 30.0 in stage 3.0 (TID 425)
[2025-07-19T21:02:31.858+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 27.0 in stage 3.0 (TID 423)
[2025-07-19T21:02:31.859+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.859+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:31.861+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.862+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:31.862+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.862+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T21:02:31.862+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/18/.1.delta.9c3f2d82-3053-47b6-a13f-66dcd38c7342.TID418.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/18/1.delta
[2025-07-19T21:02:31.862+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=18),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/18] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/18/1.delta
[2025-07-19T21:02:31.862+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 18 (task 418, attempt 0, stage 3.0)
[2025-07-19T21:02:31.862+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/20/.1.delta.819a16f1-ac79-4c47-9e44-682a8c284f64.TID419.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/20/1.delta
[2025-07-19T21:02:31.862+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=20),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/20] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/20/1.delta
[2025-07-19T21:02:31.862+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 20 (task 419, attempt 0, stage 3.0)
[2025-07-19T21:02:31.862+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e4dc71c
[2025-07-19T21:02:31.863+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=27, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:31.863+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=27),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/27] for update
[2025-07-19T21:02:31.863+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.870+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/22/.1.delta.2be34c9c-982a-4c34-9c59-560fb80ce253.TID420.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/22/1.delta
[2025-07-19T21:02:31.871+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=22),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/22] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/22/1.delta
[2025-07-19T21:02:31.871+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/26/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/26/.1.delta.2a4966ae-0ef3-4e0a-8810-7359046e08f3.TID422.tmp
[2025-07-19T21:02:31.871+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 22 (task 420, attempt 0, stage 3.0)
[2025-07-19T21:02:31.884+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 8b44f3d35cfa:38433 in memory (size: 19.6 KiB, free: 434.2 MiB)
[2025-07-19T21:02:31.885+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 18 (task 418, attempt 0, stage 3.0)
[2025-07-19T21:02:31.886+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 18.0 in stage 3.0 (TID 418). 9156 bytes result sent to driver
[2025-07-19T21:02:31.887+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@115c427
[2025-07-19T21:02:31.888+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 31.0 in stage 3.0 (TID 426) (8b44f3d35cfa, executor driver, partition 31, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.888+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 31.0 in stage 3.0 (TID 426)
[2025-07-19T21:02:31.889+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 18.0 in stage 3.0 (TID 418) in 150 ms on 8b44f3d35cfa (executor driver) (16/200)
[2025-07-19T21:02:31.891+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/27/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/27/.1.delta.e46b2311-edb7-4c5b-936a-2ef10d783cb8.TID423.tmp
[2025-07-19T21:02:31.892+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=28, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:31.892+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=28),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/28] for update
[2025-07-19T21:02:31.893+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/23/.1.delta.6aa4c3b8-edf2-40e8-836b-5229fced8ae1.TID421.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/23/1.delta
[2025-07-19T21:02:31.893+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.896+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=23),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/23] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/23/1.delta
[2025-07-19T21:02:31.897+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 23 (task 421, attempt 0, stage 3.0)
[2025-07-19T21:02:31.897+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 20 (task 419, attempt 0, stage 3.0)
[2025-07-19T21:02:31.900+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 20.0 in stage 3.0 (TID 419). 9152 bytes result sent to driver
[2025-07-19T21:02:31.901+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.901+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 22 (task 420, attempt 0, stage 3.0)
[2025-07-19T21:02:31.901+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.903+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 22.0 in stage 3.0 (TID 420). 9149 bytes result sent to driver
[2025-07-19T21:02:31.904+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 33.0 in stage 3.0 (TID 427) (8b44f3d35cfa, executor driver, partition 33, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.905+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 35.0 in stage 3.0 (TID 428) (8b44f3d35cfa, executor driver, partition 35, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.906+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 35.0 in stage 3.0 (TID 428)
[2025-07-19T21:02:31.906+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 33.0 in stage 3.0 (TID 427)
[2025-07-19T21:02:31.907+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 22.0 in stage 3.0 (TID 420) in 129 ms on 8b44f3d35cfa (executor driver) (17/200)
[2025-07-19T21:02:31.907+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 20.0 in stage 3.0 (TID 419) in 135 ms on 8b44f3d35cfa (executor driver) (18/200)
[2025-07-19T21:02:31.907+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.908+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.909+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@575f8a43
[2025-07-19T21:02:31.909+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=30, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:31.909+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=30),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/30] for update
[2025-07-19T21:02:31.911+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.915+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.916+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T21:02:31.916+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 23 (task 421, attempt 0, stage 3.0)
[2025-07-19T21:02:31.916+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/28/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/28/.1.delta.6dffb40c-3986-499d-9d0f-cd13a7975149.TID424.tmp
[2025-07-19T21:02:31.917+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 23.0 in stage 3.0 (TID 421). 9171 bytes result sent to driver
[2025-07-19T21:02:31.919+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 37.0 in stage 3.0 (TID 429) (8b44f3d35cfa, executor driver, partition 37, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.920+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 23.0 in stage 3.0 (TID 421) in 140 ms on 8b44f3d35cfa (executor driver) (19/200)
[2025-07-19T21:02:31.920+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f007d52
[2025-07-19T21:02:31.921+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=31, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:31.922+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=31),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/31] for update
[2025-07-19T21:02:31.923+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.923+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 37.0 in stage 3.0 (TID 429)
[2025-07-19T21:02:31.927+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.931+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/30/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/30/.1.delta.ae672339-3da5-4651-a3ee-a96a6b6e6168.TID425.tmp
[2025-07-19T21:02:31.931+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56fed185
[2025-07-19T21:02:31.932+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/26/.1.delta.2a4966ae-0ef3-4e0a-8810-7359046e08f3.TID422.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/26/1.delta
[2025-07-19T21:02:31.932+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:31.932+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=26),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/26] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/26/1.delta
[2025-07-19T21:02:31.932+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=33, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:31.932+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 26 (task 422, attempt 0, stage 3.0)
[2025-07-19T21:02:31.932+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=33),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/33] for update
[2025-07-19T21:02:31.936+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.940+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/31/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/31/.1.delta.a5c2d57f-0734-4b9f-acf4-e1ab7807a11a.TID426.tmp
[2025-07-19T21:02:31.941+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@132ecd37
[2025-07-19T21:02:31.942+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=37, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:31.943+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=37),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/37] for update
[2025-07-19T21:02:31.943+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.946+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/27/.1.delta.e46b2311-edb7-4c5b-936a-2ef10d783cb8.TID423.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/27/1.delta
[2025-07-19T21:02:31.946+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=27),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/27] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/27/1.delta
[2025-07-19T21:02:31.946+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 27 (task 423, attempt 0, stage 3.0)
[2025-07-19T21:02:31.950+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@76c3748e
[2025-07-19T21:02:31.952+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/33/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/33/.1.delta.c703083a-9e6c-494e-8ec5-d10b935f0f6f.TID427.tmp
[2025-07-19T21:02:31.952+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=35, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:31.952+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=35),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/35] for update
[2025-07-19T21:02:31.953+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.956+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/37/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/37/.1.delta.91680929-ae5e-4f35-b3b4-1730341527fe.TID429.tmp
[2025-07-19T21:02:31.957+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 26 (task 422, attempt 0, stage 3.0)
[2025-07-19T21:02:31.957+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 26.0 in stage 3.0 (TID 422). 9117 bytes result sent to driver
[2025-07-19T21:02:31.957+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 26.0 in stage 3.0 (TID 422) in 141 ms on 8b44f3d35cfa (executor driver) (20/200)
[2025-07-19T21:02:31.959+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 38.0 in stage 3.0 (TID 430) (8b44f3d35cfa, executor driver, partition 38, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.960+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 38.0 in stage 3.0 (TID 430)
[2025-07-19T21:02:31.964+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.965+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.966+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 27 (task 423, attempt 0, stage 3.0)
[2025-07-19T21:02:31.966+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 27.0 in stage 3.0 (TID 423). 9113 bytes result sent to driver
[2025-07-19T21:02:31.967+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 39.0 in stage 3.0 (TID 431) (8b44f3d35cfa, executor driver, partition 39, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.967+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/28/.1.delta.6dffb40c-3986-499d-9d0f-cd13a7975149.TID424.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/28/1.delta
[2025-07-19T21:02:31.968+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=28),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/28] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/28/1.delta
[2025-07-19T21:02:31.968+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 39.0 in stage 3.0 (TID 431)
[2025-07-19T21:02:31.970+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 28 (task 424, attempt 0, stage 3.0)
[2025-07-19T21:02:31.971+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 27.0 in stage 3.0 (TID 423) in 127 ms on 8b44f3d35cfa (executor driver) (21/200)
[2025-07-19T21:02:31.971+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.972+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.973+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/35/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/35/.1.delta.2d08aa9b-fe9a-4b32-b33b-afc495f413e5.TID428.tmp
[2025-07-19T21:02:31.974+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f35d2dd
[2025-07-19T21:02:31.975+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=38, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:31.976+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=38),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/38] for update
[2025-07-19T21:02:31.976+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.978+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HadoopTableOperations: Committed a new metadata file s3a://warehouse/bronze/Reservations_raw/metadata/v65.metadata.json
[2025-07-19T21:02:31.980+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f3dc099
[2025-07-19T21:02:31.982+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=39, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:31.982+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=39),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/39] for update
[2025-07-19T21:02:31.982+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Committed partition 28 (task 424, attempt 0, stage 3.0)
[2025-07-19T21:02:31.983+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:31.983+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/30/.1.delta.ae672339-3da5-4651-a3ee-a96a6b6e6168.TID425.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/30/1.delta
[2025-07-19T21:02:31.983+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=30),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/30] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/30/1.delta
[2025-07-19T21:02:31.984+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Finished task 28.0 in stage 3.0 (TID 424). 9128 bytes result sent to driver
[2025-07-19T21:02:31.985+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Starting task 40.0 in stage 3.0 (TID 432) (8b44f3d35cfa, executor driver, partition 40, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:31.985+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO Executor: Running task 40.0 in stage 3.0 (TID 432)
[2025-07-19T21:02:31.985+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO TaskSetManager: Finished task 28.0 in stage 3.0 (TID 424) in 144 ms on 8b44f3d35cfa (executor driver) (22/200)
[2025-07-19T21:02:31.986+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 30 (task 425, attempt 0, stage 3.0)
[2025-07-19T21:02:31.989+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/38/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/38/.1.delta.8c46056a-58af-4881-8760-e24056442758.TID430.tmp
[2025-07-19T21:02:31.989+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:31.990+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:31.995+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6eaf1324
[2025-07-19T21:02:31.995+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=40, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:31.995+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/39/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/39/.1.delta.a78c91b3-aa96-4552-bab8-8b873c7697d1.TID431.tmp
[2025-07-19T21:02:31.996+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=40),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/40] for update
[2025-07-19T21:02:31.997+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/31/.1.delta.a5c2d57f-0734-4b9f-acf4-e1ab7807a11a.TID426.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/31/1.delta
[2025-07-19T21:02:31.997+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=31),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/31] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/31/1.delta
[2025-07-19T21:02:31.997+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO DataWritingSparkTask: Commit authorized for partition 31 (task 426, attempt 0, stage 3.0)
[2025-07-19T21:02:31.998+0000] {subprocess.py:93} INFO - 25/07/19 21:02:31 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.006+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/33/.1.delta.c703083a-9e6c-494e-8ec5-d10b935f0f6f.TID427.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/33/1.delta
[2025-07-19T21:02:32.007+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=33),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/33] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/33/1.delta
[2025-07-19T21:02:32.007+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 33 (task 427, attempt 0, stage 3.0)
[2025-07-19T21:02:32.007+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/40/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/40/.1.delta.55fe2729-3fe7-4c06-aecb-277cf908d340.TID432.tmp
[2025-07-19T21:02:32.011+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/37/.1.delta.91680929-ae5e-4f35-b3b4-1730341527fe.TID429.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/37/1.delta
[2025-07-19T21:02:32.011+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=37),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/37] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/37/1.delta
[2025-07-19T21:02:32.012+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 37 (task 429, attempt 0, stage 3.0)
[2025-07-19T21:02:32.013+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 30 (task 425, attempt 0, stage 3.0)
[2025-07-19T21:02:32.013+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 30.0 in stage 3.0 (TID 425). 9120 bytes result sent to driver
[2025-07-19T21:02:32.014+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 41.0 in stage 3.0 (TID 433) (8b44f3d35cfa, executor driver, partition 41, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.015+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 41.0 in stage 3.0 (TID 433)
[2025-07-19T21:02:32.017+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.018+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.018+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 30.0 in stage 3.0 (TID 425) in 174 ms on 8b44f3d35cfa (executor driver) (23/200)
[2025-07-19T21:02:32.022+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO SnapshotProducer: Committed snapshot 2013260881954734421 (FastAppend)
[2025-07-19T21:02:32.023+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 31 (task 426, attempt 0, stage 3.0)
[2025-07-19T21:02:32.024+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 31.0 in stage 3.0 (TID 426). 9125 bytes result sent to driver
[2025-07-19T21:02:32.024+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/35/.1.delta.2d08aa9b-fe9a-4b32-b33b-afc495f413e5.TID428.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/35/1.delta
[2025-07-19T21:02:32.025+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=35),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/35] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/35/1.delta
[2025-07-19T21:02:32.025+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 42.0 in stage 3.0 (TID 434) (8b44f3d35cfa, executor driver, partition 42, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.025+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 31.0 in stage 3.0 (TID 426) in 135 ms on 8b44f3d35cfa (executor driver) (24/200)
[2025-07-19T21:02:32.025+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 42.0 in stage 3.0 (TID 434)
[2025-07-19T21:02:32.025+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 35 (task 428, attempt 0, stage 3.0)
[2025-07-19T21:02:32.027+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 33 (task 427, attempt 0, stage 3.0)
[2025-07-19T21:02:32.027+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 33.0 in stage 3.0 (TID 427). 9114 bytes result sent to driver
[2025-07-19T21:02:32.028+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.029+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.029+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 43.0 in stage 3.0 (TID 435) (8b44f3d35cfa, executor driver, partition 43, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.030+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 43.0 in stage 3.0 (TID 435)
[2025-07-19T21:02:32.030+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 33.0 in stage 3.0 (TID 427) in 125 ms on 8b44f3d35cfa (executor driver) (25/200)
[2025-07-19T21:02:32.030+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2cfcee68
[2025-07-19T21:02:32.032+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=41, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.033+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=41),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/41] for update
[2025-07-19T21:02:32.034+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.035+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.035+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.036+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3bc5b382
[2025-07-19T21:02:32.036+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=43, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.037+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=43),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/43] for update
[2025-07-19T21:02:32.037+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.042+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/39/.1.delta.a78c91b3-aa96-4552-bab8-8b873c7697d1.TID431.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/39/1.delta
[2025-07-19T21:02:32.042+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=39),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/39] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/39/1.delta
[2025-07-19T21:02:32.043+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@75e05590
[2025-07-19T21:02:32.043+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 39 (task 431, attempt 0, stage 3.0)
[2025-07-19T21:02:32.044+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=42, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.044+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=42),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/42] for update
[2025-07-19T21:02:32.045+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 35 (task 428, attempt 0, stage 3.0)
[2025-07-19T21:02:32.045+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/38/.1.delta.8c46056a-58af-4881-8760-e24056442758.TID430.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/38/1.delta
[2025-07-19T21:02:32.046+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=38),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/38] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/38/1.delta
[2025-07-19T21:02:32.047+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.047+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 35.0 in stage 3.0 (TID 428). 9105 bytes result sent to driver
[2025-07-19T21:02:32.048+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 38 (task 430, attempt 0, stage 3.0)
[2025-07-19T21:02:32.048+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 45.0 in stage 3.0 (TID 436) (8b44f3d35cfa, executor driver, partition 45, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.048+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 35.0 in stage 3.0 (TID 428) in 140 ms on 8b44f3d35cfa (executor driver) (26/200)
[2025-07-19T21:02:32.049+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 45.0 in stage 3.0 (TID 436)
[2025-07-19T21:02:32.049+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/43/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/43/.1.delta.5d59e5da-8e96-4a40-a3a0-42db6ccfb270.TID435.tmp
[2025-07-19T21:02:32.050+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/41/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/41/.1.delta.43d338c3-be88-44b4-bb39-16bb427cd276.TID433.tmp
[2025-07-19T21:02:32.051+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.051+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T21:02:32.052+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/42/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/42/.1.delta.51b4bf53-76ea-4aab-826a-523e3532a8a6.TID434.tmp
[2025-07-19T21:02:32.053+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/40/.1.delta.55fe2729-3fe7-4c06-aecb-277cf908d340.TID432.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/40/1.delta
[2025-07-19T21:02:32.055+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=40),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/40] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/40/1.delta
[2025-07-19T21:02:32.056+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 40 (task 432, attempt 0, stage 3.0)
[2025-07-19T21:02:32.058+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 37 (task 429, attempt 0, stage 3.0)
[2025-07-19T21:02:32.059+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 37.0 in stage 3.0 (TID 429). 9133 bytes result sent to driver
[2025-07-19T21:02:32.061+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 46.0 in stage 3.0 (TID 437) (8b44f3d35cfa, executor driver, partition 46, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.063+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 39 (task 431, attempt 0, stage 3.0)
[2025-07-19T21:02:32.063+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 37.0 in stage 3.0 (TID 429) in 143 ms on 8b44f3d35cfa (executor driver) (27/200)
[2025-07-19T21:02:32.063+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 46.0 in stage 3.0 (TID 437)
[2025-07-19T21:02:32.064+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 39.0 in stage 3.0 (TID 431). 9103 bytes result sent to driver
[2025-07-19T21:02:32.065+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 47.0 in stage 3.0 (TID 438) (8b44f3d35cfa, executor driver, partition 47, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.066+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.069+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.070+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@693bfef2
[2025-07-19T21:02:32.070+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 47.0 in stage 3.0 (TID 438)
[2025-07-19T21:02:32.070+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=45, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.071+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=45),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/45] for update
[2025-07-19T21:02:32.071+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 39.0 in stage 3.0 (TID 431) in 99 ms on 8b44f3d35cfa (executor driver) (28/200)
[2025-07-19T21:02:32.072+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 38 (task 430, attempt 0, stage 3.0)
[2025-07-19T21:02:32.072+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 38.0 in stage 3.0 (TID 430). 9119 bytes result sent to driver
[2025-07-19T21:02:32.073+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.073+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T21:02:32.077+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 48.0 in stage 3.0 (TID 439) (8b44f3d35cfa, executor driver, partition 48, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.077+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 38.0 in stage 3.0 (TID 430) in 109 ms on 8b44f3d35cfa (executor driver) (29/200)
[2025-07-19T21:02:32.077+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 48.0 in stage 3.0 (TID 439)
[2025-07-19T21:02:32.078+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.078+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@30b327f9
[2025-07-19T21:02:32.078+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=46, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.078+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=46),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/46] for update
[2025-07-19T21:02:32.078+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.078+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:32.078+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO LoggingMetricsReporter: Received metrics report: CommitReport{tableName=my_catalog.bronze.Reservations_raw, snapshotId=2013260881954734421, sequenceNumber=64, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.292993292S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=CounterResult{unit=COUNT, value=132}, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=6158}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=CounterResult{unit=COUNT, value=227}, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=8709}, addedFilesSizeInBytes=CounterResult{unit=BYTES, value=395634}, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=18358367}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}}, metadata={engine-version=3.5.6, app-id=local-1752958935081, engine-name=spark, iceberg-version=Apache Iceberg 1.4.0 (commit 10367c380098c2e06a49521a33681ac7f6c64b2c)}}
[2025-07-19T21:02:32.079+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO SparkWrite: Committed in 293 ms
[2025-07-19T21:02:32.080+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Reservations_raw, format=PARQUET)] committed.
[2025-07-19T21:02:32.080+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 40 (task 432, attempt 0, stage 3.0)
[2025-07-19T21:02:32.081+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.081+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 40.0 in stage 3.0 (TID 432). 9109 bytes result sent to driver
[2025-07-19T21:02:32.082+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 50.0 in stage 3.0 (TID 440) (8b44f3d35cfa, executor driver, partition 50, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.082+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 40.0 in stage 3.0 (TID 432) in 92 ms on 8b44f3d35cfa (executor driver) (30/200)
[2025-07-19T21:02:32.082+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b9024b
[2025-07-19T21:02:32.083+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=47, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.083+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=47),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/47] for update
[2025-07-19T21:02:32.084+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 50.0 in stage 3.0 (TID 440)
[2025-07-19T21:02:32.084+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.084+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.085+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.088+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/45/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/45/.1.delta.36b216cc-5a67-406f-a7ff-a75f2269aff2.TID436.tmp
[2025-07-19T21:02:32.089+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@565ceaf1
[2025-07-19T21:02:32.089+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=48, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.090+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=48),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/48] for update
[2025-07-19T21:02:32.090+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.090+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/46/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/46/.1.delta.9a34099f-e016-4f17-83a1-60bf21727de6.TID437.tmp
[2025-07-19T21:02:32.092+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@767dfcd2
[2025-07-19T21:02:32.092+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=50, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.092+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=50),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/50] for update
[2025-07-19T21:02:32.093+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/47/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/47/.1.delta.796ce592-08e5-4166-8b25-9c361ef4635c.TID438.tmp
[2025-07-19T21:02:32.094+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.096+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/43/.1.delta.5d59e5da-8e96-4a40-a3a0-42db6ccfb270.TID435.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/43/1.delta
[2025-07-19T21:02:32.096+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=43),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/43] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/43/1.delta
[2025-07-19T21:02:32.097+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/commits/0 using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/commits/.0.d5428899-59e3-4dcb-a6ca-8e2e8b884316.tmp
[2025-07-19T21:02:32.098+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 43 (task 435, attempt 0, stage 3.0)
[2025-07-19T21:02:32.100+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/42/.1.delta.51b4bf53-76ea-4aab-826a-523e3532a8a6.TID434.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/42/1.delta
[2025-07-19T21:02:32.100+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=42),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/42] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/42/1.delta
[2025-07-19T21:02:32.100+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 42 (task 434, attempt 0, stage 3.0)
[2025-07-19T21:02:32.103+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/48/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/48/.1.delta.fe0c1257-e3c1-47ce-aa17-bbac78279a09.TID439.tmp
[2025-07-19T21:02:32.105+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/41/.1.delta.43d338c3-be88-44b4-bb39-16bb427cd276.TID433.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/41/1.delta
[2025-07-19T21:02:32.105+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=41),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/41] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/41/1.delta
[2025-07-19T21:02:32.105+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 41 (task 433, attempt 0, stage 3.0)
[2025-07-19T21:02:32.105+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/50/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/50/.1.delta.e941ae5b-4c72-4ba9-ac1b-7db3a7d70009.TID440.tmp
[2025-07-19T21:02:32.114+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 42 (task 434, attempt 0, stage 3.0)
[2025-07-19T21:02:32.115+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 42.0 in stage 3.0 (TID 434). 9117 bytes result sent to driver
[2025-07-19T21:02:32.116+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 43 (task 435, attempt 0, stage 3.0)
[2025-07-19T21:02:32.117+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 51.0 in stage 3.0 (TID 441) (8b44f3d35cfa, executor driver, partition 51, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.117+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 43.0 in stage 3.0 (TID 435). 9094 bytes result sent to driver
[2025-07-19T21:02:32.118+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 52.0 in stage 3.0 (TID 442) (8b44f3d35cfa, executor driver, partition 52, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.118+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 51.0 in stage 3.0 (TID 441)
[2025-07-19T21:02:32.118+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 43.0 in stage 3.0 (TID 435) in 90 ms on 8b44f3d35cfa (executor driver) (31/200)
[2025-07-19T21:02:32.118+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 41 (task 433, attempt 0, stage 3.0)
[2025-07-19T21:02:32.118+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 52.0 in stage 3.0 (TID 442)
[2025-07-19T21:02:32.118+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 42.0 in stage 3.0 (TID 434) in 94 ms on 8b44f3d35cfa (executor driver) (32/200)
[2025-07-19T21:02:32.119+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 41.0 in stage 3.0 (TID 433). 9130 bytes result sent to driver
[2025-07-19T21:02:32.120+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 54.0 in stage 3.0 (TID 443) (8b44f3d35cfa, executor driver, partition 54, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.120+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 41.0 in stage 3.0 (TID 433) in 105 ms on 8b44f3d35cfa (executor driver) (33/200)
[2025-07-19T21:02:32.120+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 54.0 in stage 3.0 (TID 443)
[2025-07-19T21:02:32.120+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.121+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.121+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.121+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.122+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.122+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.123+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/45/.1.delta.36b216cc-5a67-406f-a7ff-a75f2269aff2.TID436.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/45/1.delta
[2025-07-19T21:02:32.123+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=45),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/45] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/45/1.delta
[2025-07-19T21:02:32.124+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 45 (task 436, attempt 0, stage 3.0)
[2025-07-19T21:02:32.126+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1bfffbcf
[2025-07-19T21:02:32.126+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=51, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.127+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=51),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/51] for update
[2025-07-19T21:02:32.129+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/46/.1.delta.9a34099f-e016-4f17-83a1-60bf21727de6.TID437.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/46/1.delta
[2025-07-19T21:02:32.129+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=46),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/46] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/46/1.delta
[2025-07-19T21:02:32.130+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 46 (task 437, attempt 0, stage 3.0)
[2025-07-19T21:02:32.130+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.131+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@51bc9195
[2025-07-19T21:02:32.135+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=52, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.135+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=52),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/52] for update
[2025-07-19T21:02:32.139+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.139+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/47/.1.delta.796ce592-08e5-4166-8b25-9c361ef4635c.TID438.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/47/1.delta
[2025-07-19T21:02:32.139+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=47),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/47] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/47/1.delta
[2025-07-19T21:02:32.140+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/commits/.0.d5428899-59e3-4dcb-a6ca-8e2e8b884316.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T21:00:00+00:00/commits/0
[2025-07-19T21:02:32.140+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 47 (task 438, attempt 0, stage 3.0)
[2025-07-19T21:02:32.144+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 45 (task 436, attempt 0, stage 3.0)
[2025-07-19T21:02:32.145+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 45.0 in stage 3.0 (TID 436). 9105 bytes result sent to driver
[2025-07-19T21:02:32.146+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/48/.1.delta.fe0c1257-e3c1-47ce-aa17-bbac78279a09.TID439.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/48/1.delta
[2025-07-19T21:02:32.147+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=48),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/48] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/48/1.delta
[2025-07-19T21:02:32.148+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 55.0 in stage 3.0 (TID 444) (8b44f3d35cfa, executor driver, partition 55, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.149+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 55.0 in stage 3.0 (TID 444)
[2025-07-19T21:02:32.150+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 45.0 in stage 3.0 (TID 436) in 101 ms on 8b44f3d35cfa (executor driver) (34/200)
[2025-07-19T21:02:32.150+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.151+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.151+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 48 (task 439, attempt 0, stage 3.0)
[2025-07-19T21:02:32.151+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/50/.1.delta.e941ae5b-4c72-4ba9-ac1b-7db3a7d70009.TID440.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/50/1.delta
[2025-07-19T21:02:32.151+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=50),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/50] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/50/1.delta
[2025-07-19T21:02:32.152+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 46 (task 437, attempt 0, stage 3.0)
[2025-07-19T21:02:32.153+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 50 (task 440, attempt 0, stage 3.0)
[2025-07-19T21:02:32.154+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 46.0 in stage 3.0 (TID 437). 9105 bytes result sent to driver
[2025-07-19T21:02:32.154+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 56.0 in stage 3.0 (TID 445) (8b44f3d35cfa, executor driver, partition 56, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.155+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 56.0 in stage 3.0 (TID 445)
[2025-07-19T21:02:32.156+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 46.0 in stage 3.0 (TID 437) in 93 ms on 8b44f3d35cfa (executor driver) (35/200)
[2025-07-19T21:02:32.156+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.157+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.157+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/51/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/51/.1.delta.d85f77b0-4f8e-4d13-ab6a-3bdc2119e948.TID441.tmp
[2025-07-19T21:02:32.157+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO MicroBatchExecution: Streaming query made progress: {
[2025-07-19T21:02:32.157+0000] {subprocess.py:93} INFO -   "id" : "73830d4c-ed35-482d-8a53-860d8476043f",
[2025-07-19T21:02:32.159+0000] {subprocess.py:93} INFO -   "runId" : "40450798-f492-4fd3-9974-3406c234d637",
[2025-07-19T21:02:32.160+0000] {subprocess.py:93} INFO -   "name" : null,
[2025-07-19T21:02:32.160+0000] {subprocess.py:93} INFO -   "timestamp" : "2025-07-19T21:02:17.814Z",
[2025-07-19T21:02:32.160+0000] {subprocess.py:93} INFO -   "batchId" : 0,
[2025-07-19T21:02:32.160+0000] {subprocess.py:93} INFO -   "numInputRows" : 234,
[2025-07-19T21:02:32.160+0000] {subprocess.py:93} INFO -   "inputRowsPerSecond" : 0.0,
[2025-07-19T21:02:32.160+0000] {subprocess.py:93} INFO -   "processedRowsPerSecond" : 16.339641086516306,
[2025-07-19T21:02:32.161+0000] {subprocess.py:93} INFO -   "durationMs" : {
[2025-07-19T21:02:32.161+0000] {subprocess.py:93} INFO -     "addBatch" : 12697,
[2025-07-19T21:02:32.161+0000] {subprocess.py:93} INFO -     "commitOffsets" : 53,
[2025-07-19T21:02:32.161+0000] {subprocess.py:93} INFO -     "getBatch" : 11,
[2025-07-19T21:02:32.161+0000] {subprocess.py:93} INFO -     "latestOffset" : 981,
[2025-07-19T21:02:32.163+0000] {subprocess.py:93} INFO -     "queryPlanning" : 440,
[2025-07-19T21:02:32.163+0000] {subprocess.py:93} INFO -     "triggerExecution" : 14321,
[2025-07-19T21:02:32.163+0000] {subprocess.py:93} INFO -     "walCommit" : 111
[2025-07-19T21:02:32.164+0000] {subprocess.py:93} INFO -   },
[2025-07-19T21:02:32.164+0000] {subprocess.py:93} INFO -   "eventTime" : {
[2025-07-19T21:02:32.165+0000] {subprocess.py:93} INFO -     "avg" : "1970-01-01T00:00:00.000Z",
[2025-07-19T21:02:32.166+0000] {subprocess.py:93} INFO -     "max" : "1970-01-01T00:00:00.000Z",
[2025-07-19T21:02:32.166+0000] {subprocess.py:93} INFO -     "min" : "1970-01-01T00:00:00.000Z",
[2025-07-19T21:02:32.167+0000] {subprocess.py:93} INFO -     "watermark" : "1970-01-01T00:00:00.000Z"
[2025-07-19T21:02:32.167+0000] {subprocess.py:93} INFO -   },
[2025-07-19T21:02:32.168+0000] {subprocess.py:93} INFO -   "stateOperators" : [ {
[2025-07-19T21:02:32.168+0000] {subprocess.py:93} INFO -     "operatorName" : "dedupe",
[2025-07-19T21:02:32.168+0000] {subprocess.py:93} INFO -     "numRowsTotal" : 227,
[2025-07-19T21:02:32.169+0000] {subprocess.py:93} INFO -     "numRowsUpdated" : 227,
[2025-07-19T21:02:32.169+0000] {subprocess.py:93} INFO -     "allUpdatesTimeMs" : 3535,
[2025-07-19T21:02:32.170+0000] {subprocess.py:93} INFO -     "numRowsRemoved" : 0,
[2025-07-19T21:02:32.172+0000] {subprocess.py:93} INFO -     "allRemovalsTimeMs" : 195,
[2025-07-19T21:02:32.172+0000] {subprocess.py:93} INFO -     "commitTimeMs" : 13554,
[2025-07-19T21:02:32.173+0000] {subprocess.py:93} INFO -     "memoryUsedBytes" : 100328,
[2025-07-19T21:02:32.173+0000] {subprocess.py:93} INFO -     "numRowsDroppedByWatermark" : 0,
[2025-07-19T21:02:32.173+0000] {subprocess.py:93} INFO -     "numShufflePartitions" : 200,
[2025-07-19T21:02:32.173+0000] {subprocess.py:93} INFO -     "numStateStoreInstances" : 200,
[2025-07-19T21:02:32.174+0000] {subprocess.py:93} INFO -     "customMetrics" : {
[2025-07-19T21:02:32.174+0000] {subprocess.py:93} INFO -       "loadedMapCacheHitCount" : 0,
[2025-07-19T21:02:32.176+0000] {subprocess.py:93} INFO -       "loadedMapCacheMissCount" : 0,
[2025-07-19T21:02:32.177+0000] {subprocess.py:93} INFO -       "numDroppedDuplicateRows" : 7,
[2025-07-19T21:02:32.177+0000] {subprocess.py:93} INFO -       "stateOnCurrentVersionSizeBytes" : 71528
[2025-07-19T21:02:32.178+0000] {subprocess.py:93} INFO -     }
[2025-07-19T21:02:32.179+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T21:02:32.181+0000] {subprocess.py:93} INFO -   "sources" : [ {
[2025-07-19T21:02:32.182+0000] {subprocess.py:93} INFO -     "description" : "KafkaV2[Subscribe[reservations]]",
[2025-07-19T21:02:32.183+0000] {subprocess.py:93} INFO -     "startOffset" : null,
[2025-07-19T21:02:32.183+0000] {subprocess.py:93} INFO -     "endOffset" : {
[2025-07-19T21:02:32.184+0000] {subprocess.py:93} INFO -       "reservations" : {
[2025-07-19T21:02:32.184+0000] {subprocess.py:93} INFO -         "0" : 234
[2025-07-19T21:02:32.184+0000] {subprocess.py:93} INFO -       }
[2025-07-19T21:02:32.184+0000] {subprocess.py:93} INFO -     },
[2025-07-19T21:02:32.185+0000] {subprocess.py:93} INFO -     "latestOffset" : {
[2025-07-19T21:02:32.185+0000] {subprocess.py:93} INFO -       "reservations" : {
[2025-07-19T21:02:32.186+0000] {subprocess.py:93} INFO -         "0" : 234
[2025-07-19T21:02:32.186+0000] {subprocess.py:93} INFO -       }
[2025-07-19T21:02:32.186+0000] {subprocess.py:93} INFO -     },
[2025-07-19T21:02:32.187+0000] {subprocess.py:93} INFO -     "numInputRows" : 234,
[2025-07-19T21:02:32.187+0000] {subprocess.py:93} INFO -     "inputRowsPerSecond" : 0.0,
[2025-07-19T21:02:32.189+0000] {subprocess.py:93} INFO -     "processedRowsPerSecond" : 16.339641086516306,
[2025-07-19T21:02:32.189+0000] {subprocess.py:93} INFO -     "metrics" : {
[2025-07-19T21:02:32.189+0000] {subprocess.py:93} INFO -       "avgOffsetsBehindLatest" : "0.0",
[2025-07-19T21:02:32.189+0000] {subprocess.py:93} INFO -       "maxOffsetsBehindLatest" : "0",
[2025-07-19T21:02:32.189+0000] {subprocess.py:93} INFO -       "minOffsetsBehindLatest" : "0"
[2025-07-19T21:02:32.190+0000] {subprocess.py:93} INFO -     }
[2025-07-19T21:02:32.190+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T21:02:32.190+0000] {subprocess.py:93} INFO -   "sink" : {
[2025-07-19T21:02:32.190+0000] {subprocess.py:93} INFO -     "description" : "my_catalog.bronze.Reservations_raw",
[2025-07-19T21:02:32.190+0000] {subprocess.py:93} INFO -     "numOutputRows" : 227
[2025-07-19T21:02:32.191+0000] {subprocess.py:93} INFO -   }
[2025-07-19T21:02:32.191+0000] {subprocess.py:93} INFO - }
[2025-07-19T21:02:32.191+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/52/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/52/.1.delta.bed0c8cb-d041-4299-a1e5-99a2a537a603.TID442.tmp
[2025-07-19T21:02:32.192+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a936d72
[2025-07-19T21:02:32.192+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=54, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.192+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=54),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/54] for update
[2025-07-19T21:02:32.193+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.193+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 47 (task 438, attempt 0, stage 3.0)
[2025-07-19T21:02:32.194+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 47.0 in stage 3.0 (TID 438). 9101 bytes result sent to driver
[2025-07-19T21:02:32.194+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 57.0 in stage 3.0 (TID 446) (8b44f3d35cfa, executor driver, partition 57, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.195+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 48 (task 439, attempt 0, stage 3.0)
[2025-07-19T21:02:32.195+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a1c4bbd
[2025-07-19T21:02:32.195+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 48.0 in stage 3.0 (TID 439). 9109 bytes result sent to driver
[2025-07-19T21:02:32.195+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 57.0 in stage 3.0 (TID 446)
[2025-07-19T21:02:32.195+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/54/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/54/.1.delta.b96678fb-93f2-475a-aff3-f31cdbac8a7b.TID443.tmp
[2025-07-19T21:02:32.196+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 50 (task 440, attempt 0, stage 3.0)
[2025-07-19T21:02:32.196+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 50.0 in stage 3.0 (TID 440). 9117 bytes result sent to driver
[2025-07-19T21:02:32.197+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 47.0 in stage 3.0 (TID 438) in 112 ms on 8b44f3d35cfa (executor driver) (36/200)
[2025-07-19T21:02:32.197+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 58.0 in stage 3.0 (TID 447) (8b44f3d35cfa, executor driver, partition 58, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.197+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 58.0 in stage 3.0 (TID 447)
[2025-07-19T21:02:32.198+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 59.0 in stage 3.0 (TID 448) (8b44f3d35cfa, executor driver, partition 59, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.198+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=56, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.199+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=56),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/56] for update
[2025-07-19T21:02:32.199+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 59.0 in stage 3.0 (TID 448)
[2025-07-19T21:02:32.200+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.200+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T21:02:32.200+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.200+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.202+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.204+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 50.0 in stage 3.0 (TID 440) in 107 ms on 8b44f3d35cfa (executor driver) (37/200)
[2025-07-19T21:02:32.204+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.205+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 48.0 in stage 3.0 (TID 439) in 125 ms on 8b44f3d35cfa (executor driver) (38/200)
[2025-07-19T21:02:32.205+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.205+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@767c54
[2025-07-19T21:02:32.206+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=55, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.206+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=55),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/55] for update
[2025-07-19T21:02:32.206+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.206+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7cb7f913
[2025-07-19T21:02:32.207+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=59, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.207+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=59),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/59] for update
[2025-07-19T21:02:32.207+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.213+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/51/.1.delta.d85f77b0-4f8e-4d13-ab6a-3bdc2119e948.TID441.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/51/1.delta
[2025-07-19T21:02:32.214+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=51),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/51] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/51/1.delta
[2025-07-19T21:02:32.214+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 51 (task 441, attempt 0, stage 3.0)
[2025-07-19T21:02:32.214+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/56/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/56/.1.delta.b1e77246-5ac6-4e2f-ab9e-0ca40fffefac.TID445.tmp
[2025-07-19T21:02:32.214+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/55/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/55/.1.delta.1817d1e3-2392-4bce-860e-87bbbb918c01.TID444.tmp
[2025-07-19T21:02:32.214+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a35c270
[2025-07-19T21:02:32.214+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=58, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.214+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=58),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/58] for update
[2025-07-19T21:02:32.217+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.222+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/59/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/59/.1.delta.f1bbd971-ebd4-475c-a9af-79cab946c10f.TID448.tmp
[2025-07-19T21:02:32.222+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58be4bb9
[2025-07-19T21:02:32.224+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=57, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.224+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=57),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/57] for update
[2025-07-19T21:02:32.229+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/52/.1.delta.bed0c8cb-d041-4299-a1e5-99a2a537a603.TID442.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/52/1.delta
[2025-07-19T21:02:32.230+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=52),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/52] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/52/1.delta
[2025-07-19T21:02:32.230+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.231+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 52 (task 442, attempt 0, stage 3.0)
[2025-07-19T21:02:32.232+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/58/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/58/.1.delta.00dd36ce-f3ed-4d7a-b653-156bd2f0f8b3.TID447.tmp
[2025-07-19T21:02:32.236+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/54/.1.delta.b96678fb-93f2-475a-aff3-f31cdbac8a7b.TID443.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/54/1.delta
[2025-07-19T21:02:32.236+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=54),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/54] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/54/1.delta
[2025-07-19T21:02:32.237+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 54 (task 443, attempt 0, stage 3.0)
[2025-07-19T21:02:32.240+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/57/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/57/.1.delta.813da999-3722-47fb-9df7-9e22ef1bf819.TID446.tmp
[2025-07-19T21:02:32.242+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 51 (task 441, attempt 0, stage 3.0)
[2025-07-19T21:02:32.243+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 51.0 in stage 3.0 (TID 441). 9150 bytes result sent to driver
[2025-07-19T21:02:32.245+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 60.0 in stage 3.0 (TID 449) (8b44f3d35cfa, executor driver, partition 60, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.246+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 60.0 in stage 3.0 (TID 449)
[2025-07-19T21:02:32.246+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 51.0 in stage 3.0 (TID 441) in 130 ms on 8b44f3d35cfa (executor driver) (39/200)
[2025-07-19T21:02:32.247+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/55/.1.delta.1817d1e3-2392-4bce-860e-87bbbb918c01.TID444.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/55/1.delta
[2025-07-19T21:02:32.248+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=55),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/55] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/55/1.delta
[2025-07-19T21:02:32.248+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.248+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 55 (task 444, attempt 0, stage 3.0)
[2025-07-19T21:02:32.248+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.249+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 52 (task 442, attempt 0, stage 3.0)
[2025-07-19T21:02:32.254+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 52.0 in stage 3.0 (TID 442). 9160 bytes result sent to driver
[2025-07-19T21:02:32.254+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 62.0 in stage 3.0 (TID 450) (8b44f3d35cfa, executor driver, partition 62, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.254+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 62.0 in stage 3.0 (TID 450)
[2025-07-19T21:02:32.255+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 54 (task 443, attempt 0, stage 3.0)
[2025-07-19T21:02:32.256+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 54.0 in stage 3.0 (TID 443). 9164 bytes result sent to driver
[2025-07-19T21:02:32.256+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 52.0 in stage 3.0 (TID 442) in 139 ms on 8b44f3d35cfa (executor driver) (40/200)
[2025-07-19T21:02:32.257+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 63.0 in stage 3.0 (TID 451) (8b44f3d35cfa, executor driver, partition 63, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.259+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 63.0 in stage 3.0 (TID 451)
[2025-07-19T21:02:32.263+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a84964e
[2025-07-19T21:02:32.263+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 54.0 in stage 3.0 (TID 443) in 145 ms on 8b44f3d35cfa (executor driver) (41/200)
[2025-07-19T21:02:32.263+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.263+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.264+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.264+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.266+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=60, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.268+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=60),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/60] for update
[2025-07-19T21:02:32.268+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.273+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 55 (task 444, attempt 0, stage 3.0)
[2025-07-19T21:02:32.275+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 55.0 in stage 3.0 (TID 444). 9152 bytes result sent to driver
[2025-07-19T21:02:32.276+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/56/.1.delta.b1e77246-5ac6-4e2f-ab9e-0ca40fffefac.TID445.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/56/1.delta
[2025-07-19T21:02:32.276+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=56),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/56] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/56/1.delta
[2025-07-19T21:02:32.277+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56fa3714
[2025-07-19T21:02:32.281+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 56 (task 445, attempt 0, stage 3.0)
[2025-07-19T21:02:32.282+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 65.0 in stage 3.0 (TID 452) (8b44f3d35cfa, executor driver, partition 65, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.283+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=62, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.285+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=62),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/62] for update
[2025-07-19T21:02:32.285+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 65.0 in stage 3.0 (TID 452)
[2025-07-19T21:02:32.285+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 55.0 in stage 3.0 (TID 444) in 138 ms on 8b44f3d35cfa (executor driver) (42/200)
[2025-07-19T21:02:32.285+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.285+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/59/.1.delta.f1bbd971-ebd4-475c-a9af-79cab946c10f.TID448.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/59/1.delta
[2025-07-19T21:02:32.285+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=59),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/59] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/59/1.delta
[2025-07-19T21:02:32.285+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 59 (task 448, attempt 0, stage 3.0)
[2025-07-19T21:02:32.289+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/57/.1.delta.813da999-3722-47fb-9df7-9e22ef1bf819.TID446.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/57/1.delta
[2025-07-19T21:02:32.290+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=57),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/57] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/57/1.delta
[2025-07-19T21:02:32.290+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.291+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.293+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 57 (task 446, attempt 0, stage 3.0)
[2025-07-19T21:02:32.293+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@124209ef
[2025-07-19T21:02:32.294+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=63, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.294+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/60/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/60/.1.delta.8e7079e7-29ea-464f-a97a-6cb8b55f8bf4.TID449.tmp
[2025-07-19T21:02:32.295+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=63),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/63] for update
[2025-07-19T21:02:32.295+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/58/.1.delta.00dd36ce-f3ed-4d7a-b653-156bd2f0f8b3.TID447.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/58/1.delta
[2025-07-19T21:02:32.296+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=58),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/58] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/58/1.delta
[2025-07-19T21:02:32.298+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 58 (task 447, attempt 0, stage 3.0)
[2025-07-19T21:02:32.300+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.302+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/62/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/62/.1.delta.f40a9bdc-222a-452e-919b-19801dc4eaed.TID450.tmp
[2025-07-19T21:02:32.303+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@8e62fd3
[2025-07-19T21:02:32.303+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=65, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.303+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=65),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/65] for update
[2025-07-19T21:02:32.304+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/63/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/63/.1.delta.b13513e7-835d-4e62-8856-6db0708bca0e.TID451.tmp
[2025-07-19T21:02:32.305+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.306+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 56 (task 445, attempt 0, stage 3.0)
[2025-07-19T21:02:32.310+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 56.0 in stage 3.0 (TID 445). 9152 bytes result sent to driver
[2025-07-19T21:02:32.311+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 66.0 in stage 3.0 (TID 453) (8b44f3d35cfa, executor driver, partition 66, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.311+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 56.0 in stage 3.0 (TID 445) in 161 ms on 8b44f3d35cfa (executor driver) (43/200)
[2025-07-19T21:02:32.312+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 66.0 in stage 3.0 (TID 453)
[2025-07-19T21:02:32.322+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 57 (task 446, attempt 0, stage 3.0)
[2025-07-19T21:02:32.323+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 57.0 in stage 3.0 (TID 446). 9150 bytes result sent to driver
[2025-07-19T21:02:32.324+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 67.0 in stage 3.0 (TID 454) (8b44f3d35cfa, executor driver, partition 67, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.325+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 8b44f3d35cfa:38433 in memory (size: 29.6 KiB, free: 434.2 MiB)
[2025-07-19T21:02:32.325+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 67.0 in stage 3.0 (TID 454)
[2025-07-19T21:02:32.326+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.326+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/65/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/65/.1.delta.a5c9471a-5079-4df3-9dde-4e1e3bfaafde.TID452.tmp
[2025-07-19T21:02:32.326+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.326+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 57.0 in stage 3.0 (TID 446) in 155 ms on 8b44f3d35cfa (executor driver) (44/200)
[2025-07-19T21:02:32.329+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3202a32a
[2025-07-19T21:02:32.330+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=66, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.331+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=66),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/66] for update
[2025-07-19T21:02:32.335+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.336+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T21:02:32.340+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.341+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 59 (task 448, attempt 0, stage 3.0)
[2025-07-19T21:02:32.342+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 59.0 in stage 3.0 (TID 448). 9162 bytes result sent to driver
[2025-07-19T21:02:32.342+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 68.0 in stage 3.0 (TID 455) (8b44f3d35cfa, executor driver, partition 68, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.342+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 68.0 in stage 3.0 (TID 455)
[2025-07-19T21:02:32.342+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 58 (task 447, attempt 0, stage 3.0)
[2025-07-19T21:02:32.343+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 59.0 in stage 3.0 (TID 448) in 161 ms on 8b44f3d35cfa (executor driver) (45/200)
[2025-07-19T21:02:32.344+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 58.0 in stage 3.0 (TID 447). 9141 bytes result sent to driver
[2025-07-19T21:02:32.345+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 71.0 in stage 3.0 (TID 456) (8b44f3d35cfa, executor driver, partition 71, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.347+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 71.0 in stage 3.0 (TID 456)
[2025-07-19T21:02:32.347+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.349+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.349+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.350+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.350+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 58.0 in stage 3.0 (TID 447) in 170 ms on 8b44f3d35cfa (executor driver) (46/200)
[2025-07-19T21:02:32.350+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ac571da
[2025-07-19T21:02:32.350+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 8b44f3d35cfa:38433 in memory (size: 35.4 KiB, free: 434.2 MiB)
[2025-07-19T21:02:32.351+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=67, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.351+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=67),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/67] for update
[2025-07-19T21:02:32.356+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/66/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/66/.1.delta.6117f144-c73b-4a25-9245-28b2c05d2cfb.TID453.tmp
[2025-07-19T21:02:32.357+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.361+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71a87d3a
[2025-07-19T21:02:32.364+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=71, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.364+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=71),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/71] for update
[2025-07-19T21:02:32.364+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.373+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@251fcd81
[2025-07-19T21:02:32.374+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/67/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/67/.1.delta.3094735b-ac27-45c8-8325-f810b751d6c1.TID454.tmp
[2025-07-19T21:02:32.375+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=68, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.376+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=68),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/68] for update
[2025-07-19T21:02:32.376+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/63/.1.delta.b13513e7-835d-4e62-8856-6db0708bca0e.TID451.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/63/1.delta
[2025-07-19T21:02:32.376+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=63),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/63] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/63/1.delta
[2025-07-19T21:02:32.376+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 63 (task 451, attempt 0, stage 3.0)
[2025-07-19T21:02:32.377+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.378+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/71/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/71/.1.delta.f3461d5b-0ebd-4103-9f79-0b1f882bba79.TID456.tmp
[2025-07-19T21:02:32.381+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/60/.1.delta.8e7079e7-29ea-464f-a97a-6cb8b55f8bf4.TID449.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/60/1.delta
[2025-07-19T21:02:32.381+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=60),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/60] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/60/1.delta
[2025-07-19T21:02:32.381+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 60 (task 449, attempt 0, stage 3.0)
[2025-07-19T21:02:32.383+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/62/.1.delta.f40a9bdc-222a-452e-919b-19801dc4eaed.TID450.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/62/1.delta
[2025-07-19T21:02:32.384+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=62),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/62] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/62/1.delta
[2025-07-19T21:02:32.385+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 62 (task 450, attempt 0, stage 3.0)
[2025-07-19T21:02:32.391+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/68/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/68/.1.delta.9a10c5eb-b682-42f3-bd8e-1e9774581ca9.TID455.tmp
[2025-07-19T21:02:32.396+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/65/.1.delta.a5c9471a-5079-4df3-9dde-4e1e3bfaafde.TID452.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/65/1.delta
[2025-07-19T21:02:32.402+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=65),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/65] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/65/1.delta
[2025-07-19T21:02:32.403+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 65 (task 452, attempt 0, stage 3.0)
[2025-07-19T21:02:32.408+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 60 (task 449, attempt 0, stage 3.0)
[2025-07-19T21:02:32.409+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 60.0 in stage 3.0 (TID 449). 9170 bytes result sent to driver
[2025-07-19T21:02:32.410+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 72.0 in stage 3.0 (TID 457) (8b44f3d35cfa, executor driver, partition 72, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.411+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/66/.1.delta.6117f144-c73b-4a25-9245-28b2c05d2cfb.TID453.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/66/1.delta
[2025-07-19T21:02:32.412+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=66),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/66] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/66/1.delta
[2025-07-19T21:02:32.412+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 72.0 in stage 3.0 (TID 457)
[2025-07-19T21:02:32.413+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 62 (task 450, attempt 0, stage 3.0)
[2025-07-19T21:02:32.413+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 66 (task 453, attempt 0, stage 3.0)
[2025-07-19T21:02:32.413+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 60.0 in stage 3.0 (TID 449) in 167 ms on 8b44f3d35cfa (executor driver) (47/200)
[2025-07-19T21:02:32.414+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.414+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.414+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 63 (task 451, attempt 0, stage 3.0)
[2025-07-19T21:02:32.415+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 63.0 in stage 3.0 (TID 451). 9160 bytes result sent to driver
[2025-07-19T21:02:32.416+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 74.0 in stage 3.0 (TID 458) (8b44f3d35cfa, executor driver, partition 74, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.416+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 74.0 in stage 3.0 (TID 458)
[2025-07-19T21:02:32.416+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 62.0 in stage 3.0 (TID 450). 9144 bytes result sent to driver
[2025-07-19T21:02:32.416+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 75.0 in stage 3.0 (TID 459) (8b44f3d35cfa, executor driver, partition 75, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.416+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 63.0 in stage 3.0 (TID 451) in 159 ms on 8b44f3d35cfa (executor driver) (48/200)
[2025-07-19T21:02:32.416+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 62.0 in stage 3.0 (TID 450) in 163 ms on 8b44f3d35cfa (executor driver) (49/200)
[2025-07-19T21:02:32.417+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 75.0 in stage 3.0 (TID 459)
[2025-07-19T21:02:32.418+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.418+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.422+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.422+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.425+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@70f6b84c
[2025-07-19T21:02:32.426+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/67/.1.delta.3094735b-ac27-45c8-8325-f810b751d6c1.TID454.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/67/1.delta
[2025-07-19T21:02:32.427+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=67),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/67] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/67/1.delta
[2025-07-19T21:02:32.427+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 67 (task 454, attempt 0, stage 3.0)
[2025-07-19T21:02:32.429+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=72, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.429+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=72),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/72] for update
[2025-07-19T21:02:32.430+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 65 (task 452, attempt 0, stage 3.0)
[2025-07-19T21:02:32.430+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 65.0 in stage 3.0 (TID 452). 9115 bytes result sent to driver
[2025-07-19T21:02:32.430+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 76.0 in stage 3.0 (TID 460) (8b44f3d35cfa, executor driver, partition 76, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.431+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 76.0 in stage 3.0 (TID 460)
[2025-07-19T21:02:32.431+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 65.0 in stage 3.0 (TID 452) in 151 ms on 8b44f3d35cfa (executor driver) (50/200)
[2025-07-19T21:02:32.432+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.433+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.434+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.435+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f4b2ba2
[2025-07-19T21:02:32.436+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=75, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.437+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=75),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/75] for update
[2025-07-19T21:02:32.442+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/71/.1.delta.f3461d5b-0ebd-4103-9f79-0b1f882bba79.TID456.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/71/1.delta
[2025-07-19T21:02:32.443+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=71),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/71] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/71/1.delta
[2025-07-19T21:02:32.443+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 66 (task 453, attempt 0, stage 3.0)
[2025-07-19T21:02:32.443+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 71 (task 456, attempt 0, stage 3.0)
[2025-07-19T21:02:32.445+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 66.0 in stage 3.0 (TID 453). 9099 bytes result sent to driver
[2025-07-19T21:02:32.445+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 77.0 in stage 3.0 (TID 461) (8b44f3d35cfa, executor driver, partition 77, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.446+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 77.0 in stage 3.0 (TID 461)
[2025-07-19T21:02:32.447+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 66.0 in stage 3.0 (TID 453) in 131 ms on 8b44f3d35cfa (executor driver) (51/200)
[2025-07-19T21:02:32.448+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.448+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/68/.1.delta.9a10c5eb-b682-42f3-bd8e-1e9774581ca9.TID455.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/68/1.delta
[2025-07-19T21:02:32.448+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=68),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/68] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/68/1.delta
[2025-07-19T21:02:32.449+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.449+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 68 (task 455, attempt 0, stage 3.0)
[2025-07-19T21:02:32.449+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:32.449+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2fa30c0b
[2025-07-19T21:02:32.450+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=74, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.450+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=74),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/74] for update
[2025-07-19T21:02:32.451+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/72/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/72/.1.delta.7145e2b3-d123-49dd-a5ac-0fdddc0e2f08.TID457.tmp
[2025-07-19T21:02:32.451+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.451+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 67 (task 454, attempt 0, stage 3.0)
[2025-07-19T21:02:32.451+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 67.0 in stage 3.0 (TID 454). 9117 bytes result sent to driver
[2025-07-19T21:02:32.453+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 78.0 in stage 3.0 (TID 462) (8b44f3d35cfa, executor driver, partition 78, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.456+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 78.0 in stage 3.0 (TID 462)
[2025-07-19T21:02:32.457+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@740d55fd
[2025-07-19T21:02:32.459+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 67.0 in stage 3.0 (TID 454) in 133 ms on 8b44f3d35cfa (executor driver) (52/200)
[2025-07-19T21:02:32.460+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 71 (task 456, attempt 0, stage 3.0)
[2025-07-19T21:02:32.460+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 71.0 in stage 3.0 (TID 456). 9122 bytes result sent to driver
[2025-07-19T21:02:32.460+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 68 (task 455, attempt 0, stage 3.0)
[2025-07-19T21:02:32.460+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=77, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.460+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=77),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/77] for update
[2025-07-19T21:02:32.461+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 79.0 in stage 3.0 (TID 463) (8b44f3d35cfa, executor driver, partition 79, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.461+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 79.0 in stage 3.0 (TID 463)
[2025-07-19T21:02:32.462+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 68.0 in stage 3.0 (TID 455). 9119 bytes result sent to driver
[2025-07-19T21:02:32.462+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 71.0 in stage 3.0 (TID 456) in 113 ms on 8b44f3d35cfa (executor driver) (53/200)
[2025-07-19T21:02:32.462+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 80.0 in stage 3.0 (TID 464) (8b44f3d35cfa, executor driver, partition 80, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.462+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.462+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.462+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/75/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/75/.1.delta.c95923c7-9f5a-49b6-8c09-86b0218ff667.TID459.tmp
[2025-07-19T21:02:32.462+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 80.0 in stage 3.0 (TID 464)
[2025-07-19T21:02:32.462+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.463+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.463+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 68.0 in stage 3.0 (TID 455) in 120 ms on 8b44f3d35cfa (executor driver) (54/200)
[2025-07-19T21:02:32.463+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.463+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.464+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.466+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/74/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/74/.1.delta.97d05a75-21ff-45a0-acba-14a8ef7a3164.TID458.tmp
[2025-07-19T21:02:32.469+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1f47198
[2025-07-19T21:02:32.470+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=76, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.470+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=76),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/76] for update
[2025-07-19T21:02:32.472+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.475+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@538f318a
[2025-07-19T21:02:32.478+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=78, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.478+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=78),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/78] for update
[2025-07-19T21:02:32.479+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/77/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/77/.1.delta.214afc53-faed-4271-b665-0ecfdad7ad56.TID461.tmp
[2025-07-19T21:02:32.480+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.484+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/76/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/76/.1.delta.a72e6d21-6091-4c29-b50b-9864898fc1b4.TID460.tmp
[2025-07-19T21:02:32.486+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@472be44
[2025-07-19T21:02:32.487+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=80, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.488+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=80),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/80] for update
[2025-07-19T21:02:32.491+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/78/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/78/.1.delta.01e5d389-fbe7-47e9-bd2b-9ae4b88742b7.TID462.tmp
[2025-07-19T21:02:32.491+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.497+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@409fd60d
[2025-07-19T21:02:32.498+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/80/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/80/.1.delta.c66d629a-5106-40f1-b270-c93f1909b68c.TID464.tmp
[2025-07-19T21:02:32.498+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=79, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.498+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=79),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/79] for update
[2025-07-19T21:02:32.501+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/72/.1.delta.7145e2b3-d123-49dd-a5ac-0fdddc0e2f08.TID457.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/72/1.delta
[2025-07-19T21:02:32.502+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=72),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/72] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/72/1.delta
[2025-07-19T21:02:32.503+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 72 (task 457, attempt 0, stage 3.0)
[2025-07-19T21:02:32.504+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.507+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/75/.1.delta.c95923c7-9f5a-49b6-8c09-86b0218ff667.TID459.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/75/1.delta
[2025-07-19T21:02:32.508+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=75),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/75] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/75/1.delta
[2025-07-19T21:02:32.509+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 75 (task 459, attempt 0, stage 3.0)
[2025-07-19T21:02:32.509+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/74/.1.delta.97d05a75-21ff-45a0-acba-14a8ef7a3164.TID458.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/74/1.delta
[2025-07-19T21:02:32.509+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=74),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/74] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/74/1.delta
[2025-07-19T21:02:32.510+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 74 (task 458, attempt 0, stage 3.0)
[2025-07-19T21:02:32.516+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/79/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/79/.1.delta.879a20ed-8d29-4382-b6b6-18463980a7f2.TID463.tmp
[2025-07-19T21:02:32.518+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/77/.1.delta.214afc53-faed-4271-b665-0ecfdad7ad56.TID461.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/77/1.delta
[2025-07-19T21:02:32.519+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=77),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/77] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/77/1.delta
[2025-07-19T21:02:32.519+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 72 (task 457, attempt 0, stage 3.0)
[2025-07-19T21:02:32.520+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 77 (task 461, attempt 0, stage 3.0)
[2025-07-19T21:02:32.520+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 72.0 in stage 3.0 (TID 457). 9119 bytes result sent to driver
[2025-07-19T21:02:32.524+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 82.0 in stage 3.0 (TID 465) (8b44f3d35cfa, executor driver, partition 82, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.525+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 82.0 in stage 3.0 (TID 465)
[2025-07-19T21:02:32.526+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 72.0 in stage 3.0 (TID 457) in 115 ms on 8b44f3d35cfa (executor driver) (55/200)
[2025-07-19T21:02:32.527+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 74 (task 458, attempt 0, stage 3.0)
[2025-07-19T21:02:32.528+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 74.0 in stage 3.0 (TID 458). 9113 bytes result sent to driver
[2025-07-19T21:02:32.528+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 83.0 in stage 3.0 (TID 466) (8b44f3d35cfa, executor driver, partition 83, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.529+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.529+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.529+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 75 (task 459, attempt 0, stage 3.0)
[2025-07-19T21:02:32.530+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 75.0 in stage 3.0 (TID 459). 9135 bytes result sent to driver
[2025-07-19T21:02:32.530+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 83.0 in stage 3.0 (TID 466)
[2025-07-19T21:02:32.531+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 84.0 in stage 3.0 (TID 467) (8b44f3d35cfa, executor driver, partition 84, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.531+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 84.0 in stage 3.0 (TID 467)
[2025-07-19T21:02:32.531+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 74.0 in stage 3.0 (TID 458) in 116 ms on 8b44f3d35cfa (executor driver) (56/200)
[2025-07-19T21:02:32.532+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.532+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.534+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.534+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.534+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@736da304
[2025-07-19T21:02:32.534+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=82, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.535+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=82),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/82] for update
[2025-07-19T21:02:32.535+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/78/.1.delta.01e5d389-fbe7-47e9-bd2b-9ae4b88742b7.TID462.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/78/1.delta
[2025-07-19T21:02:32.535+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=78),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/78] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/78/1.delta
[2025-07-19T21:02:32.535+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/80/.1.delta.c66d629a-5106-40f1-b270-c93f1909b68c.TID464.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/80/1.delta
[2025-07-19T21:02:32.536+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=80),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/80] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/80/1.delta
[2025-07-19T21:02:32.536+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 80 (task 464, attempt 0, stage 3.0)
[2025-07-19T21:02:32.536+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 75.0 in stage 3.0 (TID 459) in 115 ms on 8b44f3d35cfa (executor driver) (57/200)
[2025-07-19T21:02:32.536+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/76/.1.delta.a72e6d21-6091-4c29-b50b-9864898fc1b4.TID460.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/76/1.delta
[2025-07-19T21:02:32.536+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=76),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/76] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/76/1.delta
[2025-07-19T21:02:32.537+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 78 (task 462, attempt 0, stage 3.0)
[2025-07-19T21:02:32.537+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 76 (task 460, attempt 0, stage 3.0)
[2025-07-19T21:02:32.540+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.540+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e5c60f
[2025-07-19T21:02:32.541+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=84, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.542+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=84),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/84] for update
[2025-07-19T21:02:32.542+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.543+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 77 (task 461, attempt 0, stage 3.0)
[2025-07-19T21:02:32.544+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 77.0 in stage 3.0 (TID 461). 9132 bytes result sent to driver
[2025-07-19T21:02:32.547+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 85.0 in stage 3.0 (TID 468) (8b44f3d35cfa, executor driver, partition 85, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.547+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 77.0 in stage 3.0 (TID 461) in 107 ms on 8b44f3d35cfa (executor driver) (58/200)
[2025-07-19T21:02:32.548+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@21c52ce0
[2025-07-19T21:02:32.548+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 85.0 in stage 3.0 (TID 468)
[2025-07-19T21:02:32.549+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.549+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.550+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=83, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.551+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=83),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/83] for update
[2025-07-19T21:02:32.551+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.552+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 78 (task 462, attempt 0, stage 3.0)
[2025-07-19T21:02:32.552+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 78.0 in stage 3.0 (TID 462). 9129 bytes result sent to driver
[2025-07-19T21:02:32.560+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/84/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/84/.1.delta.8a9f3db3-0eb5-454a-9bdd-2d604f8887aa.TID467.tmp
[2025-07-19T21:02:32.561+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 87.0 in stage 3.0 (TID 469) (8b44f3d35cfa, executor driver, partition 87, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.561+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1e6a5fd5
[2025-07-19T21:02:32.562+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 78.0 in stage 3.0 (TID 462) in 106 ms on 8b44f3d35cfa (executor driver) (59/200)
[2025-07-19T21:02:32.562+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/82/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/82/.1.delta.35a60085-b9d9-4736-8e41-0fb920e88c86.TID465.tmp
[2025-07-19T21:02:32.563+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 87.0 in stage 3.0 (TID 469)
[2025-07-19T21:02:32.563+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=85, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.564+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=85),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/85] for update
[2025-07-19T21:02:32.564+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.564+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.564+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.564+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/83/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/83/.1.delta.84205d94-504c-4c8e-b8d3-78dff3452fb0.TID466.tmp
[2025-07-19T21:02:32.570+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 80 (task 464, attempt 0, stage 3.0)
[2025-07-19T21:02:32.571+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 80.0 in stage 3.0 (TID 464). 9119 bytes result sent to driver
[2025-07-19T21:02:32.572+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 88.0 in stage 3.0 (TID 470) (8b44f3d35cfa, executor driver, partition 88, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.573+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 76 (task 460, attempt 0, stage 3.0)
[2025-07-19T21:02:32.574+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 80.0 in stage 3.0 (TID 464) in 114 ms on 8b44f3d35cfa (executor driver) (60/200)
[2025-07-19T21:02:32.575+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 88.0 in stage 3.0 (TID 470)
[2025-07-19T21:02:32.576+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2979ff2f
[2025-07-19T21:02:32.577+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 76.0 in stage 3.0 (TID 460). 9127 bytes result sent to driver
[2025-07-19T21:02:32.578+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 94.0 in stage 3.0 (TID 471) (8b44f3d35cfa, executor driver, partition 94, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.578+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 76.0 in stage 3.0 (TID 460) in 144 ms on 8b44f3d35cfa (executor driver) (61/200)
[2025-07-19T21:02:32.579+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/79/.1.delta.879a20ed-8d29-4382-b6b6-18463980a7f2.TID463.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/79/1.delta
[2025-07-19T21:02:32.579+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=79),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/79] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/79/1.delta
[2025-07-19T21:02:32.579+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=87, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.580+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=87),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/87] for update
[2025-07-19T21:02:32.581+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 79 (task 463, attempt 0, stage 3.0)
[2025-07-19T21:02:32.581+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 94.0 in stage 3.0 (TID 471)
[2025-07-19T21:02:32.583+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.584+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.585+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/85/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/85/.1.delta.46e493bf-e4b6-4d3f-aaf2-3f3a25a92d13.TID468.tmp
[2025-07-19T21:02:32.586+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.587+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.587+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.587+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@41ad66ce
[2025-07-19T21:02:32.588+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/87/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/87/.1.delta.00212322-7469-41f9-92a0-11ce7bf05959.TID469.tmp
[2025-07-19T21:02:32.588+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=88, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.588+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=88),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/88] for update
[2025-07-19T21:02:32.589+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.597+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33c6d774
[2025-07-19T21:02:32.599+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=94, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.599+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=94),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/94] for update
[2025-07-19T21:02:32.601+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 79 (task 463, attempt 0, stage 3.0)
[2025-07-19T21:02:32.601+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 79.0 in stage 3.0 (TID 463). 9109 bytes result sent to driver
[2025-07-19T21:02:32.601+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 95.0 in stage 3.0 (TID 472) (8b44f3d35cfa, executor driver, partition 95, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.602+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 95.0 in stage 3.0 (TID 472)
[2025-07-19T21:02:32.602+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 79.0 in stage 3.0 (TID 463) in 145 ms on 8b44f3d35cfa (executor driver) (62/200)
[2025-07-19T21:02:32.602+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.605+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.606+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.610+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/88/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/88/.1.delta.6b4d0630-f20f-44b4-96bb-0c8e84595442.TID470.tmp
[2025-07-19T21:02:32.611+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/82/.1.delta.35a60085-b9d9-4736-8e41-0fb920e88c86.TID465.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/82/1.delta
[2025-07-19T21:02:32.612+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=82),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/82] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/82/1.delta
[2025-07-19T21:02:32.613+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 82 (task 465, attempt 0, stage 3.0)
[2025-07-19T21:02:32.613+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/84/.1.delta.8a9f3db3-0eb5-454a-9bdd-2d604f8887aa.TID467.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/84/1.delta
[2025-07-19T21:02:32.614+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=84),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/84] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/84/1.delta
[2025-07-19T21:02:32.614+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 84 (task 467, attempt 0, stage 3.0)
[2025-07-19T21:02:32.615+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7149e20b
[2025-07-19T21:02:32.620+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/83/.1.delta.84205d94-504c-4c8e-b8d3-78dff3452fb0.TID466.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/83/1.delta
[2025-07-19T21:02:32.621+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=83),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/83] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/83/1.delta
[2025-07-19T21:02:32.621+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/94/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/94/.1.delta.4826f351-1b1e-4d13-b85e-a2dbe02eb1d4.TID471.tmp
[2025-07-19T21:02:32.621+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=95, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.622+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 83 (task 466, attempt 0, stage 3.0)
[2025-07-19T21:02:32.622+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=95),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/95] for update
[2025-07-19T21:02:32.622+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.632+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/95/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/95/.1.delta.93af9978-86fc-4e6c-8a10-e6fa9602a67c.TID472.tmp
[2025-07-19T21:02:32.634+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 82 (task 465, attempt 0, stage 3.0)
[2025-07-19T21:02:32.635+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 84 (task 467, attempt 0, stage 3.0)
[2025-07-19T21:02:32.635+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 82.0 in stage 3.0 (TID 465). 9105 bytes result sent to driver
[2025-07-19T21:02:32.637+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 84.0 in stage 3.0 (TID 467). 9111 bytes result sent to driver
[2025-07-19T21:02:32.638+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/87/.1.delta.00212322-7469-41f9-92a0-11ce7bf05959.TID469.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/87/1.delta
[2025-07-19T21:02:32.638+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=87),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/87] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/87/1.delta
[2025-07-19T21:02:32.639+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 96.0 in stage 3.0 (TID 473) (8b44f3d35cfa, executor driver, partition 96, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.639+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/85/.1.delta.46e493bf-e4b6-4d3f-aaf2-3f3a25a92d13.TID468.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/85/1.delta
[2025-07-19T21:02:32.639+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=85),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/85] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/85/1.delta
[2025-07-19T21:02:32.639+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 82.0 in stage 3.0 (TID 465) in 115 ms on 8b44f3d35cfa (executor driver) (63/200)
[2025-07-19T21:02:32.641+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 96.0 in stage 3.0 (TID 473)
[2025-07-19T21:02:32.641+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 97.0 in stage 3.0 (TID 474) (8b44f3d35cfa, executor driver, partition 97, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.642+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 87 (task 469, attempt 0, stage 3.0)
[2025-07-19T21:02:32.643+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 85 (task 468, attempt 0, stage 3.0)
[2025-07-19T21:02:32.644+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.644+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.645+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 84.0 in stage 3.0 (TID 467) in 113 ms on 8b44f3d35cfa (executor driver) (64/200)
[2025-07-19T21:02:32.645+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 97.0 in stage 3.0 (TID 474)
[2025-07-19T21:02:32.646+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 83 (task 466, attempt 0, stage 3.0)
[2025-07-19T21:02:32.646+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.647+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.648+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 83.0 in stage 3.0 (TID 466). 9113 bytes result sent to driver
[2025-07-19T21:02:32.648+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c358536
[2025-07-19T21:02:32.648+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=96, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.649+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=96),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/96] for update
[2025-07-19T21:02:32.649+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 99.0 in stage 3.0 (TID 475) (8b44f3d35cfa, executor driver, partition 99, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.651+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 83.0 in stage 3.0 (TID 466) in 122 ms on 8b44f3d35cfa (executor driver) (65/200)
[2025-07-19T21:02:32.652+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 99.0 in stage 3.0 (TID 475)
[2025-07-19T21:02:32.653+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.654+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.655+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.656+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 87 (task 469, attempt 0, stage 3.0)
[2025-07-19T21:02:32.657+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 87.0 in stage 3.0 (TID 469). 9113 bytes result sent to driver
[2025-07-19T21:02:32.657+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 100.0 in stage 3.0 (TID 476) (8b44f3d35cfa, executor driver, partition 100, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.658+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5eb855eb
[2025-07-19T21:02:32.658+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 100.0 in stage 3.0 (TID 476)
[2025-07-19T21:02:32.658+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 87.0 in stage 3.0 (TID 469) in 99 ms on 8b44f3d35cfa (executor driver) (66/200)
[2025-07-19T21:02:32.658+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=97, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.658+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=97),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/97] for update
[2025-07-19T21:02:32.659+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.660+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/88/.1.delta.6b4d0630-f20f-44b4-96bb-0c8e84595442.TID470.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/88/1.delta
[2025-07-19T21:02:32.660+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=88),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/88] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/88/1.delta
[2025-07-19T21:02:32.661+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.661+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.661+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 85 (task 468, attempt 0, stage 3.0)
[2025-07-19T21:02:32.663+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 85.0 in stage 3.0 (TID 468). 9129 bytes result sent to driver
[2025-07-19T21:02:32.663+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 88 (task 470, attempt 0, stage 3.0)
[2025-07-19T21:02:32.664+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 101.0 in stage 3.0 (TID 477) (8b44f3d35cfa, executor driver, partition 101, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.664+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 101.0 in stage 3.0 (TID 477)
[2025-07-19T21:02:32.665+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 85.0 in stage 3.0 (TID 468) in 118 ms on 8b44f3d35cfa (executor driver) (67/200)
[2025-07-19T21:02:32.665+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/94/.1.delta.4826f351-1b1e-4d13-b85e-a2dbe02eb1d4.TID471.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/94/1.delta
[2025-07-19T21:02:32.666+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=94),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/94] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/94/1.delta
[2025-07-19T21:02:32.666+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 94 (task 471, attempt 0, stage 3.0)
[2025-07-19T21:02:32.667+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.668+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:32.668+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@42fb1943
[2025-07-19T21:02:32.669+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=99, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.669+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=99),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/99] for update
[2025-07-19T21:02:32.670+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/96/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/96/.1.delta.02e76094-f0f6-4a1c-ae1b-99fa095e40b5.TID473.tmp
[2025-07-19T21:02:32.671+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.676+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/97/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/97/.1.delta.514f50c7-ef78-4269-8483-2239bc92afe2.TID474.tmp
[2025-07-19T21:02:32.676+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c92f1f1
[2025-07-19T21:02:32.677+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=101, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.679+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=101),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/101] for update
[2025-07-19T21:02:32.680+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.680+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/95/.1.delta.93af9978-86fc-4e6c-8a10-e6fa9602a67c.TID472.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/95/1.delta
[2025-07-19T21:02:32.680+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=95),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/95] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/95/1.delta
[2025-07-19T21:02:32.680+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 95 (task 472, attempt 0, stage 3.0)
[2025-07-19T21:02:32.681+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/99/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/99/.1.delta.0c637734-a82f-46e3-a205-48192f313b7f.TID475.tmp
[2025-07-19T21:02:32.684+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5151ff7a
[2025-07-19T21:02:32.685+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 88 (task 470, attempt 0, stage 3.0)
[2025-07-19T21:02:32.687+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 88.0 in stage 3.0 (TID 470). 9119 bytes result sent to driver
[2025-07-19T21:02:32.687+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=100, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.688+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=100),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/100] for update
[2025-07-19T21:02:32.688+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 103.0 in stage 3.0 (TID 478) (8b44f3d35cfa, executor driver, partition 103, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.688+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.688+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 88.0 in stage 3.0 (TID 470) in 115 ms on 8b44f3d35cfa (executor driver) (68/200)
[2025-07-19T21:02:32.688+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 94 (task 471, attempt 0, stage 3.0)
[2025-07-19T21:02:32.689+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 94.0 in stage 3.0 (TID 471). 9126 bytes result sent to driver
[2025-07-19T21:02:32.690+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 104.0 in stage 3.0 (TID 479) (8b44f3d35cfa, executor driver, partition 104, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.691+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 104.0 in stage 3.0 (TID 479)
[2025-07-19T21:02:32.691+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/101/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/101/.1.delta.5e6405c6-54d4-4158-b665-951253c66270.TID477.tmp
[2025-07-19T21:02:32.692+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 103.0 in stage 3.0 (TID 478)
[2025-07-19T21:02:32.692+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 94.0 in stage 3.0 (TID 471) in 117 ms on 8b44f3d35cfa (executor driver) (69/200)
[2025-07-19T21:02:32.693+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.693+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.694+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.694+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.703+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/100/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/100/.1.delta.780174f3-e742-4a01-b381-ce397b0c7bb1.TID476.tmp
[2025-07-19T21:02:32.704+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@261a9820
[2025-07-19T21:02:32.707+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=103, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.707+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=103),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/103] for update
[2025-07-19T21:02:32.710+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 95 (task 472, attempt 0, stage 3.0)
[2025-07-19T21:02:32.710+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.711+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 95.0 in stage 3.0 (TID 472). 9156 bytes result sent to driver
[2025-07-19T21:02:32.711+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 106.0 in stage 3.0 (TID 480) (8b44f3d35cfa, executor driver, partition 106, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.712+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 106.0 in stage 3.0 (TID 480)
[2025-07-19T21:02:32.715+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 95.0 in stage 3.0 (TID 472) in 114 ms on 8b44f3d35cfa (executor driver) (70/200)
[2025-07-19T21:02:32.720+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.721+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5cef4e6a
[2025-07-19T21:02:32.721+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.722+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=104, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.722+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=104),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/104] for update
[2025-07-19T21:02:32.722+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.723+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/103/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/103/.1.delta.5963f15e-87ac-4b25-8615-74f12badaa84.TID478.tmp
[2025-07-19T21:02:32.725+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/97/.1.delta.514f50c7-ef78-4269-8483-2239bc92afe2.TID474.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/97/1.delta
[2025-07-19T21:02:32.726+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=97),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/97] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/97/1.delta
[2025-07-19T21:02:32.729+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/96/.1.delta.02e76094-f0f6-4a1c-ae1b-99fa095e40b5.TID473.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/96/1.delta
[2025-07-19T21:02:32.729+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=96),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/96] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/96/1.delta
[2025-07-19T21:02:32.729+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 97 (task 474, attempt 0, stage 3.0)
[2025-07-19T21:02:32.729+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 96 (task 473, attempt 0, stage 3.0)
[2025-07-19T21:02:32.732+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e838364
[2025-07-19T21:02:32.732+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=106, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.733+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=106),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/106] for update
[2025-07-19T21:02:32.734+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/104/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/104/.1.delta.7a3a2d83-003f-4dd9-819b-aac27ac42dab.TID479.tmp
[2025-07-19T21:02:32.738+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.744+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 97 (task 474, attempt 0, stage 3.0)
[2025-07-19T21:02:32.744+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/99/.1.delta.0c637734-a82f-46e3-a205-48192f313b7f.TID475.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/99/1.delta
[2025-07-19T21:02:32.744+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=99),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/99] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/99/1.delta
[2025-07-19T21:02:32.750+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 97.0 in stage 3.0 (TID 474). 9141 bytes result sent to driver
[2025-07-19T21:02:32.751+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 108.0 in stage 3.0 (TID 481) (8b44f3d35cfa, executor driver, partition 108, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.751+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 97.0 in stage 3.0 (TID 474) in 109 ms on 8b44f3d35cfa (executor driver) (71/200)
[2025-07-19T21:02:32.751+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 99 (task 475, attempt 0, stage 3.0)
[2025-07-19T21:02:32.751+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 108.0 in stage 3.0 (TID 481)
[2025-07-19T21:02:32.752+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 96 (task 473, attempt 0, stage 3.0)
[2025-07-19T21:02:32.752+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 96.0 in stage 3.0 (TID 473). 9213 bytes result sent to driver
[2025-07-19T21:02:32.753+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.753+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.754+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 110.0 in stage 3.0 (TID 482) (8b44f3d35cfa, executor driver, partition 110, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.755+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 110.0 in stage 3.0 (TID 482)
[2025-07-19T21:02:32.756+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 96.0 in stage 3.0 (TID 473) in 113 ms on 8b44f3d35cfa (executor driver) (72/200)
[2025-07-19T21:02:32.757+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.757+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.758+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/106/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/106/.1.delta.058e4d9f-abff-47c0-ab9e-7adc40236b77.TID480.tmp
[2025-07-19T21:02:32.759+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/101/.1.delta.5e6405c6-54d4-4158-b665-951253c66270.TID477.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/101/1.delta
[2025-07-19T21:02:32.759+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74cc2269
[2025-07-19T21:02:32.761+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=108, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.763+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=108),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/108] for update
[2025-07-19T21:02:32.764+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=101),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/101] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/101/1.delta
[2025-07-19T21:02:32.766+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 101 (task 477, attempt 0, stage 3.0)
[2025-07-19T21:02:32.773+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73598598
[2025-07-19T21:02:32.774+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=110, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.774+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=110),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/110] for update
[2025-07-19T21:02:32.789+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 99 (task 475, attempt 0, stage 3.0)
[2025-07-19T21:02:32.799+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 99.0 in stage 3.0 (TID 475). 9201 bytes result sent to driver
[2025-07-19T21:02:32.800+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.805+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 111.0 in stage 3.0 (TID 483) (8b44f3d35cfa, executor driver, partition 111, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.806+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/100/.1.delta.780174f3-e742-4a01-b381-ce397b0c7bb1.TID476.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/100/1.delta
[2025-07-19T21:02:32.809+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=100),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/100] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/100/1.delta
[2025-07-19T21:02:32.811+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.812+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 100 (task 476, attempt 0, stage 3.0)
[2025-07-19T21:02:32.817+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 99.0 in stage 3.0 (TID 475) in 168 ms on 8b44f3d35cfa (executor driver) (73/200)
[2025-07-19T21:02:32.819+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 111.0 in stage 3.0 (TID 483)
[2025-07-19T21:02:32.827+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 101 (task 477, attempt 0, stage 3.0)
[2025-07-19T21:02:32.828+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 101.0 in stage 3.0 (TID 477). 9162 bytes result sent to driver
[2025-07-19T21:02:32.829+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 112.0 in stage 3.0 (TID 484) (8b44f3d35cfa, executor driver, partition 112, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.830+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 101.0 in stage 3.0 (TID 477) in 168 ms on 8b44f3d35cfa (executor driver) (74/200)
[2025-07-19T21:02:32.832+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 112.0 in stage 3.0 (TID 484)
[2025-07-19T21:02:32.837+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/108/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/108/.1.delta.2e110cfa-13d6-4030-9ca3-1293943ef09a.TID481.tmp
[2025-07-19T21:02:32.838+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.839+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.840+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.840+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.840+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/103/.1.delta.5963f15e-87ac-4b25-8615-74f12badaa84.TID478.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/103/1.delta
[2025-07-19T21:02:32.840+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=103),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/103] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/103/1.delta
[2025-07-19T21:02:32.840+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/104/.1.delta.7a3a2d83-003f-4dd9-819b-aac27ac42dab.TID479.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/104/1.delta
[2025-07-19T21:02:32.841+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 103 (task 478, attempt 0, stage 3.0)
[2025-07-19T21:02:32.842+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 100 (task 476, attempt 0, stage 3.0)
[2025-07-19T21:02:32.843+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 100.0 in stage 3.0 (TID 476). 9163 bytes result sent to driver
[2025-07-19T21:02:32.844+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=104),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/104] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/104/1.delta
[2025-07-19T21:02:32.845+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 113.0 in stage 3.0 (TID 485) (8b44f3d35cfa, executor driver, partition 113, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.845+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 113.0 in stage 3.0 (TID 485)
[2025-07-19T21:02:32.847+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 100.0 in stage 3.0 (TID 476) in 191 ms on 8b44f3d35cfa (executor driver) (75/200)
[2025-07-19T21:02:32.848+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 104 (task 479, attempt 0, stage 3.0)
[2025-07-19T21:02:32.848+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19217f5b
[2025-07-19T21:02:32.849+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=112, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.849+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=112),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/112] for update
[2025-07-19T21:02:32.849+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/110/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/110/.1.delta.d6450ba1-a6fa-4b08-aa5a-f92d52bd7d00.TID482.tmp
[2025-07-19T21:02:32.853+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.856+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.857+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:32.863+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6778792d
[2025-07-19T21:02:32.864+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=111, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.864+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=111),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/111] for update
[2025-07-19T21:02:32.865+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.879+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@195c6a0b
[2025-07-19T21:02:32.881+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=113, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.882+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=113),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/113] for update
[2025-07-19T21:02:32.883+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/106/.1.delta.058e4d9f-abff-47c0-ab9e-7adc40236b77.TID480.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/106/1.delta
[2025-07-19T21:02:32.884+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=106),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/106] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/106/1.delta
[2025-07-19T21:02:32.884+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/112/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/112/.1.delta.8d3b55f4-bb40-40f3-bff0-472ae496c416.TID484.tmp
[2025-07-19T21:02:32.884+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 103 (task 478, attempt 0, stage 3.0)
[2025-07-19T21:02:32.885+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 103.0 in stage 3.0 (TID 478). 9148 bytes result sent to driver
[2025-07-19T21:02:32.885+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 114.0 in stage 3.0 (TID 486) (8b44f3d35cfa, executor driver, partition 114, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.885+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 103.0 in stage 3.0 (TID 478) in 198 ms on 8b44f3d35cfa (executor driver) (76/200)
[2025-07-19T21:02:32.885+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 114.0 in stage 3.0 (TID 486)
[2025-07-19T21:02:32.885+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 104 (task 479, attempt 0, stage 3.0)
[2025-07-19T21:02:32.885+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 104.0 in stage 3.0 (TID 479). 9160 bytes result sent to driver
[2025-07-19T21:02:32.886+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.886+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 106 (task 480, attempt 0, stage 3.0)
[2025-07-19T21:02:32.894+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 115.0 in stage 3.0 (TID 487) (8b44f3d35cfa, executor driver, partition 115, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.895+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 115.0 in stage 3.0 (TID 487)
[2025-07-19T21:02:32.895+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/111/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/111/.1.delta.42268f0a-bd16-4a83-ba05-ddcc33631b32.TID483.tmp
[2025-07-19T21:02:32.895+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 104.0 in stage 3.0 (TID 479) in 199 ms on 8b44f3d35cfa (executor driver) (77/200)
[2025-07-19T21:02:32.902+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.902+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:32.907+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/113/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/113/.1.delta.c219f7ed-4326-4030-839a-a626fe54eaf4.TID485.tmp
[2025-07-19T21:02:32.909+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.910+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:32.915+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f2ea613
[2025-07-19T21:02:32.915+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=115, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.916+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=115),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/115] for update
[2025-07-19T21:02:32.920+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 106 (task 480, attempt 0, stage 3.0)
[2025-07-19T21:02:32.921+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 106.0 in stage 3.0 (TID 480). 9156 bytes result sent to driver
[2025-07-19T21:02:32.925+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 117.0 in stage 3.0 (TID 488) (8b44f3d35cfa, executor driver, partition 117, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.925+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 117.0 in stage 3.0 (TID 488)
[2025-07-19T21:02:32.925+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 106.0 in stage 3.0 (TID 480) in 213 ms on 8b44f3d35cfa (executor driver) (78/200)
[2025-07-19T21:02:32.927+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.928+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/108/.1.delta.2e110cfa-13d6-4030-9ca3-1293943ef09a.TID481.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/108/1.delta
[2025-07-19T21:02:32.928+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=108),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/108] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/108/1.delta
[2025-07-19T21:02:32.930+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39ed369d
[2025-07-19T21:02:32.931+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 108 (task 481, attempt 0, stage 3.0)
[2025-07-19T21:02:32.931+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/110/.1.delta.d6450ba1-a6fa-4b08-aa5a-f92d52bd7d00.TID482.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/110/1.delta
[2025-07-19T21:02:32.932+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=110),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/110] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/110/1.delta
[2025-07-19T21:02:32.932+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=114, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.933+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=114),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/114] for update
[2025-07-19T21:02:32.935+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.936+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:32.936+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 110 (task 482, attempt 0, stage 3.0)
[2025-07-19T21:02:32.937+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.937+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/111/.1.delta.42268f0a-bd16-4a83-ba05-ddcc33631b32.TID483.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/111/1.delta
[2025-07-19T21:02:32.938+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=111),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/111] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/111/1.delta
[2025-07-19T21:02:32.939+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 111 (task 483, attempt 0, stage 3.0)
[2025-07-19T21:02:32.940+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3588c796
[2025-07-19T21:02:32.941+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=117, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.941+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=117),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/117] for update
[2025-07-19T21:02:32.943+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.948+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/115/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/115/.1.delta.55729a30-ddec-4593-81d2-3735ab917d6d.TID487.tmp
[2025-07-19T21:02:32.949+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 108 (task 481, attempt 0, stage 3.0)
[2025-07-19T21:02:32.950+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/112/.1.delta.8d3b55f4-bb40-40f3-bff0-472ae496c416.TID484.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/112/1.delta
[2025-07-19T21:02:32.951+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=112),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/112] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/112/1.delta
[2025-07-19T21:02:32.952+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 110 (task 482, attempt 0, stage 3.0)
[2025-07-19T21:02:32.952+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 108.0 in stage 3.0 (TID 481). 9140 bytes result sent to driver
[2025-07-19T21:02:32.953+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 110.0 in stage 3.0 (TID 482). 9156 bytes result sent to driver
[2025-07-19T21:02:32.953+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 118.0 in stage 3.0 (TID 489) (8b44f3d35cfa, executor driver, partition 118, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.954+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 118.0 in stage 3.0 (TID 489)
[2025-07-19T21:02:32.955+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/114/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/114/.1.delta.9b124a86-1be7-4e5e-b30a-6eb66292ad5c.TID486.tmp
[2025-07-19T21:02:32.956+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 119.0 in stage 3.0 (TID 490) (8b44f3d35cfa, executor driver, partition 119, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.957+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 110.0 in stage 3.0 (TID 482) in 206 ms on 8b44f3d35cfa (executor driver) (79/200)
[2025-07-19T21:02:32.957+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 108.0 in stage 3.0 (TID 481) in 209 ms on 8b44f3d35cfa (executor driver) (80/200)
[2025-07-19T21:02:32.957+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 119.0 in stage 3.0 (TID 490)
[2025-07-19T21:02:32.958+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 112 (task 484, attempt 0, stage 3.0)
[2025-07-19T21:02:32.958+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.960+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:32.961+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/117/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/117/.1.delta.56d6c04e-14cc-4ee3-a7a7-234dfd71689f.TID488.tmp
[2025-07-19T21:02:32.961+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.962+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:32.963+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 111 (task 483, attempt 0, stage 3.0)
[2025-07-19T21:02:32.964+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 111.0 in stage 3.0 (TID 483). 9124 bytes result sent to driver
[2025-07-19T21:02:32.964+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 120.0 in stage 3.0 (TID 491) (8b44f3d35cfa, executor driver, partition 120, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.965+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 111.0 in stage 3.0 (TID 483) in 158 ms on 8b44f3d35cfa (executor driver) (81/200)
[2025-07-19T21:02:32.965+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 120.0 in stage 3.0 (TID 491)
[2025-07-19T21:02:32.965+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.965+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.970+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/113/.1.delta.c219f7ed-4326-4030-839a-a626fe54eaf4.TID485.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/113/1.delta
[2025-07-19T21:02:32.970+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=113),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/113] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/113/1.delta
[2025-07-19T21:02:32.970+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 113 (task 485, attempt 0, stage 3.0)
[2025-07-19T21:02:32.972+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@13c8584d
[2025-07-19T21:02:32.974+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=119, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.974+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=119),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/119] for update
[2025-07-19T21:02:32.975+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 112 (task 484, attempt 0, stage 3.0)
[2025-07-19T21:02:32.975+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 112.0 in stage 3.0 (TID 484). 9123 bytes result sent to driver
[2025-07-19T21:02:32.976+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 121.0 in stage 3.0 (TID 492) (8b44f3d35cfa, executor driver, partition 121, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.977+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 112.0 in stage 3.0 (TID 484) in 149 ms on 8b44f3d35cfa (executor driver) (82/200)
[2025-07-19T21:02:32.977+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.978+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 121.0 in stage 3.0 (TID 492)
[2025-07-19T21:02:32.979+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.979+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.980+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65f11f07
[2025-07-19T21:02:32.981+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=120, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.981+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=120),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/120] for update
[2025-07-19T21:02:32.985+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/115/.1.delta.55729a30-ddec-4593-81d2-3735ab917d6d.TID487.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/115/1.delta
[2025-07-19T21:02:32.986+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=115),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/115] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/115/1.delta
[2025-07-19T21:02:32.987+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 113 (task 485, attempt 0, stage 3.0)
[2025-07-19T21:02:32.987+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 115 (task 487, attempt 0, stage 3.0)
[2025-07-19T21:02:32.987+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.987+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 113.0 in stage 3.0 (TID 485). 9115 bytes result sent to driver
[2025-07-19T21:02:32.987+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 122.0 in stage 3.0 (TID 493) (8b44f3d35cfa, executor driver, partition 122, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:32.987+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 122.0 in stage 3.0 (TID 493)
[2025-07-19T21:02:32.987+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 113.0 in stage 3.0 (TID 485) in 141 ms on 8b44f3d35cfa (executor driver) (83/200)
[2025-07-19T21:02:32.988+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:32.988+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:32.990+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/119/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/119/.1.delta.682b4a26-89de-4003-832e-4db4001b529a.TID490.tmp
[2025-07-19T21:02:32.993+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ab072b
[2025-07-19T21:02:32.994+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=118, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:32.997+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=118),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/118] for update
[2025-07-19T21:02:32.997+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Committed partition 115 (task 487, attempt 0, stage 3.0)
[2025-07-19T21:02:32.998+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Finished task 115.0 in stage 3.0 (TID 487). 9099 bytes result sent to driver
[2025-07-19T21:02:32.999+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:32.999+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Starting task 125.0 in stage 3.0 (TID 494) (8b44f3d35cfa, executor driver, partition 125, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.000+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO TaskSetManager: Finished task 115.0 in stage 3.0 (TID 487) in 109 ms on 8b44f3d35cfa (executor driver) (84/200)
[2025-07-19T21:02:33.001+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO Executor: Running task 125.0 in stage 3.0 (TID 494)
[2025-07-19T21:02:33.002+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/120/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/120/.1.delta.7e34e61a-2ff2-44b3-904c-db11d815df8d.TID491.tmp
[2025-07-19T21:02:33.003+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/114/.1.delta.9b124a86-1be7-4e5e-b30a-6eb66292ad5c.TID486.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/114/1.delta
[2025-07-19T21:02:33.005+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=114),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/114] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/114/1.delta
[2025-07-19T21:02:33.005+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO DataWritingSparkTask: Commit authorized for partition 114 (task 486, attempt 0, stage 3.0)
[2025-07-19T21:02:33.006+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.006+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.006+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d6ae2a6
[2025-07-19T21:02:33.007+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=122, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.007+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=122),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/122] for update
[2025-07-19T21:02:33.008+0000] {subprocess.py:93} INFO - 25/07/19 21:02:32 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.009+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/118/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/118/.1.delta.a1ceff5e-6efa-4bdc-a04f-50803e273a8e.TID489.tmp
[2025-07-19T21:02:33.009+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/117/.1.delta.56d6c04e-14cc-4ee3-a7a7-234dfd71689f.TID488.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/117/1.delta
[2025-07-19T21:02:33.010+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=117),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/117] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/117/1.delta
[2025-07-19T21:02:33.011+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22c4ee6f
[2025-07-19T21:02:33.011+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 117 (task 488, attempt 0, stage 3.0)
[2025-07-19T21:02:33.012+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=125, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.013+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/122/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/122/.1.delta.8e0c8d94-8c5a-46dd-9131-dcbfc56a1809.TID493.tmp
[2025-07-19T21:02:33.013+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=125),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/125] for update
[2025-07-19T21:02:33.017+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.019+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 114 (task 486, attempt 0, stage 3.0)
[2025-07-19T21:02:33.020+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 114.0 in stage 3.0 (TID 486). 9125 bytes result sent to driver
[2025-07-19T21:02:33.021+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 128.0 in stage 3.0 (TID 495) (8b44f3d35cfa, executor driver, partition 128, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.021+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 128.0 in stage 3.0 (TID 495)
[2025-07-19T21:02:33.022+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1214c85e
[2025-07-19T21:02:33.023+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 114.0 in stage 3.0 (TID 486) in 140 ms on 8b44f3d35cfa (executor driver) (85/200)
[2025-07-19T21:02:33.024+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=121, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.024+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=121),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/121] for update
[2025-07-19T21:02:33.025+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.026+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:33.033+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.034+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 117 (task 488, attempt 0, stage 3.0)
[2025-07-19T21:02:33.034+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 117.0 in stage 3.0 (TID 488). 9119 bytes result sent to driver
[2025-07-19T21:02:33.034+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/125/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/125/.1.delta.5ad790a3-1133-40fd-b5d7-d169a61dfc9c.TID494.tmp
[2025-07-19T21:02:33.034+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@67a40ef7
[2025-07-19T21:02:33.034+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=128, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.034+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=128),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/128] for update
[2025-07-19T21:02:33.034+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 129.0 in stage 3.0 (TID 496) (8b44f3d35cfa, executor driver, partition 129, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.034+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 117.0 in stage 3.0 (TID 488) in 111 ms on 8b44f3d35cfa (executor driver) (86/200)
[2025-07-19T21:02:33.035+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.038+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 129.0 in stage 3.0 (TID 496)
[2025-07-19T21:02:33.039+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (593.0 B) non-empty blocks including 1 (593.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.043+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/128/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/128/.1.delta.896b1b7b-3aad-4b22-8f14-4d04844d2892.TID495.tmp
[2025-07-19T21:02:33.044+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:33.049+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/121/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/121/.1.delta.c08288ab-b5a8-4e61-80c5-9dac91628d5d.TID492.tmp
[2025-07-19T21:02:33.050+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f63118a
[2025-07-19T21:02:33.052+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=129, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.053+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=129),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/129] for update
[2025-07-19T21:02:33.055+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/120/.1.delta.7e34e61a-2ff2-44b3-904c-db11d815df8d.TID491.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/120/1.delta
[2025-07-19T21:02:33.056+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=120),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/120] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/120/1.delta
[2025-07-19T21:02:33.056+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.056+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 120 (task 491, attempt 0, stage 3.0)
[2025-07-19T21:02:33.057+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/119/.1.delta.682b4a26-89de-4003-832e-4db4001b529a.TID490.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/119/1.delta
[2025-07-19T21:02:33.057+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=119),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/119] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/119/1.delta
[2025-07-19T21:02:33.057+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 119 (task 490, attempt 0, stage 3.0)
[2025-07-19T21:02:33.057+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/118/.1.delta.a1ceff5e-6efa-4bdc-a04f-50803e273a8e.TID489.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/118/1.delta
[2025-07-19T21:02:33.058+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=118),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/118] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/118/1.delta
[2025-07-19T21:02:33.058+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 118 (task 489, attempt 0, stage 3.0)
[2025-07-19T21:02:33.064+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/129/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/129/.1.delta.1d4cc82a-f639-41b9-ac1f-e7d9bd3c4f46.TID496.tmp
[2025-07-19T21:02:33.066+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/122/.1.delta.8e0c8d94-8c5a-46dd-9131-dcbfc56a1809.TID493.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/122/1.delta
[2025-07-19T21:02:33.066+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=122),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/122] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/122/1.delta
[2025-07-19T21:02:33.067+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 122 (task 493, attempt 0, stage 3.0)
[2025-07-19T21:02:33.073+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 120 (task 491, attempt 0, stage 3.0)
[2025-07-19T21:02:33.074+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 120.0 in stage 3.0 (TID 491). 9126 bytes result sent to driver
[2025-07-19T21:02:33.076+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 130.0 in stage 3.0 (TID 497) (8b44f3d35cfa, executor driver, partition 130, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.076+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 130.0 in stage 3.0 (TID 497)
[2025-07-19T21:02:33.077+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 118 (task 489, attempt 0, stage 3.0)
[2025-07-19T21:02:33.077+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 118.0 in stage 3.0 (TID 489). 9113 bytes result sent to driver
[2025-07-19T21:02:33.078+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/125/.1.delta.5ad790a3-1133-40fd-b5d7-d169a61dfc9c.TID494.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/125/1.delta
[2025-07-19T21:02:33.079+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=125),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/125] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/125/1.delta
[2025-07-19T21:02:33.079+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.079+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.079+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 120.0 in stage 3.0 (TID 491) in 117 ms on 8b44f3d35cfa (executor driver) (87/200)
[2025-07-19T21:02:33.079+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 131.0 in stage 3.0 (TID 498) (8b44f3d35cfa, executor driver, partition 131, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.079+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 131.0 in stage 3.0 (TID 498)
[2025-07-19T21:02:33.080+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 118.0 in stage 3.0 (TID 489) in 128 ms on 8b44f3d35cfa (executor driver) (88/200)
[2025-07-19T21:02:33.080+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 125 (task 494, attempt 0, stage 3.0)
[2025-07-19T21:02:33.082+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 122 (task 493, attempt 0, stage 3.0)
[2025-07-19T21:02:33.082+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 122.0 in stage 3.0 (TID 493). 9109 bytes result sent to driver
[2025-07-19T21:02:33.083+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.083+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.084+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 133.0 in stage 3.0 (TID 499) (8b44f3d35cfa, executor driver, partition 133, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.088+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 122.0 in stage 3.0 (TID 493) in 99 ms on 8b44f3d35cfa (executor driver) (89/200)
[2025-07-19T21:02:33.089+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 133.0 in stage 3.0 (TID 499)
[2025-07-19T21:02:33.089+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 119 (task 490, attempt 0, stage 3.0)
[2025-07-19T21:02:33.090+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 119.0 in stage 3.0 (TID 490). 9109 bytes result sent to driver
[2025-07-19T21:02:33.090+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/128/.1.delta.896b1b7b-3aad-4b22-8f14-4d04844d2892.TID495.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/128/1.delta
[2025-07-19T21:02:33.090+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=128),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/128] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/128/1.delta
[2025-07-19T21:02:33.091+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 128 (task 495, attempt 0, stage 3.0)
[2025-07-19T21:02:33.091+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.092+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.093+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 134.0 in stage 3.0 (TID 500) (8b44f3d35cfa, executor driver, partition 134, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.094+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 134.0 in stage 3.0 (TID 500)
[2025-07-19T21:02:33.094+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 119.0 in stage 3.0 (TID 490) in 134 ms on 8b44f3d35cfa (executor driver) (90/200)
[2025-07-19T21:02:33.094+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.095+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.095+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/121/.1.delta.c08288ab-b5a8-4e61-80c5-9dac91628d5d.TID492.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/121/1.delta
[2025-07-19T21:02:33.095+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=121),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/121] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/121/1.delta
[2025-07-19T21:02:33.095+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 121 (task 492, attempt 0, stage 3.0)
[2025-07-19T21:02:33.095+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@317e28f6
[2025-07-19T21:02:33.096+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=130, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.096+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=130),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/130] for update
[2025-07-19T21:02:33.097+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/129/.1.delta.1d4cc82a-f639-41b9-ac1f-e7d9bd3c4f46.TID496.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/129/1.delta
[2025-07-19T21:02:33.097+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=129),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/129] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/129/1.delta
[2025-07-19T21:02:33.098+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 129 (task 496, attempt 0, stage 3.0)
[2025-07-19T21:02:33.098+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.100+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2c5273ed
[2025-07-19T21:02:33.101+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=134, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.101+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=134),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/134] for update
[2025-07-19T21:02:33.102+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 125 (task 494, attempt 0, stage 3.0)
[2025-07-19T21:02:33.102+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.103+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 125.0 in stage 3.0 (TID 494). 9115 bytes result sent to driver
[2025-07-19T21:02:33.104+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 135.0 in stage 3.0 (TID 501) (8b44f3d35cfa, executor driver, partition 135, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.106+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 125.0 in stage 3.0 (TID 494) in 108 ms on 8b44f3d35cfa (executor driver) (91/200)
[2025-07-19T21:02:33.106+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 128 (task 495, attempt 0, stage 3.0)
[2025-07-19T21:02:33.110+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 135.0 in stage 3.0 (TID 501)
[2025-07-19T21:02:33.110+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 128.0 in stage 3.0 (TID 495). 9132 bytes result sent to driver
[2025-07-19T21:02:33.111+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 137.0 in stage 3.0 (TID 502) (8b44f3d35cfa, executor driver, partition 137, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.112+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 128.0 in stage 3.0 (TID 495) in 86 ms on 8b44f3d35cfa (executor driver) (92/200)
[2025-07-19T21:02:33.112+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a58f1df
[2025-07-19T21:02:33.112+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 137.0 in stage 3.0 (TID 502)
[2025-07-19T21:02:33.112+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=133, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.112+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=133),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/133] for update
[2025-07-19T21:02:33.112+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.112+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.113+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.114+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.114+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/130/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/130/.1.delta.d3e90f0f-b255-4850-84a1-ac9bbe4d22ec.TID497.tmp
[2025-07-19T21:02:33.114+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.114+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/134/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/134/.1.delta.0a515f11-2576-4082-b610-e5fa7a3224ae.TID500.tmp
[2025-07-19T21:02:33.115+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 129 (task 496, attempt 0, stage 3.0)
[2025-07-19T21:02:33.115+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@551dbdd7
[2025-07-19T21:02:33.115+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 121 (task 492, attempt 0, stage 3.0)
[2025-07-19T21:02:33.115+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 129.0 in stage 3.0 (TID 496). 9119 bytes result sent to driver
[2025-07-19T21:02:33.115+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 121.0 in stage 3.0 (TID 492). 9109 bytes result sent to driver
[2025-07-19T21:02:33.115+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=131, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.116+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=131),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/131] for update
[2025-07-19T21:02:33.116+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 139.0 in stage 3.0 (TID 503) (8b44f3d35cfa, executor driver, partition 139, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.116+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 141.0 in stage 3.0 (TID 504) (8b44f3d35cfa, executor driver, partition 141, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.116+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 139.0 in stage 3.0 (TID 503)
[2025-07-19T21:02:33.116+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 141.0 in stage 3.0 (TID 504)
[2025-07-19T21:02:33.116+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 121.0 in stage 3.0 (TID 492) in 141 ms on 8b44f3d35cfa (executor driver) (93/200)
[2025-07-19T21:02:33.116+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 129.0 in stage 3.0 (TID 496) in 82 ms on 8b44f3d35cfa (executor driver) (94/200)
[2025-07-19T21:02:33.118+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.119+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.120+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.120+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.120+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.123+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/131/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/131/.1.delta.b89ba64a-a4f0-4668-abb2-5a63dc90e1a1.TID498.tmp
[2025-07-19T21:02:33.124+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2245bd9c
[2025-07-19T21:02:33.125+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/133/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/133/.1.delta.203a2b65-d027-4ed1-8c42-c6eaf92b6f74.TID499.tmp
[2025-07-19T21:02:33.127+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=137, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.127+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=137),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/137] for update
[2025-07-19T21:02:33.127+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.129+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@67da0fae
[2025-07-19T21:02:33.131+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=135, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.131+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=135),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/135] for update
[2025-07-19T21:02:33.132+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.137+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/137/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/137/.1.delta.db050e5d-eb35-49fb-bfcc-385f08ef4d41.TID502.tmp
[2025-07-19T21:02:33.138+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d7e1d82
[2025-07-19T21:02:33.138+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=139, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.140+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=139),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/139] for update
[2025-07-19T21:02:33.143+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.144+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/134/.1.delta.0a515f11-2576-4082-b610-e5fa7a3224ae.TID500.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/134/1.delta
[2025-07-19T21:02:33.144+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=134),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/134] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/134/1.delta
[2025-07-19T21:02:33.144+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 134 (task 500, attempt 0, stage 3.0)
[2025-07-19T21:02:33.148+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d39fd4e
[2025-07-19T21:02:33.149+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/135/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/135/.1.delta.672bd70b-e0d7-47e4-8040-e9560b213cd9.TID501.tmp
[2025-07-19T21:02:33.150+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=141, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.150+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=141),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/141] for update
[2025-07-19T21:02:33.151+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.154+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/130/.1.delta.d3e90f0f-b255-4850-84a1-ac9bbe4d22ec.TID497.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/130/1.delta
[2025-07-19T21:02:33.154+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=130),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/130] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/130/1.delta
[2025-07-19T21:02:33.155+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/139/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/139/.1.delta.06b9d281-8006-401c-a345-c3273455d947.TID503.tmp
[2025-07-19T21:02:33.155+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 130 (task 497, attempt 0, stage 3.0)
[2025-07-19T21:02:33.161+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/141/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/141/.1.delta.bc697b8f-fce3-44a3-bd32-4b841458929a.TID504.tmp
[2025-07-19T21:02:33.172+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 134 (task 500, attempt 0, stage 3.0)
[2025-07-19T21:02:33.174+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 134.0 in stage 3.0 (TID 500). 9119 bytes result sent to driver
[2025-07-19T21:02:33.175+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 142.0 in stage 3.0 (TID 505) (8b44f3d35cfa, executor driver, partition 142, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.176+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/131/.1.delta.b89ba64a-a4f0-4668-abb2-5a63dc90e1a1.TID498.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/131/1.delta
[2025-07-19T21:02:33.176+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=131),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/131] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/131/1.delta
[2025-07-19T21:02:33.176+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 142.0 in stage 3.0 (TID 505)
[2025-07-19T21:02:33.176+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 131 (task 498, attempt 0, stage 3.0)
[2025-07-19T21:02:33.178+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 134.0 in stage 3.0 (TID 500) in 92 ms on 8b44f3d35cfa (executor driver) (95/200)
[2025-07-19T21:02:33.179+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 130 (task 497, attempt 0, stage 3.0)
[2025-07-19T21:02:33.179+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 130.0 in stage 3.0 (TID 497). 9131 bytes result sent to driver
[2025-07-19T21:02:33.180+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.181+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/137/.1.delta.db050e5d-eb35-49fb-bfcc-385f08ef4d41.TID502.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/137/1.delta
[2025-07-19T21:02:33.182+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=137),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/137] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/137/1.delta
[2025-07-19T21:02:33.182+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:33.182+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/133/.1.delta.203a2b65-d027-4ed1-8c42-c6eaf92b6f74.TID499.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/133/1.delta
[2025-07-19T21:02:33.183+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 143.0 in stage 3.0 (TID 506) (8b44f3d35cfa, executor driver, partition 143, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.184+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=133),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/133] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/133/1.delta
[2025-07-19T21:02:33.184+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 137 (task 502, attempt 0, stage 3.0)
[2025-07-19T21:02:33.185+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 130.0 in stage 3.0 (TID 497) in 110 ms on 8b44f3d35cfa (executor driver) (96/200)
[2025-07-19T21:02:33.185+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 133 (task 499, attempt 0, stage 3.0)
[2025-07-19T21:02:33.185+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 143.0 in stage 3.0 (TID 506)
[2025-07-19T21:02:33.186+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@565d7121
[2025-07-19T21:02:33.190+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/135/.1.delta.672bd70b-e0d7-47e4-8040-e9560b213cd9.TID501.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/135/1.delta
[2025-07-19T21:02:33.191+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=135),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/135] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/135/1.delta
[2025-07-19T21:02:33.193+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 135 (task 501, attempt 0, stage 3.0)
[2025-07-19T21:02:33.196+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=142, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.197+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=142),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/142] for update
[2025-07-19T21:02:33.198+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.198+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.198+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.199+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 131 (task 498, attempt 0, stage 3.0)
[2025-07-19T21:02:33.199+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 131.0 in stage 3.0 (TID 498). 9109 bytes result sent to driver
[2025-07-19T21:02:33.199+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 144.0 in stage 3.0 (TID 507) (8b44f3d35cfa, executor driver, partition 144, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.199+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 144.0 in stage 3.0 (TID 507)
[2025-07-19T21:02:33.199+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 131.0 in stage 3.0 (TID 498) in 121 ms on 8b44f3d35cfa (executor driver) (97/200)
[2025-07-19T21:02:33.202+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.202+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.203+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/139/.1.delta.06b9d281-8006-401c-a345-c3273455d947.TID503.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/139/1.delta
[2025-07-19T21:02:33.204+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=139),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/139] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/139/1.delta
[2025-07-19T21:02:33.205+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 139 (task 503, attempt 0, stage 3.0)
[2025-07-19T21:02:33.207+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 133 (task 499, attempt 0, stage 3.0)
[2025-07-19T21:02:33.208+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33a2dc7d
[2025-07-19T21:02:33.209+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 133.0 in stage 3.0 (TID 499). 9117 bytes result sent to driver
[2025-07-19T21:02:33.209+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 137 (task 502, attempt 0, stage 3.0)
[2025-07-19T21:02:33.209+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 137.0 in stage 3.0 (TID 502). 9121 bytes result sent to driver
[2025-07-19T21:02:33.209+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/141/.1.delta.bc697b8f-fce3-44a3-bd32-4b841458929a.TID504.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/141/1.delta
[2025-07-19T21:02:33.209+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/142/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/142/.1.delta.8d86edd5-d734-49ab-9943-2d3dd858601a.TID505.tmp
[2025-07-19T21:02:33.210+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=141),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/141] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/141/1.delta
[2025-07-19T21:02:33.210+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 141 (task 504, attempt 0, stage 3.0)
[2025-07-19T21:02:33.211+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=143, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.211+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=143),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/143] for update
[2025-07-19T21:02:33.212+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.216+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 145.0 in stage 3.0 (TID 508) (8b44f3d35cfa, executor driver, partition 145, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.216+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 146.0 in stage 3.0 (TID 509) (8b44f3d35cfa, executor driver, partition 146, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.216+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 137.0 in stage 3.0 (TID 502) in 110 ms on 8b44f3d35cfa (executor driver) (98/200)
[2025-07-19T21:02:33.217+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 146.0 in stage 3.0 (TID 509)
[2025-07-19T21:02:33.217+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 133.0 in stage 3.0 (TID 499) in 134 ms on 8b44f3d35cfa (executor driver) (99/200)
[2025-07-19T21:02:33.218+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 145.0 in stage 3.0 (TID 508)
[2025-07-19T21:02:33.218+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 135 (task 501, attempt 0, stage 3.0)
[2025-07-19T21:02:33.220+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.221+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.221+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 135.0 in stage 3.0 (TID 501). 9121 bytes result sent to driver
[2025-07-19T21:02:33.221+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 139 (task 503, attempt 0, stage 3.0)
[2025-07-19T21:02:33.221+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 139.0 in stage 3.0 (TID 503). 9125 bytes result sent to driver
[2025-07-19T21:02:33.221+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 147.0 in stage 3.0 (TID 510) (8b44f3d35cfa, executor driver, partition 147, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.221+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 147.0 in stage 3.0 (TID 510)
[2025-07-19T21:02:33.221+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 135.0 in stage 3.0 (TID 501) in 117 ms on 8b44f3d35cfa (executor driver) (100/200)
[2025-07-19T21:02:33.221+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e44c101
[2025-07-19T21:02:33.222+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=144, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.222+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=144),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/144] for update
[2025-07-19T21:02:33.223+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 148.0 in stage 3.0 (TID 511) (8b44f3d35cfa, executor driver, partition 148, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.223+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.225+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 148.0 in stage 3.0 (TID 511)
[2025-07-19T21:02:33.226+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.226+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.226+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 139.0 in stage 3.0 (TID 503) in 112 ms on 8b44f3d35cfa (executor driver) (101/200)
[2025-07-19T21:02:33.228+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 141 (task 504, attempt 0, stage 3.0)
[2025-07-19T21:02:33.228+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.228+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.229+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 141.0 in stage 3.0 (TID 504). 9103 bytes result sent to driver
[2025-07-19T21:02:33.229+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 149.0 in stage 3.0 (TID 512) (8b44f3d35cfa, executor driver, partition 149, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.229+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/143/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/143/.1.delta.97679027-55b9-4bcf-8fd2-d656f49c9e05.TID506.tmp
[2025-07-19T21:02:33.229+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 149.0 in stage 3.0 (TID 512)
[2025-07-19T21:02:33.229+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 141.0 in stage 3.0 (TID 504) in 114 ms on 8b44f3d35cfa (executor driver) (102/200)
[2025-07-19T21:02:33.231+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.236+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.237+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.238+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.240+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19036a1
[2025-07-19T21:02:33.241+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=146, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.241+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=146),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/146] for update
[2025-07-19T21:02:33.242+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/144/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/144/.1.delta.9411846a-007b-46b3-bc7c-6741f30df209.TID507.tmp
[2025-07-19T21:02:33.242+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.247+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56d7d824
[2025-07-19T21:02:33.247+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=145, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.247+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=145),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/145] for update
[2025-07-19T21:02:33.251+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.253+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/146/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/146/.1.delta.b4d25a9b-e58b-4cc8-9045-c3b26ae377ca.TID509.tmp
[2025-07-19T21:02:33.255+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f18deea
[2025-07-19T21:02:33.258+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=149, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.259+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=149),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/149] for update
[2025-07-19T21:02:33.260+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.260+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/142/.1.delta.8d86edd5-d734-49ab-9943-2d3dd858601a.TID505.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/142/1.delta
[2025-07-19T21:02:33.260+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=142),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/142] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/142/1.delta
[2025-07-19T21:02:33.261+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 142 (task 505, attempt 0, stage 3.0)
[2025-07-19T21:02:33.265+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/145/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/145/.1.delta.6b6387c9-155c-4c7f-8bca-d59e0e749b2a.TID508.tmp
[2025-07-19T21:02:33.268+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@9e73a1d
[2025-07-19T21:02:33.269+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=148, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.271+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=148),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/148] for update
[2025-07-19T21:02:33.273+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/143/.1.delta.97679027-55b9-4bcf-8fd2-d656f49c9e05.TID506.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/143/1.delta
[2025-07-19T21:02:33.273+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=143),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/143] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/143/1.delta
[2025-07-19T21:02:33.274+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 143 (task 506, attempt 0, stage 3.0)
[2025-07-19T21:02:33.274+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.274+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/149/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/149/.1.delta.b74cccd9-e3e6-4655-93f4-c1c8eacee56d.TID512.tmp
[2025-07-19T21:02:33.277+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/144/.1.delta.9411846a-007b-46b3-bc7c-6741f30df209.TID507.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/144/1.delta
[2025-07-19T21:02:33.277+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=144),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/144] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/144/1.delta
[2025-07-19T21:02:33.278+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 144 (task 507, attempt 0, stage 3.0)
[2025-07-19T21:02:33.281+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@794e1976
[2025-07-19T21:02:33.281+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=147, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.282+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=147),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/147] for update
[2025-07-19T21:02:33.283+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.284+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/148/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/148/.1.delta.405bfab4-5db6-4264-b1c1-21429bb1592c.TID511.tmp
[2025-07-19T21:02:33.294+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 142 (task 505, attempt 0, stage 3.0)
[2025-07-19T21:02:33.295+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 144 (task 507, attempt 0, stage 3.0)
[2025-07-19T21:02:33.296+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 144.0 in stage 3.0 (TID 507). 9137 bytes result sent to driver
[2025-07-19T21:02:33.296+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 142.0 in stage 3.0 (TID 505). 9164 bytes result sent to driver
[2025-07-19T21:02:33.299+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 150.0 in stage 3.0 (TID 513) (8b44f3d35cfa, executor driver, partition 150, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.300+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/147/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/147/.1.delta.913bde80-d067-419c-81f6-b83d31d90630.TID510.tmp
[2025-07-19T21:02:33.300+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 151.0 in stage 3.0 (TID 514) (8b44f3d35cfa, executor driver, partition 151, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.300+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 151.0 in stage 3.0 (TID 514)
[2025-07-19T21:02:33.300+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 144.0 in stage 3.0 (TID 507) in 100 ms on 8b44f3d35cfa (executor driver) (103/200)
[2025-07-19T21:02:33.300+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 150.0 in stage 3.0 (TID 513)
[2025-07-19T21:02:33.300+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 142.0 in stage 3.0 (TID 505) in 123 ms on 8b44f3d35cfa (executor driver) (104/200)
[2025-07-19T21:02:33.300+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 143 (task 506, attempt 0, stage 3.0)
[2025-07-19T21:02:33.300+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 143.0 in stage 3.0 (TID 506). 9164 bytes result sent to driver
[2025-07-19T21:02:33.301+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 153.0 in stage 3.0 (TID 515) (8b44f3d35cfa, executor driver, partition 153, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.301+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 153.0 in stage 3.0 (TID 515)
[2025-07-19T21:02:33.301+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.301+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.303+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 143.0 in stage 3.0 (TID 506) in 123 ms on 8b44f3d35cfa (executor driver) (105/200)
[2025-07-19T21:02:33.316+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.318+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.321+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@46fc1d57
[2025-07-19T21:02:33.323+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.323+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:33.323+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=151, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.324+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=151),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/151] for update
[2025-07-19T21:02:33.324+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.338+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/146/.1.delta.b4d25a9b-e58b-4cc8-9045-c3b26ae377ca.TID509.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/146/1.delta
[2025-07-19T21:02:33.340+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=146),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/146] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/146/1.delta
[2025-07-19T21:02:33.340+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@66872599
[2025-07-19T21:02:33.340+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 146 (task 509, attempt 0, stage 3.0)
[2025-07-19T21:02:33.340+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=153, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.340+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=153),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/153] for update
[2025-07-19T21:02:33.343+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.351+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/149/.1.delta.b74cccd9-e3e6-4655-93f4-c1c8eacee56d.TID512.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/149/1.delta
[2025-07-19T21:02:33.352+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=149),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/149] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/149/1.delta
[2025-07-19T21:02:33.352+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 149 (task 512, attempt 0, stage 3.0)
[2025-07-19T21:02:33.353+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/148/.1.delta.405bfab4-5db6-4264-b1c1-21429bb1592c.TID511.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/148/1.delta
[2025-07-19T21:02:33.353+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=148),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/148] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/148/1.delta
[2025-07-19T21:02:33.356+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/145/.1.delta.6b6387c9-155c-4c7f-8bca-d59e0e749b2a.TID508.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/145/1.delta
[2025-07-19T21:02:33.357+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=145),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/145] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/145/1.delta
[2025-07-19T21:02:33.358+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 145 (task 508, attempt 0, stage 3.0)
[2025-07-19T21:02:33.358+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7384de94
[2025-07-19T21:02:33.359+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 148 (task 511, attempt 0, stage 3.0)
[2025-07-19T21:02:33.361+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=150, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.361+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=150),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/150] for update
[2025-07-19T21:02:33.362+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/151/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/151/.1.delta.4dbd39e4-4361-423c-90eb-5cca4d0f36f3.TID514.tmp
[2025-07-19T21:02:33.365+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.372+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/153/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/153/.1.delta.9d2a77a8-c506-4050-bb99-1c249367c3f1.TID515.tmp
[2025-07-19T21:02:33.372+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/147/.1.delta.913bde80-d067-419c-81f6-b83d31d90630.TID510.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/147/1.delta
[2025-07-19T21:02:33.373+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=147),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/147] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/147/1.delta
[2025-07-19T21:02:33.376+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 147 (task 510, attempt 0, stage 3.0)
[2025-07-19T21:02:33.378+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 146 (task 509, attempt 0, stage 3.0)
[2025-07-19T21:02:33.379+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 146.0 in stage 3.0 (TID 509). 9146 bytes result sent to driver
[2025-07-19T21:02:33.380+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/150/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/150/.1.delta.d80096c0-1d74-4036-942b-0e1c4f1a81cf.TID513.tmp
[2025-07-19T21:02:33.380+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 154.0 in stage 3.0 (TID 516) (8b44f3d35cfa, executor driver, partition 154, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.383+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 154.0 in stage 3.0 (TID 516)
[2025-07-19T21:02:33.384+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 146.0 in stage 3.0 (TID 509) in 159 ms on 8b44f3d35cfa (executor driver) (106/200)
[2025-07-19T21:02:33.384+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.384+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.386+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 149 (task 512, attempt 0, stage 3.0)
[2025-07-19T21:02:33.389+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 149.0 in stage 3.0 (TID 512). 9162 bytes result sent to driver
[2025-07-19T21:02:33.390+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 156.0 in stage 3.0 (TID 517) (8b44f3d35cfa, executor driver, partition 156, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.390+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 156.0 in stage 3.0 (TID 517)
[2025-07-19T21:02:33.391+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 149.0 in stage 3.0 (TID 512) in 161 ms on 8b44f3d35cfa (executor driver) (107/200)
[2025-07-19T21:02:33.392+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.393+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.394+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 148 (task 511, attempt 0, stage 3.0)
[2025-07-19T21:02:33.394+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 145 (task 508, attempt 0, stage 3.0)
[2025-07-19T21:02:33.395+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 145.0 in stage 3.0 (TID 508). 9167 bytes result sent to driver
[2025-07-19T21:02:33.397+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 157.0 in stage 3.0 (TID 518) (8b44f3d35cfa, executor driver, partition 157, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.399+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 148.0 in stage 3.0 (TID 511). 9172 bytes result sent to driver
[2025-07-19T21:02:33.399+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 157.0 in stage 3.0 (TID 518)
[2025-07-19T21:02:33.399+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 158.0 in stage 3.0 (TID 519) (8b44f3d35cfa, executor driver, partition 158, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.400+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 145.0 in stage 3.0 (TID 508) in 180 ms on 8b44f3d35cfa (executor driver) (108/200)
[2025-07-19T21:02:33.400+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54fe5a68
[2025-07-19T21:02:33.400+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 158.0 in stage 3.0 (TID 519)
[2025-07-19T21:02:33.400+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=154, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.400+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=154),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/154] for update
[2025-07-19T21:02:33.407+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 147 (task 510, attempt 0, stage 3.0)
[2025-07-19T21:02:33.408+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 148.0 in stage 3.0 (TID 511) in 176 ms on 8b44f3d35cfa (executor driver) (109/200)
[2025-07-19T21:02:33.415+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.416+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 147.0 in stage 3.0 (TID 510). 9154 bytes result sent to driver
[2025-07-19T21:02:33.419+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@30e1f402
[2025-07-19T21:02:33.421+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.422+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.422+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.423+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.425+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 159.0 in stage 3.0 (TID 520) (8b44f3d35cfa, executor driver, partition 159, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.425+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=156, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.426+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=156),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/156] for update
[2025-07-19T21:02:33.426+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 159.0 in stage 3.0 (TID 520)
[2025-07-19T21:02:33.427+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 147.0 in stage 3.0 (TID 510) in 201 ms on 8b44f3d35cfa (executor driver) (110/200)
[2025-07-19T21:02:33.427+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.435+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/150/.1.delta.d80096c0-1d74-4036-942b-0e1c4f1a81cf.TID513.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/150/1.delta
[2025-07-19T21:02:33.436+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2025-07-19T21:02:33.436+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=150),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/150] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/150/1.delta
[2025-07-19T21:02:33.436+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3218e240
[2025-07-19T21:02:33.436+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.437+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/154/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/154/.1.delta.b1091811-b089-4dc6-bf5e-1fabdaed2ac1.TID516.tmp
[2025-07-19T21:02:33.437+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/153/.1.delta.9d2a77a8-c506-4050-bb99-1c249367c3f1.TID515.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/153/1.delta
[2025-07-19T21:02:33.437+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=153),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/153] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/153/1.delta
[2025-07-19T21:02:33.437+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 150 (task 513, attempt 0, stage 3.0)
[2025-07-19T21:02:33.437+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/151/.1.delta.4dbd39e4-4361-423c-90eb-5cca4d0f36f3.TID514.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/151/1.delta
[2025-07-19T21:02:33.439+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=151),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/151] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/151/1.delta
[2025-07-19T21:02:33.440+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 153 (task 515, attempt 0, stage 3.0)
[2025-07-19T21:02:33.440+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=157, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.440+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=157),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/157] for update
[2025-07-19T21:02:33.441+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 151 (task 514, attempt 0, stage 3.0)
[2025-07-19T21:02:33.446+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.456+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b94b337
[2025-07-19T21:02:33.456+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=158, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.457+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=158),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/158] for update
[2025-07-19T21:02:33.462+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/156/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/156/.1.delta.8389ea24-c034-4926-a0c3-4c08b8df2cf7.TID517.tmp
[2025-07-19T21:02:33.464+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 150 (task 513, attempt 0, stage 3.0)
[2025-07-19T21:02:33.465+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.465+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 150.0 in stage 3.0 (TID 513). 9175 bytes result sent to driver
[2025-07-19T21:02:33.466+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 151 (task 514, attempt 0, stage 3.0)
[2025-07-19T21:02:33.467+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 162.0 in stage 3.0 (TID 521) (8b44f3d35cfa, executor driver, partition 162, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.467+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 150.0 in stage 3.0 (TID 513) in 166 ms on 8b44f3d35cfa (executor driver) (111/200)
[2025-07-19T21:02:33.467+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 151.0 in stage 3.0 (TID 514). 9173 bytes result sent to driver
[2025-07-19T21:02:33.468+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 165.0 in stage 3.0 (TID 522) (8b44f3d35cfa, executor driver, partition 165, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.468+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/157/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/157/.1.delta.a9e80870-c07c-4f42-ad99-04b4bee826d3.TID518.tmp
[2025-07-19T21:02:33.469+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 165.0 in stage 3.0 (TID 522)
[2025-07-19T21:02:33.469+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 151.0 in stage 3.0 (TID 514) in 167 ms on 8b44f3d35cfa (executor driver) (112/200)
[2025-07-19T21:02:33.470+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 153 (task 515, attempt 0, stage 3.0)
[2025-07-19T21:02:33.470+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 162.0 in stage 3.0 (TID 521)
[2025-07-19T21:02:33.471+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 153.0 in stage 3.0 (TID 515). 9166 bytes result sent to driver
[2025-07-19T21:02:33.473+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.474+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2fb35795
[2025-07-19T21:02:33.474+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 167.0 in stage 3.0 (TID 523) (8b44f3d35cfa, executor driver, partition 167, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.474+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 153.0 in stage 3.0 (TID 515) in 168 ms on 8b44f3d35cfa (executor driver) (113/200)
[2025-07-19T21:02:33.474+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:33.474+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 167.0 in stage 3.0 (TID 523)
[2025-07-19T21:02:33.474+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=159, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.474+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=159),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/159] for update
[2025-07-19T21:02:33.475+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/158/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/158/.1.delta.25b057d8-963a-41dc-ae89-250ebe768d53.TID519.tmp
[2025-07-19T21:02:33.475+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.475+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.475+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.475+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.475+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:33.482+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7479a7ec
[2025-07-19T21:02:33.483+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=165, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.484+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=165),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/165] for update
[2025-07-19T21:02:33.484+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/154/.1.delta.b1091811-b089-4dc6-bf5e-1fabdaed2ac1.TID516.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/154/1.delta
[2025-07-19T21:02:33.484+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=154),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/154] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/154/1.delta
[2025-07-19T21:02:33.485+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/159/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/159/.1.delta.1ef3db45-867c-46e9-a885-ebc73bf6b923.TID520.tmp
[2025-07-19T21:02:33.485+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 154 (task 516, attempt 0, stage 3.0)
[2025-07-19T21:02:33.485+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.489+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5285dfb6
[2025-07-19T21:02:33.490+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=167, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.490+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=167),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/167] for update
[2025-07-19T21:02:33.492+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.495+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/165/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/165/.1.delta.bbd2ac88-9a08-49c7-b3f0-4d5771fe3938.TID522.tmp
[2025-07-19T21:02:33.499+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@495a6e19
[2025-07-19T21:02:33.500+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=162, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.500+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=162),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/162] for update
[2025-07-19T21:02:33.501+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/156/.1.delta.8389ea24-c034-4926-a0c3-4c08b8df2cf7.TID517.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/156/1.delta
[2025-07-19T21:02:33.501+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=156),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/156] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/156/1.delta
[2025-07-19T21:02:33.502+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 156 (task 517, attempt 0, stage 3.0)
[2025-07-19T21:02:33.502+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.504+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 154 (task 516, attempt 0, stage 3.0)
[2025-07-19T21:02:33.506+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/167/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/167/.1.delta.6774d820-ae92-406c-a508-dc034c957587.TID523.tmp
[2025-07-19T21:02:33.506+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 154.0 in stage 3.0 (TID 516). 9117 bytes result sent to driver
[2025-07-19T21:02:33.507+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 168.0 in stage 3.0 (TID 524) (8b44f3d35cfa, executor driver, partition 168, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.510+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 154.0 in stage 3.0 (TID 516) in 136 ms on 8b44f3d35cfa (executor driver) (114/200)
[2025-07-19T21:02:33.510+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/162/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/162/.1.delta.86f04cd2-b36d-477e-a27e-1738c1f2a2d3.TID521.tmp
[2025-07-19T21:02:33.511+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 168.0 in stage 3.0 (TID 524)
[2025-07-19T21:02:33.523+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.525+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2025-07-19T21:02:33.531+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/158/.1.delta.25b057d8-963a-41dc-ae89-250ebe768d53.TID519.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/158/1.delta
[2025-07-19T21:02:33.532+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=158),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/158] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/158/1.delta
[2025-07-19T21:02:33.534+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/157/.1.delta.a9e80870-c07c-4f42-ad99-04b4bee826d3.TID518.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/157/1.delta
[2025-07-19T21:02:33.534+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=157),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/157] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/157/1.delta
[2025-07-19T21:02:33.535+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 157 (task 518, attempt 0, stage 3.0)
[2025-07-19T21:02:33.536+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 158 (task 519, attempt 0, stage 3.0)
[2025-07-19T21:02:33.536+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 156 (task 517, attempt 0, stage 3.0)
[2025-07-19T21:02:33.546+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 156.0 in stage 3.0 (TID 517). 9123 bytes result sent to driver
[2025-07-19T21:02:33.547+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 169.0 in stage 3.0 (TID 525) (8b44f3d35cfa, executor driver, partition 169, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.547+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 169.0 in stage 3.0 (TID 525)
[2025-07-19T21:02:33.548+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 156.0 in stage 3.0 (TID 517) in 157 ms on 8b44f3d35cfa (executor driver) (115/200)
[2025-07-19T21:02:33.552+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@667cb16d
[2025-07-19T21:02:33.553+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=168, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.554+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=168),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/168] for update
[2025-07-19T21:02:33.568+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.571+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/159/.1.delta.1ef3db45-867c-46e9-a885-ebc73bf6b923.TID520.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/159/1.delta
[2025-07-19T21:02:33.574+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=159),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/159] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/159/1.delta
[2025-07-19T21:02:33.575+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.575+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 159 (task 520, attempt 0, stage 3.0)
[2025-07-19T21:02:33.581+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T21:02:33.585+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/168/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/168/.1.delta.453a81db-f688-4942-ae0b-044144422e4d.TID524.tmp
[2025-07-19T21:02:33.598+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 157 (task 518, attempt 0, stage 3.0)
[2025-07-19T21:02:33.600+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 157.0 in stage 3.0 (TID 518). 9124 bytes result sent to driver
[2025-07-19T21:02:33.604+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@29af5439
[2025-07-19T21:02:33.605+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 170.0 in stage 3.0 (TID 526) (8b44f3d35cfa, executor driver, partition 170, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.605+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=169, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.605+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=169),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/169] for update
[2025-07-19T21:02:33.605+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 157.0 in stage 3.0 (TID 518) in 198 ms on 8b44f3d35cfa (executor driver) (116/200)
[2025-07-19T21:02:33.605+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 170.0 in stage 3.0 (TID 526)
[2025-07-19T21:02:33.606+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 158 (task 519, attempt 0, stage 3.0)
[2025-07-19T21:02:33.606+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 158.0 in stage 3.0 (TID 519). 9122 bytes result sent to driver
[2025-07-19T21:02:33.607+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/167/.1.delta.6774d820-ae92-406c-a508-dc034c957587.TID523.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/167/1.delta
[2025-07-19T21:02:33.607+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=167),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/167] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/167/1.delta
[2025-07-19T21:02:33.607+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 167 (task 523, attempt 0, stage 3.0)
[2025-07-19T21:02:33.607+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 171.0 in stage 3.0 (TID 527) (8b44f3d35cfa, executor driver, partition 171, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.609+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.610+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 158.0 in stage 3.0 (TID 519) in 203 ms on 8b44f3d35cfa (executor driver) (117/200)
[2025-07-19T21:02:33.610+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.611+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.611+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 171.0 in stage 3.0 (TID 527)
[2025-07-19T21:02:33.612+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.613+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.614+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/165/.1.delta.bbd2ac88-9a08-49c7-b3f0-4d5771fe3938.TID522.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/165/1.delta
[2025-07-19T21:02:33.615+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=165),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/165] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/165/1.delta
[2025-07-19T21:02:33.615+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 165 (task 522, attempt 0, stage 3.0)
[2025-07-19T21:02:33.616+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5829a755
[2025-07-19T21:02:33.616+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=170, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.616+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 159 (task 520, attempt 0, stage 3.0)
[2025-07-19T21:02:33.616+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=170),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/170] for update
[2025-07-19T21:02:33.617+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/169/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/169/.1.delta.6dbd86c9-fd6f-4825-9719-09a803de7af3.TID525.tmp
[2025-07-19T21:02:33.618+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 159.0 in stage 3.0 (TID 520). 9122 bytes result sent to driver
[2025-07-19T21:02:33.618+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 172.0 in stage 3.0 (TID 528) (8b44f3d35cfa, executor driver, partition 172, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.618+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 159.0 in stage 3.0 (TID 520) in 197 ms on 8b44f3d35cfa (executor driver) (118/200)
[2025-07-19T21:02:33.619+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 167 (task 523, attempt 0, stage 3.0)
[2025-07-19T21:02:33.619+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.620+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 172.0 in stage 3.0 (TID 528)
[2025-07-19T21:02:33.620+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 167.0 in stage 3.0 (TID 523). 9119 bytes result sent to driver
[2025-07-19T21:02:33.622+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 173.0 in stage 3.0 (TID 529) (8b44f3d35cfa, executor driver, partition 173, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.622+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/162/.1.delta.86f04cd2-b36d-477e-a27e-1738c1f2a2d3.TID521.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/162/1.delta
[2025-07-19T21:02:33.623+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=162),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/162] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/162/1.delta
[2025-07-19T21:02:33.624+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 173.0 in stage 3.0 (TID 529)
[2025-07-19T21:02:33.625+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 167.0 in stage 3.0 (TID 523) in 155 ms on 8b44f3d35cfa (executor driver) (119/200)
[2025-07-19T21:02:33.625+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 162 (task 521, attempt 0, stage 3.0)
[2025-07-19T21:02:33.625+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.626+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.627+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.627+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.628+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c44ed2a
[2025-07-19T21:02:33.628+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=171, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.629+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=171),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/171] for update
[2025-07-19T21:02:33.629+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.630+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 165 (task 522, attempt 0, stage 3.0)
[2025-07-19T21:02:33.630+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 165.0 in stage 3.0 (TID 522). 9109 bytes result sent to driver
[2025-07-19T21:02:33.632+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 174.0 in stage 3.0 (TID 530) (8b44f3d35cfa, executor driver, partition 174, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.634+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 174.0 in stage 3.0 (TID 530)
[2025-07-19T21:02:33.636+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/170/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/170/.1.delta.da96eb22-c624-4997-86ae-66152d91cacb.TID526.tmp
[2025-07-19T21:02:33.637+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 165.0 in stage 3.0 (TID 522) in 172 ms on 8b44f3d35cfa (executor driver) (120/200)
[2025-07-19T21:02:33.637+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.637+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.638+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2dd74ae2
[2025-07-19T21:02:33.640+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=173, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.641+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/171/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/171/.1.delta.cb39d638-a781-4f51-8626-99416cd29ac1.TID527.tmp
[2025-07-19T21:02:33.642+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=173),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/173] for update
[2025-07-19T21:02:33.643+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 162 (task 521, attempt 0, stage 3.0)
[2025-07-19T21:02:33.644+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 162.0 in stage 3.0 (TID 521). 9103 bytes result sent to driver
[2025-07-19T21:02:33.645+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 175.0 in stage 3.0 (TID 531) (8b44f3d35cfa, executor driver, partition 175, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.646+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 175.0 in stage 3.0 (TID 531)
[2025-07-19T21:02:33.646+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 162.0 in stage 3.0 (TID 521) in 183 ms on 8b44f3d35cfa (executor driver) (121/200)
[2025-07-19T21:02:33.647+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.647+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.647+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.651+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@41215ec3
[2025-07-19T21:02:33.652+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=172, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.652+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=172),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/172] for update
[2025-07-19T21:02:33.653+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.655+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/173/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/173/.1.delta.c2afa919-2c39-4e23-a8b4-a34c29bc9ebd.TID529.tmp
[2025-07-19T21:02:33.658+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@170810b5
[2025-07-19T21:02:33.659+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=175, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.660+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=175),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/175] for update
[2025-07-19T21:02:33.661+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/168/.1.delta.453a81db-f688-4942-ae0b-044144422e4d.TID524.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/168/1.delta
[2025-07-19T21:02:33.661+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=168),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/168] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/168/1.delta
[2025-07-19T21:02:33.661+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 168 (task 524, attempt 0, stage 3.0)
[2025-07-19T21:02:33.663+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/172/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/172/.1.delta.5ea7d64e-3684-48c3-a9c8-2271e0799ca2.TID528.tmp
[2025-07-19T21:02:33.665+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.669+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22a2a3a5
[2025-07-19T21:02:33.669+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=174, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.670+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=174),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/174] for update
[2025-07-19T21:02:33.670+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/169/.1.delta.6dbd86c9-fd6f-4825-9719-09a803de7af3.TID525.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/169/1.delta
[2025-07-19T21:02:33.671+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=169),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/169] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/169/1.delta
[2025-07-19T21:02:33.672+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 169 (task 525, attempt 0, stage 3.0)
[2025-07-19T21:02:33.672+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.672+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/175/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/175/.1.delta.dc84148e-dee2-4cff-9ddf-403663d03486.TID531.tmp
[2025-07-19T21:02:33.679+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 168 (task 524, attempt 0, stage 3.0)
[2025-07-19T21:02:33.679+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 168.0 in stage 3.0 (TID 524). 9124 bytes result sent to driver
[2025-07-19T21:02:33.680+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 178.0 in stage 3.0 (TID 532) (8b44f3d35cfa, executor driver, partition 178, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.681+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 178.0 in stage 3.0 (TID 532)
[2025-07-19T21:02:33.682+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 168.0 in stage 3.0 (TID 524) in 173 ms on 8b44f3d35cfa (executor driver) (122/200)
[2025-07-19T21:02:33.683+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/170/.1.delta.da96eb22-c624-4997-86ae-66152d91cacb.TID526.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/170/1.delta
[2025-07-19T21:02:33.683+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=170),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/170] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/170/1.delta
[2025-07-19T21:02:33.683+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 170 (task 526, attempt 0, stage 3.0)
[2025-07-19T21:02:33.684+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/174/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/174/.1.delta.2f4a9e66-d1df-40c6-8d61-23a40f6936ae.TID530.tmp
[2025-07-19T21:02:33.684+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.684+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.689+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/171/.1.delta.cb39d638-a781-4f51-8626-99416cd29ac1.TID527.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/171/1.delta
[2025-07-19T21:02:33.691+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=171),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/171] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/171/1.delta
[2025-07-19T21:02:33.692+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 171 (task 527, attempt 0, stage 3.0)
[2025-07-19T21:02:33.692+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 169 (task 525, attempt 0, stage 3.0)
[2025-07-19T21:02:33.693+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@86454b1
[2025-07-19T21:02:33.694+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 169.0 in stage 3.0 (TID 525). 9111 bytes result sent to driver
[2025-07-19T21:02:33.694+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=178, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.695+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=178),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/178] for update
[2025-07-19T21:02:33.695+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 179.0 in stage 3.0 (TID 533) (8b44f3d35cfa, executor driver, partition 179, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.695+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 169.0 in stage 3.0 (TID 525) in 150 ms on 8b44f3d35cfa (executor driver) (123/200)
[2025-07-19T21:02:33.696+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 179.0 in stage 3.0 (TID 533)
[2025-07-19T21:02:33.697+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.700+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 170 (task 526, attempt 0, stage 3.0)
[2025-07-19T21:02:33.702+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 170.0 in stage 3.0 (TID 526). 9111 bytes result sent to driver
[2025-07-19T21:02:33.704+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 170.0 in stage 3.0 (TID 526) in 111 ms on 8b44f3d35cfa (executor driver) (124/200)
[2025-07-19T21:02:33.704+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/173/.1.delta.c2afa919-2c39-4e23-a8b4-a34c29bc9ebd.TID529.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/173/1.delta
[2025-07-19T21:02:33.705+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 180.0 in stage 3.0 (TID 534) (8b44f3d35cfa, executor driver, partition 180, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.705+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=173),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/173] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/173/1.delta
[2025-07-19T21:02:33.706+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 180.0 in stage 3.0 (TID 534)
[2025-07-19T21:02:33.706+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 173 (task 529, attempt 0, stage 3.0)
[2025-07-19T21:02:33.707+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.708+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.709+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.710+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.710+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b3f874a
[2025-07-19T21:02:33.711+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=179, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.711+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=179),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/179] for update
[2025-07-19T21:02:33.712+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/178/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/178/.1.delta.88115606-13b9-48ca-bef7-b05dd688d812.TID532.tmp
[2025-07-19T21:02:33.713+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 171 (task 527, attempt 0, stage 3.0)
[2025-07-19T21:02:33.713+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.713+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 171.0 in stage 3.0 (TID 527). 9119 bytes result sent to driver
[2025-07-19T21:02:33.713+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 181.0 in stage 3.0 (TID 535) (8b44f3d35cfa, executor driver, partition 181, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.713+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 181.0 in stage 3.0 (TID 535)
[2025-07-19T21:02:33.714+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 171.0 in stage 3.0 (TID 527) in 118 ms on 8b44f3d35cfa (executor driver) (125/200)
[2025-07-19T21:02:33.714+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/175/.1.delta.dc84148e-dee2-4cff-9ddf-403663d03486.TID531.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/175/1.delta
[2025-07-19T21:02:33.715+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=175),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/175] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/175/1.delta
[2025-07-19T21:02:33.715+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 175 (task 531, attempt 0, stage 3.0)
[2025-07-19T21:02:33.720+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 173 (task 529, attempt 0, stage 3.0)
[2025-07-19T21:02:33.720+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@669f29d5
[2025-07-19T21:02:33.721+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=180, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.721+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/172/.1.delta.5ea7d64e-3684-48c3-a9c8-2271e0799ca2.TID528.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/172/1.delta
[2025-07-19T21:02:33.721+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=180),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/180] for update
[2025-07-19T21:02:33.722+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=172),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/172] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/172/1.delta
[2025-07-19T21:02:33.722+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 173.0 in stage 3.0 (TID 529). 9115 bytes result sent to driver
[2025-07-19T21:02:33.723+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 172 (task 528, attempt 0, stage 3.0)
[2025-07-19T21:02:33.723+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 182.0 in stage 3.0 (TID 536) (8b44f3d35cfa, executor driver, partition 182, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.723+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 182.0 in stage 3.0 (TID 536)
[2025-07-19T21:02:33.724+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.724+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 173.0 in stage 3.0 (TID 529) in 99 ms on 8b44f3d35cfa (executor driver) (126/200)
[2025-07-19T21:02:33.724+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.724+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:33.724+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.724+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.727+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 175 (task 531, attempt 0, stage 3.0)
[2025-07-19T21:02:33.728+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 175.0 in stage 3.0 (TID 531). 9109 bytes result sent to driver
[2025-07-19T21:02:33.728+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 172 (task 528, attempt 0, stage 3.0)
[2025-07-19T21:02:33.729+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 172.0 in stage 3.0 (TID 528). 9110 bytes result sent to driver
[2025-07-19T21:02:33.730+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 183.0 in stage 3.0 (TID 537) (8b44f3d35cfa, executor driver, partition 183, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.731+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 184.0 in stage 3.0 (TID 538) (8b44f3d35cfa, executor driver, partition 184, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.732+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 175.0 in stage 3.0 (TID 531) in 87 ms on 8b44f3d35cfa (executor driver) (127/200)
[2025-07-19T21:02:33.733+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 184.0 in stage 3.0 (TID 538)
[2025-07-19T21:02:33.733+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 183.0 in stage 3.0 (TID 537)
[2025-07-19T21:02:33.734+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 172.0 in stage 3.0 (TID 528) in 114 ms on 8b44f3d35cfa (executor driver) (128/200)
[2025-07-19T21:02:33.734+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/179/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/179/.1.delta.c2e6bc0e-817c-4c78-a8c5-bb6b6b145771.TID533.tmp
[2025-07-19T21:02:33.734+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/174/.1.delta.2f4a9e66-d1df-40c6-8d61-23a40f6936ae.TID530.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/174/1.delta
[2025-07-19T21:02:33.735+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=174),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/174] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/174/1.delta
[2025-07-19T21:02:33.735+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 174 (task 530, attempt 0, stage 3.0)
[2025-07-19T21:02:33.736+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.737+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.737+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.737+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.738+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2c28272
[2025-07-19T21:02:33.738+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/180/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/180/.1.delta.9f91daf3-2a9e-433a-ba8b-ca31fb05b407.TID534.tmp
[2025-07-19T21:02:33.738+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=181, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.738+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=181),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/181] for update
[2025-07-19T21:02:33.739+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.743+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@cdee591
[2025-07-19T21:02:33.744+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=183, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.745+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=183),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/183] for update
[2025-07-19T21:02:33.745+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 174 (task 530, attempt 0, stage 3.0)
[2025-07-19T21:02:33.745+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 174.0 in stage 3.0 (TID 530). 9101 bytes result sent to driver
[2025-07-19T21:02:33.745+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.746+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 185.0 in stage 3.0 (TID 539) (8b44f3d35cfa, executor driver, partition 185, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.746+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/181/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/181/.1.delta.21f13554-6054-4ab1-ae25-7754ae30c214.TID535.tmp
[2025-07-19T21:02:33.746+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 185.0 in stage 3.0 (TID 539)
[2025-07-19T21:02:33.746+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 174.0 in stage 3.0 (TID 530) in 114 ms on 8b44f3d35cfa (executor driver) (129/200)
[2025-07-19T21:02:33.748+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.748+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.750+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2839fdcf
[2025-07-19T21:02:33.751+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=184, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.751+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=184),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/184] for update
[2025-07-19T21:02:33.754+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/183/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/183/.1.delta.4ed09c3c-c6ba-4e11-acf3-a3f4a857918d.TID537.tmp
[2025-07-19T21:02:33.755+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/178/.1.delta.88115606-13b9-48ca-bef7-b05dd688d812.TID532.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/178/1.delta
[2025-07-19T21:02:33.755+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=178),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/178] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/178/1.delta
[2025-07-19T21:02:33.755+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.756+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 178 (task 532, attempt 0, stage 3.0)
[2025-07-19T21:02:33.758+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6bbef24e
[2025-07-19T21:02:33.759+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=182, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.759+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=182),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/182] for update
[2025-07-19T21:02:33.760+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.768+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@67ab484c
[2025-07-19T21:02:33.769+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/179/.1.delta.c2e6bc0e-817c-4c78-a8c5-bb6b6b145771.TID533.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/179/1.delta
[2025-07-19T21:02:33.769+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=179),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/179] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/179/1.delta
[2025-07-19T21:02:33.769+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=185, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.770+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=185),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/185] for update
[2025-07-19T21:02:33.771+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/182/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/182/.1.delta.1e1136a5-9ff2-4439-9e9e-eb0a8c2796d4.TID536.tmp
[2025-07-19T21:02:33.772+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 179 (task 533, attempt 0, stage 3.0)
[2025-07-19T21:02:33.772+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/184/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/184/.1.delta.4287a1d8-a99b-47d8-bac6-01e2059917b7.TID538.tmp
[2025-07-19T21:02:33.772+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.775+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 178 (task 532, attempt 0, stage 3.0)
[2025-07-19T21:02:33.775+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 178.0 in stage 3.0 (TID 532). 9113 bytes result sent to driver
[2025-07-19T21:02:33.777+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 187.0 in stage 3.0 (TID 540) (8b44f3d35cfa, executor driver, partition 187, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.777+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/180/.1.delta.9f91daf3-2a9e-433a-ba8b-ca31fb05b407.TID534.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/180/1.delta
[2025-07-19T21:02:33.778+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=180),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/180] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/180/1.delta
[2025-07-19T21:02:33.778+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 178.0 in stage 3.0 (TID 532) in 98 ms on 8b44f3d35cfa (executor driver) (130/200)
[2025-07-19T21:02:33.779+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 187.0 in stage 3.0 (TID 540)
[2025-07-19T21:02:33.779+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.781+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.785+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 179 (task 533, attempt 0, stage 3.0)
[2025-07-19T21:02:33.787+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 180 (task 534, attempt 0, stage 3.0)
[2025-07-19T21:02:33.787+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 179.0 in stage 3.0 (TID 533). 9107 bytes result sent to driver
[2025-07-19T21:02:33.788+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/185/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/185/.1.delta.cdbdd738-d676-48d8-8bff-fda74902b99e.TID539.tmp
[2025-07-19T21:02:33.788+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 188.0 in stage 3.0 (TID 541) (8b44f3d35cfa, executor driver, partition 188, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.788+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 188.0 in stage 3.0 (TID 541)
[2025-07-19T21:02:33.790+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.791+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.792+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 179.0 in stage 3.0 (TID 533) in 95 ms on 8b44f3d35cfa (executor driver) (131/200)
[2025-07-19T21:02:33.792+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d21a808
[2025-07-19T21:02:33.793+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=187, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.793+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=187),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/187] for update
[2025-07-19T21:02:33.793+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.799+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 180 (task 534, attempt 0, stage 3.0)
[2025-07-19T21:02:33.800+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/183/.1.delta.4ed09c3c-c6ba-4e11-acf3-a3f4a857918d.TID537.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/183/1.delta
[2025-07-19T21:02:33.800+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=183),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/183] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/183/1.delta
[2025-07-19T21:02:33.802+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 183 (task 537, attempt 0, stage 3.0)
[2025-07-19T21:02:33.802+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/181/.1.delta.21f13554-6054-4ab1-ae25-7754ae30c214.TID535.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/181/1.delta
[2025-07-19T21:02:33.802+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=181),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/181] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/181/1.delta
[2025-07-19T21:02:33.802+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 180.0 in stage 3.0 (TID 534). 9150 bytes result sent to driver
[2025-07-19T21:02:33.802+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1f9cd888
[2025-07-19T21:02:33.803+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 189.0 in stage 3.0 (TID 542) (8b44f3d35cfa, executor driver, partition 189, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.803+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 181 (task 535, attempt 0, stage 3.0)
[2025-07-19T21:02:33.803+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 189.0 in stage 3.0 (TID 542)
[2025-07-19T21:02:33.803+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 180.0 in stage 3.0 (TID 534) in 100 ms on 8b44f3d35cfa (executor driver) (132/200)
[2025-07-19T21:02:33.803+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=188, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.803+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=188),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/188] for update
[2025-07-19T21:02:33.806+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.807+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.807+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.808+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/187/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/187/.1.delta.3ec4b49d-c0d9-4ea5-b369-5716aa406ebc.TID540.tmp
[2025-07-19T21:02:33.816+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23179cd5
[2025-07-19T21:02:33.819+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=189, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.820+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=189),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/189] for update
[2025-07-19T21:02:33.828+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.829+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 183 (task 537, attempt 0, stage 3.0)
[2025-07-19T21:02:33.829+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 183.0 in stage 3.0 (TID 537). 9141 bytes result sent to driver
[2025-07-19T21:02:33.831+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 192.0 in stage 3.0 (TID 543) (8b44f3d35cfa, executor driver, partition 192, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.831+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 183.0 in stage 3.0 (TID 537) in 98 ms on 8b44f3d35cfa (executor driver) (133/200)
[2025-07-19T21:02:33.832+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 192.0 in stage 3.0 (TID 543)
[2025-07-19T21:02:33.833+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/184/.1.delta.4287a1d8-a99b-47d8-bac6-01e2059917b7.TID538.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/184/1.delta
[2025-07-19T21:02:33.833+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=184),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/184] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/184/1.delta
[2025-07-19T21:02:33.833+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/188/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/188/.1.delta.5a054c92-9ba8-4dd5-953c-fbc2b85857c8.TID541.tmp
[2025-07-19T21:02:33.834+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/182/.1.delta.1e1136a5-9ff2-4439-9e9e-eb0a8c2796d4.TID536.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/182/1.delta
[2025-07-19T21:02:33.835+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=182),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/182] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/182/1.delta
[2025-07-19T21:02:33.835+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.836+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.837+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 182 (task 536, attempt 0, stage 3.0)
[2025-07-19T21:02:33.837+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 184 (task 538, attempt 0, stage 3.0)
[2025-07-19T21:02:33.838+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 181 (task 535, attempt 0, stage 3.0)
[2025-07-19T21:02:33.838+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 181.0 in stage 3.0 (TID 535). 9113 bytes result sent to driver
[2025-07-19T21:02:33.838+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 194.0 in stage 3.0 (TID 544) (8b44f3d35cfa, executor driver, partition 194, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.839+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 181.0 in stage 3.0 (TID 535) in 120 ms on 8b44f3d35cfa (executor driver) (134/200)
[2025-07-19T21:02:33.839+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 194.0 in stage 3.0 (TID 544)
[2025-07-19T21:02:33.839+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.841+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/189/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/189/.1.delta.6163bb11-bdaf-4677-9165-4de35453f98d.TID542.tmp
[2025-07-19T21:02:33.842+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2025-07-19T21:02:33.847+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 182 (task 536, attempt 0, stage 3.0)
[2025-07-19T21:02:33.849+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 182.0 in stage 3.0 (TID 536). 9118 bytes result sent to driver
[2025-07-19T21:02:33.850+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 196.0 in stage 3.0 (TID 545) (8b44f3d35cfa, executor driver, partition 196, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.850+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@667342cb
[2025-07-19T21:02:33.850+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 196.0 in stage 3.0 (TID 545)
[2025-07-19T21:02:33.851+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 182.0 in stage 3.0 (TID 536) in 132 ms on 8b44f3d35cfa (executor driver) (135/200)
[2025-07-19T21:02:33.851+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=192, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.854+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.854+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=192),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/192] for update
[2025-07-19T21:02:33.854+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 184 (task 538, attempt 0, stage 3.0)
[2025-07-19T21:02:33.854+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:33.857+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 184.0 in stage 3.0 (TID 538). 9107 bytes result sent to driver
[2025-07-19T21:02:33.858+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.858+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 184.0 in stage 3.0 (TID 538) in 125 ms on 8b44f3d35cfa (executor driver) (136/200)
[2025-07-19T21:02:33.862+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 197.0 in stage 3.0 (TID 546) (8b44f3d35cfa, executor driver, partition 197, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.863+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 197.0 in stage 3.0 (TID 546)
[2025-07-19T21:02:33.864+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/187/.1.delta.3ec4b49d-c0d9-4ea5-b369-5716aa406ebc.TID540.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/187/1.delta
[2025-07-19T21:02:33.864+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=187),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/187] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/187/1.delta
[2025-07-19T21:02:33.866+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 187 (task 540, attempt 0, stage 3.0)
[2025-07-19T21:02:33.867+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.870+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.870+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/185/.1.delta.cdbdd738-d676-48d8-8bff-fda74902b99e.TID539.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/185/1.delta
[2025-07-19T21:02:33.872+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=185),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/185] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/185/1.delta
[2025-07-19T21:02:33.873+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 185 (task 539, attempt 0, stage 3.0)
[2025-07-19T21:02:33.873+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ca60318
[2025-07-19T21:02:33.873+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=196, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.873+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=196),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/196] for update
[2025-07-19T21:02:33.873+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/192/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/192/.1.delta.44a8986c-08ef-43d3-b19b-07c1e77f0697.TID543.tmp
[2025-07-19T21:02:33.875+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.876+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/188/.1.delta.5a054c92-9ba8-4dd5-953c-fbc2b85857c8.TID541.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/188/1.delta
[2025-07-19T21:02:33.877+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=188),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/188] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/188/1.delta
[2025-07-19T21:02:33.877+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 188 (task 541, attempt 0, stage 3.0)
[2025-07-19T21:02:33.880+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 185 (task 539, attempt 0, stage 3.0)
[2025-07-19T21:02:33.883+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 185.0 in stage 3.0 (TID 539). 9156 bytes result sent to driver
[2025-07-19T21:02:33.884+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1f50084
[2025-07-19T21:02:33.884+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 198.0 in stage 3.0 (TID 547) (8b44f3d35cfa, executor driver, partition 198, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.885+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=194, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.885+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 198.0 in stage 3.0 (TID 547)
[2025-07-19T21:02:33.885+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=194),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/194] for update
[2025-07-19T21:02:33.885+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 185.0 in stage 3.0 (TID 539) in 137 ms on 8b44f3d35cfa (executor driver) (137/200)
[2025-07-19T21:02:33.885+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.886+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.886+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.887+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@61ba470
[2025-07-19T21:02:33.888+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/196/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/196/.1.delta.401fd4b2-5a71-4cf8-9c22-8fb06782bef4.TID545.tmp
[2025-07-19T21:02:33.888+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=197, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.889+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=197),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/197] for update
[2025-07-19T21:02:33.890+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.890+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 187 (task 540, attempt 0, stage 3.0)
[2025-07-19T21:02:33.897+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 187.0 in stage 3.0 (TID 540). 9214 bytes result sent to driver
[2025-07-19T21:02:33.898+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/197/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/197/.1.delta.8753aa29-38f7-4741-b1c6-2454cb346506.TID546.tmp
[2025-07-19T21:02:33.898+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 188 (task 541, attempt 0, stage 3.0)
[2025-07-19T21:02:33.898+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 188.0 in stage 3.0 (TID 541). 9163 bytes result sent to driver
[2025-07-19T21:02:33.899+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 187.0 in stage 3.0 (TID 540) in 119 ms on 8b44f3d35cfa (executor driver) (138/200)
[2025-07-19T21:02:33.899+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 199.0 in stage 3.0 (TID 548) (8b44f3d35cfa, executor driver, partition 199, NODE_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.901+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 5.0 in stage 3.0 (TID 549) (8b44f3d35cfa, executor driver, partition 5, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.901+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 5.0 in stage 3.0 (TID 549)
[2025-07-19T21:02:33.902+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3cc9b74e
[2025-07-19T21:02:33.902+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 199.0 in stage 3.0 (TID 548)
[2025-07-19T21:02:33.903+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=198, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.904+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=198),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/198] for update
[2025-07-19T21:02:33.905+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 188.0 in stage 3.0 (TID 541) in 114 ms on 8b44f3d35cfa (executor driver) (139/200)
[2025-07-19T21:02:33.905+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.905+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/194/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/194/.1.delta.4ca4dd4f-9d17-420c-b190-66a928f2c362.TID544.tmp
[2025-07-19T21:02:33.906+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.906+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.907+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/189/.1.delta.6163bb11-bdaf-4677-9165-4de35453f98d.TID542.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/189/1.delta
[2025-07-19T21:02:33.907+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=189),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/189] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/189/1.delta
[2025-07-19T21:02:33.908+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 189 (task 542, attempt 0, stage 3.0)
[2025-07-19T21:02:33.908+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.908+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.910+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@21568ea2
[2025-07-19T21:02:33.911+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=199, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.912+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=199),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/199] for update
[2025-07-19T21:02:33.912+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/198/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/198/.1.delta.52e9108b-1b6a-4637-8950-e906cc6bb263.TID547.tmp
[2025-07-19T21:02:33.912+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.919+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28a89810
[2025-07-19T21:02:33.920+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=5, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.921+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/5] for update
[2025-07-19T21:02:33.922+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.923+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 189 (task 542, attempt 0, stage 3.0)
[2025-07-19T21:02:33.923+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 189.0 in stage 3.0 (TID 542). 9158 bytes result sent to driver
[2025-07-19T21:02:33.924+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 6.0 in stage 3.0 (TID 550) (8b44f3d35cfa, executor driver, partition 6, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.925+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 6.0 in stage 3.0 (TID 550)
[2025-07-19T21:02:33.925+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/199/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/199/.1.delta.5cbe8ad9-55cb-4778-bfd0-bf41cd9a5a0e.TID548.tmp
[2025-07-19T21:02:33.925+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 189.0 in stage 3.0 (TID 542) in 125 ms on 8b44f3d35cfa (executor driver) (140/200)
[2025-07-19T21:02:33.926+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/192/.1.delta.44a8986c-08ef-43d3-b19b-07c1e77f0697.TID543.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/192/1.delta
[2025-07-19T21:02:33.927+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=192),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/192] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/192/1.delta
[2025-07-19T21:02:33.927+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 192 (task 543, attempt 0, stage 3.0)
[2025-07-19T21:02:33.927+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.928+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.930+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/196/.1.delta.401fd4b2-5a71-4cf8-9c22-8fb06782bef4.TID545.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/196/1.delta
[2025-07-19T21:02:33.930+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=196),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/196] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/196/1.delta
[2025-07-19T21:02:33.932+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 196 (task 545, attempt 0, stage 3.0)
[2025-07-19T21:02:33.933+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@469c3e18
[2025-07-19T21:02:33.937+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=6, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.937+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/6] for update
[2025-07-19T21:02:33.938+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/5/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/5/.1.delta.9911c1c2-32d7-4eb7-aafa-e626cc847b5e.TID549.tmp
[2025-07-19T21:02:33.938+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.942+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 192 (task 543, attempt 0, stage 3.0)
[2025-07-19T21:02:33.943+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/194/.1.delta.4ca4dd4f-9d17-420c-b190-66a928f2c362.TID544.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/194/1.delta
[2025-07-19T21:02:33.943+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=194),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/194] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/194/1.delta
[2025-07-19T21:02:33.944+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 192.0 in stage 3.0 (TID 543). 9150 bytes result sent to driver
[2025-07-19T21:02:33.944+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 17.0 in stage 3.0 (TID 551) (8b44f3d35cfa, executor driver, partition 17, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.945+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 192.0 in stage 3.0 (TID 543) in 120 ms on 8b44f3d35cfa (executor driver) (141/200)
[2025-07-19T21:02:33.945+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 194 (task 544, attempt 0, stage 3.0)
[2025-07-19T21:02:33.946+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/6/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/6/.1.delta.eb934da1-0aa5-4858-86e8-977f5990b33a.TID550.tmp
[2025-07-19T21:02:33.946+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 17.0 in stage 3.0 (TID 551)
[2025-07-19T21:02:33.949+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.951+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.951+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 196 (task 545, attempt 0, stage 3.0)
[2025-07-19T21:02:33.951+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 196.0 in stage 3.0 (TID 545). 9150 bytes result sent to driver
[2025-07-19T21:02:33.951+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/197/.1.delta.8753aa29-38f7-4741-b1c6-2454cb346506.TID546.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/197/1.delta
[2025-07-19T21:02:33.953+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=197),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/197] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/197/1.delta
[2025-07-19T21:02:33.954+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 19.0 in stage 3.0 (TID 552) (8b44f3d35cfa, executor driver, partition 19, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.955+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 19.0 in stage 3.0 (TID 552)
[2025-07-19T21:02:33.955+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 197 (task 546, attempt 0, stage 3.0)
[2025-07-19T21:02:33.955+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 196.0 in stage 3.0 (TID 545) in 104 ms on 8b44f3d35cfa (executor driver) (142/200)
[2025-07-19T21:02:33.955+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.955+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.955+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@77a64d11
[2025-07-19T21:02:33.956+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=17, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.956+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=17),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/17] for update
[2025-07-19T21:02:33.957+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.961+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 194 (task 544, attempt 0, stage 3.0)
[2025-07-19T21:02:33.963+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ceb5bf6
[2025-07-19T21:02:33.964+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 194.0 in stage 3.0 (TID 544). 9167 bytes result sent to driver
[2025-07-19T21:02:33.964+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=19, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.964+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 21.0 in stage 3.0 (TID 553) (8b44f3d35cfa, executor driver, partition 21, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.964+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 21.0 in stage 3.0 (TID 553)
[2025-07-19T21:02:33.965+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=19),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/19] for update
[2025-07-19T21:02:33.966+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 194.0 in stage 3.0 (TID 544) in 131 ms on 8b44f3d35cfa (executor driver) (143/200)
[2025-07-19T21:02:33.967+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/198/.1.delta.52e9108b-1b6a-4637-8950-e906cc6bb263.TID547.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/198/1.delta
[2025-07-19T21:02:33.967+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=198),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/198] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/198/1.delta
[2025-07-19T21:02:33.968+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 198 (task 547, attempt 0, stage 3.0)
[2025-07-19T21:02:33.968+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.969+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.969+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/199/.1.delta.5cbe8ad9-55cb-4778-bfd0-bf41cd9a5a0e.TID548.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/199/1.delta
[2025-07-19T21:02:33.969+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=199),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/199] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/199/1.delta
[2025-07-19T21:02:33.970+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.970+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 199 (task 548, attempt 0, stage 3.0)
[2025-07-19T21:02:33.971+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/17/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/17/.1.delta.a8f91bc2-1828-40b2-9167-c4772fb6979f.TID551.tmp
[2025-07-19T21:02:33.971+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@725c8ea
[2025-07-19T21:02:33.972+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=21, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.973+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=21),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/21] for update
[2025-07-19T21:02:33.973+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 197 (task 546, attempt 0, stage 3.0)
[2025-07-19T21:02:33.974+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 197.0 in stage 3.0 (TID 546). 9156 bytes result sent to driver
[2025-07-19T21:02:33.975+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.976+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 24.0 in stage 3.0 (TID 554) (8b44f3d35cfa, executor driver, partition 24, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.977+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 197.0 in stage 3.0 (TID 546) in 120 ms on 8b44f3d35cfa (executor driver) (144/200)
[2025-07-19T21:02:33.977+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 24.0 in stage 3.0 (TID 554)
[2025-07-19T21:02:33.977+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/5/.1.delta.9911c1c2-32d7-4eb7-aafa-e626cc847b5e.TID549.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/5/1.delta
[2025-07-19T21:02:33.978+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/5] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/5/1.delta
[2025-07-19T21:02:33.978+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Commit authorized for partition 5 (task 549, attempt 0, stage 3.0)
[2025-07-19T21:02:33.979+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.979+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.981+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 198 (task 547, attempt 0, stage 3.0)
[2025-07-19T21:02:33.981+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 198.0 in stage 3.0 (TID 547). 9154 bytes result sent to driver
[2025-07-19T21:02:33.981+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/19/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/19/.1.delta.9454f5b5-e1dd-4429-85e2-d7c4a0d6ef6a.TID552.tmp
[2025-07-19T21:02:33.982+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 5 (task 549, attempt 0, stage 3.0)
[2025-07-19T21:02:33.982+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 25.0 in stage 3.0 (TID 555) (8b44f3d35cfa, executor driver, partition 25, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.982+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO DataWritingSparkTask: Committed partition 199 (task 548, attempt 0, stage 3.0)
[2025-07-19T21:02:33.987+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 5.0 in stage 3.0 (TID 549). 6286 bytes result sent to driver
[2025-07-19T21:02:33.987+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 25.0 in stage 3.0 (TID 555)
[2025-07-19T21:02:33.987+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/21/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/21/.1.delta.c74d31bc-3f10-4c6a-8bf9-2768ffde5fe9.TID553.tmp
[2025-07-19T21:02:33.988+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Finished task 199.0 in stage 3.0 (TID 548). 9197 bytes result sent to driver
[2025-07-19T21:02:33.989+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 198.0 in stage 3.0 (TID 547) in 107 ms on 8b44f3d35cfa (executor driver) (145/200)
[2025-07-19T21:02:33.990+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@41570e49
[2025-07-19T21:02:33.991+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 29.0 in stage 3.0 (TID 556) (8b44f3d35cfa, executor driver, partition 29, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.991+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 29.0 in stage 3.0 (TID 556)
[2025-07-19T21:02:33.991+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Starting task 32.0 in stage 3.0 (TID 557) (8b44f3d35cfa, executor driver, partition 32, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:33.991+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.991+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=24, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.991+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=24),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/24] for update
[2025-07-19T21:02:33.993+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.993+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 5.0 in stage 3.0 (TID 549) in 93 ms on 8b44f3d35cfa (executor driver) (146/200)
[2025-07-19T21:02:33.993+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO TaskSetManager: Finished task 199.0 in stage 3.0 (TID 548) in 94 ms on 8b44f3d35cfa (executor driver) (147/200)
[2025-07-19T21:02:33.993+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:33.993+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO Executor: Running task 32.0 in stage 3.0 (TID 557)
[2025-07-19T21:02:33.993+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:33.994+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:33.997+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c1c873d
[2025-07-19T21:02:33.999+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=25, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:33.999+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=25),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/25] for update
[2025-07-19T21:02:34.000+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.000+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:34.000+0000] {subprocess.py:93} INFO - 25/07/19 21:02:33 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.003+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b8a848a
[2025-07-19T21:02:34.004+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/6/.1.delta.eb934da1-0aa5-4858-86e8-977f5990b33a.TID550.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/6/1.delta
[2025-07-19T21:02:34.004+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/6] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/6/1.delta
[2025-07-19T21:02:34.004+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 6 (task 550, attempt 0, stage 3.0)
[2025-07-19T21:02:34.005+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=29, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.006+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=29),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/29] for update
[2025-07-19T21:02:34.007+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.012+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 6 (task 550, attempt 0, stage 3.0)
[2025-07-19T21:02:34.013+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 6.0 in stage 3.0 (TID 550). 6243 bytes result sent to driver
[2025-07-19T21:02:34.014+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 34.0 in stage 3.0 (TID 558) (8b44f3d35cfa, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.015+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 34.0 in stage 3.0 (TID 558)
[2025-07-19T21:02:34.016+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 6.0 in stage 3.0 (TID 550) in 88 ms on 8b44f3d35cfa (executor driver) (148/200)
[2025-07-19T21:02:34.016+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.017+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.017+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f57566e
[2025-07-19T21:02:34.017+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/24/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/24/.1.delta.707a1f9d-264c-4db8-888b-f2eab2a2fda3.TID554.tmp
[2025-07-19T21:02:34.018+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=32, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.018+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=32),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/32] for update
[2025-07-19T21:02:34.018+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/25/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/25/.1.delta.6e2294da-6908-49a9-829b-c128fbfd0ecc.TID555.tmp
[2025-07-19T21:02:34.018+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.021+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/29/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/29/.1.delta.a173fac3-95b7-416c-82d8-226bb752696f.TID556.tmp
[2025-07-19T21:02:34.024+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/17/.1.delta.a8f91bc2-1828-40b2-9167-c4772fb6979f.TID551.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/17/1.delta
[2025-07-19T21:02:34.028+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=17),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/17] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/17/1.delta
[2025-07-19T21:02:34.028+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 17 (task 551, attempt 0, stage 3.0)
[2025-07-19T21:02:34.030+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 17 (task 551, attempt 0, stage 3.0)
[2025-07-19T21:02:34.030+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 17.0 in stage 3.0 (TID 551). 6243 bytes result sent to driver
[2025-07-19T21:02:34.030+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ae5858f
[2025-07-19T21:02:34.030+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 36.0 in stage 3.0 (TID 559) (8b44f3d35cfa, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.030+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 36.0 in stage 3.0 (TID 559)
[2025-07-19T21:02:34.031+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 17.0 in stage 3.0 (TID 551) in 85 ms on 8b44f3d35cfa (executor driver) (149/200)
[2025-07-19T21:02:34.031+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=34, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.031+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=34),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/34] for update
[2025-07-19T21:02:34.033+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.035+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:34.036+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/32/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/32/.1.delta.86f300e8-754d-49d7-8f70-541dd4c1bb98.TID557.tmp
[2025-07-19T21:02:34.036+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.039+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/19/.1.delta.9454f5b5-e1dd-4429-85e2-d7c4a0d6ef6a.TID552.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/19/1.delta
[2025-07-19T21:02:34.040+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=19),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/19] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/19/1.delta
[2025-07-19T21:02:34.040+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 19 (task 552, attempt 0, stage 3.0)
[2025-07-19T21:02:34.041+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@44d1ad86
[2025-07-19T21:02:34.041+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=36, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.041+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=36),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/36] for update
[2025-07-19T21:02:34.052+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 19 (task 552, attempt 0, stage 3.0)
[2025-07-19T21:02:34.053+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.053+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 19.0 in stage 3.0 (TID 552). 6243 bytes result sent to driver
[2025-07-19T21:02:34.054+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 44.0 in stage 3.0 (TID 560) (8b44f3d35cfa, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.054+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 19.0 in stage 3.0 (TID 552) in 102 ms on 8b44f3d35cfa (executor driver) (150/200)
[2025-07-19T21:02:34.054+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/21/.1.delta.c74d31bc-3f10-4c6a-8bf9-2768ffde5fe9.TID553.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/21/1.delta
[2025-07-19T21:02:34.054+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=21),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/21] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/21/1.delta
[2025-07-19T21:02:34.055+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/34/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/34/.1.delta.d27011be-db02-4e06-848d-40583c7b3cb6.TID558.tmp
[2025-07-19T21:02:34.056+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 21 (task 553, attempt 0, stage 3.0)
[2025-07-19T21:02:34.056+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 44.0 in stage 3.0 (TID 560)
[2025-07-19T21:02:34.059+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.062+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/36/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/36/.1.delta.9bb2da55-a7ed-4af2-9c9f-0c145be247ee.TID559.tmp
[2025-07-19T21:02:34.063+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 21 (task 553, attempt 0, stage 3.0)
[2025-07-19T21:02:34.064+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T21:02:34.064+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 21.0 in stage 3.0 (TID 553). 6243 bytes result sent to driver
[2025-07-19T21:02:34.064+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 49.0 in stage 3.0 (TID 561) (8b44f3d35cfa, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.064+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 21.0 in stage 3.0 (TID 553) in 103 ms on 8b44f3d35cfa (executor driver) (151/200)
[2025-07-19T21:02:34.067+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 49.0 in stage 3.0 (TID 561)
[2025-07-19T21:02:34.068+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/24/.1.delta.707a1f9d-264c-4db8-888b-f2eab2a2fda3.TID554.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/24/1.delta
[2025-07-19T21:02:34.069+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=24),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/24] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/24/1.delta
[2025-07-19T21:02:34.069+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 24 (task 554, attempt 0, stage 3.0)
[2025-07-19T21:02:34.069+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/25/.1.delta.6e2294da-6908-49a9-829b-c128fbfd0ecc.TID555.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/25/1.delta
[2025-07-19T21:02:34.069+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=25),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/25] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/25/1.delta
[2025-07-19T21:02:34.070+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@525b8d48
[2025-07-19T21:02:34.070+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.070+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:34.070+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 25 (task 555, attempt 0, stage 3.0)
[2025-07-19T21:02:34.070+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=44, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.071+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 24 (task 554, attempt 0, stage 3.0)
[2025-07-19T21:02:34.071+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=44),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/44] for update
[2025-07-19T21:02:34.072+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 24.0 in stage 3.0 (TID 554). 6243 bytes result sent to driver
[2025-07-19T21:02:34.073+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 53.0 in stage 3.0 (TID 562) (8b44f3d35cfa, executor driver, partition 53, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.074+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.074+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 24.0 in stage 3.0 (TID 554) in 101 ms on 8b44f3d35cfa (executor driver) (152/200)
[2025-07-19T21:02:34.075+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 53.0 in stage 3.0 (TID 562)
[2025-07-19T21:02:34.076+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 25 (task 555, attempt 0, stage 3.0)
[2025-07-19T21:02:34.078+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.078+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 25.0 in stage 3.0 (TID 555). 6243 bytes result sent to driver
[2025-07-19T21:02:34.079+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.079+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 61.0 in stage 3.0 (TID 563) (8b44f3d35cfa, executor driver, partition 61, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.079+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 25.0 in stage 3.0 (TID 555) in 96 ms on 8b44f3d35cfa (executor driver) (153/200)
[2025-07-19T21:02:34.079+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 61.0 in stage 3.0 (TID 563)
[2025-07-19T21:02:34.080+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ceec8df
[2025-07-19T21:02:34.081+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/29/.1.delta.a173fac3-95b7-416c-82d8-226bb752696f.TID556.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/29/1.delta
[2025-07-19T21:02:34.081+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=29),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/29] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/29/1.delta
[2025-07-19T21:02:34.082+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=49, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.082+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=49),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/49] for update
[2025-07-19T21:02:34.082+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.082+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 29 (task 556, attempt 0, stage 3.0)
[2025-07-19T21:02:34.084+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:34.086+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/32/.1.delta.86f300e8-754d-49d7-8f70-541dd4c1bb98.TID557.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/32/1.delta
[2025-07-19T21:02:34.086+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=32),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/32] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/32/1.delta
[2025-07-19T21:02:34.089+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 32 (task 557, attempt 0, stage 3.0)
[2025-07-19T21:02:34.090+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ad1401b
[2025-07-19T21:02:34.091+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=53, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.091+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.092+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=53),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/53] for update
[2025-07-19T21:02:34.092+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/44/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/44/.1.delta.a2247001-e7e6-4cf1-8f79-f362d7af88e4.TID560.tmp
[2025-07-19T21:02:34.095+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 29 (task 556, attempt 0, stage 3.0)
[2025-07-19T21:02:34.096+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 29.0 in stage 3.0 (TID 556). 6243 bytes result sent to driver
[2025-07-19T21:02:34.096+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 64.0 in stage 3.0 (TID 564) (8b44f3d35cfa, executor driver, partition 64, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.097+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 64.0 in stage 3.0 (TID 564)
[2025-07-19T21:02:34.097+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 32 (task 557, attempt 0, stage 3.0)
[2025-07-19T21:02:34.098+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 29.0 in stage 3.0 (TID 556) in 103 ms on 8b44f3d35cfa (executor driver) (154/200)
[2025-07-19T21:02:34.098+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.099+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 32.0 in stage 3.0 (TID 557). 6243 bytes result sent to driver
[2025-07-19T21:02:34.099+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.099+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.101+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 69.0 in stage 3.0 (TID 565) (8b44f3d35cfa, executor driver, partition 69, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.101+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 32.0 in stage 3.0 (TID 557) in 104 ms on 8b44f3d35cfa (executor driver) (155/200)
[2025-07-19T21:02:34.102+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 69.0 in stage 3.0 (TID 565)
[2025-07-19T21:02:34.102+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.102+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.103+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5cf77ca
[2025-07-19T21:02:34.104+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/34/.1.delta.d27011be-db02-4e06-848d-40583c7b3cb6.TID558.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/34/1.delta
[2025-07-19T21:02:34.105+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=34),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/34] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/34/1.delta
[2025-07-19T21:02:34.105+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=61, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.105+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/49/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/49/.1.delta.9f198c9b-110e-4d8d-836b-2ce99265b03e.TID561.tmp
[2025-07-19T21:02:34.106+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 34 (task 558, attempt 0, stage 3.0)
[2025-07-19T21:02:34.106+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=61),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/61] for update
[2025-07-19T21:02:34.107+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.108+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 34 (task 558, attempt 0, stage 3.0)
[2025-07-19T21:02:34.109+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 34.0 in stage 3.0 (TID 558). 6200 bytes result sent to driver
[2025-07-19T21:02:34.109+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 70.0 in stage 3.0 (TID 566) (8b44f3d35cfa, executor driver, partition 70, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.109+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 34.0 in stage 3.0 (TID 558) in 94 ms on 8b44f3d35cfa (executor driver) (156/200)
[2025-07-19T21:02:34.110+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 70.0 in stage 3.0 (TID 566)
[2025-07-19T21:02:34.110+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/53/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/53/.1.delta.5ba44587-7f4e-4b80-bd80-251dd2efb58d.TID562.tmp
[2025-07-19T21:02:34.111+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.112+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.112+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@42902c16
[2025-07-19T21:02:34.113+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=64, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.113+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=64),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/64] for update
[2025-07-19T21:02:34.113+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.113+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/61/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/61/.1.delta.d2b34cc2-d4c8-4772-ad93-9f505cff351c.TID563.tmp
[2025-07-19T21:02:34.113+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b0cbaf1
[2025-07-19T21:02:34.114+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=69, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.114+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=69),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/69] for update
[2025-07-19T21:02:34.117+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.120+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e625f88
[2025-07-19T21:02:34.120+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=70, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.121+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=70),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/70] for update
[2025-07-19T21:02:34.121+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/36/.1.delta.9bb2da55-a7ed-4af2-9c9f-0c145be247ee.TID559.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/36/1.delta
[2025-07-19T21:02:34.122+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=36),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/36] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/36/1.delta
[2025-07-19T21:02:34.123+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 36 (task 559, attempt 0, stage 3.0)
[2025-07-19T21:02:34.124+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/64/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/64/.1.delta.292b33b9-0455-4f76-9e64-5c695af66315.TID564.tmp
[2025-07-19T21:02:34.125+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.125+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/69/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/69/.1.delta.c6785046-e12c-4ac7-8889-8e3991eca842.TID565.tmp
[2025-07-19T21:02:34.126+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/44/.1.delta.a2247001-e7e6-4cf1-8f79-f362d7af88e4.TID560.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/44/1.delta
[2025-07-19T21:02:34.127+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=44),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/44] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/44/1.delta
[2025-07-19T21:02:34.127+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 44 (task 560, attempt 0, stage 3.0)
[2025-07-19T21:02:34.130+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 36 (task 559, attempt 0, stage 3.0)
[2025-07-19T21:02:34.131+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 44 (task 560, attempt 0, stage 3.0)
[2025-07-19T21:02:34.132+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 44.0 in stage 3.0 (TID 560). 6200 bytes result sent to driver
[2025-07-19T21:02:34.132+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 36.0 in stage 3.0 (TID 559). 6200 bytes result sent to driver
[2025-07-19T21:02:34.132+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 73.0 in stage 3.0 (TID 567) (8b44f3d35cfa, executor driver, partition 73, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.133+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 81.0 in stage 3.0 (TID 568) (8b44f3d35cfa, executor driver, partition 81, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.133+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 73.0 in stage 3.0 (TID 567)
[2025-07-19T21:02:34.134+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 44.0 in stage 3.0 (TID 560) in 79 ms on 8b44f3d35cfa (executor driver) (157/200)
[2025-07-19T21:02:34.134+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 81.0 in stage 3.0 (TID 568)
[2025-07-19T21:02:34.136+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 36.0 in stage 3.0 (TID 559) in 104 ms on 8b44f3d35cfa (executor driver) (158/200)
[2025-07-19T21:02:34.136+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.136+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.136+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/70/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/70/.1.delta.46a13756-11ee-4ca4-9851-ba977c92a9fc.TID566.tmp
[2025-07-19T21:02:34.137+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.138+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.138+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1991865
[2025-07-19T21:02:34.139+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=81, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.140+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=81),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/81] for update
[2025-07-19T21:02:34.141+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.144+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/49/.1.delta.9f198c9b-110e-4d8d-836b-2ce99265b03e.TID561.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/49/1.delta
[2025-07-19T21:02:34.146+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=49),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/49] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/49/1.delta
[2025-07-19T21:02:34.147+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 49 (task 561, attempt 0, stage 3.0)
[2025-07-19T21:02:34.147+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@662e91bf
[2025-07-19T21:02:34.148+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=73, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.148+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=73),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/73] for update
[2025-07-19T21:02:34.148+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.149+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/81/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/81/.1.delta.2438ed3d-f461-44be-91c1-6f1e83c4b846.TID568.tmp
[2025-07-19T21:02:34.151+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/61/.1.delta.d2b34cc2-d4c8-4772-ad93-9f505cff351c.TID563.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/61/1.delta
[2025-07-19T21:02:34.152+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=61),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/61] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/61/1.delta
[2025-07-19T21:02:34.152+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 61 (task 563, attempt 0, stage 3.0)
[2025-07-19T21:02:34.153+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 49 (task 561, attempt 0, stage 3.0)
[2025-07-19T21:02:34.154+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/53/.1.delta.5ba44587-7f4e-4b80-bd80-251dd2efb58d.TID562.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/53/1.delta
[2025-07-19T21:02:34.154+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=53),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/53] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/53/1.delta
[2025-07-19T21:02:34.156+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 49.0 in stage 3.0 (TID 561). 6200 bytes result sent to driver
[2025-07-19T21:02:34.157+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 53 (task 562, attempt 0, stage 3.0)
[2025-07-19T21:02:34.158+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 86.0 in stage 3.0 (TID 569) (8b44f3d35cfa, executor driver, partition 86, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.158+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 49.0 in stage 3.0 (TID 561) in 90 ms on 8b44f3d35cfa (executor driver) (159/200)
[2025-07-19T21:02:34.158+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 86.0 in stage 3.0 (TID 569)
[2025-07-19T21:02:34.158+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 61 (task 563, attempt 0, stage 3.0)
[2025-07-19T21:02:34.159+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 61.0 in stage 3.0 (TID 563). 6200 bytes result sent to driver
[2025-07-19T21:02:34.160+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 89.0 in stage 3.0 (TID 570) (8b44f3d35cfa, executor driver, partition 89, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.160+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 89.0 in stage 3.0 (TID 570)
[2025-07-19T21:02:34.161+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 61.0 in stage 3.0 (TID 563) in 79 ms on 8b44f3d35cfa (executor driver) (160/200)
[2025-07-19T21:02:34.161+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.161+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.161+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.162+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.164+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/73/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/73/.1.delta.99e94801-cbd3-4caf-89cb-fee8b5ed6d37.TID567.tmp
[2025-07-19T21:02:34.165+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 53 (task 562, attempt 0, stage 3.0)
[2025-07-19T21:02:34.165+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 53.0 in stage 3.0 (TID 562). 6200 bytes result sent to driver
[2025-07-19T21:02:34.165+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 90.0 in stage 3.0 (TID 571) (8b44f3d35cfa, executor driver, partition 90, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.165+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 53.0 in stage 3.0 (TID 562) in 88 ms on 8b44f3d35cfa (executor driver) (161/200)
[2025-07-19T21:02:34.165+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63ad8cd7
[2025-07-19T21:02:34.166+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/69/.1.delta.c6785046-e12c-4ac7-8889-8e3991eca842.TID565.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/69/1.delta
[2025-07-19T21:02:34.166+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=69),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/69] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/69/1.delta
[2025-07-19T21:02:34.166+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=86, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.166+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=86),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/86] for update
[2025-07-19T21:02:34.166+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/64/.1.delta.292b33b9-0455-4f76-9e64-5c695af66315.TID564.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/64/1.delta
[2025-07-19T21:02:34.166+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=64),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/64] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/64/1.delta
[2025-07-19T21:02:34.166+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 69 (task 565, attempt 0, stage 3.0)
[2025-07-19T21:02:34.166+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 64 (task 564, attempt 0, stage 3.0)
[2025-07-19T21:02:34.167+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 90.0 in stage 3.0 (TID 571)
[2025-07-19T21:02:34.170+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.172+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.172+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.173+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 64 (task 564, attempt 0, stage 3.0)
[2025-07-19T21:02:34.173+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 64.0 in stage 3.0 (TID 564). 6200 bytes result sent to driver
[2025-07-19T21:02:34.173+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 91.0 in stage 3.0 (TID 572) (8b44f3d35cfa, executor driver, partition 91, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.173+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 69 (task 565, attempt 0, stage 3.0)
[2025-07-19T21:02:34.174+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 69.0 in stage 3.0 (TID 565). 6200 bytes result sent to driver
[2025-07-19T21:02:34.174+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 64.0 in stage 3.0 (TID 564) in 85 ms on 8b44f3d35cfa (executor driver) (162/200)
[2025-07-19T21:02:34.175+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 91.0 in stage 3.0 (TID 572)
[2025-07-19T21:02:34.176+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 92.0 in stage 3.0 (TID 573) (8b44f3d35cfa, executor driver, partition 92, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.176+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@34c8f9f3
[2025-07-19T21:02:34.177+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 69.0 in stage 3.0 (TID 565) in 83 ms on 8b44f3d35cfa (executor driver) (163/200)
[2025-07-19T21:02:34.178+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=89, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.178+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=89),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/89] for update
[2025-07-19T21:02:34.179+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 92.0 in stage 3.0 (TID 573)
[2025-07-19T21:02:34.180+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.183+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.184+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.184+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.184+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.184+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/70/.1.delta.46a13756-11ee-4ca4-9851-ba977c92a9fc.TID566.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/70/1.delta
[2025-07-19T21:02:34.185+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=70),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/70] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/70/1.delta
[2025-07-19T21:02:34.185+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20ea3a41
[2025-07-19T21:02:34.185+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 70 (task 566, attempt 0, stage 3.0)
[2025-07-19T21:02:34.186+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=90, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.186+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=90),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/90] for update
[2025-07-19T21:02:34.186+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.187+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/86/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/86/.1.delta.7a9eee65-f638-46e5-b108-da7b747d2b1d.TID569.tmp
[2025-07-19T21:02:34.187+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@bac47a8
[2025-07-19T21:02:34.188+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=91, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.189+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=91),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/91] for update
[2025-07-19T21:02:34.189+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.190+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 70 (task 566, attempt 0, stage 3.0)
[2025-07-19T21:02:34.190+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 70.0 in stage 3.0 (TID 566). 6200 bytes result sent to driver
[2025-07-19T21:02:34.192+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 93.0 in stage 3.0 (TID 574) (8b44f3d35cfa, executor driver, partition 93, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.192+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 93.0 in stage 3.0 (TID 574)
[2025-07-19T21:02:34.193+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 70.0 in stage 3.0 (TID 566) in 88 ms on 8b44f3d35cfa (executor driver) (164/200)
[2025-07-19T21:02:34.193+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/89/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/89/.1.delta.525e04bd-2b79-49f2-aaf7-1611a68a97cb.TID570.tmp
[2025-07-19T21:02:34.196+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.196+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.199+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74b56024
[2025-07-19T21:02:34.201+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=92, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.201+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=92),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/92] for update
[2025-07-19T21:02:34.203+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/91/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/91/.1.delta.655a0a62-d2dc-43c3-a1e0-b2407f77324a.TID572.tmp
[2025-07-19T21:02:34.203+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/90/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/90/.1.delta.438ac1c7-808c-4ae6-b14f-0bb1649a5a0c.TID571.tmp
[2025-07-19T21:02:34.204+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.204+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/81/.1.delta.2438ed3d-f461-44be-91c1-6f1e83c4b846.TID568.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/81/1.delta
[2025-07-19T21:02:34.205+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=81),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/81] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/81/1.delta
[2025-07-19T21:02:34.205+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 81 (task 568, attempt 0, stage 3.0)
[2025-07-19T21:02:34.208+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/73/.1.delta.99e94801-cbd3-4caf-89cb-fee8b5ed6d37.TID567.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/73/1.delta
[2025-07-19T21:02:34.208+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=73),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/73] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/73/1.delta
[2025-07-19T21:02:34.208+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 73 (task 567, attempt 0, stage 3.0)
[2025-07-19T21:02:34.209+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 81 (task 568, attempt 0, stage 3.0)
[2025-07-19T21:02:34.209+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 81.0 in stage 3.0 (TID 568). 6200 bytes result sent to driver
[2025-07-19T21:02:34.210+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 98.0 in stage 3.0 (TID 575) (8b44f3d35cfa, executor driver, partition 98, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.210+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35466e76
[2025-07-19T21:02:34.211+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 81.0 in stage 3.0 (TID 568) in 80 ms on 8b44f3d35cfa (executor driver) (165/200)
[2025-07-19T21:02:34.212+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 98.0 in stage 3.0 (TID 575)
[2025-07-19T21:02:34.212+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=93, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.213+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=93),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/93] for update
[2025-07-19T21:02:34.214+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.215+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.216+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 73 (task 567, attempt 0, stage 3.0)
[2025-07-19T21:02:34.216+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.217+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 73.0 in stage 3.0 (TID 567). 6200 bytes result sent to driver
[2025-07-19T21:02:34.218+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 102.0 in stage 3.0 (TID 576) (8b44f3d35cfa, executor driver, partition 102, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.218+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/92/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/92/.1.delta.2fb3bf40-0bfe-48cb-b8f3-ca1a43a28d78.TID573.tmp
[2025-07-19T21:02:34.219+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 102.0 in stage 3.0 (TID 576)
[2025-07-19T21:02:34.219+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 73.0 in stage 3.0 (TID 567) in 88 ms on 8b44f3d35cfa (executor driver) (166/200)
[2025-07-19T21:02:34.220+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.221+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.227+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1054ed3e
[2025-07-19T21:02:34.227+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/93/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/93/.1.delta.5661b04d-641f-40d1-8313-fbfbf5fac922.TID574.tmp
[2025-07-19T21:02:34.227+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=98, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.230+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=98),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/98] for update
[2025-07-19T21:02:34.234+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.241+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@78098e3
[2025-07-19T21:02:34.243+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=102, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.243+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=102),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/102] for update
[2025-07-19T21:02:34.244+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.244+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/91/.1.delta.655a0a62-d2dc-43c3-a1e0-b2407f77324a.TID572.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/91/1.delta
[2025-07-19T21:02:34.245+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=91),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/91] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/91/1.delta
[2025-07-19T21:02:34.245+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 91 (task 572, attempt 0, stage 3.0)
[2025-07-19T21:02:34.246+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/90/.1.delta.438ac1c7-808c-4ae6-b14f-0bb1649a5a0c.TID571.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/90/1.delta
[2025-07-19T21:02:34.246+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=90),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/90] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/90/1.delta
[2025-07-19T21:02:34.247+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/98/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/98/.1.delta.9eb597d0-fcba-41e0-96ed-7b879a40d257.TID575.tmp
[2025-07-19T21:02:34.247+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/86/.1.delta.7a9eee65-f638-46e5-b108-da7b747d2b1d.TID569.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/86/1.delta
[2025-07-19T21:02:34.248+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=86),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/86] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/86/1.delta
[2025-07-19T21:02:34.248+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 90 (task 571, attempt 0, stage 3.0)
[2025-07-19T21:02:34.248+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 86 (task 569, attempt 0, stage 3.0)
[2025-07-19T21:02:34.251+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 90 (task 571, attempt 0, stage 3.0)
[2025-07-19T21:02:34.252+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 86 (task 569, attempt 0, stage 3.0)
[2025-07-19T21:02:34.253+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 90.0 in stage 3.0 (TID 571). 6243 bytes result sent to driver
[2025-07-19T21:02:34.253+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 105.0 in stage 3.0 (TID 577) (8b44f3d35cfa, executor driver, partition 105, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.255+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 91 (task 572, attempt 0, stage 3.0)
[2025-07-19T21:02:34.255+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 91.0 in stage 3.0 (TID 572). 6200 bytes result sent to driver
[2025-07-19T21:02:34.258+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 105.0 in stage 3.0 (TID 577)
[2025-07-19T21:02:34.259+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 86.0 in stage 3.0 (TID 569). 6200 bytes result sent to driver
[2025-07-19T21:02:34.259+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 90.0 in stage 3.0 (TID 571) in 93 ms on 8b44f3d35cfa (executor driver) (167/200)
[2025-07-19T21:02:34.260+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 107.0 in stage 3.0 (TID 578) (8b44f3d35cfa, executor driver, partition 107, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.260+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/89/.1.delta.525e04bd-2b79-49f2-aaf7-1611a68a97cb.TID570.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/89/1.delta
[2025-07-19T21:02:34.261+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=89),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/89] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/89/1.delta
[2025-07-19T21:02:34.261+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 107.0 in stage 3.0 (TID 578)
[2025-07-19T21:02:34.261+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 109.0 in stage 3.0 (TID 579) (8b44f3d35cfa, executor driver, partition 109, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.261+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 91.0 in stage 3.0 (TID 572) in 84 ms on 8b44f3d35cfa (executor driver) (168/200)
[2025-07-19T21:02:34.261+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 86.0 in stage 3.0 (TID 569) in 104 ms on 8b44f3d35cfa (executor driver) (169/200)
[2025-07-19T21:02:34.262+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.262+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.263+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 89 (task 570, attempt 0, stage 3.0)
[2025-07-19T21:02:34.264+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/102/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/102/.1.delta.000b0279-5eca-49ba-a965-a6374daccb8b.TID576.tmp
[2025-07-19T21:02:34.264+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 109.0 in stage 3.0 (TID 579)
[2025-07-19T21:02:34.264+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 89 (task 570, attempt 0, stage 3.0)
[2025-07-19T21:02:34.264+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31abf1c1
[2025-07-19T21:02:34.264+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 89.0 in stage 3.0 (TID 570). 6200 bytes result sent to driver
[2025-07-19T21:02:34.264+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/92/.1.delta.2fb3bf40-0bfe-48cb-b8f3-ca1a43a28d78.TID573.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/92/1.delta
[2025-07-19T21:02:34.264+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=92),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/92] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/92/1.delta
[2025-07-19T21:02:34.265+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.265+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:34.265+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=107, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.265+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 92 (task 573, attempt 0, stage 3.0)
[2025-07-19T21:02:34.265+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=107),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/107] for update
[2025-07-19T21:02:34.265+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 116.0 in stage 3.0 (TID 580) (8b44f3d35cfa, executor driver, partition 116, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.268+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 89.0 in stage 3.0 (TID 570) in 109 ms on 8b44f3d35cfa (executor driver) (170/200)
[2025-07-19T21:02:34.270+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.271+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.271+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.272+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 116.0 in stage 3.0 (TID 580)
[2025-07-19T21:02:34.272+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 92 (task 573, attempt 0, stage 3.0)
[2025-07-19T21:02:34.272+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.273+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.273+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 92.0 in stage 3.0 (TID 573). 6200 bytes result sent to driver
[2025-07-19T21:02:34.273+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1df75689
[2025-07-19T21:02:34.274+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 123.0 in stage 3.0 (TID 581) (8b44f3d35cfa, executor driver, partition 123, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.278+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 92.0 in stage 3.0 (TID 573) in 95 ms on 8b44f3d35cfa (executor driver) (171/200)
[2025-07-19T21:02:34.279+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=109, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.279+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=109),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/109] for update
[2025-07-19T21:02:34.279+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 123.0 in stage 3.0 (TID 581)
[2025-07-19T21:02:34.280+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.280+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.280+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.281+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/107/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/107/.1.delta.3f41a9a9-2270-4518-9bf5-16009cf24b7d.TID578.tmp
[2025-07-19T21:02:34.281+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/93/.1.delta.5661b04d-641f-40d1-8313-fbfbf5fac922.TID574.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/93/1.delta
[2025-07-19T21:02:34.282+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=93),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/93] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/93/1.delta
[2025-07-19T21:02:34.282+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 93 (task 574, attempt 0, stage 3.0)
[2025-07-19T21:02:34.283+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d7d90dd
[2025-07-19T21:02:34.285+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=105, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.286+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=105),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/105] for update
[2025-07-19T21:02:34.296+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/109/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/109/.1.delta.74320e61-5344-4066-8403-3f08aa089bc3.TID579.tmp
[2025-07-19T21:02:34.296+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.296+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 93 (task 574, attempt 0, stage 3.0)
[2025-07-19T21:02:34.297+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 93.0 in stage 3.0 (TID 574). 6200 bytes result sent to driver
[2025-07-19T21:02:34.297+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 124.0 in stage 3.0 (TID 582) (8b44f3d35cfa, executor driver, partition 124, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.297+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 93.0 in stage 3.0 (TID 574) in 100 ms on 8b44f3d35cfa (executor driver) (172/200)
[2025-07-19T21:02:34.297+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@305e72b4
[2025-07-19T21:02:34.298+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 124.0 in stage 3.0 (TID 582)
[2025-07-19T21:02:34.298+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=123, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.298+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=123),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/123] for update
[2025-07-19T21:02:34.298+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.302+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.303+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.309+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7deb7820
[2025-07-19T21:02:34.315+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/105/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/105/.1.delta.48464afb-ca2a-411f-821d-4637d58e4b29.TID577.tmp
[2025-07-19T21:02:34.315+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=116, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.315+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=116),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/116] for update
[2025-07-19T21:02:34.316+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.316+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/102/.1.delta.000b0279-5eca-49ba-a965-a6374daccb8b.TID576.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/102/1.delta
[2025-07-19T21:02:34.317+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=102),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/102] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/102/1.delta
[2025-07-19T21:02:34.319+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 102 (task 576, attempt 0, stage 3.0)
[2025-07-19T21:02:34.320+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/98/.1.delta.9eb597d0-fcba-41e0-96ed-7b879a40d257.TID575.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/98/1.delta
[2025-07-19T21:02:34.320+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=98),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/98] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/98/1.delta
[2025-07-19T21:02:34.321+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 98 (task 575, attempt 0, stage 3.0)
[2025-07-19T21:02:34.322+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/123/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/123/.1.delta.60507fce-15e6-4387-8178-4079ec039df5.TID581.tmp
[2025-07-19T21:02:34.323+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ecdfd83
[2025-07-19T21:02:34.323+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=124, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.323+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=124),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/124] for update
[2025-07-19T21:02:34.324+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 98 (task 575, attempt 0, stage 3.0)
[2025-07-19T21:02:34.329+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/116/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/116/.1.delta.f0b1218c-9aa5-4fbc-ba21-ef20324b5617.TID580.tmp
[2025-07-19T21:02:34.330+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 102 (task 576, attempt 0, stage 3.0)
[2025-07-19T21:02:34.330+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 102.0 in stage 3.0 (TID 576). 6200 bytes result sent to driver
[2025-07-19T21:02:34.331+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 98.0 in stage 3.0 (TID 575). 6200 bytes result sent to driver
[2025-07-19T21:02:34.332+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.332+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 126.0 in stage 3.0 (TID 583) (8b44f3d35cfa, executor driver, partition 126, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.334+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 126.0 in stage 3.0 (TID 583)
[2025-07-19T21:02:34.334+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 127.0 in stage 3.0 (TID 584) (8b44f3d35cfa, executor driver, partition 127, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.335+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 98.0 in stage 3.0 (TID 575) in 125 ms on 8b44f3d35cfa (executor driver) (173/200)
[2025-07-19T21:02:34.335+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 102.0 in stage 3.0 (TID 576) in 116 ms on 8b44f3d35cfa (executor driver) (174/200)
[2025-07-19T21:02:34.335+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 127.0 in stage 3.0 (TID 584)
[2025-07-19T21:02:34.336+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.337+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:34.339+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.339+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.342+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/124/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/124/.1.delta.9da979f4-1e5e-4a3e-8478-d7b2fa17a2b7.TID582.tmp
[2025-07-19T21:02:34.343+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b79a375
[2025-07-19T21:02:34.355+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=126, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.356+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=126),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/126] for update
[2025-07-19T21:02:34.357+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.358+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/107/.1.delta.3f41a9a9-2270-4518-9bf5-16009cf24b7d.TID578.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/107/1.delta
[2025-07-19T21:02:34.359+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=107),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/107] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/107/1.delta
[2025-07-19T21:02:34.359+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 107 (task 578, attempt 0, stage 3.0)
[2025-07-19T21:02:34.362+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 107 (task 578, attempt 0, stage 3.0)
[2025-07-19T21:02:34.363+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 107.0 in stage 3.0 (TID 578). 6200 bytes result sent to driver
[2025-07-19T21:02:34.364+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 132.0 in stage 3.0 (TID 585) (8b44f3d35cfa, executor driver, partition 132, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.364+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 107.0 in stage 3.0 (TID 578) in 109 ms on 8b44f3d35cfa (executor driver) (175/200)
[2025-07-19T21:02:34.365+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 132.0 in stage 3.0 (TID 585)
[2025-07-19T21:02:34.365+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@529fe7c4
[2025-07-19T21:02:34.366+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/109/.1.delta.74320e61-5344-4066-8403-3f08aa089bc3.TID579.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/109/1.delta
[2025-07-19T21:02:34.367+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=109),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/109] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/109/1.delta
[2025-07-19T21:02:34.367+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=127, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.368+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 109 (task 579, attempt 0, stage 3.0)
[2025-07-19T21:02:34.369+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=127),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/127] for update
[2025-07-19T21:02:34.370+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.371+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.372+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/126/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/126/.1.delta.df82ff56-867d-4016-907d-81dc6d206401.TID583.tmp
[2025-07-19T21:02:34.372+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.372+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 109 (task 579, attempt 0, stage 3.0)
[2025-07-19T21:02:34.372+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 109.0 in stage 3.0 (TID 579). 6200 bytes result sent to driver
[2025-07-19T21:02:34.373+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 136.0 in stage 3.0 (TID 586) (8b44f3d35cfa, executor driver, partition 136, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.374+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 136.0 in stage 3.0 (TID 586)
[2025-07-19T21:02:34.375+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@435120f2
[2025-07-19T21:02:34.375+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 109.0 in stage 3.0 (TID 579) in 119 ms on 8b44f3d35cfa (executor driver) (176/200)
[2025-07-19T21:02:34.376+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=132, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.377+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=132),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/132] for update
[2025-07-19T21:02:34.377+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/105/.1.delta.48464afb-ca2a-411f-821d-4637d58e4b29.TID577.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/105/1.delta
[2025-07-19T21:02:34.377+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=105),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/105] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/105/1.delta
[2025-07-19T21:02:34.377+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.378+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 105 (task 577, attempt 0, stage 3.0)
[2025-07-19T21:02:34.379+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.379+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.380+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/123/.1.delta.60507fce-15e6-4387-8178-4079ec039df5.TID581.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/123/1.delta
[2025-07-19T21:02:34.380+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=123),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/123] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/123/1.delta
[2025-07-19T21:02:34.380+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 123 (task 581, attempt 0, stage 3.0)
[2025-07-19T21:02:34.382+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/127/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/127/.1.delta.be8a923a-e96d-4081-b366-4bad4074dc74.TID584.tmp
[2025-07-19T21:02:34.385+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 105 (task 577, attempt 0, stage 3.0)
[2025-07-19T21:02:34.386+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 105.0 in stage 3.0 (TID 577). 6200 bytes result sent to driver
[2025-07-19T21:02:34.386+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 138.0 in stage 3.0 (TID 587) (8b44f3d35cfa, executor driver, partition 138, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.386+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 105.0 in stage 3.0 (TID 577) in 134 ms on 8b44f3d35cfa (executor driver) (177/200)
[2025-07-19T21:02:34.387+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 138.0 in stage 3.0 (TID 587)
[2025-07-19T21:02:34.389+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/116/.1.delta.f0b1218c-9aa5-4fbc-ba21-ef20324b5617.TID580.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/116/1.delta
[2025-07-19T21:02:34.390+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=116),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/116] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/116/1.delta
[2025-07-19T21:02:34.391+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 116 (task 580, attempt 0, stage 3.0)
[2025-07-19T21:02:34.391+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 123 (task 581, attempt 0, stage 3.0)
[2025-07-19T21:02:34.392+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4165ed9d
[2025-07-19T21:02:34.392+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.392+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.394+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=136, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.395+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=136),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/136] for update
[2025-07-19T21:02:34.395+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 116 (task 580, attempt 0, stage 3.0)
[2025-07-19T21:02:34.398+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 123.0 in stage 3.0 (TID 581). 6200 bytes result sent to driver
[2025-07-19T21:02:34.398+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 140.0 in stage 3.0 (TID 588) (8b44f3d35cfa, executor driver, partition 140, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.398+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.399+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 140.0 in stage 3.0 (TID 588)
[2025-07-19T21:02:34.400+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 116.0 in stage 3.0 (TID 580). 6200 bytes result sent to driver
[2025-07-19T21:02:34.400+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 123.0 in stage 3.0 (TID 581) in 123 ms on 8b44f3d35cfa (executor driver) (178/200)
[2025-07-19T21:02:34.400+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 116.0 in stage 3.0 (TID 580) in 129 ms on 8b44f3d35cfa (executor driver) (179/200)
[2025-07-19T21:02:34.401+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 152.0 in stage 3.0 (TID 589) (8b44f3d35cfa, executor driver, partition 152, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.401+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 152.0 in stage 3.0 (TID 589)
[2025-07-19T21:02:34.401+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.402+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.402+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a26c867
[2025-07-19T21:02:34.402+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/132/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/132/.1.delta.0199b5cb-2a09-40a2-9d1d-1bae8a50993b.TID585.tmp
[2025-07-19T21:02:34.402+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=138, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.403+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=138),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/138] for update
[2025-07-19T21:02:34.403+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.404+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.404+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.405+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/136/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/136/.1.delta.22acac9c-19d2-4e58-a938-8987b09a3f1b.TID586.tmp
[2025-07-19T21:02:34.405+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e2536ab
[2025-07-19T21:02:34.409+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=152, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.410+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=152),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/152] for update
[2025-07-19T21:02:34.411+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/124/.1.delta.9da979f4-1e5e-4a3e-8478-d7b2fa17a2b7.TID582.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/124/1.delta
[2025-07-19T21:02:34.412+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=124),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/124] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/124/1.delta
[2025-07-19T21:02:34.413+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/126/.1.delta.df82ff56-867d-4016-907d-81dc6d206401.TID583.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/126/1.delta
[2025-07-19T21:02:34.413+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=126),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/126] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/126/1.delta
[2025-07-19T21:02:34.413+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 124 (task 582, attempt 0, stage 3.0)
[2025-07-19T21:02:34.413+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 126 (task 583, attempt 0, stage 3.0)
[2025-07-19T21:02:34.414+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.414+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/138/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/138/.1.delta.95fdc4c4-2efb-4330-968f-50279e6b843a.TID587.tmp
[2025-07-19T21:02:34.417+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f3fbb2d
[2025-07-19T21:02:34.418+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=140, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.419+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=140),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/140] for update
[2025-07-19T21:02:34.419+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 126 (task 583, attempt 0, stage 3.0)
[2025-07-19T21:02:34.419+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 126.0 in stage 3.0 (TID 583). 6200 bytes result sent to driver
[2025-07-19T21:02:34.420+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 124 (task 582, attempt 0, stage 3.0)
[2025-07-19T21:02:34.420+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.420+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 155.0 in stage 3.0 (TID 590) (8b44f3d35cfa, executor driver, partition 155, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.420+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 126.0 in stage 3.0 (TID 583) in 89 ms on 8b44f3d35cfa (executor driver) (180/200)
[2025-07-19T21:02:34.420+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 155.0 in stage 3.0 (TID 590)
[2025-07-19T21:02:34.432+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 124.0 in stage 3.0 (TID 582). 6286 bytes result sent to driver
[2025-07-19T21:02:34.433+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 160.0 in stage 3.0 (TID 591) (8b44f3d35cfa, executor driver, partition 160, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.433+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 160.0 in stage 3.0 (TID 591)
[2025-07-19T21:02:34.433+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 124.0 in stage 3.0 (TID 582) in 139 ms on 8b44f3d35cfa (executor driver) (181/200)
[2025-07-19T21:02:34.433+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.433+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.433+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.434+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.435+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/152/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/152/.1.delta.c1a72730-2c32-48a5-8aa4-b7328433fa6c.TID589.tmp
[2025-07-19T21:02:34.436+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@50a20359
[2025-07-19T21:02:34.437+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=155, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.438+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=155),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/155] for update
[2025-07-19T21:02:34.438+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/127/.1.delta.be8a923a-e96d-4081-b366-4bad4074dc74.TID584.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/127/1.delta
[2025-07-19T21:02:34.438+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=127),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/127] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/127/1.delta
[2025-07-19T21:02:34.439+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.443+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 127 (task 584, attempt 0, stage 3.0)
[2025-07-19T21:02:34.443+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/140/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/140/.1.delta.608a320e-3ef7-425a-8780-19230e421bac.TID588.tmp
[2025-07-19T21:02:34.449+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 127 (task 584, attempt 0, stage 3.0)
[2025-07-19T21:02:34.449+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 127.0 in stage 3.0 (TID 584). 6243 bytes result sent to driver
[2025-07-19T21:02:34.450+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 161.0 in stage 3.0 (TID 592) (8b44f3d35cfa, executor driver, partition 161, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.450+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 161.0 in stage 3.0 (TID 592)
[2025-07-19T21:02:34.450+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 127.0 in stage 3.0 (TID 584) in 117 ms on 8b44f3d35cfa (executor driver) (182/200)
[2025-07-19T21:02:34.450+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52afb1ec
[2025-07-19T21:02:34.450+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.451+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.452+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=160, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.453+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=160),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/160] for update
[2025-07-19T21:02:34.454+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/155/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/155/.1.delta.02c34384-9928-4fe1-8196-f56966a1b82d.TID590.tmp
[2025-07-19T21:02:34.455+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.457+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/132/.1.delta.0199b5cb-2a09-40a2-9d1d-1bae8a50993b.TID585.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/132/1.delta
[2025-07-19T21:02:34.458+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=132),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/132] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/132/1.delta
[2025-07-19T21:02:34.458+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 132 (task 585, attempt 0, stage 3.0)
[2025-07-19T21:02:34.464+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/136/.1.delta.22acac9c-19d2-4e58-a938-8987b09a3f1b.TID586.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/136/1.delta
[2025-07-19T21:02:34.466+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=136),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/136] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/136/1.delta
[2025-07-19T21:02:34.466+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 136 (task 586, attempt 0, stage 3.0)
[2025-07-19T21:02:34.468+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/138/.1.delta.95fdc4c4-2efb-4330-968f-50279e6b843a.TID587.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/138/1.delta
[2025-07-19T21:02:34.469+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=138),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/138] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/138/1.delta
[2025-07-19T21:02:34.471+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43e9ed17
[2025-07-19T21:02:34.473+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 138 (task 587, attempt 0, stage 3.0)
[2025-07-19T21:02:34.474+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 132 (task 585, attempt 0, stage 3.0)
[2025-07-19T21:02:34.475+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 132.0 in stage 3.0 (TID 585). 6243 bytes result sent to driver
[2025-07-19T21:02:34.477+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=161, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.477+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 163.0 in stage 3.0 (TID 593) (8b44f3d35cfa, executor driver, partition 163, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.478+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=161),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/161] for update
[2025-07-19T21:02:34.478+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 163.0 in stage 3.0 (TID 593)
[2025-07-19T21:02:34.478+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 132.0 in stage 3.0 (TID 585) in 103 ms on 8b44f3d35cfa (executor driver) (183/200)
[2025-07-19T21:02:34.478+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.478+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/160/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/160/.1.delta.348a9fad-4769-43b4-8770-d792b0abac66.TID591.tmp
[2025-07-19T21:02:34.479+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 138 (task 587, attempt 0, stage 3.0)
[2025-07-19T21:02:34.479+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.479+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.480+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 136 (task 586, attempt 0, stage 3.0)
[2025-07-19T21:02:34.480+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 136.0 in stage 3.0 (TID 586). 6243 bytes result sent to driver
[2025-07-19T21:02:34.481+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 138.0 in stage 3.0 (TID 587). 6286 bytes result sent to driver
[2025-07-19T21:02:34.482+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 164.0 in stage 3.0 (TID 594) (8b44f3d35cfa, executor driver, partition 164, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.482+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 164.0 in stage 3.0 (TID 594)
[2025-07-19T21:02:34.482+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 166.0 in stage 3.0 (TID 595) (8b44f3d35cfa, executor driver, partition 166, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.482+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 166.0 in stage 3.0 (TID 595)
[2025-07-19T21:02:34.482+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 138.0 in stage 3.0 (TID 587) in 87 ms on 8b44f3d35cfa (executor driver) (184/200)
[2025-07-19T21:02:34.483+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 136.0 in stage 3.0 (TID 586) in 99 ms on 8b44f3d35cfa (executor driver) (185/200)
[2025-07-19T21:02:34.483+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.483+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.483+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.483+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:34.483+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@79bf675c
[2025-07-19T21:02:34.483+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/161/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/161/.1.delta.0bd3377f-8374-4190-ab14-71b722057628.TID592.tmp
[2025-07-19T21:02:34.483+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=163, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.484+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=163),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/163] for update
[2025-07-19T21:02:34.484+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.486+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@10b2191
[2025-07-19T21:02:34.486+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=164, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.486+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=164),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/164] for update
[2025-07-19T21:02:34.487+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.488+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/140/.1.delta.608a320e-3ef7-425a-8780-19230e421bac.TID588.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/140/1.delta
[2025-07-19T21:02:34.489+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=140),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/140] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/140/1.delta
[2025-07-19T21:02:34.489+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/152/.1.delta.c1a72730-2c32-48a5-8aa4-b7328433fa6c.TID589.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/152/1.delta
[2025-07-19T21:02:34.489+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=152),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/152] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/152/1.delta
[2025-07-19T21:02:34.490+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 140 (task 588, attempt 0, stage 3.0)
[2025-07-19T21:02:34.490+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 152 (task 589, attempt 0, stage 3.0)
[2025-07-19T21:02:34.499+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 152 (task 589, attempt 0, stage 3.0)
[2025-07-19T21:02:34.499+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 140 (task 588, attempt 0, stage 3.0)
[2025-07-19T21:02:34.500+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 140.0 in stage 3.0 (TID 588). 6243 bytes result sent to driver
[2025-07-19T21:02:34.501+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 176.0 in stage 3.0 (TID 596) (8b44f3d35cfa, executor driver, partition 176, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.505+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 176.0 in stage 3.0 (TID 596)
[2025-07-19T21:02:34.506+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 140.0 in stage 3.0 (TID 588) in 108 ms on 8b44f3d35cfa (executor driver) (186/200)
[2025-07-19T21:02:34.507+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@599cec70
[2025-07-19T21:02:34.507+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 152.0 in stage 3.0 (TID 589). 6243 bytes result sent to driver
[2025-07-19T21:02:34.507+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=166, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.507+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 177.0 in stage 3.0 (TID 597) (8b44f3d35cfa, executor driver, partition 177, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.507+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 152.0 in stage 3.0 (TID 589) in 107 ms on 8b44f3d35cfa (executor driver) (187/200)
[2025-07-19T21:02:34.507+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=166),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/166] for update
[2025-07-19T21:02:34.508+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 177.0 in stage 3.0 (TID 597)
[2025-07-19T21:02:34.508+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.509+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.509+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.509+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.510+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:34.510+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/155/.1.delta.02c34384-9928-4fe1-8196-f56966a1b82d.TID590.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/155/1.delta
[2025-07-19T21:02:34.510+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=155),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/155] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/155/1.delta
[2025-07-19T21:02:34.511+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 155 (task 590, attempt 0, stage 3.0)
[2025-07-19T21:02:34.511+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/163/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/163/.1.delta.f4781955-6057-47d6-a191-25a9f4d875f7.TID593.tmp
[2025-07-19T21:02:34.511+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@318f87ba
[2025-07-19T21:02:34.512+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=176, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.512+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=176),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/176] for update
[2025-07-19T21:02:34.513+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.514+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 155 (task 590, attempt 0, stage 3.0)
[2025-07-19T21:02:34.515+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/164/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/164/.1.delta.cc0a84a0-9fdf-4616-b1e5-f67b22fedda7.TID594.tmp
[2025-07-19T21:02:34.518+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 155.0 in stage 3.0 (TID 590). 6243 bytes result sent to driver
[2025-07-19T21:02:34.519+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 186.0 in stage 3.0 (TID 598) (8b44f3d35cfa, executor driver, partition 186, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.519+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 155.0 in stage 3.0 (TID 590) in 98 ms on 8b44f3d35cfa (executor driver) (188/200)
[2025-07-19T21:02:34.519+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 186.0 in stage 3.0 (TID 598)
[2025-07-19T21:02:34.520+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7000d2d1
[2025-07-19T21:02:34.520+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=177, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.520+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=177),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/177] for update
[2025-07-19T21:02:34.523+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.524+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/166/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/166/.1.delta.1b8a3732-3b95-4d0a-a4f3-a0d7afd8136d.TID595.tmp
[2025-07-19T21:02:34.526+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.527+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.529+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/176/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/176/.1.delta.314fda25-9605-48bd-994b-d7a48931015c.TID596.tmp
[2025-07-19T21:02:34.529+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/160/.1.delta.348a9fad-4769-43b4-8770-d792b0abac66.TID591.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/160/1.delta
[2025-07-19T21:02:34.530+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=160),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/160] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/160/1.delta
[2025-07-19T21:02:34.532+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 160 (task 591, attempt 0, stage 3.0)
[2025-07-19T21:02:34.534+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@338152a4
[2025-07-19T21:02:34.535+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=186, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.536+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=186),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/186] for update
[2025-07-19T21:02:34.536+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.537+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 160 (task 591, attempt 0, stage 3.0)
[2025-07-19T21:02:34.538+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 160.0 in stage 3.0 (TID 591). 6243 bytes result sent to driver
[2025-07-19T21:02:34.538+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 190.0 in stage 3.0 (TID 599) (8b44f3d35cfa, executor driver, partition 190, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.540+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 190.0 in stage 3.0 (TID 599)
[2025-07-19T21:02:34.540+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 160.0 in stage 3.0 (TID 591) in 112 ms on 8b44f3d35cfa (executor driver) (189/200)
[2025-07-19T21:02:34.541+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/177/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/177/.1.delta.e502c139-d199-43a5-8cee-58b9375ec208.TID597.tmp
[2025-07-19T21:02:34.542+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.543+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.544+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/161/.1.delta.0bd3377f-8374-4190-ab14-71b722057628.TID592.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/161/1.delta
[2025-07-19T21:02:34.544+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=161),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/161] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/161/1.delta
[2025-07-19T21:02:34.545+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 161 (task 592, attempt 0, stage 3.0)
[2025-07-19T21:02:34.551+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/186/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/186/.1.delta.cb24b613-2b16-4bc8-8f7b-74c68ff06b3a.TID598.tmp
[2025-07-19T21:02:34.553+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 161 (task 592, attempt 0, stage 3.0)
[2025-07-19T21:02:34.555+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 161.0 in stage 3.0 (TID 592). 6243 bytes result sent to driver
[2025-07-19T21:02:34.555+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 191.0 in stage 3.0 (TID 600) (8b44f3d35cfa, executor driver, partition 191, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.556+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 191.0 in stage 3.0 (TID 600)
[2025-07-19T21:02:34.556+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 161.0 in stage 3.0 (TID 592) in 105 ms on 8b44f3d35cfa (executor driver) (190/200)
[2025-07-19T21:02:34.557+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58b82134
[2025-07-19T21:02:34.557+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=190, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.559+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=190),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/190] for update
[2025-07-19T21:02:34.559+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.559+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.560+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.564+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b34bd16
[2025-07-19T21:02:34.566+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=191, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.568+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=191),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/191] for update
[2025-07-19T21:02:34.568+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.568+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/163/.1.delta.f4781955-6057-47d6-a191-25a9f4d875f7.TID593.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/163/1.delta
[2025-07-19T21:02:34.568+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=163),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/163] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/163/1.delta
[2025-07-19T21:02:34.569+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 163 (task 593, attempt 0, stage 3.0)
[2025-07-19T21:02:34.573+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/190/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/190/.1.delta.c1871189-9e48-47a4-aef9-12f3c50d6934.TID599.tmp
[2025-07-19T21:02:34.575+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/191/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/191/.1.delta.64340377-77a9-4d17-8dbc-a04c07991096.TID600.tmp
[2025-07-19T21:02:34.577+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 163 (task 593, attempt 0, stage 3.0)
[2025-07-19T21:02:34.579+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 163.0 in stage 3.0 (TID 593). 6243 bytes result sent to driver
[2025-07-19T21:02:34.581+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/176/.1.delta.314fda25-9605-48bd-994b-d7a48931015c.TID596.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/176/1.delta
[2025-07-19T21:02:34.582+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=176),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/176] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/176/1.delta
[2025-07-19T21:02:34.582+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 176 (task 596, attempt 0, stage 3.0)
[2025-07-19T21:02:34.582+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 193.0 in stage 3.0 (TID 601) (8b44f3d35cfa, executor driver, partition 193, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.583+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 163.0 in stage 3.0 (TID 593) in 115 ms on 8b44f3d35cfa (executor driver) (191/200)
[2025-07-19T21:02:34.583+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 193.0 in stage 3.0 (TID 601)
[2025-07-19T21:02:34.584+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/164/.1.delta.cc0a84a0-9fdf-4616-b1e5-f67b22fedda7.TID594.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/164/1.delta
[2025-07-19T21:02:34.584+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=164),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/164] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/164/1.delta
[2025-07-19T21:02:34.586+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 164 (task 594, attempt 0, stage 3.0)
[2025-07-19T21:02:34.587+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 176 (task 596, attempt 0, stage 3.0)
[2025-07-19T21:02:34.588+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 176.0 in stage 3.0 (TID 596). 6200 bytes result sent to driver
[2025-07-19T21:02:34.588+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.588+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.589+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 195.0 in stage 3.0 (TID 602) (8b44f3d35cfa, executor driver, partition 195, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.589+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 176.0 in stage 3.0 (TID 596) in 87 ms on 8b44f3d35cfa (executor driver) (192/200)
[2025-07-19T21:02:34.591+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 195.0 in stage 3.0 (TID 602)
[2025-07-19T21:02:34.592+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 164 (task 594, attempt 0, stage 3.0)
[2025-07-19T21:02:34.593+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 164.0 in stage 3.0 (TID 594). 6243 bytes result sent to driver
[2025-07-19T21:02:34.593+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.593+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.594+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 603) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.594+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 0.0 in stage 7.0 (TID 603)
[2025-07-19T21:02:34.595+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 164.0 in stage 3.0 (TID 594) in 120 ms on 8b44f3d35cfa (executor driver) (193/200)
[2025-07-19T21:02:34.595+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c669912
[2025-07-19T21:02:34.596+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=193, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.596+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=193),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/193] for update
[2025-07-19T21:02:34.596+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.599+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.600+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.603+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/166/.1.delta.1b8a3732-3b95-4d0a-a4f3-a0d7afd8136d.TID595.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/166/1.delta
[2025-07-19T21:02:34.605+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=166),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/166] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/166/1.delta
[2025-07-19T21:02:34.605+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 166 (task 595, attempt 0, stage 3.0)
[2025-07-19T21:02:34.605+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/186/.1.delta.cb24b613-2b16-4bc8-8f7b-74c68ff06b3a.TID598.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/186/1.delta
[2025-07-19T21:02:34.606+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=186),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/186] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/186/1.delta
[2025-07-19T21:02:34.607+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 186 (task 598, attempt 0, stage 3.0)
[2025-07-19T21:02:34.608+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d47f024
[2025-07-19T21:02:34.609+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=195, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:34.610+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=195),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/195] for update
[2025-07-19T21:02:34.610+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 166 (task 595, attempt 0, stage 3.0)
[2025-07-19T21:02:34.611+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 186 (task 598, attempt 0, stage 3.0)
[2025-07-19T21:02:34.611+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/177/.1.delta.e502c139-d199-43a5-8cee-58b9375ec208.TID597.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/177/1.delta
[2025-07-19T21:02:34.611+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=177),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/177] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/177/1.delta
[2025-07-19T21:02:34.612+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 166.0 in stage 3.0 (TID 595). 6243 bytes result sent to driver
[2025-07-19T21:02:34.613+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 177 (task 597, attempt 0, stage 3.0)
[2025-07-19T21:02:34.614+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 186.0 in stage 3.0 (TID 598). 6200 bytes result sent to driver
[2025-07-19T21:02:34.615+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/193/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/193/.1.delta.ffc2809a-0de4-4cf0-b7f0-91ce7afe0fb2.TID601.tmp
[2025-07-19T21:02:34.615+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 166.0 in stage 3.0 (TID 595) in 130 ms on 8b44f3d35cfa (executor driver) (194/200)
[2025-07-19T21:02:34.615+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.615+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 604) (8b44f3d35cfa, executor driver, partition 1, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.616+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 1.0 in stage 7.0 (TID 604)
[2025-07-19T21:02:34.616+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@330e4b72
[2025-07-19T21:02:34.616+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 605) (8b44f3d35cfa, executor driver, partition 2, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.616+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=0, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:34.616+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 2.0 in stage 7.0 (TID 605)
[2025-07-19T21:02:34.616+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/0] for update
[2025-07-19T21:02:34.617+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 186.0 in stage 3.0 (TID 598) in 86 ms on 8b44f3d35cfa (executor driver) (195/200)
[2025-07-19T21:02:34.617+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.617+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.618+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.618+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.618+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63f090a3
[2025-07-19T21:02:34.618+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=2, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:34.619+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/2] for update
[2025-07-19T21:02:34.619+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 177 (task 597, attempt 0, stage 3.0)
[2025-07-19T21:02:34.619+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 177.0 in stage 3.0 (TID 597). 6200 bytes result sent to driver
[2025-07-19T21:02:34.619+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35e90e26
[2025-07-19T21:02:34.620+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 606) (8b44f3d35cfa, executor driver, partition 3, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.620+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 177.0 in stage 3.0 (TID 597) in 110 ms on 8b44f3d35cfa (executor driver) (196/200)
[2025-07-19T21:02:34.620+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 3.0 in stage 7.0 (TID 606)
[2025-07-19T21:02:34.620+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=1, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:34.620+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/1] for update
[2025-07-19T21:02:34.620+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.620+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.620+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/195/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/195/.1.delta.a37d1d97-c459-46c3-a542-09f837686a48.TID602.tmp
[2025-07-19T21:02:34.620+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3e78a197
[2025-07-19T21:02:34.620+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=3, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:34.620+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/3] for update
[2025-07-19T21:02:34.621+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.621+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.621+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.621+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.631+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/191/.1.delta.64340377-77a9-4d17-8dbc-a04c07991096.TID600.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/191/1.delta
[2025-07-19T21:02:34.632+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=191),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/191] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/191/1.delta
[2025-07-19T21:02:34.633+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/190/.1.delta.c1871189-9e48-47a4-aef9-12f3c50d6934.TID599.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/190/1.delta
[2025-07-19T21:02:34.633+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=190),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/190] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/190/1.delta
[2025-07-19T21:02:34.635+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodeGenerator: Code generated in 12.009334 ms
[2025-07-19T21:02:34.636+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 191 (task 600, attempt 0, stage 3.0)
[2025-07-19T21:02:34.638+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 190 (task 599, attempt 0, stage 3.0)
[2025-07-19T21:02:34.638+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 191 (task 600, attempt 0, stage 3.0)
[2025-07-19T21:02:34.638+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 190 (task 599, attempt 0, stage 3.0)
[2025-07-19T21:02:34.640+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/3/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/3/.2.delta.c4f74ce6-f97d-44b1-8b70-1d376b29863a.TID606.tmp
[2025-07-19T21:02:34.643+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 190.0 in stage 3.0 (TID 599). 6286 bytes result sent to driver
[2025-07-19T21:02:34.645+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/1/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/1/.2.delta.4db52972-453e-49af-b114-9636b3731ba4.TID604.tmp
[2025-07-19T21:02:34.645+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 607) (8b44f3d35cfa, executor driver, partition 4, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.646+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 191.0 in stage 3.0 (TID 600). 6286 bytes result sent to driver
[2025-07-19T21:02:34.646+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/2/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/2/.2.delta.b09ebe8d-4fe1-4c37-926a-9d6fb0cc1f3e.TID605.tmp
[2025-07-19T21:02:34.647+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 190.0 in stage 3.0 (TID 599) in 106 ms on 8b44f3d35cfa (executor driver) (197/200)
[2025-07-19T21:02:34.647+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 608) (8b44f3d35cfa, executor driver, partition 5, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.648+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 4.0 in stage 7.0 (TID 607)
[2025-07-19T21:02:34.648+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 5.0 in stage 7.0 (TID 608)
[2025-07-19T21:02:34.649+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/0/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/0/.2.delta.14314597-73cd-49f0-8ba8-11287c9541e5.TID603.tmp
[2025-07-19T21:02:34.649+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 191.0 in stage 3.0 (TID 600) in 94 ms on 8b44f3d35cfa (executor driver) (198/200)
[2025-07-19T21:02:34.651+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.652+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.654+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.655+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T21:02:34.660+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1fb03706
[2025-07-19T21:02:34.661+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=4, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:34.661+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/4] for update
[2025-07-19T21:02:34.662+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43796917
[2025-07-19T21:02:34.662+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.662+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=5, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:34.663+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/5] for update
[2025-07-19T21:02:34.665+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.665+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/193/.1.delta.ffc2809a-0de4-4cf0-b7f0-91ce7afe0fb2.TID601.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/193/1.delta
[2025-07-19T21:02:34.666+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=193),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/193] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/193/1.delta
[2025-07-19T21:02:34.667+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 193 (task 601, attempt 0, stage 3.0)
[2025-07-19T21:02:34.669+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 193 (task 601, attempt 0, stage 3.0)
[2025-07-19T21:02:34.671+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 193.0 in stage 3.0 (TID 601). 6243 bytes result sent to driver
[2025-07-19T21:02:34.673+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 609) (8b44f3d35cfa, executor driver, partition 6, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.673+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 6.0 in stage 7.0 (TID 609)
[2025-07-19T21:02:34.675+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/5/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/5/.2.delta.0167a7e3-745e-49de-b865-6da47c8aef1f.TID608.tmp
[2025-07-19T21:02:34.677+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/4/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/4/.2.delta.3b5b63a7-17fe-4e88-a031-5fddb704c776.TID607.tmp
[2025-07-19T21:02:34.679+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 193.0 in stage 3.0 (TID 601) in 93 ms on 8b44f3d35cfa (executor driver) (199/200)
[2025-07-19T21:02:34.679+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.680+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.681+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f3c4ab5
[2025-07-19T21:02:34.681+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/195/.1.delta.a37d1d97-c459-46c3-a542-09f837686a48.TID602.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/195/1.delta
[2025-07-19T21:02:34.682+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=195),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/195] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/195/1.delta
[2025-07-19T21:02:34.682+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=6, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:34.683+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 195 (task 602, attempt 0, stage 3.0)
[2025-07-19T21:02:34.683+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/6] for update
[2025-07-19T21:02:34.683+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.689+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 195 (task 602, attempt 0, stage 3.0)
[2025-07-19T21:02:34.689+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 195.0 in stage 3.0 (TID 602). 6243 bytes result sent to driver
[2025-07-19T21:02:34.689+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 610) (8b44f3d35cfa, executor driver, partition 7, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.690+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 7.0 in stage 7.0 (TID 610)
[2025-07-19T21:02:34.690+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 195.0 in stage 3.0 (TID 602) in 105 ms on 8b44f3d35cfa (executor driver) (200/200)
[2025-07-19T21:02:34.691+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
[2025-07-19T21:02:34.691+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DAGScheduler: ResultStage 3 (start at <unknown>:0) finished in 13.108 s
[2025-07-19T21:02:34.691+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-19T21:02:34.692+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/1/.2.delta.4db52972-453e-49af-b114-9636b3731ba4.TID604.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/1/2.delta
[2025-07-19T21:02:34.692+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
[2025-07-19T21:02:34.692+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/1] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/1/2.delta
[2025-07-19T21:02:34.693+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 1 (task 604, attempt 0, stage 7.0)
[2025-07-19T21:02:34.693+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DAGScheduler: Job 2 finished: start at <unknown>:0, took 14.564272 s
[2025-07-19T21:02:34.693+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Feedback_raw, format=PARQUET)] is committing.
[2025-07-19T21:02:34.697+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 1 (task 604, attempt 0, stage 7.0)
[2025-07-19T21:02:34.698+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO SparkWrite: Committing epoch 0 for query 30463049-c973-45be-97a0-fdd3d358740a in append mode
[2025-07-19T21:02:34.698+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.699+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/6/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/6/.2.delta.8ab6c3c7-be21-4ab0-aae9-fa2ed1640711.TID609.tmp
[2025-07-19T21:02:34.702+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:34.702+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/3/.2.delta.c4f74ce6-f97d-44b1-8b70-1d376b29863a.TID606.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/3/2.delta
[2025-07-19T21:02:34.703+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 1.0 in stage 7.0 (TID 604). 5872 bytes result sent to driver
[2025-07-19T21:02:34.703+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/3] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/3/2.delta
[2025-07-19T21:02:34.703+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 611) (8b44f3d35cfa, executor driver, partition 8, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.703+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 3 (task 606, attempt 0, stage 7.0)
[2025-07-19T21:02:34.703+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 8.0 in stage 7.0 (TID 611)
[2025-07-19T21:02:34.703+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 604) in 101 ms on 8b44f3d35cfa (executor driver) (1/200)
[2025-07-19T21:02:34.705+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@13ffbfee
[2025-07-19T21:02:34.706+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=7, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:34.707+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/7] for update
[2025-07-19T21:02:34.710+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.711+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.712+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 3 (task 606, attempt 0, stage 7.0)
[2025-07-19T21:02:34.712+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/0/.2.delta.14314597-73cd-49f0-8ba8-11287c9541e5.TID603.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/0/2.delta
[2025-07-19T21:02:34.713+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/0] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/0/2.delta
[2025-07-19T21:02:34.713+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 603, attempt 0, stage 7.0)
[2025-07-19T21:02:34.713+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@672af8db
[2025-07-19T21:02:34.713+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.714+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 3.0 in stage 7.0 (TID 606). 5872 bytes result sent to driver
[2025-07-19T21:02:34.714+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=8, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:34.714+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/8] for update
[2025-07-19T21:02:34.721+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 612) (8b44f3d35cfa, executor driver, partition 9, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.721+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 606) in 111 ms on 8b44f3d35cfa (executor driver) (2/200)
[2025-07-19T21:02:34.722+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.722+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/2/.2.delta.b09ebe8d-4fe1-4c37-926a-9d6fb0cc1f3e.TID605.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/2/2.delta
[2025-07-19T21:02:34.722+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/2] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/2/2.delta
[2025-07-19T21:02:34.722+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 9.0 in stage 7.0 (TID 612)
[2025-07-19T21:02:34.722+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 2 (task 605, attempt 0, stage 7.0)
[2025-07-19T21:02:34.730+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 0 (task 603, attempt 0, stage 7.0)
[2025-07-19T21:02:34.731+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 0.0 in stage 7.0 (TID 603). 5872 bytes result sent to driver
[2025-07-19T21:02:34.732+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 2 (task 605, attempt 0, stage 7.0)
[2025-07-19T21:02:34.732+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 603) in 139 ms on 8b44f3d35cfa (executor driver) (3/200)
[2025-07-19T21:02:34.733+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 10.0 in stage 7.0 (TID 613) (8b44f3d35cfa, executor driver, partition 10, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.733+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 2.0 in stage 7.0 (TID 605). 5872 bytes result sent to driver
[2025-07-19T21:02:34.734+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.734+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.736+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 11.0 in stage 7.0 (TID 614) (8b44f3d35cfa, executor driver, partition 11, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.736+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 11.0 in stage 7.0 (TID 614)
[2025-07-19T21:02:34.737+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@401b373e
[2025-07-19T21:02:34.737+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 10.0 in stage 7.0 (TID 613)
[2025-07-19T21:02:34.739+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 605) in 131 ms on 8b44f3d35cfa (executor driver) (4/200)
[2025-07-19T21:02:34.740+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/4/.2.delta.3b5b63a7-17fe-4e88-a031-5fddb704c776.TID607.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/4/2.delta
[2025-07-19T21:02:34.740+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/4] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/4/2.delta
[2025-07-19T21:02:34.741+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO SparkWrite: Committing streaming append with 146 new data files to table my_catalog.bronze.Feedback_raw
[2025-07-19T21:02:34.741+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 4 (task 607, attempt 0, stage 7.0)
[2025-07-19T21:02:34.741+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.741+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.741+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=9, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:34.741+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/9] for update
[2025-07-19T21:02:34.741+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.741+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/7/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/7/.2.delta.5bd81052-5488-43a8-a9e9-5f9ea1a7c524.TID610.tmp
[2025-07-19T21:02:34.741+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:34.742+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.742+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a28c37c
[2025-07-19T21:02:34.742+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=11, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:34.742+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=11),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/11] for update
[2025-07-19T21:02:34.743+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.747+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@42e9d7ec
[2025-07-19T21:02:34.748+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=10, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:34.749+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=10),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/10] for update
[2025-07-19T21:02:34.750+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/8/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/8/.2.delta.d5280a7e-4138-412d-b239-cd0552be072d.TID611.tmp
[2025-07-19T21:02:34.751+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 4 (task 607, attempt 0, stage 7.0)
[2025-07-19T21:02:34.752+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.752+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 4.0 in stage 7.0 (TID 607). 5829 bytes result sent to driver
[2025-07-19T21:02:34.753+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 12.0 in stage 7.0 (TID 615) (8b44f3d35cfa, executor driver, partition 12, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.753+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 607) in 103 ms on 8b44f3d35cfa (executor driver) (5/200)
[2025-07-19T21:02:34.753+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/5/.2.delta.0167a7e3-745e-49de-b865-6da47c8aef1f.TID608.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/5/2.delta
[2025-07-19T21:02:34.754+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/5] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/5/2.delta
[2025-07-19T21:02:34.755+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 5 (task 608, attempt 0, stage 7.0)
[2025-07-19T21:02:34.756+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 12.0 in stage 7.0 (TID 615)
[2025-07-19T21:02:34.756+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.756+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:34.756+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52a953b9
[2025-07-19T21:02:34.756+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=12, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:34.757+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=12),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/12] for update
[2025-07-19T21:02:34.759+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/9/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/9/.2.delta.6f5918f5-7ca7-4984-bc05-7fc2c1c0d8be.TID612.tmp
[2025-07-19T21:02:34.759+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 5 (task 608, attempt 0, stage 7.0)
[2025-07-19T21:02:34.760+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.761+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/10/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/10/.2.delta.d0ea09af-4254-49a7-b2ae-e62574301bcc.TID613.tmp
[2025-07-19T21:02:34.764+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/11/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/11/.2.delta.99081666-9c32-4489-9acc-cc1d3a999097.TID614.tmp
[2025-07-19T21:02:34.767+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 5.0 in stage 7.0 (TID 608). 5829 bytes result sent to driver
[2025-07-19T21:02:34.768+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/6/.2.delta.8ab6c3c7-be21-4ab0-aae9-fa2ed1640711.TID609.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/6/2.delta
[2025-07-19T21:02:34.769+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/6] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/6/2.delta
[2025-07-19T21:02:34.769+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/12/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/12/.2.delta.55c40c3c-525c-4ca4-844e-f14948ba33ca.TID615.tmp
[2025-07-19T21:02:34.769+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 13.0 in stage 7.0 (TID 616) (8b44f3d35cfa, executor driver, partition 13, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.769+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 6 (task 609, attempt 0, stage 7.0)
[2025-07-19T21:02:34.769+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 608) in 124 ms on 8b44f3d35cfa (executor driver) (6/200)
[2025-07-19T21:02:34.769+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 13.0 in stage 7.0 (TID 616)
[2025-07-19T21:02:34.771+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 6 (task 609, attempt 0, stage 7.0)
[2025-07-19T21:02:34.772+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 6.0 in stage 7.0 (TID 609). 5829 bytes result sent to driver
[2025-07-19T21:02:34.772+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 14.0 in stage 7.0 (TID 617) (8b44f3d35cfa, executor driver, partition 14, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.773+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 14.0 in stage 7.0 (TID 617)
[2025-07-19T21:02:34.773+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 609) in 103 ms on 8b44f3d35cfa (executor driver) (7/200)
[2025-07-19T21:02:34.773+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.774+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.775+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.775+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.777+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5409b5d5
[2025-07-19T21:02:34.779+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=14, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:34.779+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=14),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/14] for update
[2025-07-19T21:02:34.779+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@283ac85b
[2025-07-19T21:02:34.779+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.779+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=13, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:34.780+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=13),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/13] for update
[2025-07-19T21:02:34.780+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.790+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/14/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/14/.2.delta.0b965d56-7641-4f3a-9874-526669bf2c76.TID617.tmp
[2025-07-19T21:02:34.792+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/13/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/13/.2.delta.495fe4fd-9b87-4352-827a-3e8561a4c571.TID616.tmp
[2025-07-19T21:02:34.793+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/7/.2.delta.5bd81052-5488-43a8-a9e9-5f9ea1a7c524.TID610.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/7/2.delta
[2025-07-19T21:02:34.794+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/7] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/7/2.delta
[2025-07-19T21:02:34.795+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 7 (task 610, attempt 0, stage 7.0)
[2025-07-19T21:02:34.797+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/8/.2.delta.d5280a7e-4138-412d-b239-cd0552be072d.TID611.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/8/2.delta
[2025-07-19T21:02:34.797+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/8] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/8/2.delta
[2025-07-19T21:02:34.797+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 8 (task 611, attempt 0, stage 7.0)
[2025-07-19T21:02:34.799+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 7 (task 610, attempt 0, stage 7.0)
[2025-07-19T21:02:34.802+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 7.0 in stage 7.0 (TID 610). 5829 bytes result sent to driver
[2025-07-19T21:02:34.804+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 15.0 in stage 7.0 (TID 618) (8b44f3d35cfa, executor driver, partition 15, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.804+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 15.0 in stage 7.0 (TID 618)
[2025-07-19T21:02:34.805+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 610) in 113 ms on 8b44f3d35cfa (executor driver) (8/200)
[2025-07-19T21:02:34.806+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 8 (task 611, attempt 0, stage 7.0)
[2025-07-19T21:02:34.807+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.808+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.809+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2455526d
[2025-07-19T21:02:34.811+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=15, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:34.811+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=15),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/15] for update
[2025-07-19T21:02:34.811+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 8.0 in stage 7.0 (TID 611). 5829 bytes result sent to driver
[2025-07-19T21:02:34.812+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 16.0 in stage 7.0 (TID 619) (8b44f3d35cfa, executor driver, partition 16, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.812+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 16.0 in stage 7.0 (TID 619)
[2025-07-19T21:02:34.813+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/10/.2.delta.d0ea09af-4254-49a7-b2ae-e62574301bcc.TID613.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/10/2.delta
[2025-07-19T21:02:34.814+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=10),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/10] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/10/2.delta
[2025-07-19T21:02:34.815+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 611) in 107 ms on 8b44f3d35cfa (executor driver) (9/200)
[2025-07-19T21:02:34.815+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/11/.2.delta.99081666-9c32-4489-9acc-cc1d3a999097.TID614.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/11/2.delta
[2025-07-19T21:02:34.815+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=11),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/11] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/11/2.delta
[2025-07-19T21:02:34.815+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 10 (task 613, attempt 0, stage 7.0)
[2025-07-19T21:02:34.815+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.815+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 11 (task 614, attempt 0, stage 7.0)
[2025-07-19T21:02:34.815+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.815+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.815+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b7f72d3
[2025-07-19T21:02:34.816+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=16, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:34.816+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=16),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/16] for update
[2025-07-19T21:02:34.817+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 11 (task 614, attempt 0, stage 7.0)
[2025-07-19T21:02:34.817+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 11.0 in stage 7.0 (TID 614). 5829 bytes result sent to driver
[2025-07-19T21:02:34.817+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.817+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 17.0 in stage 7.0 (TID 620) (8b44f3d35cfa, executor driver, partition 17, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.817+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 11.0 in stage 7.0 (TID 614) in 85 ms on 8b44f3d35cfa (executor driver) (10/200)
[2025-07-19T21:02:34.818+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 17.0 in stage 7.0 (TID 620)
[2025-07-19T21:02:34.818+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 10 (task 613, attempt 0, stage 7.0)
[2025-07-19T21:02:34.818+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.819+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.819+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 10.0 in stage 7.0 (TID 613). 5829 bytes result sent to driver
[2025-07-19T21:02:34.819+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/9/.2.delta.6f5918f5-7ca7-4984-bc05-7fc2c1c0d8be.TID612.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/9/2.delta
[2025-07-19T21:02:34.819+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/9] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/9/2.delta
[2025-07-19T21:02:34.820+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/12/.2.delta.55c40c3c-525c-4ca4-844e-f14948ba33ca.TID615.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/12/2.delta
[2025-07-19T21:02:34.820+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=12),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/12] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/12/2.delta
[2025-07-19T21:02:34.822+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 18.0 in stage 7.0 (TID 621) (8b44f3d35cfa, executor driver, partition 18, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.823+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/15/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/15/.2.delta.1d21bf2b-6b2a-48f3-b093-649a7ef3b96a.TID618.tmp
[2025-07-19T21:02:34.824+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 18.0 in stage 7.0 (TID 621)
[2025-07-19T21:02:34.824+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 9 (task 612, attempt 0, stage 7.0)
[2025-07-19T21:02:34.824+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 10.0 in stage 7.0 (TID 613) in 93 ms on 8b44f3d35cfa (executor driver) (11/200)
[2025-07-19T21:02:34.824+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 12 (task 615, attempt 0, stage 7.0)
[2025-07-19T21:02:34.825+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/16/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/16/.2.delta.9af9a2e7-3746-484e-be86-a9c366a336fc.TID619.tmp
[2025-07-19T21:02:34.826+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.826+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.830+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c008af8
[2025-07-19T21:02:34.830+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=17, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:34.831+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=17),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/17] for update
[2025-07-19T21:02:34.831+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a479429
[2025-07-19T21:02:34.833+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/13/.2.delta.495fe4fd-9b87-4352-827a-3e8561a4c571.TID616.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/13/2.delta
[2025-07-19T21:02:34.834+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=13),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/13] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/13/2.delta
[2025-07-19T21:02:34.834+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 9 (task 612, attempt 0, stage 7.0)
[2025-07-19T21:02:34.836+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 9.0 in stage 7.0 (TID 612). 5829 bytes result sent to driver
[2025-07-19T21:02:34.836+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.837+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 13 (task 616, attempt 0, stage 7.0)
[2025-07-19T21:02:34.837+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 19.0 in stage 7.0 (TID 622) (8b44f3d35cfa, executor driver, partition 19, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.837+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=18, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:34.837+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 12 (task 615, attempt 0, stage 7.0)
[2025-07-19T21:02:34.837+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 12.0 in stage 7.0 (TID 615). 5829 bytes result sent to driver
[2025-07-19T21:02:34.837+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=18),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/18] for update
[2025-07-19T21:02:34.837+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 19.0 in stage 7.0 (TID 622)
[2025-07-19T21:02:34.839+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 612) in 124 ms on 8b44f3d35cfa (executor driver) (12/200)
[2025-07-19T21:02:34.842+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 20.0 in stage 7.0 (TID 623) (8b44f3d35cfa, executor driver, partition 20, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.842+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.842+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 12.0 in stage 7.0 (TID 615) in 91 ms on 8b44f3d35cfa (executor driver) (13/200)
[2025-07-19T21:02:34.842+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.843+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:34.843+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 20.0 in stage 7.0 (TID 623)
[2025-07-19T21:02:34.844+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@788157f2
[2025-07-19T21:02:34.845+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/18/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/18/.2.delta.34d7165d-df54-4c7a-aaf0-4a0d63b00720.TID621.tmp
[2025-07-19T21:02:34.847+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.848+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 13 (task 616, attempt 0, stage 7.0)
[2025-07-19T21:02:34.848+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.848+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/17/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/17/.2.delta.5c499733-cae9-4aea-a964-643d1a48798a.TID620.tmp
[2025-07-19T21:02:34.849+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=19, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:34.849+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=19),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/19] for update
[2025-07-19T21:02:34.849+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 13.0 in stage 7.0 (TID 616). 5829 bytes result sent to driver
[2025-07-19T21:02:34.850+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 21.0 in stage 7.0 (TID 624) (8b44f3d35cfa, executor driver, partition 21, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.850+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 21.0 in stage 7.0 (TID 624)
[2025-07-19T21:02:34.850+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 13.0 in stage 7.0 (TID 616) in 79 ms on 8b44f3d35cfa (executor driver) (14/200)
[2025-07-19T21:02:34.850+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2fb24caf
[2025-07-19T21:02:34.850+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.851+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=20, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:34.851+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=20),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/20] for update
[2025-07-19T21:02:34.851+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:34.854+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/14/.2.delta.0b965d56-7641-4f3a-9874-526669bf2c76.TID617.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/14/2.delta
[2025-07-19T21:02:34.855+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=14),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/14] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/14/2.delta
[2025-07-19T21:02:34.855+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@76e57066
[2025-07-19T21:02:34.855+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 14 (task 617, attempt 0, stage 7.0)
[2025-07-19T21:02:34.856+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.856+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=21, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:34.856+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=21),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/21] for update
[2025-07-19T21:02:34.859+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.860+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.861+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/15/.2.delta.1d21bf2b-6b2a-48f3-b093-649a7ef3b96a.TID618.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/15/2.delta
[2025-07-19T21:02:34.861+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=15),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/15] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/15/2.delta
[2025-07-19T21:02:34.862+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 15 (task 618, attempt 0, stage 7.0)
[2025-07-19T21:02:34.865+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/19/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/19/.2.delta.8015e46b-e0b4-4151-a2cb-2cf517068f7d.TID622.tmp
[2025-07-19T21:02:34.867+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 15 (task 618, attempt 0, stage 7.0)
[2025-07-19T21:02:34.868+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/20/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/20/.2.delta.aa01dcd5-ffe2-4a4e-a282-8965a082f9a2.TID623.tmp
[2025-07-19T21:02:34.869+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 15.0 in stage 7.0 (TID 618). 5829 bytes result sent to driver
[2025-07-19T21:02:34.870+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 22.0 in stage 7.0 (TID 625) (8b44f3d35cfa, executor driver, partition 22, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.870+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 15.0 in stage 7.0 (TID 618) in 68 ms on 8b44f3d35cfa (executor driver) (15/200)
[2025-07-19T21:02:34.870+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 22.0 in stage 7.0 (TID 625)
[2025-07-19T21:02:34.870+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 14 (task 617, attempt 0, stage 7.0)
[2025-07-19T21:02:34.871+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 14.0 in stage 7.0 (TID 617). 5829 bytes result sent to driver
[2025-07-19T21:02:34.873+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.873+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:34.873+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 23.0 in stage 7.0 (TID 626) (8b44f3d35cfa, executor driver, partition 23, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.874+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/16/.2.delta.9af9a2e7-3746-484e-be86-a9c366a336fc.TID619.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/16/2.delta
[2025-07-19T21:02:34.874+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=16),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/16] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/16/2.delta
[2025-07-19T21:02:34.874+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c8d9dc0
[2025-07-19T21:02:34.875+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 16 (task 619, attempt 0, stage 7.0)
[2025-07-19T21:02:34.876+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=22, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:34.876+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=22),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/22] for update
[2025-07-19T21:02:34.876+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 23.0 in stage 7.0 (TID 626)
[2025-07-19T21:02:34.876+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 14.0 in stage 7.0 (TID 617) in 101 ms on 8b44f3d35cfa (executor driver) (16/200)
[2025-07-19T21:02:34.877+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.877+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.877+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@61e92b08
[2025-07-19T21:02:34.877+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=23, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:34.877+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=23),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/23] for update
[2025-07-19T21:02:34.879+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/21/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/21/.2.delta.9a81313f-05b9-4783-88a5-de364c41e348.TID624.tmp
[2025-07-19T21:02:34.889+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/17/.2.delta.5c499733-cae9-4aea-a964-643d1a48798a.TID620.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/17/2.delta
[2025-07-19T21:02:34.889+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=17),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/17] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/17/2.delta
[2025-07-19T21:02:34.890+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/18/.2.delta.34d7165d-df54-4c7a-aaf0-4a0d63b00720.TID621.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/18/2.delta
[2025-07-19T21:02:34.891+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=18),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/18] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/18/2.delta
[2025-07-19T21:02:34.891+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 17 (task 620, attempt 0, stage 7.0)
[2025-07-19T21:02:34.892+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 18 (task 621, attempt 0, stage 7.0)
[2025-07-19T21:02:34.893+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 16 (task 619, attempt 0, stage 7.0)
[2025-07-19T21:02:34.894+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 16.0 in stage 7.0 (TID 619). 5829 bytes result sent to driver
[2025-07-19T21:02:34.895+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 24.0 in stage 7.0 (TID 627) (8b44f3d35cfa, executor driver, partition 24, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.896+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 16.0 in stage 7.0 (TID 619) in 87 ms on 8b44f3d35cfa (executor driver) (17/200)
[2025-07-19T21:02:34.896+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 24.0 in stage 7.0 (TID 627)
[2025-07-19T21:02:34.896+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.897+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.897+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.898+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ddc7f5
[2025-07-19T21:02:34.899+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=24, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:34.899+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=24),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/24] for update
[2025-07-19T21:02:34.900+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.901+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.902+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 18 (task 621, attempt 0, stage 7.0)
[2025-07-19T21:02:34.903+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 18.0 in stage 7.0 (TID 621). 5829 bytes result sent to driver
[2025-07-19T21:02:34.904+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 17 (task 620, attempt 0, stage 7.0)
[2025-07-19T21:02:34.905+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 17.0 in stage 7.0 (TID 620). 5829 bytes result sent to driver
[2025-07-19T21:02:34.908+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 25.0 in stage 7.0 (TID 628) (8b44f3d35cfa, executor driver, partition 25, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.909+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 26.0 in stage 7.0 (TID 629) (8b44f3d35cfa, executor driver, partition 26, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.909+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 18.0 in stage 7.0 (TID 621) in 83 ms on 8b44f3d35cfa (executor driver) (18/200)
[2025-07-19T21:02:34.910+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 26.0 in stage 7.0 (TID 629)
[2025-07-19T21:02:34.910+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.910+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 17.0 in stage 7.0 (TID 620) in 91 ms on 8b44f3d35cfa (executor driver) (19/200)
[2025-07-19T21:02:34.911+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 25.0 in stage 7.0 (TID 628)
[2025-07-19T21:02:34.911+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.911+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/20/.2.delta.aa01dcd5-ffe2-4a4e-a282-8965a082f9a2.TID623.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/20/2.delta
[2025-07-19T21:02:34.911+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=20),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/20] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/20/2.delta
[2025-07-19T21:02:34.911+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/19/.2.delta.8015e46b-e0b4-4151-a2cb-2cf517068f7d.TID622.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/19/2.delta
[2025-07-19T21:02:34.912+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=19),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/19] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/19/2.delta
[2025-07-19T21:02:34.912+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47d23273
[2025-07-19T21:02:34.912+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.913+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.914+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 19 (task 622, attempt 0, stage 7.0)
[2025-07-19T21:02:34.914+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/23/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/23/.2.delta.a5f5f302-54b6-4501-aa64-996a1ccd997b.TID626.tmp
[2025-07-19T21:02:34.915+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/22/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/22/.2.delta.b137eb34-3502-4930-833f-2ae92dc5835c.TID625.tmp
[2025-07-19T21:02:34.915+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 20 (task 623, attempt 0, stage 7.0)
[2025-07-19T21:02:34.916+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=26, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:34.917+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=26),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/26] for update
[2025-07-19T21:02:34.917+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 19 (task 622, attempt 0, stage 7.0)
[2025-07-19T21:02:34.919+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@461cccf7
[2025-07-19T21:02:34.920+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 20 (task 623, attempt 0, stage 7.0)
[2025-07-19T21:02:34.920+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.922+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 19.0 in stage 7.0 (TID 622). 5829 bytes result sent to driver
[2025-07-19T21:02:34.922+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 27.0 in stage 7.0 (TID 630) (8b44f3d35cfa, executor driver, partition 27, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.923+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 27.0 in stage 7.0 (TID 630)
[2025-07-19T21:02:34.923+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 19.0 in stage 7.0 (TID 622) in 86 ms on 8b44f3d35cfa (executor driver) (20/200)
[2025-07-19T21:02:34.923+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 20.0 in stage 7.0 (TID 623). 5829 bytes result sent to driver
[2025-07-19T21:02:34.923+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 28.0 in stage 7.0 (TID 631) (8b44f3d35cfa, executor driver, partition 28, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.924+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=25, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:34.924+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=25),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/25] for update
[2025-07-19T21:02:34.926+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 20.0 in stage 7.0 (TID 623) in 84 ms on 8b44f3d35cfa (executor driver) (21/200)
[2025-07-19T21:02:34.926+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.927+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.928+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 28.0 in stage 7.0 (TID 631)
[2025-07-19T21:02:34.930+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/21/.2.delta.9a81313f-05b9-4783-88a5-de364c41e348.TID624.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/21/2.delta
[2025-07-19T21:02:34.930+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53312a87
[2025-07-19T21:02:34.930+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=21),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/21] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/21/2.delta
[2025-07-19T21:02:34.930+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=27, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:34.932+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=27),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/27] for update
[2025-07-19T21:02:34.933+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.933+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 21 (task 624, attempt 0, stage 7.0)
[2025-07-19T21:02:34.933+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.933+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.933+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.933+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 21 (task 624, attempt 0, stage 7.0)
[2025-07-19T21:02:34.934+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a357e97
[2025-07-19T21:02:34.934+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=28, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:34.934+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=28),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/28] for update
[2025-07-19T21:02:34.934+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 21.0 in stage 7.0 (TID 624). 5829 bytes result sent to driver
[2025-07-19T21:02:34.934+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 29.0 in stage 7.0 (TID 632) (8b44f3d35cfa, executor driver, partition 29, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.934+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 21.0 in stage 7.0 (TID 624) in 86 ms on 8b44f3d35cfa (executor driver) (22/200)
[2025-07-19T21:02:34.934+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.938+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 29.0 in stage 7.0 (TID 632)
[2025-07-19T21:02:34.939+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/27/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/27/.2.delta.4278dcf0-f86a-42e2-951b-4222891d829c.TID630.tmp
[2025-07-19T21:02:34.939+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/26/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/26/.2.delta.db390898-1800-459e-82a7-0cc407d7c6fd.TID629.tmp
[2025-07-19T21:02:34.940+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/25/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/25/.2.delta.1939c000-92dd-443b-9906-2bb99f7fc57d.TID628.tmp
[2025-07-19T21:02:34.940+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.940+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:34.945+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/24/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/24/.2.delta.486244dd-3d11-4aca-9e3c-b19174c5d749.TID627.tmp
[2025-07-19T21:02:34.945+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/28/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/28/.2.delta.0d2d4708-3ced-45f2-9c23-1d9815d61c75.TID631.tmp
[2025-07-19T21:02:34.946+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3bd9b802
[2025-07-19T21:02:34.946+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=29, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:34.947+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=29),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/29] for update
[2025-07-19T21:02:34.950+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.954+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HadoopTableOperations: Committed a new metadata file s3a://warehouse/bronze/Feedback_raw/metadata/v128.metadata.json
[2025-07-19T21:02:34.962+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/22/.2.delta.b137eb34-3502-4930-833f-2ae92dc5835c.TID625.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/22/2.delta
[2025-07-19T21:02:34.963+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=22),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/22] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/22/2.delta
[2025-07-19T21:02:34.963+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 22 (task 625, attempt 0, stage 7.0)
[2025-07-19T21:02:34.968+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/29/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/29/.2.delta.54c0a8d3-ad52-4f57-b1c1-c37dcf1d8c79.TID632.tmp
[2025-07-19T21:02:34.968+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/23/.2.delta.a5f5f302-54b6-4501-aa64-996a1ccd997b.TID626.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/23/2.delta
[2025-07-19T21:02:34.969+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=23),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/23] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/23/2.delta
[2025-07-19T21:02:34.970+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 23 (task 626, attempt 0, stage 7.0)
[2025-07-19T21:02:34.971+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 22 (task 625, attempt 0, stage 7.0)
[2025-07-19T21:02:34.971+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 22.0 in stage 7.0 (TID 625). 5829 bytes result sent to driver
[2025-07-19T21:02:34.974+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 23 (task 626, attempt 0, stage 7.0)
[2025-07-19T21:02:34.975+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 23.0 in stage 7.0 (TID 626). 5829 bytes result sent to driver
[2025-07-19T21:02:34.976+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 30.0 in stage 7.0 (TID 633) (8b44f3d35cfa, executor driver, partition 30, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.977+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 31.0 in stage 7.0 (TID 634) (8b44f3d35cfa, executor driver, partition 31, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.977+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 22.0 in stage 7.0 (TID 625) in 105 ms on 8b44f3d35cfa (executor driver) (23/200)
[2025-07-19T21:02:34.977+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 23.0 in stage 7.0 (TID 626) in 100 ms on 8b44f3d35cfa (executor driver) (24/200)
[2025-07-19T21:02:34.977+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/27/.2.delta.4278dcf0-f86a-42e2-951b-4222891d829c.TID630.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/27/2.delta
[2025-07-19T21:02:34.978+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=27),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/27] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/27/2.delta
[2025-07-19T21:02:34.978+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 27 (task 630, attempt 0, stage 7.0)
[2025-07-19T21:02:34.978+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/25/.2.delta.1939c000-92dd-443b-9906-2bb99f7fc57d.TID628.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/25/2.delta
[2025-07-19T21:02:34.979+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=25),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/25] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/25/2.delta
[2025-07-19T21:02:34.979+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 25 (task 628, attempt 0, stage 7.0)
[2025-07-19T21:02:34.980+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/26/.2.delta.db390898-1800-459e-82a7-0cc407d7c6fd.TID629.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/26/2.delta
[2025-07-19T21:02:34.981+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=26),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/26] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/26/2.delta
[2025-07-19T21:02:34.981+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 31.0 in stage 7.0 (TID 634)
[2025-07-19T21:02:34.982+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 30.0 in stage 7.0 (TID 633)
[2025-07-19T21:02:34.982+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 26 (task 629, attempt 0, stage 7.0)
[2025-07-19T21:02:34.982+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/28/.2.delta.0d2d4708-3ced-45f2-9c23-1d9815d61c75.TID631.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/28/2.delta
[2025-07-19T21:02:34.982+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=28),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/28] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/28/2.delta
[2025-07-19T21:02:34.985+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/24/.2.delta.486244dd-3d11-4aca-9e3c-b19174c5d749.TID627.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/24/2.delta
[2025-07-19T21:02:34.986+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=24),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/24] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/24/2.delta
[2025-07-19T21:02:34.987+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 28 (task 631, attempt 0, stage 7.0)
[2025-07-19T21:02:34.987+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Commit authorized for partition 24 (task 627, attempt 0, stage 7.0)
[2025-07-19T21:02:34.988+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.989+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T21:02:34.990+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@72e20022
[2025-07-19T21:02:34.990+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=31, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:34.990+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.990+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T21:02:34.990+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=31),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/31] for update
[2025-07-19T21:02:34.990+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f82a0f3
[2025-07-19T21:02:34.991+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 25 (task 628, attempt 0, stage 7.0)
[2025-07-19T21:02:34.991+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 24 (task 627, attempt 0, stage 7.0)
[2025-07-19T21:02:34.992+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 25.0 in stage 7.0 (TID 628). 5829 bytes result sent to driver
[2025-07-19T21:02:34.993+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 26 (task 629, attempt 0, stage 7.0)
[2025-07-19T21:02:34.993+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 32.0 in stage 7.0 (TID 635) (8b44f3d35cfa, executor driver, partition 32, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.994+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 26.0 in stage 7.0 (TID 629). 5829 bytes result sent to driver
[2025-07-19T21:02:34.994+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 24.0 in stage 7.0 (TID 627). 5829 bytes result sent to driver
[2025-07-19T21:02:34.995+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 33.0 in stage 7.0 (TID 636) (8b44f3d35cfa, executor driver, partition 33, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.995+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 34.0 in stage 7.0 (TID 637) (8b44f3d35cfa, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.995+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 33.0 in stage 7.0 (TID 636)
[2025-07-19T21:02:34.995+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 34.0 in stage 7.0 (TID 637)
[2025-07-19T21:02:34.995+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.995+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 25.0 in stage 7.0 (TID 628) in 88 ms on 8b44f3d35cfa (executor driver) (25/200)
[2025-07-19T21:02:34.995+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 24.0 in stage 7.0 (TID 627) in 98 ms on 8b44f3d35cfa (executor driver) (26/200)
[2025-07-19T21:02:34.995+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 28 (task 631, attempt 0, stage 7.0)
[2025-07-19T21:02:34.996+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO DataWritingSparkTask: Committed partition 27 (task 630, attempt 0, stage 7.0)
[2025-07-19T21:02:34.996+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 26.0 in stage 7.0 (TID 629) in 88 ms on 8b44f3d35cfa (executor driver) (27/200)
[2025-07-19T21:02:34.996+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 28.0 in stage 7.0 (TID 631). 5829 bytes result sent to driver
[2025-07-19T21:02:34.996+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Starting task 35.0 in stage 7.0 (TID 638) (8b44f3d35cfa, executor driver, partition 35, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:34.996+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=30, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:34.996+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=30),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/30] for update
[2025-07-19T21:02:34.996+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Finished task 27.0 in stage 7.0 (TID 630). 5829 bytes result sent to driver
[2025-07-19T21:02:34.996+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO TaskSetManager: Finished task 28.0 in stage 7.0 (TID 631) in 72 ms on 8b44f3d35cfa (executor driver) (28/200)
[2025-07-19T21:02:34.996+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 32.0 in stage 7.0 (TID 635)
[2025-07-19T21:02:34.997+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO Executor: Running task 35.0 in stage 7.0 (TID 638)
[2025-07-19T21:02:34.997+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.997+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.997+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.997+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.997+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:34.997+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:34.998+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:34.998+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/29/.2.delta.54c0a8d3-ad52-4f57-b1c1-c37dcf1d8c79.TID632.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/29/2.delta
[2025-07-19T21:02:34.998+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=29),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/29] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/29/2.delta
[2025-07-19T21:02:34.998+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/31/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/31/.2.delta.1db86959-88b9-4217-9e55-25dcd0bf27e1.TID634.tmp
[2025-07-19T21:02:34.999+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.000+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.000+0000] {subprocess.py:93} INFO - 25/07/19 21:02:34 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/30/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/30/.2.delta.4da486b5-ab68-4cc4-930a-05f606bc79fc.TID633.tmp
[2025-07-19T21:02:35.001+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 36.0 in stage 7.0 (TID 639) (8b44f3d35cfa, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.008+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 29 (task 632, attempt 0, stage 7.0)
[2025-07-19T21:02:35.009+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 27.0 in stage 7.0 (TID 630) in 86 ms on 8b44f3d35cfa (executor driver) (29/200)
[2025-07-19T21:02:35.010+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 36.0 in stage 7.0 (TID 639)
[2025-07-19T21:02:35.011+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.011+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.012+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@67120f35
[2025-07-19T21:02:35.012+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=32, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.013+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=32),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/32] for update
[2025-07-19T21:02:35.014+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23b737df
[2025-07-19T21:02:35.014+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 29 (task 632, attempt 0, stage 7.0)
[2025-07-19T21:02:35.014+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.015+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 29.0 in stage 7.0 (TID 632). 5829 bytes result sent to driver
[2025-07-19T21:02:35.015+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 37.0 in stage 7.0 (TID 640) (8b44f3d35cfa, executor driver, partition 37, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.015+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=36, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.016+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=36),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/36] for update
[2025-07-19T21:02:35.016+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.017+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d26cb85
[2025-07-19T21:02:35.024+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 29.0 in stage 7.0 (TID 632) in 94 ms on 8b44f3d35cfa (executor driver) (30/200)
[2025-07-19T21:02:35.026+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=35, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.028+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=35),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/35] for update
[2025-07-19T21:02:35.028+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 37.0 in stage 7.0 (TID 640)
[2025-07-19T21:02:35.030+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/31/.2.delta.1db86959-88b9-4217-9e55-25dcd0bf27e1.TID634.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/31/2.delta
[2025-07-19T21:02:35.031+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=31),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/31] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/31/2.delta
[2025-07-19T21:02:35.031+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55397dee
[2025-07-19T21:02:35.032+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.033+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=34, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.033+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=34),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/34] for update
[2025-07-19T21:02:35.034+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.034+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.035+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.035+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@581325e3
[2025-07-19T21:02:35.035+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=37, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.035+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=37),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/37] for update
[2025-07-19T21:02:35.035+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/32/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/32/.2.delta.ef420664-7bab-41e2-91e1-067ae8455708.TID635.tmp
[2025-07-19T21:02:35.036+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.036+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 31 (task 634, attempt 0, stage 7.0)
[2025-07-19T21:02:35.037+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO SnapshotProducer: Committed snapshot 8741241315777032740 (FastAppend)
[2025-07-19T21:02:35.037+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@598c8c00
[2025-07-19T21:02:35.040+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=33, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.040+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=33),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/33] for update
[2025-07-19T21:02:35.041+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.041+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/37/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/37/.2.delta.f1bb86a7-0df7-4e91-95fb-04f9bb1fd2bd.TID640.tmp
[2025-07-19T21:02:35.042+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/36/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/36/.2.delta.60075dc9-4b54-4e49-9bae-1061e844a180.TID639.tmp
[2025-07-19T21:02:35.042+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/34/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/34/.2.delta.887bdc78-fbf6-4a92-ac6d-64501e1fb61e.TID637.tmp
[2025-07-19T21:02:35.043+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 31 (task 634, attempt 0, stage 7.0)
[2025-07-19T21:02:35.044+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/30/.2.delta.4da486b5-ab68-4cc4-930a-05f606bc79fc.TID633.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/30/2.delta
[2025-07-19T21:02:35.047+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=30),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/30] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/30/2.delta
[2025-07-19T21:02:35.047+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 30 (task 633, attempt 0, stage 7.0)
[2025-07-19T21:02:35.047+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 31.0 in stage 7.0 (TID 634). 5872 bytes result sent to driver
[2025-07-19T21:02:35.048+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/35/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/35/.2.delta.7b87a5ee-80b8-4936-9886-df4184f80a09.TID638.tmp
[2025-07-19T21:02:35.048+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 38.0 in stage 7.0 (TID 641) (8b44f3d35cfa, executor driver, partition 38, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.048+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 31.0 in stage 7.0 (TID 634) in 72 ms on 8b44f3d35cfa (executor driver) (31/200)
[2025-07-19T21:02:35.048+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/33/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/33/.2.delta.61cce6df-2dfd-4277-bf0c-8ab6db066adb.TID636.tmp
[2025-07-19T21:02:35.049+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 38.0 in stage 7.0 (TID 641)
[2025-07-19T21:02:35.051+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 30 (task 633, attempt 0, stage 7.0)
[2025-07-19T21:02:35.052+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 30.0 in stage 7.0 (TID 633). 5872 bytes result sent to driver
[2025-07-19T21:02:35.054+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.055+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.055+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 39.0 in stage 7.0 (TID 642) (8b44f3d35cfa, executor driver, partition 39, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.055+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 30.0 in stage 7.0 (TID 633) in 83 ms on 8b44f3d35cfa (executor driver) (32/200)
[2025-07-19T21:02:35.056+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@50f07b72
[2025-07-19T21:02:35.057+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=38, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.057+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=38),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/38] for update
[2025-07-19T21:02:35.058+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 39.0 in stage 7.0 (TID 642)
[2025-07-19T21:02:35.060+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.061+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.065+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.066+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a0dfd55
[2025-07-19T21:02:35.067+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=39, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.067+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=39),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/39] for update
[2025-07-19T21:02:35.068+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.074+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO LoggingMetricsReporter: Received metrics report: CommitReport{tableName=my_catalog.bronze.Feedback_raw, snapshotId=8741241315777032740, sequenceNumber=127, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.336174667S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=CounterResult{unit=COUNT, value=146}, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=6406}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=CounterResult{unit=COUNT, value=234}, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=8928}, addedFilesSizeInBytes=CounterResult{unit=BYTES, value=423329}, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=18464384}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}}, metadata={engine-version=3.5.6, app-id=local-1752958935081, engine-name=spark, iceberg-version=Apache Iceberg 1.4.0 (commit 10367c380098c2e06a49521a33681ac7f6c64b2c)}}
[2025-07-19T21:02:35.074+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO SparkWrite: Committed in 336 ms
[2025-07-19T21:02:35.074+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Feedback_raw, format=PARQUET)] committed.
[2025-07-19T21:02:35.074+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO WatermarkTracker: Updating event-time watermark from 0 to 1752786128000 ms
[2025-07-19T21:02:35.091+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/32/.2.delta.ef420664-7bab-41e2-91e1-067ae8455708.TID635.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/32/2.delta
[2025-07-19T21:02:35.092+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=32),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/32] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/32/2.delta
[2025-07-19T21:02:35.093+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/38/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/38/.2.delta.62e60288-7ac7-4d0e-8a3c-ce40db95a076.TID641.tmp
[2025-07-19T21:02:35.094+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 32 (task 635, attempt 0, stage 7.0)
[2025-07-19T21:02:35.094+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/39/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/39/.2.delta.24f8efdf-4505-4143-b9ed-1529d2e84df0.TID642.tmp
[2025-07-19T21:02:35.096+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/34/.2.delta.887bdc78-fbf6-4a92-ac6d-64501e1fb61e.TID637.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/34/2.delta
[2025-07-19T21:02:35.096+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=34),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/34] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/34/2.delta
[2025-07-19T21:02:35.097+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 34 (task 637, attempt 0, stage 7.0)
[2025-07-19T21:02:35.097+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/commits/0 using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/commits/.0.e4a28d87-01b3-49e6-82d3-c1cdf8366db9.tmp
[2025-07-19T21:02:35.102+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/36/.2.delta.60075dc9-4b54-4e49-9bae-1061e844a180.TID639.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/36/2.delta
[2025-07-19T21:02:35.103+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=36),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/36] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/36/2.delta
[2025-07-19T21:02:35.105+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/37/.2.delta.f1bb86a7-0df7-4e91-95fb-04f9bb1fd2bd.TID640.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/37/2.delta
[2025-07-19T21:02:35.106+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=37),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/37] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/37/2.delta
[2025-07-19T21:02:35.107+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 37 (task 640, attempt 0, stage 7.0)
[2025-07-19T21:02:35.107+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 36 (task 639, attempt 0, stage 7.0)
[2025-07-19T21:02:35.107+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 32 (task 635, attempt 0, stage 7.0)
[2025-07-19T21:02:35.107+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/35/.2.delta.7b87a5ee-80b8-4936-9886-df4184f80a09.TID638.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/35/2.delta
[2025-07-19T21:02:35.107+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=35),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/35] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/35/2.delta
[2025-07-19T21:02:35.107+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 35 (task 638, attempt 0, stage 7.0)
[2025-07-19T21:02:35.108+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/33/.2.delta.61cce6df-2dfd-4277-bf0c-8ab6db066adb.TID636.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/33/2.delta
[2025-07-19T21:02:35.108+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=33),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/33] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/33/2.delta
[2025-07-19T21:02:35.109+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 37 (task 640, attempt 0, stage 7.0)
[2025-07-19T21:02:35.112+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 33 (task 636, attempt 0, stage 7.0)
[2025-07-19T21:02:35.114+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 32.0 in stage 7.0 (TID 635). 5872 bytes result sent to driver
[2025-07-19T21:02:35.115+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 37.0 in stage 7.0 (TID 640). 5872 bytes result sent to driver
[2025-07-19T21:02:35.117+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 40.0 in stage 7.0 (TID 643) (8b44f3d35cfa, executor driver, partition 40, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.118+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 36 (task 639, attempt 0, stage 7.0)
[2025-07-19T21:02:35.119+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 34 (task 637, attempt 0, stage 7.0)
[2025-07-19T21:02:35.119+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 32.0 in stage 7.0 (TID 635) in 117 ms on 8b44f3d35cfa (executor driver) (33/200)
[2025-07-19T21:02:35.120+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 40.0 in stage 7.0 (TID 643)
[2025-07-19T21:02:35.122+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 41.0 in stage 7.0 (TID 644) (8b44f3d35cfa, executor driver, partition 41, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.122+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 41.0 in stage 7.0 (TID 644)
[2025-07-19T21:02:35.123+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 35 (task 638, attempt 0, stage 7.0)
[2025-07-19T21:02:35.125+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 34.0 in stage 7.0 (TID 637). 5872 bytes result sent to driver
[2025-07-19T21:02:35.126+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 36.0 in stage 7.0 (TID 639). 5872 bytes result sent to driver
[2025-07-19T21:02:35.128+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 42.0 in stage 7.0 (TID 645) (8b44f3d35cfa, executor driver, partition 42, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.128+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 42.0 in stage 7.0 (TID 645)
[2025-07-19T21:02:35.128+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 43.0 in stage 7.0 (TID 646) (8b44f3d35cfa, executor driver, partition 43, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.129+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 43.0 in stage 7.0 (TID 646)
[2025-07-19T21:02:35.129+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 37.0 in stage 7.0 (TID 640) in 98 ms on 8b44f3d35cfa (executor driver) (34/200)
[2025-07-19T21:02:35.129+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 36.0 in stage 7.0 (TID 639) in 111 ms on 8b44f3d35cfa (executor driver) (35/200)
[2025-07-19T21:02:35.130+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 35.0 in stage 7.0 (TID 638). 5872 bytes result sent to driver
[2025-07-19T21:02:35.131+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 34.0 in stage 7.0 (TID 637) in 122 ms on 8b44f3d35cfa (executor driver) (36/200)
[2025-07-19T21:02:35.131+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 33 (task 636, attempt 0, stage 7.0)
[2025-07-19T21:02:35.131+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 33.0 in stage 7.0 (TID 636). 5872 bytes result sent to driver
[2025-07-19T21:02:35.132+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.134+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.134+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.134+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.134+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 44.0 in stage 7.0 (TID 647) (8b44f3d35cfa, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.134+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 35.0 in stage 7.0 (TID 638) in 123 ms on 8b44f3d35cfa (executor driver) (37/200)
[2025-07-19T21:02:35.134+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 45.0 in stage 7.0 (TID 648) (8b44f3d35cfa, executor driver, partition 45, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.135+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 45.0 in stage 7.0 (TID 648)
[2025-07-19T21:02:35.135+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 44.0 in stage 7.0 (TID 647)
[2025-07-19T21:02:35.136+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71cd35ef
[2025-07-19T21:02:35.136+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.136+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:35.136+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 33.0 in stage 7.0 (TID 636) in 129 ms on 8b44f3d35cfa (executor driver) (38/200)
[2025-07-19T21:02:35.136+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.137+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.137+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.137+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=40, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.137+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=40),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/40] for update
[2025-07-19T21:02:35.137+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.137+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22c32f64
[2025-07-19T21:02:35.138+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=43, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.139+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=43),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/43] for update
[2025-07-19T21:02:35.139+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.140+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:35.141+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.141+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.141+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@579bfe85
[2025-07-19T21:02:35.142+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=41, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.143+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=41),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/41] for update
[2025-07-19T21:02:35.143+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d80fca8
[2025-07-19T21:02:35.143+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=42, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.143+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=42),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/42] for update
[2025-07-19T21:02:35.143+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.144+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@588419c2
[2025-07-19T21:02:35.144+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=44, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.144+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=44),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/44] for update
[2025-07-19T21:02:35.145+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.145+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.145+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/39/.2.delta.24f8efdf-4505-4143-b9ed-1529d2e84df0.TID642.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/39/2.delta
[2025-07-19T21:02:35.145+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=39),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/39] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/39/2.delta
[2025-07-19T21:02:35.146+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 39 (task 642, attempt 0, stage 7.0)
[2025-07-19T21:02:35.146+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6aeab6de
[2025-07-19T21:02:35.147+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=45, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.148+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=45),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/45] for update
[2025-07-19T21:02:35.148+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/40/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/40/.2.delta.cd48e100-67fb-4cc9-94f6-d16004a7a1fc.TID643.tmp
[2025-07-19T21:02:35.149+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 39 (task 642, attempt 0, stage 7.0)
[2025-07-19T21:02:35.149+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 39.0 in stage 7.0 (TID 642). 5872 bytes result sent to driver
[2025-07-19T21:02:35.149+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.149+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 46.0 in stage 7.0 (TID 649) (8b44f3d35cfa, executor driver, partition 46, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.149+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 46.0 in stage 7.0 (TID 649)
[2025-07-19T21:02:35.150+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 39.0 in stage 7.0 (TID 642) in 84 ms on 8b44f3d35cfa (executor driver) (39/200)
[2025-07-19T21:02:35.150+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.150+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.150+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a07ace0
[2025-07-19T21:02:35.150+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=46, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.150+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=46),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/46] for update
[2025-07-19T21:02:35.150+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.150+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/41/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/41/.2.delta.1ef87e0e-f1be-4d5d-aa5e-1fb9611c6ded.TID644.tmp
[2025-07-19T21:02:35.150+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/38/.2.delta.62e60288-7ac7-4d0e-8a3c-ce40db95a076.TID641.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/38/2.delta
[2025-07-19T21:02:35.151+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=38),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/38] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/38/2.delta
[2025-07-19T21:02:35.152+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/43/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/43/.2.delta.417564e4-1dc3-4d30-b393-9b6d8a82d8f5.TID646.tmp
[2025-07-19T21:02:35.153+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 38 (task 641, attempt 0, stage 7.0)
[2025-07-19T21:02:35.153+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/42/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/42/.2.delta.aae93f72-adb4-4523-afec-e5df774b140c.TID645.tmp
[2025-07-19T21:02:35.154+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/44/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/44/.2.delta.d2560be8-1e26-464f-b95c-0dfb270fb19e.TID647.tmp
[2025-07-19T21:02:35.154+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 38 (task 641, attempt 0, stage 7.0)
[2025-07-19T21:02:35.158+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 38.0 in stage 7.0 (TID 641). 5872 bytes result sent to driver
[2025-07-19T21:02:35.159+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 47.0 in stage 7.0 (TID 650) (8b44f3d35cfa, executor driver, partition 47, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.160+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 47.0 in stage 7.0 (TID 650)
[2025-07-19T21:02:35.160+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 38.0 in stage 7.0 (TID 641) in 110 ms on 8b44f3d35cfa (executor driver) (40/200)
[2025-07-19T21:02:35.161+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.162+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.162+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/45/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/45/.2.delta.bc45689c-5c93-46d9-bca8-d96f57f3984b.TID648.tmp
[2025-07-19T21:02:35.162+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54a946b9
[2025-07-19T21:02:35.163+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/commits/.0.e4a28d87-01b3-49e6-82d3-c1cdf8366db9.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/commits/0
[2025-07-19T21:02:35.163+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=47, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.164+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=47),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/47] for update
[2025-07-19T21:02:35.165+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/46/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/46/.2.delta.4f274d45-28ed-4ab5-a86b-a9caf5e0df8b.TID649.tmp
[2025-07-19T21:02:35.165+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.174+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/47/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/47/.2.delta.71c7ef0d-abc5-425e-bb6f-9314c245bf00.TID650.tmp
[2025-07-19T21:02:35.177+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/40/.2.delta.cd48e100-67fb-4cc9-94f6-d16004a7a1fc.TID643.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/40/2.delta
[2025-07-19T21:02:35.185+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO MicroBatchExecution: Streaming query made progress: {
[2025-07-19T21:02:35.186+0000] {subprocess.py:93} INFO -   "id" : "30463049-c973-45be-97a0-fdd3d358740a",
[2025-07-19T21:02:35.186+0000] {subprocess.py:93} INFO -   "runId" : "07295437-5b62-45a1-8005-3d2155adaa4b",
[2025-07-19T21:02:35.186+0000] {subprocess.py:93} INFO -   "name" : null,
[2025-07-19T21:02:35.186+0000] {subprocess.py:93} INFO -   "timestamp" : "2025-07-19T21:02:18.554Z",
[2025-07-19T21:02:35.186+0000] {subprocess.py:93} INFO -   "batchId" : 0,
[2025-07-19T21:02:35.186+0000] {subprocess.py:93} INFO -   "numInputRows" : 234,
[2025-07-19T21:02:35.186+0000] {subprocess.py:93} INFO -   "inputRowsPerSecond" : 0.0,
[2025-07-19T21:02:35.187+0000] {subprocess.py:93} INFO -   "processedRowsPerSecond" : 14.072648544623526,
[2025-07-19T21:02:35.187+0000] {subprocess.py:93} INFO -   "durationMs" : {
[2025-07-19T21:02:35.188+0000] {subprocess.py:93} INFO -     "addBatch" : 15692,
[2025-07-19T21:02:35.188+0000] {subprocess.py:93} INFO -     "commitOffsets" : 86,
[2025-07-19T21:02:35.188+0000] {subprocess.py:93} INFO -     "getBatch" : 24,
[2025-07-19T21:02:35.188+0000] {subprocess.py:93} INFO -     "latestOffset" : 248,
[2025-07-19T21:02:35.189+0000] {subprocess.py:93} INFO -     "queryPlanning" : 440,
[2025-07-19T21:02:35.189+0000] {subprocess.py:93} INFO -     "triggerExecution" : 16628,
[2025-07-19T21:02:35.189+0000] {subprocess.py:93} INFO -     "walCommit" : 96
[2025-07-19T21:02:35.189+0000] {subprocess.py:93} INFO -   },
[2025-07-19T21:02:35.189+0000] {subprocess.py:93} INFO -   "eventTime" : {
[2025-07-19T21:02:35.189+0000] {subprocess.py:93} INFO -     "avg" : "2025-07-19T19:14:56.525Z",
[2025-07-19T21:02:35.189+0000] {subprocess.py:93} INFO -     "max" : "2025-07-19T21:02:08.000Z",
[2025-07-19T21:02:35.189+0000] {subprocess.py:93} INFO -     "min" : "2025-07-19T18:00:01.000Z",
[2025-07-19T21:02:35.189+0000] {subprocess.py:93} INFO -     "watermark" : "1970-01-01T00:00:00.000Z"
[2025-07-19T21:02:35.190+0000] {subprocess.py:93} INFO -   },
[2025-07-19T21:02:35.190+0000] {subprocess.py:93} INFO -   "stateOperators" : [ {
[2025-07-19T21:02:35.190+0000] {subprocess.py:93} INFO -     "operatorName" : "dedupe",
[2025-07-19T21:02:35.191+0000] {subprocess.py:93} INFO -     "numRowsTotal" : 234,
[2025-07-19T21:02:35.191+0000] {subprocess.py:93} INFO -     "numRowsUpdated" : 234,
[2025-07-19T21:02:35.192+0000] {subprocess.py:93} INFO -     "allUpdatesTimeMs" : 5142,
[2025-07-19T21:02:35.192+0000] {subprocess.py:93} INFO -     "numRowsRemoved" : 0,
[2025-07-19T21:02:35.193+0000] {subprocess.py:93} INFO -     "allRemovalsTimeMs" : 164,
[2025-07-19T21:02:35.193+0000] {subprocess.py:93} INFO -     "commitTimeMs" : 12380,
[2025-07-19T21:02:35.193+0000] {subprocess.py:93} INFO -     "memoryUsedBytes" : 102736,
[2025-07-19T21:02:35.193+0000] {subprocess.py:93} INFO -     "numRowsDroppedByWatermark" : 0,
[2025-07-19T21:02:35.193+0000] {subprocess.py:93} INFO -     "numShufflePartitions" : 200,
[2025-07-19T21:02:35.194+0000] {subprocess.py:93} INFO -     "numStateStoreInstances" : 200,
[2025-07-19T21:02:35.194+0000] {subprocess.py:93} INFO -     "customMetrics" : {
[2025-07-19T21:02:35.194+0000] {subprocess.py:93} INFO -       "loadedMapCacheHitCount" : 0,
[2025-07-19T21:02:35.195+0000] {subprocess.py:93} INFO -       "loadedMapCacheMissCount" : 0,
[2025-07-19T21:02:35.195+0000] {subprocess.py:93} INFO -       "numDroppedDuplicateRows" : 0,
[2025-07-19T21:02:35.195+0000] {subprocess.py:93} INFO -       "stateOnCurrentVersionSizeBytes" : 73936
[2025-07-19T21:02:35.196+0000] {subprocess.py:93} INFO -     }
[2025-07-19T21:02:35.196+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T21:02:35.196+0000] {subprocess.py:93} INFO -   "sources" : [ {
[2025-07-19T21:02:35.196+0000] {subprocess.py:93} INFO -     "description" : "KafkaV2[Subscribe[feedback]]",
[2025-07-19T21:02:35.197+0000] {subprocess.py:93} INFO -     "startOffset" : null,
[2025-07-19T21:02:35.197+0000] {subprocess.py:93} INFO -     "endOffset" : {
[2025-07-19T21:02:35.198+0000] {subprocess.py:93} INFO -       "feedback" : {
[2025-07-19T21:02:35.199+0000] {subprocess.py:93} INFO -         "0" : 234
[2025-07-19T21:02:35.199+0000] {subprocess.py:93} INFO -       }
[2025-07-19T21:02:35.200+0000] {subprocess.py:93} INFO -     },
[2025-07-19T21:02:35.200+0000] {subprocess.py:93} INFO -     "latestOffset" : {
[2025-07-19T21:02:35.200+0000] {subprocess.py:93} INFO -       "feedback" : {
[2025-07-19T21:02:35.200+0000] {subprocess.py:93} INFO -         "0" : 234
[2025-07-19T21:02:35.200+0000] {subprocess.py:93} INFO -       }
[2025-07-19T21:02:35.200+0000] {subprocess.py:93} INFO -     },
[2025-07-19T21:02:35.200+0000] {subprocess.py:93} INFO -     "numInputRows" : 234,
[2025-07-19T21:02:35.200+0000] {subprocess.py:93} INFO -     "inputRowsPerSecond" : 0.0,
[2025-07-19T21:02:35.200+0000] {subprocess.py:93} INFO -     "processedRowsPerSecond" : 14.072648544623526,
[2025-07-19T21:02:35.200+0000] {subprocess.py:93} INFO -     "metrics" : {
[2025-07-19T21:02:35.200+0000] {subprocess.py:93} INFO -       "avgOffsetsBehindLatest" : "0.0",
[2025-07-19T21:02:35.201+0000] {subprocess.py:93} INFO -       "maxOffsetsBehindLatest" : "0",
[2025-07-19T21:02:35.201+0000] {subprocess.py:93} INFO -       "minOffsetsBehindLatest" : "0"
[2025-07-19T21:02:35.201+0000] {subprocess.py:93} INFO -     }
[2025-07-19T21:02:35.201+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T21:02:35.201+0000] {subprocess.py:93} INFO -   "sink" : {
[2025-07-19T21:02:35.201+0000] {subprocess.py:93} INFO -     "description" : "my_catalog.bronze.Feedback_raw",
[2025-07-19T21:02:35.201+0000] {subprocess.py:93} INFO -     "numOutputRows" : 234
[2025-07-19T21:02:35.201+0000] {subprocess.py:93} INFO -   }
[2025-07-19T21:02:35.202+0000] {subprocess.py:93} INFO - }
[2025-07-19T21:02:35.202+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=40),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/40] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/40/2.delta
[2025-07-19T21:02:35.202+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/42/.2.delta.aae93f72-adb4-4523-afec-e5df774b140c.TID645.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/42/2.delta
[2025-07-19T21:02:35.202+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=42),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/42] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/42/2.delta
[2025-07-19T21:02:35.202+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 40 (task 643, attempt 0, stage 7.0)
[2025-07-19T21:02:35.203+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 42 (task 645, attempt 0, stage 7.0)
[2025-07-19T21:02:35.203+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/44/.2.delta.d2560be8-1e26-464f-b95c-0dfb270fb19e.TID647.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/44/2.delta
[2025-07-19T21:02:35.203+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=44),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/44] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/44/2.delta
[2025-07-19T21:02:35.203+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 44 (task 647, attempt 0, stage 7.0)
[2025-07-19T21:02:35.203+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/43/.2.delta.417564e4-1dc3-4d30-b393-9b6d8a82d8f5.TID646.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/43/2.delta
[2025-07-19T21:02:35.203+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=43),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/43] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/43/2.delta
[2025-07-19T21:02:35.203+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 43 (task 646, attempt 0, stage 7.0)
[2025-07-19T21:02:35.204+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/45/.2.delta.bc45689c-5c93-46d9-bca8-d96f57f3984b.TID648.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/45/2.delta
[2025-07-19T21:02:35.204+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=45),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/45] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/45/2.delta
[2025-07-19T21:02:35.205+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 45 (task 648, attempt 0, stage 7.0)
[2025-07-19T21:02:35.207+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 42 (task 645, attempt 0, stage 7.0)
[2025-07-19T21:02:35.209+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/41/.2.delta.1ef87e0e-f1be-4d5d-aa5e-1fb9611c6ded.TID644.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/41/2.delta
[2025-07-19T21:02:35.209+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=41),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/41] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/41/2.delta
[2025-07-19T21:02:35.210+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 40 (task 643, attempt 0, stage 7.0)
[2025-07-19T21:02:35.211+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 40.0 in stage 7.0 (TID 643). 5829 bytes result sent to driver
[2025-07-19T21:02:35.211+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 41 (task 644, attempt 0, stage 7.0)
[2025-07-19T21:02:35.211+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 48.0 in stage 7.0 (TID 651) (8b44f3d35cfa, executor driver, partition 48, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.213+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 48.0 in stage 7.0 (TID 651)
[2025-07-19T21:02:35.214+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 40.0 in stage 7.0 (TID 643) in 96 ms on 8b44f3d35cfa (executor driver) (41/200)
[2025-07-19T21:02:35.214+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/46/.2.delta.4f274d45-28ed-4ab5-a86b-a9caf5e0df8b.TID649.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/46/2.delta
[2025-07-19T21:02:35.215+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=46),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/46] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/46/2.delta
[2025-07-19T21:02:35.215+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 44 (task 647, attempt 0, stage 7.0)
[2025-07-19T21:02:35.217+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 44.0 in stage 7.0 (TID 647). 5829 bytes result sent to driver
[2025-07-19T21:02:35.218+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 42.0 in stage 7.0 (TID 645). 5829 bytes result sent to driver
[2025-07-19T21:02:35.218+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.218+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T21:02:35.219+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 49.0 in stage 7.0 (TID 652) (8b44f3d35cfa, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.219+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 50.0 in stage 7.0 (TID 653) (8b44f3d35cfa, executor driver, partition 50, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.219+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 46 (task 649, attempt 0, stage 7.0)
[2025-07-19T21:02:35.220+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@161daab5
[2025-07-19T21:02:35.220+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 50.0 in stage 7.0 (TID 653)
[2025-07-19T21:02:35.220+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 49.0 in stage 7.0 (TID 652)
[2025-07-19T21:02:35.221+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 44.0 in stage 7.0 (TID 647) in 93 ms on 8b44f3d35cfa (executor driver) (42/200)
[2025-07-19T21:02:35.221+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 42.0 in stage 7.0 (TID 645) in 98 ms on 8b44f3d35cfa (executor driver) (43/200)
[2025-07-19T21:02:35.222+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.222+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:35.222+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 41 (task 644, attempt 0, stage 7.0)
[2025-07-19T21:02:35.222+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 41.0 in stage 7.0 (TID 644). 5829 bytes result sent to driver
[2025-07-19T21:02:35.223+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 51.0 in stage 7.0 (TID 654) (8b44f3d35cfa, executor driver, partition 51, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.223+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=48, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.224+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=48),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/48] for update
[2025-07-19T21:02:35.224+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 51.0 in stage 7.0 (TID 654)
[2025-07-19T21:02:35.224+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 45 (task 648, attempt 0, stage 7.0)
[2025-07-19T21:02:35.225+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 45.0 in stage 7.0 (TID 648). 5829 bytes result sent to driver
[2025-07-19T21:02:35.226+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22ce475
[2025-07-19T21:02:35.226+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 46 (task 649, attempt 0, stage 7.0)
[2025-07-19T21:02:35.226+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.227+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.227+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=49, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.227+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=49),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/49] for update
[2025-07-19T21:02:35.228+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/offsets/1 using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/offsets/.1.9d2809d1-aca1-42da-8214-8d8178fe9469.tmp
[2025-07-19T21:02:35.228+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.229+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 43 (task 646, attempt 0, stage 7.0)
[2025-07-19T21:02:35.229+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 52.0 in stage 7.0 (TID 655) (8b44f3d35cfa, executor driver, partition 52, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.230+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 46.0 in stage 7.0 (TID 649). 5829 bytes result sent to driver
[2025-07-19T21:02:35.230+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 52.0 in stage 7.0 (TID 655)
[2025-07-19T21:02:35.233+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 45.0 in stage 7.0 (TID 648) in 106 ms on 8b44f3d35cfa (executor driver) (44/200)
[2025-07-19T21:02:35.234+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 53.0 in stage 7.0 (TID 656) (8b44f3d35cfa, executor driver, partition 53, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.234+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 41.0 in stage 7.0 (TID 644) in 115 ms on 8b44f3d35cfa (executor driver) (45/200)
[2025-07-19T21:02:35.235+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 53.0 in stage 7.0 (TID 656)
[2025-07-19T21:02:35.236+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 43.0 in stage 7.0 (TID 646). 5786 bytes result sent to driver
[2025-07-19T21:02:35.236+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.237+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.238+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.238+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b997fb3
[2025-07-19T21:02:35.238+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.238+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.238+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:35.239+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 46.0 in stage 7.0 (TID 649) in 85 ms on 8b44f3d35cfa (executor driver) (46/200)
[2025-07-19T21:02:35.239+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=50, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.240+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=50),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/50] for update
[2025-07-19T21:02:35.240+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 54.0 in stage 7.0 (TID 657) (8b44f3d35cfa, executor driver, partition 54, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.241+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 43.0 in stage 7.0 (TID 646) in 119 ms on 8b44f3d35cfa (executor driver) (47/200)
[2025-07-19T21:02:35.241+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 54.0 in stage 7.0 (TID 657)
[2025-07-19T21:02:35.242+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.243+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.244+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.246+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
[2025-07-19T21:02:35.247+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6bd014b5
[2025-07-19T21:02:35.248+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=52, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.248+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=52),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/52] for update
[2025-07-19T21:02:35.248+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/47/.2.delta.71c7ef0d-abc5-425e-bb6f-9314c245bf00.TID650.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/47/2.delta
[2025-07-19T21:02:35.249+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=47),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/47] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/47/2.delta
[2025-07-19T21:02:35.249+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 47 (task 650, attempt 0, stage 7.0)
[2025-07-19T21:02:35.249+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.250+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39eb0784
[2025-07-19T21:02:35.251+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=53, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.251+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=53),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/53] for update
[2025-07-19T21:02:35.252+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e67568
[2025-07-19T21:02:35.252+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=51, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.252+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=51),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/51] for update
[2025-07-19T21:02:35.254+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.254+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 47 (task 650, attempt 0, stage 7.0)
[2025-07-19T21:02:35.255+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 47.0 in stage 7.0 (TID 650). 5829 bytes result sent to driver
[2025-07-19T21:02:35.255+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.255+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 55.0 in stage 7.0 (TID 658) (8b44f3d35cfa, executor driver, partition 55, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.255+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 47.0 in stage 7.0 (TID 650) in 91 ms on 8b44f3d35cfa (executor driver) (48/200)
[2025-07-19T21:02:35.255+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 55.0 in stage 7.0 (TID 658)
[2025-07-19T21:02:35.255+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.255+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.255+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68927fd1
[2025-07-19T21:02:35.256+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=54, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.256+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=54),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/54] for update
[2025-07-19T21:02:35.256+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/50/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/50/.2.delta.8f28ce37-789a-4a27-a554-bb388f8d4b2c.TID653.tmp
[2025-07-19T21:02:35.256+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/49/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/49/.2.delta.fd0d07cf-f48a-4768-8ccb-bd8e9c98eed2.TID652.tmp
[2025-07-19T21:02:35.256+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.256+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3cba6178
[2025-07-19T21:02:35.256+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=55, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.256+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=55),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/55] for update
[2025-07-19T21:02:35.257+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.264+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/48/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/48/.2.delta.63aa6a51-1576-4798-8ff5-8ffc53b29e25.TID651.tmp
[2025-07-19T21:02:35.267+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/53/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/53/.2.delta.b1158f69-edd9-40de-9b82-9b5d8fa6fa6d.TID656.tmp
[2025-07-19T21:02:35.268+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/51/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/51/.2.delta.07dbdebc-f7fa-41eb-93b9-674bb5fb01e3.TID654.tmp
[2025-07-19T21:02:35.276+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/52/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/52/.2.delta.229f19df-5ce9-4d37-9b6c-7eddb20a15d7.TID655.tmp
[2025-07-19T21:02:35.277+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/54/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/54/.2.delta.d50e150d-7f9f-459b-8c01-78204ba0fe85.TID657.tmp
[2025-07-19T21:02:35.298+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/55/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/55/.2.delta.4cac4ee0-d63c-4eb5-af0a-3273836ec697.TID658.tmp
[2025-07-19T21:02:35.304+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/offsets/.1.9d2809d1-aca1-42da-8214-8d8178fe9469.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/offsets/1
[2025-07-19T21:02:35.305+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO MicroBatchExecution: Committed offsets for batch 1. Metadata OffsetSeqMetadata(1752786128000,1752958955201,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.optimizer.pruneFiltersCanPruneStreamingSubplan -> false, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2025-07-19T21:02:35.327+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/50/.2.delta.8f28ce37-789a-4a27-a554-bb388f8d4b2c.TID653.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/50/2.delta
[2025-07-19T21:02:35.331+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=50),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/50] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/50/2.delta
[2025-07-19T21:02:35.331+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 50 (task 653, attempt 0, stage 7.0)
[2025-07-19T21:02:35.334+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/48/.2.delta.63aa6a51-1576-4798-8ff5-8ffc53b29e25.TID651.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/48/2.delta
[2025-07-19T21:02:35.335+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/51/.2.delta.07dbdebc-f7fa-41eb-93b9-674bb5fb01e3.TID654.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/51/2.delta
[2025-07-19T21:02:35.337+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=51),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/51] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/51/2.delta
[2025-07-19T21:02:35.338+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=48),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/48] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/48/2.delta
[2025-07-19T21:02:35.338+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/49/.2.delta.fd0d07cf-f48a-4768-8ccb-bd8e9c98eed2.TID652.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/49/2.delta
[2025-07-19T21:02:35.338+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=49),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/49] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/49/2.delta
[2025-07-19T21:02:35.339+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 49 (task 652, attempt 0, stage 7.0)
[2025-07-19T21:02:35.339+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 50 (task 653, attempt 0, stage 7.0)
[2025-07-19T21:02:35.340+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 51 (task 654, attempt 0, stage 7.0)
[2025-07-19T21:02:35.340+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 48 (task 651, attempt 0, stage 7.0)
[2025-07-19T21:02:35.340+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Feedback_raw
[2025-07-19T21:02:35.341+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Feedback_raw
[2025-07-19T21:02:35.341+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Feedback_raw
[2025-07-19T21:02:35.346+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 50.0 in stage 7.0 (TID 653). 5915 bytes result sent to driver
[2025-07-19T21:02:35.351+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 56.0 in stage 7.0 (TID 659) (8b44f3d35cfa, executor driver, partition 56, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.352+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 49 (task 652, attempt 0, stage 7.0)
[2025-07-19T21:02:35.353+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 50.0 in stage 7.0 (TID 653) in 141 ms on 8b44f3d35cfa (executor driver) (49/200)
[2025-07-19T21:02:35.354+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 49.0 in stage 7.0 (TID 652). 5872 bytes result sent to driver
[2025-07-19T21:02:35.355+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 56.0 in stage 7.0 (TID 659)
[2025-07-19T21:02:35.356+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 57.0 in stage 7.0 (TID 660) (8b44f3d35cfa, executor driver, partition 57, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.358+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 49.0 in stage 7.0 (TID 652) in 142 ms on 8b44f3d35cfa (executor driver) (50/200)
[2025-07-19T21:02:35.359+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 57.0 in stage 7.0 (TID 660)
[2025-07-19T21:02:35.360+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/54/.2.delta.d50e150d-7f9f-459b-8c01-78204ba0fe85.TID657.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/54/2.delta
[2025-07-19T21:02:35.360+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=54),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/54] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/54/2.delta
[2025-07-19T21:02:35.362+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 54 (task 657, attempt 0, stage 7.0)
[2025-07-19T21:02:35.363+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/53/.2.delta.b1158f69-edd9-40de-9b82-9b5d8fa6fa6d.TID656.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/53/2.delta
[2025-07-19T21:02:35.364+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=53),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/53] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/53/2.delta
[2025-07-19T21:02:35.364+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 53 (task 656, attempt 0, stage 7.0)
[2025-07-19T21:02:35.364+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 48 (task 651, attempt 0, stage 7.0)
[2025-07-19T21:02:35.364+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.364+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.365+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1626e571
[2025-07-19T21:02:35.365+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 51 (task 654, attempt 0, stage 7.0)
[2025-07-19T21:02:35.366+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 48.0 in stage 7.0 (TID 651). 5872 bytes result sent to driver
[2025-07-19T21:02:35.368+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 58.0 in stage 7.0 (TID 661) (8b44f3d35cfa, executor driver, partition 58, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.368+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=56, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.369+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 54 (task 657, attempt 0, stage 7.0)
[2025-07-19T21:02:35.369+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=56),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/56] for update
[2025-07-19T21:02:35.370+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 48.0 in stage 7.0 (TID 651) in 159 ms on 8b44f3d35cfa (executor driver) (51/200)
[2025-07-19T21:02:35.370+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 54.0 in stage 7.0 (TID 657). 5872 bytes result sent to driver
[2025-07-19T21:02:35.372+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 58.0 in stage 7.0 (TID 661)
[2025-07-19T21:02:35.373+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 59.0 in stage 7.0 (TID 662) (8b44f3d35cfa, executor driver, partition 59, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.375+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 54.0 in stage 7.0 (TID 657) in 130 ms on 8b44f3d35cfa (executor driver) (52/200)
[2025-07-19T21:02:35.376+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 59.0 in stage 7.0 (TID 662)
[2025-07-19T21:02:35.376+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.377+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 51.0 in stage 7.0 (TID 654). 5872 bytes result sent to driver
[2025-07-19T21:02:35.377+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 60.0 in stage 7.0 (TID 663) (8b44f3d35cfa, executor driver, partition 60, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.377+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 51.0 in stage 7.0 (TID 654) in 148 ms on 8b44f3d35cfa (executor driver) (53/200)
[2025-07-19T21:02:35.378+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/52/.2.delta.229f19df-5ce9-4d37-9b6c-7eddb20a15d7.TID655.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/52/2.delta
[2025-07-19T21:02:35.378+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=52),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/52] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/52/2.delta
[2025-07-19T21:02:35.378+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 52 (task 655, attempt 0, stage 7.0)
[2025-07-19T21:02:35.379+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.380+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.381+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 60.0 in stage 7.0 (TID 663)
[2025-07-19T21:02:35.381+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.381+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.381+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65008a1
[2025-07-19T21:02:35.382+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=59, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.382+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=59),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/59] for update
[2025-07-19T21:02:35.382+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.382+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.382+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3edbd424
[2025-07-19T21:02:35.382+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=58, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.382+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=58),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/58] for update
[2025-07-19T21:02:35.382+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 52 (task 655, attempt 0, stage 7.0)
[2025-07-19T21:02:35.382+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 52.0 in stage 7.0 (TID 655). 5872 bytes result sent to driver
[2025-07-19T21:02:35.383+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 53 (task 656, attempt 0, stage 7.0)
[2025-07-19T21:02:35.383+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.383+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 61.0 in stage 7.0 (TID 664) (8b44f3d35cfa, executor driver, partition 61, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.383+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 52.0 in stage 7.0 (TID 655) in 152 ms on 8b44f3d35cfa (executor driver) (54/200)
[2025-07-19T21:02:35.383+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.383+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 61.0 in stage 7.0 (TID 664)
[2025-07-19T21:02:35.383+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/55/.2.delta.4cac4ee0-d63c-4eb5-af0a-3273836ec697.TID658.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/55/2.delta
[2025-07-19T21:02:35.383+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=55),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/55] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/55/2.delta
[2025-07-19T21:02:35.384+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 55 (task 658, attempt 0, stage 7.0)
[2025-07-19T21:02:35.384+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.384+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@72120d33
[2025-07-19T21:02:35.384+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 53.0 in stage 7.0 (TID 656). 5872 bytes result sent to driver
[2025-07-19T21:02:35.384+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.384+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T21:02:35.384+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 55 (task 658, attempt 0, stage 7.0)
[2025-07-19T21:02:35.384+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 53.0 in stage 7.0 (TID 656) in 146 ms on 8b44f3d35cfa (executor driver) (55/200)
[2025-07-19T21:02:35.384+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=60, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.385+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=60),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/60] for update
[2025-07-19T21:02:35.385+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 55.0 in stage 7.0 (TID 658). 5872 bytes result sent to driver
[2025-07-19T21:02:35.385+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.385+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 62.0 in stage 7.0 (TID 665) (8b44f3d35cfa, executor driver, partition 62, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.385+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 62.0 in stage 7.0 (TID 665)
[2025-07-19T21:02:35.386+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 55.0 in stage 7.0 (TID 658) in 133 ms on 8b44f3d35cfa (executor driver) (56/200)
[2025-07-19T21:02:35.386+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 63.0 in stage 7.0 (TID 666) (8b44f3d35cfa, executor driver, partition 63, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.386+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Feedback_raw
[2025-07-19T21:02:35.386+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Feedback_raw
[2025-07-19T21:02:35.386+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Feedback_raw
[2025-07-19T21:02:35.386+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 63.0 in stage 7.0 (TID 666)
[2025-07-19T21:02:35.386+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f678fac
[2025-07-19T21:02:35.386+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=61, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.387+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=61),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/61] for update
[2025-07-19T21:02:35.387+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.387+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.387+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.387+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.388+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.389+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.390+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63894968
[2025-07-19T21:02:35.391+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/59/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/59/.2.delta.f4046722-e635-44b2-8384-56b84a14b425.TID662.tmp
[2025-07-19T21:02:35.392+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=57, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.393+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=57),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/57] for update
[2025-07-19T21:02:35.393+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/56/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/56/.2.delta.d04098d0-3dd6-4367-98a7-481138f534bf.TID659.tmp
[2025-07-19T21:02:35.394+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d186a33
[2025-07-19T21:02:35.394+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=63, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.394+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=63),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/63] for update
[2025-07-19T21:02:35.394+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@45f5a038
[2025-07-19T21:02:35.394+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/61/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/61/.2.delta.17f69886-0ae0-49e5-8236-a27fc608ba3c.TID664.tmp
[2025-07-19T21:02:35.395+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=62, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.395+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=62),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/62] for update
[2025-07-19T21:02:35.395+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.395+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.396+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/58/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/58/.2.delta.6b0ed1c2-75b4-4b43-9387-94bff4910c64.TID661.tmp
[2025-07-19T21:02:35.399+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.414+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/60/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/60/.2.delta.8a24eb67-cfe1-4313-905a-195e06a3c1e1.TID663.tmp
[2025-07-19T21:02:35.415+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Feedback_raw
[2025-07-19T21:02:35.415+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Feedback_raw
[2025-07-19T21:02:35.416+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Feedback_raw
[2025-07-19T21:02:35.435+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/63/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/63/.2.delta.caf59f51-9421-43cd-a136-bf8bb46f8ca7.TID666.tmp
[2025-07-19T21:02:35.438+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 8b44f3d35cfa:38433 in memory (size: 29.5 KiB, free: 434.3 MiB)
[2025-07-19T21:02:35.443+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/57/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/57/.2.delta.895d4038-17cd-4549-bfff-f48787b6cb60.TID660.tmp
[2025-07-19T21:02:35.444+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/62/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/62/.2.delta.b5c6cbda-635b-41a6-b17e-ac96568801a0.TID665.tmp
[2025-07-19T21:02:35.458+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 8b44f3d35cfa:38433 in memory (size: 35.4 KiB, free: 434.3 MiB)
[2025-07-19T21:02:35.471+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/56/.2.delta.d04098d0-3dd6-4367-98a7-481138f534bf.TID659.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/56/2.delta
[2025-07-19T21:02:35.472+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=56),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/56] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/56/2.delta
[2025-07-19T21:02:35.475+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 56 (task 659, attempt 0, stage 7.0)
[2025-07-19T21:02:35.475+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/59/.2.delta.f4046722-e635-44b2-8384-56b84a14b425.TID662.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/59/2.delta
[2025-07-19T21:02:35.475+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=59),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/59] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/59/2.delta
[2025-07-19T21:02:35.476+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 59 (task 662, attempt 0, stage 7.0)
[2025-07-19T21:02:35.477+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 56 (task 659, attempt 0, stage 7.0)
[2025-07-19T21:02:35.477+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 56.0 in stage 7.0 (TID 659). 5829 bytes result sent to driver
[2025-07-19T21:02:35.477+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 64.0 in stage 7.0 (TID 667) (8b44f3d35cfa, executor driver, partition 64, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.477+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 59 (task 662, attempt 0, stage 7.0)
[2025-07-19T21:02:35.479+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 64.0 in stage 7.0 (TID 667)
[2025-07-19T21:02:35.480+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 59.0 in stage 7.0 (TID 662). 5829 bytes result sent to driver
[2025-07-19T21:02:35.482+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 65.0 in stage 7.0 (TID 668) (8b44f3d35cfa, executor driver, partition 65, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.483+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 59.0 in stage 7.0 (TID 662) in 120 ms on 8b44f3d35cfa (executor driver) (57/200)
[2025-07-19T21:02:35.484+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 56.0 in stage 7.0 (TID 659) in 132 ms on 8b44f3d35cfa (executor driver) (58/200)
[2025-07-19T21:02:35.484+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 65.0 in stage 7.0 (TID 668)
[2025-07-19T21:02:35.484+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.484+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.484+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19474df5
[2025-07-19T21:02:35.484+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=64, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.484+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=64),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/64] for update
[2025-07-19T21:02:35.484+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.484+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.484+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.485+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7e450ac2
[2025-07-19T21:02:35.491+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 8b44f3d35cfa:38433 in memory (size: 19.3 KiB, free: 434.3 MiB)
[2025-07-19T21:02:35.493+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=65, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.493+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=65),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/65] for update
[2025-07-19T21:02:35.505+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.506+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/60/.2.delta.8a24eb67-cfe1-4313-905a-195e06a3c1e1.TID663.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/60/2.delta
[2025-07-19T21:02:35.507+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=60),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/60] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/60/2.delta
[2025-07-19T21:02:35.509+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 60 (task 663, attempt 0, stage 7.0)
[2025-07-19T21:02:35.514+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 60 (task 663, attempt 0, stage 7.0)
[2025-07-19T21:02:35.522+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 60.0 in stage 7.0 (TID 663). 5829 bytes result sent to driver
[2025-07-19T21:02:35.532+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 66.0 in stage 7.0 (TID 669) (8b44f3d35cfa, executor driver, partition 66, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.532+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 66.0 in stage 7.0 (TID 669)
[2025-07-19T21:02:35.533+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 60.0 in stage 7.0 (TID 663) in 152 ms on 8b44f3d35cfa (executor driver) (59/200)
[2025-07-19T21:02:35.533+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/64/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/64/.2.delta.db327068-d37a-4b37-bfb0-e346e1a4a94b.TID667.tmp
[2025-07-19T21:02:35.533+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.534+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.534+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@201cac1e
[2025-07-19T21:02:35.534+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=66, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.535+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=66),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/66] for update
[2025-07-19T21:02:35.535+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 209.0 KiB, free 433.9 MiB)
[2025-07-19T21:02:35.536+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.536+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/62/.2.delta.b5c6cbda-635b-41a6-b17e-ac96568801a0.TID665.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/62/2.delta
[2025-07-19T21:02:35.537+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=62),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/62] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/62/2.delta
[2025-07-19T21:02:35.538+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 62 (task 665, attempt 0, stage 7.0)
[2025-07-19T21:02:35.539+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/65/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/65/.2.delta.63f047e1-891b-493e-bd84-5d88a7ba9703.TID668.tmp
[2025-07-19T21:02:35.539+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 62 (task 665, attempt 0, stage 7.0)
[2025-07-19T21:02:35.540+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 62.0 in stage 7.0 (TID 665). 5829 bytes result sent to driver
[2025-07-19T21:02:35.541+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/66/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/66/.2.delta.4b974bb9-a796-41a1-ac10-d87b6fd5ef1f.TID669.tmp
[2025-07-19T21:02:35.542+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 67.0 in stage 7.0 (TID 670) (8b44f3d35cfa, executor driver, partition 67, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.543+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 67.0 in stage 7.0 (TID 670)
[2025-07-19T21:02:35.543+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 62.0 in stage 7.0 (TID 665) in 167 ms on 8b44f3d35cfa (executor driver) (60/200)
[2025-07-19T21:02:35.544+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.545+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.547+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f15d068
[2025-07-19T21:02:35.548+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=67, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.548+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=67),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/67] for update
[2025-07-19T21:02:35.550+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.557+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/63/.2.delta.caf59f51-9421-43cd-a136-bf8bb46f8ca7.TID666.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/63/2.delta
[2025-07-19T21:02:35.559+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=63),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/63] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/63/2.delta
[2025-07-19T21:02:35.559+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 63 (task 666, attempt 0, stage 7.0)
[2025-07-19T21:02:35.560+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.8 MiB)
[2025-07-19T21:02:35.560+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/61/.2.delta.17f69886-0ae0-49e5-8236-a27fc608ba3c.TID664.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/61/2.delta
[2025-07-19T21:02:35.560+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=61),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/61] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/61/2.delta
[2025-07-19T21:02:35.561+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/58/.2.delta.6b0ed1c2-75b4-4b43-9387-94bff4910c64.TID661.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/58/2.delta
[2025-07-19T21:02:35.562+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=58),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/58] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/58/2.delta
[2025-07-19T21:02:35.564+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 58 (task 661, attempt 0, stage 7.0)
[2025-07-19T21:02:35.565+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 61 (task 664, attempt 0, stage 7.0)
[2025-07-19T21:02:35.566+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 8b44f3d35cfa:38433 (size: 35.4 KiB, free: 434.3 MiB)
[2025-07-19T21:02:35.566+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 63 (task 666, attempt 0, stage 7.0)
[2025-07-19T21:02:35.567+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 61 (task 664, attempt 0, stage 7.0)
[2025-07-19T21:02:35.567+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 63.0 in stage 7.0 (TID 666). 5872 bytes result sent to driver
[2025-07-19T21:02:35.568+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO SparkContext: Created broadcast 15 from start at <unknown>:0
[2025-07-19T21:02:35.568+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 61.0 in stage 7.0 (TID 664). 5872 bytes result sent to driver
[2025-07-19T21:02:35.568+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 68.0 in stage 7.0 (TID 671) (8b44f3d35cfa, executor driver, partition 68, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.570+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 68.0 in stage 7.0 (TID 671)
[2025-07-19T21:02:35.572+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 32.0 KiB, free 433.8 MiB)
[2025-07-19T21:02:35.572+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 58 (task 661, attempt 0, stage 7.0)
[2025-07-19T21:02:35.573+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 69.0 in stage 7.0 (TID 672) (8b44f3d35cfa, executor driver, partition 69, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.573+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 58.0 in stage 7.0 (TID 661). 5829 bytes result sent to driver
[2025-07-19T21:02:35.574+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 69.0 in stage 7.0 (TID 672)
[2025-07-19T21:02:35.575+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 63.0 in stage 7.0 (TID 666) in 195 ms on 8b44f3d35cfa (executor driver) (61/200)
[2025-07-19T21:02:35.575+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 61.0 in stage 7.0 (TID 664) in 205 ms on 8b44f3d35cfa (executor driver) (62/200)
[2025-07-19T21:02:35.575+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.576+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.576+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 70.0 in stage 7.0 (TID 673) (8b44f3d35cfa, executor driver, partition 70, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.577+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 70.0 in stage 7.0 (TID 673)
[2025-07-19T21:02:35.577+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 58.0 in stage 7.0 (TID 661) in 215 ms on 8b44f3d35cfa (executor driver) (63/200)
[2025-07-19T21:02:35.578+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 433.8 MiB)
[2025-07-19T21:02:35.579+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1062692f
[2025-07-19T21:02:35.580+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.580+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.580+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 8b44f3d35cfa:38433 (size: 29.5 KiB, free: 434.3 MiB)
[2025-07-19T21:02:35.580+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:35.580+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:35.580+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO SparkContext: Created broadcast 16 from start at <unknown>:0
[2025-07-19T21:02:35.580+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=68, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.580+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=68),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/68] for update
[2025-07-19T21:02:35.580+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO WriteToDataSourceV2Exec: Start processing data source write support: MicroBatchWrite[epoch: 1, writer: IcebergStreamingWrite(table=my_catalog.bronze.Feedback_raw, format=PARQUET)]. The input RDD has 200 partitions.
[2025-07-19T21:02:35.581+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO SparkContext: Starting job: start at <unknown>:0
[2025-07-19T21:02:35.581+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d5edd15
[2025-07-19T21:02:35.581+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=70, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.582+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=70),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/70] for update
[2025-07-19T21:02:35.582+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/57/.2.delta.895d4038-17cd-4549-bfff-f48787b6cb60.TID660.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/57/2.delta
[2025-07-19T21:02:35.582+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=57),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/57] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/57/2.delta
[2025-07-19T21:02:35.583+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 57 (task 660, attempt 0, stage 7.0)
[2025-07-19T21:02:35.584+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.585+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@b01eccb
[2025-07-19T21:02:35.585+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/67/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/67/.2.delta.3fb4dc10-9b00-4168-95d4-0d6f1a0c497e.TID670.tmp
[2025-07-19T21:02:35.585+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DAGScheduler: Registering RDD 33 (start at <unknown>:0) as input to shuffle 4
[2025-07-19T21:02:35.586+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=69, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.586+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=69),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/69] for update
[2025-07-19T21:02:35.586+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DAGScheduler: Got job 4 (start at <unknown>:0) with 200 output partitions
[2025-07-19T21:02:35.586+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DAGScheduler: Final stage: ResultStage 9 (start at <unknown>:0)
[2025-07-19T21:02:35.586+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
[2025-07-19T21:02:35.586+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DAGScheduler: Missing parents: List()
[2025-07-19T21:02:35.586+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.586+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DAGScheduler: Submitting ResultStage 9 (StateStoreRDD[35] at start at <unknown>:0), which has no missing parents
[2025-07-19T21:02:35.587+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.587+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 57 (task 660, attempt 0, stage 7.0)
[2025-07-19T21:02:35.587+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 57.0 in stage 7.0 (TID 660). 5829 bytes result sent to driver
[2025-07-19T21:02:35.588+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 71.0 in stage 7.0 (TID 674) (8b44f3d35cfa, executor driver, partition 71, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.589+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 57.0 in stage 7.0 (TID 660) in 240 ms on 8b44f3d35cfa (executor driver) (64/200)
[2025-07-19T21:02:35.589+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 71.0 in stage 7.0 (TID 674)
[2025-07-19T21:02:35.592+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.593+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.593+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5cbafc16
[2025-07-19T21:02:35.593+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=71, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.594+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=71),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/71] for update
[2025-07-19T21:02:35.595+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/68/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/68/.2.delta.51d639d2-f2d0-460a-be6d-001c14b61229.TID671.tmp
[2025-07-19T21:02:35.597+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/70/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/70/.2.delta.560be885-d3f4-46f2-8612-3a8b0ba6ef1f.TID673.tmp
[2025-07-19T21:02:35.597+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/64/.2.delta.db327068-d37a-4b37-bfb0-e346e1a4a94b.TID667.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/64/2.delta
[2025-07-19T21:02:35.598+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.598+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/69/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/69/.2.delta.9786e1de-5166-46e1-b8a7-fdd91fb5a107.TID672.tmp
[2025-07-19T21:02:35.598+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=64),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/64] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/64/2.delta
[2025-07-19T21:02:35.598+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/65/.2.delta.63f047e1-891b-493e-bd84-5d88a7ba9703.TID668.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/65/2.delta
[2025-07-19T21:02:35.598+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=65),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/65] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/65/2.delta
[2025-07-19T21:02:35.598+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 65 (task 668, attempt 0, stage 7.0)
[2025-07-19T21:02:35.598+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 64 (task 667, attempt 0, stage 7.0)
[2025-07-19T21:02:35.602+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 65 (task 668, attempt 0, stage 7.0)
[2025-07-19T21:02:35.602+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 64 (task 667, attempt 0, stage 7.0)
[2025-07-19T21:02:35.603+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 64.0 in stage 7.0 (TID 667). 5829 bytes result sent to driver
[2025-07-19T21:02:35.603+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 65.0 in stage 7.0 (TID 668). 5829 bytes result sent to driver
[2025-07-19T21:02:35.603+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 72.0 in stage 7.0 (TID 675) (8b44f3d35cfa, executor driver, partition 72, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.603+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 73.0 in stage 7.0 (TID 676) (8b44f3d35cfa, executor driver, partition 73, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.604+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 73.0 in stage 7.0 (TID 676)
[2025-07-19T21:02:35.604+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 72.0 in stage 7.0 (TID 675)
[2025-07-19T21:02:35.605+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 64.0 in stage 7.0 (TID 667) in 128 ms on 8b44f3d35cfa (executor driver) (65/200)
[2025-07-19T21:02:35.605+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 65.0 in stage 7.0 (TID 668) in 128 ms on 8b44f3d35cfa (executor driver) (66/200)
[2025-07-19T21:02:35.609+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.610+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:35.610+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.610+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:35.611+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@64df1b6d
[2025-07-19T21:02:35.613+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=73, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.614+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/71/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/71/.2.delta.3cfe557b-9c06-471f-a406-7c1a5f6e6cfe.TID674.tmp
[2025-07-19T21:02:35.614+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=73),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/73] for update
[2025-07-19T21:02:35.614+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@32af045e
[2025-07-19T21:02:35.614+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/66/.2.delta.4b974bb9-a796-41a1-ac10-d87b6fd5ef1f.TID669.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/66/2.delta
[2025-07-19T21:02:35.614+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=66),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/66] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/66/2.delta
[2025-07-19T21:02:35.615+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=72, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.615+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=72),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/72] for update
[2025-07-19T21:02:35.617+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.617+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.618+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 66 (task 669, attempt 0, stage 7.0)
[2025-07-19T21:02:35.623+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/72/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/72/.2.delta.85106210-5eea-4727-92b1-0e3ac9509cd1.TID675.tmp
[2025-07-19T21:02:35.625+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 66 (task 669, attempt 0, stage 7.0)
[2025-07-19T21:02:35.626+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 66.0 in stage 7.0 (TID 669). 5829 bytes result sent to driver
[2025-07-19T21:02:35.627+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 74.0 in stage 7.0 (TID 677) (8b44f3d35cfa, executor driver, partition 74, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.627+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 74.0 in stage 7.0 (TID 677)
[2025-07-19T21:02:35.629+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 66.0 in stage 7.0 (TID 669) in 117 ms on 8b44f3d35cfa (executor driver) (67/200)
[2025-07-19T21:02:35.630+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.630+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.630+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@8321bca
[2025-07-19T21:02:35.630+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=74, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.630+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=74),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/74] for update
[2025-07-19T21:02:35.631+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.632+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/73/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/73/.2.delta.37070a20-7dd9-42fb-95c1-6def05e816d3.TID676.tmp
[2025-07-19T21:02:35.637+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 31.7 KiB, free 433.7 MiB)
[2025-07-19T21:02:35.638+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/67/.2.delta.3fb4dc10-9b00-4168-95d4-0d6f1a0c497e.TID670.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/67/2.delta
[2025-07-19T21:02:35.638+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=67),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/67] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/67/2.delta
[2025-07-19T21:02:35.641+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 67 (task 670, attempt 0, stage 7.0)
[2025-07-19T21:02:35.643+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 15.8 KiB, free 433.7 MiB)
[2025-07-19T21:02:35.644+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 8b44f3d35cfa:38433 (size: 15.8 KiB, free: 434.2 MiB)
[2025-07-19T21:02:35.646+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 67 (task 670, attempt 0, stage 7.0)
[2025-07-19T21:02:35.648+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/68/.2.delta.51d639d2-f2d0-460a-be6d-001c14b61229.TID671.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/68/2.delta
[2025-07-19T21:02:35.648+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=68),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/68] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/68/2.delta
[2025-07-19T21:02:35.649+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 67.0 in stage 7.0 (TID 670). 5829 bytes result sent to driver
[2025-07-19T21:02:35.649+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 75.0 in stage 7.0 (TID 678) (8b44f3d35cfa, executor driver, partition 75, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.650+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 67.0 in stage 7.0 (TID 670) in 106 ms on 8b44f3d35cfa (executor driver) (68/200)
[2025-07-19T21:02:35.651+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 68 (task 671, attempt 0, stage 7.0)
[2025-07-19T21:02:35.651+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/74/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/74/.2.delta.bbe145e0-e5c7-4279-b1d1-f4e210058a31.TID677.tmp
[2025-07-19T21:02:35.651+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 75.0 in stage 7.0 (TID 678)
[2025-07-19T21:02:35.652+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1611
[2025-07-19T21:02:35.653+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/70/.2.delta.560be885-d3f4-46f2-8612-3a8b0ba6ef1f.TID673.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/70/2.delta
[2025-07-19T21:02:35.653+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=70),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/70] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/70/2.delta
[2025-07-19T21:02:35.653+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 70 (task 673, attempt 0, stage 7.0)
[2025-07-19T21:02:35.653+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.653+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.653+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 9 (StateStoreRDD[35] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-07-19T21:02:35.654+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSchedulerImpl: Adding task set 9.0 with 200 tasks resource profile 0
[2025-07-19T21:02:35.654+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3618f47
[2025-07-19T21:02:35.654+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 68 (task 671, attempt 0, stage 7.0)
[2025-07-19T21:02:35.654+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=75, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.656+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=75),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/75] for update
[2025-07-19T21:02:35.656+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 68.0 in stage 7.0 (TID 671). 5829 bytes result sent to driver
[2025-07-19T21:02:35.657+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.657+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 76.0 in stage 7.0 (TID 679) (8b44f3d35cfa, executor driver, partition 76, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.657+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 76.0 in stage 7.0 (TID 679)
[2025-07-19T21:02:35.658+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 68.0 in stage 7.0 (TID 671) in 89 ms on 8b44f3d35cfa (executor driver) (69/200)
[2025-07-19T21:02:35.659+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 70 (task 673, attempt 0, stage 7.0)
[2025-07-19T21:02:35.659+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 70.0 in stage 7.0 (TID 673). 5786 bytes result sent to driver
[2025-07-19T21:02:35.660+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.661+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.662+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/69/.2.delta.9786e1de-5166-46e1-b8a7-fdd91fb5a107.TID672.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/69/2.delta
[2025-07-19T21:02:35.663+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=69),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/69] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/69/2.delta
[2025-07-19T21:02:35.663+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 77.0 in stage 7.0 (TID 680) (8b44f3d35cfa, executor driver, partition 77, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.664+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5847ee95
[2025-07-19T21:02:35.664+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 70.0 in stage 7.0 (TID 673) in 89 ms on 8b44f3d35cfa (executor driver) (70/200)
[2025-07-19T21:02:35.665+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 69 (task 672, attempt 0, stage 7.0)
[2025-07-19T21:02:35.666+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 77.0 in stage 7.0 (TID 680)
[2025-07-19T21:02:35.667+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=76, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.668+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=76),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/76] for update
[2025-07-19T21:02:35.668+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.669+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.669+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/72/.2.delta.85106210-5eea-4727-92b1-0e3ac9509cd1.TID675.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/72/2.delta
[2025-07-19T21:02:35.670+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=72),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/72] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/72/2.delta
[2025-07-19T21:02:35.672+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 69 (task 672, attempt 0, stage 7.0)
[2025-07-19T21:02:35.673+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2c4a6238
[2025-07-19T21:02:35.674+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 72 (task 675, attempt 0, stage 7.0)
[2025-07-19T21:02:35.675+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/75/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/75/.2.delta.34b831a6-f0b2-49cc-b63d-760aac9dad42.TID678.tmp
[2025-07-19T21:02:35.675+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=77, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.675+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.675+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=77),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/77] for update
[2025-07-19T21:02:35.675+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 69.0 in stage 7.0 (TID 672). 5829 bytes result sent to driver
[2025-07-19T21:02:35.675+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 78.0 in stage 7.0 (TID 681) (8b44f3d35cfa, executor driver, partition 78, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.676+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 78.0 in stage 7.0 (TID 681)
[2025-07-19T21:02:35.676+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.676+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.676+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.676+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 69.0 in stage 7.0 (TID 672) in 99 ms on 8b44f3d35cfa (executor driver) (71/200)
[2025-07-19T21:02:35.676+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c22c63b
[2025-07-19T21:02:35.676+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=78, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.676+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=78),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/78] for update
[2025-07-19T21:02:35.676+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 72 (task 675, attempt 0, stage 7.0)
[2025-07-19T21:02:35.676+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 72.0 in stage 7.0 (TID 675). 5829 bytes result sent to driver
[2025-07-19T21:02:35.677+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 79.0 in stage 7.0 (TID 682) (8b44f3d35cfa, executor driver, partition 79, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.677+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 72.0 in stage 7.0 (TID 675) in 71 ms on 8b44f3d35cfa (executor driver) (72/200)
[2025-07-19T21:02:35.677+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 79.0 in stage 7.0 (TID 682)
[2025-07-19T21:02:35.677+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/71/.2.delta.3cfe557b-9c06-471f-a406-7c1a5f6e6cfe.TID674.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/71/2.delta
[2025-07-19T21:02:35.677+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=71),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/71] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/71/2.delta
[2025-07-19T21:02:35.677+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.677+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 71 (task 674, attempt 0, stage 7.0)
[2025-07-19T21:02:35.678+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/73/.2.delta.37070a20-7dd9-42fb-95c1-6def05e816d3.TID676.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/73/2.delta
[2025-07-19T21:02:35.678+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=73),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/73] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/73/2.delta
[2025-07-19T21:02:35.678+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 73 (task 676, attempt 0, stage 7.0)
[2025-07-19T21:02:35.678+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/76/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/76/.2.delta.abf7ce0a-8cce-4d09-af67-c6f48f4dd65b.TID679.tmp
[2025-07-19T21:02:35.678+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.678+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.679+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22ba13cf
[2025-07-19T21:02:35.680+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=79, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.681+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/77/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/77/.2.delta.96890fe6-4104-41b7-bfd4-aeba8d01faeb.TID680.tmp
[2025-07-19T21:02:35.681+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=79),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/79] for update
[2025-07-19T21:02:35.683+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.684+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 73 (task 676, attempt 0, stage 7.0)
[2025-07-19T21:02:35.684+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 73.0 in stage 7.0 (TID 676). 5829 bytes result sent to driver
[2025-07-19T21:02:35.684+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 71 (task 674, attempt 0, stage 7.0)
[2025-07-19T21:02:35.684+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 80.0 in stage 7.0 (TID 683) (8b44f3d35cfa, executor driver, partition 80, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.684+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 71.0 in stage 7.0 (TID 674). 5829 bytes result sent to driver
[2025-07-19T21:02:35.685+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 81.0 in stage 7.0 (TID 684) (8b44f3d35cfa, executor driver, partition 81, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.686+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 80.0 in stage 7.0 (TID 683)
[2025-07-19T21:02:35.686+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 81.0 in stage 7.0 (TID 684)
[2025-07-19T21:02:35.688+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 73.0 in stage 7.0 (TID 676) in 84 ms on 8b44f3d35cfa (executor driver) (73/200)
[2025-07-19T21:02:35.688+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 71.0 in stage 7.0 (TID 674) in 99 ms on 8b44f3d35cfa (executor driver) (74/200)
[2025-07-19T21:02:35.689+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.689+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.689+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.690+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.690+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@145193ce
[2025-07-19T21:02:35.692+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=81, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.692+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=81),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/81] for update
[2025-07-19T21:02:35.692+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/78/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/78/.2.delta.dfc49586-f796-4c16-a325-dc10fc71b273.TID681.tmp
[2025-07-19T21:02:35.692+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2168a34a
[2025-07-19T21:02:35.693+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=80, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.694+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=80),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/80] for update
[2025-07-19T21:02:35.696+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.696+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.703+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/79/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/79/.2.delta.0b677ea3-7323-41cc-b2ae-f746948baa7e.TID682.tmp
[2025-07-19T21:02:35.704+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/74/.2.delta.bbe145e0-e5c7-4279-b1d1-f4e210058a31.TID677.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/74/2.delta
[2025-07-19T21:02:35.706+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=74),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/74] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/74/2.delta
[2025-07-19T21:02:35.706+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 74 (task 677, attempt 0, stage 7.0)
[2025-07-19T21:02:35.710+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/81/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/81/.2.delta.c29a01cd-439d-4633-b480-c48344305f42.TID684.tmp
[2025-07-19T21:02:35.710+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/80/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/80/.2.delta.93d47988-ca8d-4d15-9f78-665adc805c90.TID683.tmp
[2025-07-19T21:02:35.711+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 74 (task 677, attempt 0, stage 7.0)
[2025-07-19T21:02:35.712+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 74.0 in stage 7.0 (TID 677). 5829 bytes result sent to driver
[2025-07-19T21:02:35.712+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 82.0 in stage 7.0 (TID 685) (8b44f3d35cfa, executor driver, partition 82, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.712+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 74.0 in stage 7.0 (TID 677) in 85 ms on 8b44f3d35cfa (executor driver) (75/200)
[2025-07-19T21:02:35.712+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 82.0 in stage 7.0 (TID 685)
[2025-07-19T21:02:35.717+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/75/.2.delta.34b831a6-f0b2-49cc-b63d-760aac9dad42.TID678.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/75/2.delta
[2025-07-19T21:02:35.718+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=75),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/75] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/75/2.delta
[2025-07-19T21:02:35.720+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 75 (task 678, attempt 0, stage 7.0)
[2025-07-19T21:02:35.720+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.720+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.721+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f373873
[2025-07-19T21:02:35.722+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=82, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.723+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=82),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/82] for update
[2025-07-19T21:02:35.723+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 75 (task 678, attempt 0, stage 7.0)
[2025-07-19T21:02:35.723+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 75.0 in stage 7.0 (TID 678). 5829 bytes result sent to driver
[2025-07-19T21:02:35.724+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 83.0 in stage 7.0 (TID 686) (8b44f3d35cfa, executor driver, partition 83, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.725+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 83.0 in stage 7.0 (TID 686)
[2025-07-19T21:02:35.726+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 75.0 in stage 7.0 (TID 678) in 79 ms on 8b44f3d35cfa (executor driver) (76/200)
[2025-07-19T21:02:35.726+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.729+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.730+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.731+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d85a33
[2025-07-19T21:02:35.732+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=83, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.733+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=83),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/83] for update
[2025-07-19T21:02:35.734+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.734+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/77/.2.delta.96890fe6-4104-41b7-bfd4-aeba8d01faeb.TID680.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/77/2.delta
[2025-07-19T21:02:35.734+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/76/.2.delta.abf7ce0a-8cce-4d09-af67-c6f48f4dd65b.TID679.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/76/2.delta
[2025-07-19T21:02:35.735+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=77),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/77] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/77/2.delta
[2025-07-19T21:02:35.735+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 77 (task 680, attempt 0, stage 7.0)
[2025-07-19T21:02:35.736+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=76),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/76] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/76/2.delta
[2025-07-19T21:02:35.736+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/78/.2.delta.dfc49586-f796-4c16-a325-dc10fc71b273.TID681.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/78/2.delta
[2025-07-19T21:02:35.736+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=78),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/78] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/78/2.delta
[2025-07-19T21:02:35.737+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 76 (task 679, attempt 0, stage 7.0)
[2025-07-19T21:02:35.738+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 78 (task 681, attempt 0, stage 7.0)
[2025-07-19T21:02:35.740+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 77 (task 680, attempt 0, stage 7.0)
[2025-07-19T21:02:35.741+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 77.0 in stage 7.0 (TID 680). 5829 bytes result sent to driver
[2025-07-19T21:02:35.743+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 84.0 in stage 7.0 (TID 687) (8b44f3d35cfa, executor driver, partition 84, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.744+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 84.0 in stage 7.0 (TID 687)
[2025-07-19T21:02:35.744+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 77.0 in stage 7.0 (TID 680) in 80 ms on 8b44f3d35cfa (executor driver) (77/200)
[2025-07-19T21:02:35.745+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/82/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/82/.2.delta.33fe17c3-5919-43ff-b2a6-b9d60898b459.TID685.tmp
[2025-07-19T21:02:35.745+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 76 (task 679, attempt 0, stage 7.0)
[2025-07-19T21:02:35.746+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 76.0 in stage 7.0 (TID 679). 5829 bytes result sent to driver
[2025-07-19T21:02:35.747+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.748+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.748+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 85.0 in stage 7.0 (TID 688) (8b44f3d35cfa, executor driver, partition 85, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.749+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 76.0 in stage 7.0 (TID 679) in 91 ms on 8b44f3d35cfa (executor driver) (78/200)
[2025-07-19T21:02:35.749+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 78 (task 681, attempt 0, stage 7.0)
[2025-07-19T21:02:35.750+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/83/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/83/.2.delta.5053421a-4e30-4dfd-90f7-c964a66a3b47.TID686.tmp
[2025-07-19T21:02:35.750+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 78.0 in stage 7.0 (TID 681). 5829 bytes result sent to driver
[2025-07-19T21:02:35.751+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 85.0 in stage 7.0 (TID 688)
[2025-07-19T21:02:35.752+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 86.0 in stage 7.0 (TID 689) (8b44f3d35cfa, executor driver, partition 86, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.752+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.753+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.753+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 86.0 in stage 7.0 (TID 689)
[2025-07-19T21:02:35.755+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 78.0 in stage 7.0 (TID 681) in 80 ms on 8b44f3d35cfa (executor driver) (79/200)
[2025-07-19T21:02:35.756+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.756+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/79/.2.delta.0b677ea3-7323-41cc-b2ae-f746948baa7e.TID682.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/79/2.delta
[2025-07-19T21:02:35.760+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.761+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=79),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/79] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/79/2.delta
[2025-07-19T21:02:35.761+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@64b884f4
[2025-07-19T21:02:35.762+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 79 (task 682, attempt 0, stage 7.0)
[2025-07-19T21:02:35.762+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=84, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.762+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=84),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/84] for update
[2025-07-19T21:02:35.763+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 79 (task 682, attempt 0, stage 7.0)
[2025-07-19T21:02:35.763+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 79.0 in stage 7.0 (TID 682). 5829 bytes result sent to driver
[2025-07-19T21:02:35.763+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.764+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 87.0 in stage 7.0 (TID 690) (8b44f3d35cfa, executor driver, partition 87, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.764+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 79.0 in stage 7.0 (TID 682) in 83 ms on 8b44f3d35cfa (executor driver) (80/200)
[2025-07-19T21:02:35.764+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 87.0 in stage 7.0 (TID 690)
[2025-07-19T21:02:35.764+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e3fec58
[2025-07-19T21:02:35.764+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=86, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.764+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=86),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/86] for update
[2025-07-19T21:02:35.764+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5778d051
[2025-07-19T21:02:35.764+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=85, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.764+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=85),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/85] for update
[2025-07-19T21:02:35.764+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.764+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.765+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.765+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@75cda52c
[2025-07-19T21:02:35.765+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=87, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.765+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.765+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=87),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/87] for update
[2025-07-19T21:02:35.765+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.771+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/80/.2.delta.93d47988-ca8d-4d15-9f78-665adc805c90.TID683.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/80/2.delta
[2025-07-19T21:02:35.772+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=80),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/80] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/80/2.delta
[2025-07-19T21:02:35.773+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 80 (task 683, attempt 0, stage 7.0)
[2025-07-19T21:02:35.775+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 80 (task 683, attempt 0, stage 7.0)
[2025-07-19T21:02:35.776+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 80.0 in stage 7.0 (TID 683). 5872 bytes result sent to driver
[2025-07-19T21:02:35.776+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/81/.2.delta.c29a01cd-439d-4633-b480-c48344305f42.TID684.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/81/2.delta
[2025-07-19T21:02:35.777+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=81),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/81] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/81/2.delta
[2025-07-19T21:02:35.777+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 88.0 in stage 7.0 (TID 691) (8b44f3d35cfa, executor driver, partition 88, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.777+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 81 (task 684, attempt 0, stage 7.0)
[2025-07-19T21:02:35.777+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 88.0 in stage 7.0 (TID 691)
[2025-07-19T21:02:35.779+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 80.0 in stage 7.0 (TID 683) in 94 ms on 8b44f3d35cfa (executor driver) (81/200)
[2025-07-19T21:02:35.781+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/85/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/85/.2.delta.e55aa510-8046-45d5-b394-ac5131562a2d.TID688.tmp
[2025-07-19T21:02:35.782+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/84/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/84/.2.delta.e5894336-f53f-49b3-b286-9c006015b61b.TID687.tmp
[2025-07-19T21:02:35.783+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.784+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 81 (task 684, attempt 0, stage 7.0)
[2025-07-19T21:02:35.784+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:35.785+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/86/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/86/.2.delta.40e6e000-7a15-426d-9493-25757473df86.TID689.tmp
[2025-07-19T21:02:35.786+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 81.0 in stage 7.0 (TID 684). 5829 bytes result sent to driver
[2025-07-19T21:02:35.787+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/87/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/87/.2.delta.93246689-b60e-4e92-ada3-39d0a616c4cd.TID690.tmp
[2025-07-19T21:02:35.788+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 81.0 in stage 7.0 (TID 684) in 101 ms on 8b44f3d35cfa (executor driver) (82/200)
[2025-07-19T21:02:35.789+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 89.0 in stage 7.0 (TID 692) (8b44f3d35cfa, executor driver, partition 89, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.789+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e2a0991
[2025-07-19T21:02:35.789+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=88, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.790+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=88),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/88] for update
[2025-07-19T21:02:35.791+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 89.0 in stage 7.0 (TID 692)
[2025-07-19T21:02:35.792+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.792+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.792+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.793+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@fcf273a
[2025-07-19T21:02:35.795+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=89, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.796+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=89),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/89] for update
[2025-07-19T21:02:35.797+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/82/.2.delta.33fe17c3-5919-43ff-b2a6-b9d60898b459.TID685.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/82/2.delta
[2025-07-19T21:02:35.799+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=82),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/82] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/82/2.delta
[2025-07-19T21:02:35.800+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 82 (task 685, attempt 0, stage 7.0)
[2025-07-19T21:02:35.801+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.802+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 82 (task 685, attempt 0, stage 7.0)
[2025-07-19T21:02:35.802+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 82.0 in stage 7.0 (TID 685). 5872 bytes result sent to driver
[2025-07-19T21:02:35.802+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 90.0 in stage 7.0 (TID 693) (8b44f3d35cfa, executor driver, partition 90, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.803+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 90.0 in stage 7.0 (TID 693)
[2025-07-19T21:02:35.804+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.804+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.804+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 82.0 in stage 7.0 (TID 685) in 90 ms on 8b44f3d35cfa (executor driver) (83/200)
[2025-07-19T21:02:35.804+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47e3579b
[2025-07-19T21:02:35.805+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=90, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.806+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=90),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/90] for update
[2025-07-19T21:02:35.806+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/88/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/88/.2.delta.bcab8b3d-5892-419b-a563-5ce3bcdcb70f.TID691.tmp
[2025-07-19T21:02:35.807+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.807+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/89/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/89/.2.delta.1a6cda3b-fa87-4298-9db9-eb1ecccd2400.TID692.tmp
[2025-07-19T21:02:35.809+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/83/.2.delta.5053421a-4e30-4dfd-90f7-c964a66a3b47.TID686.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/83/2.delta
[2025-07-19T21:02:35.810+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=83),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/83] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/83/2.delta
[2025-07-19T21:02:35.810+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/90/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/90/.2.delta.59586262-2d9a-4122-9a3a-e5bcca42129f.TID693.tmp
[2025-07-19T21:02:35.811+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 83 (task 686, attempt 0, stage 7.0)
[2025-07-19T21:02:35.813+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 83 (task 686, attempt 0, stage 7.0)
[2025-07-19T21:02:35.814+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 83.0 in stage 7.0 (TID 686). 5872 bytes result sent to driver
[2025-07-19T21:02:35.814+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 91.0 in stage 7.0 (TID 694) (8b44f3d35cfa, executor driver, partition 91, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.815+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 83.0 in stage 7.0 (TID 686) in 91 ms on 8b44f3d35cfa (executor driver) (84/200)
[2025-07-19T21:02:35.815+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 91.0 in stage 7.0 (TID 694)
[2025-07-19T21:02:35.816+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.816+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.819+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58b960d8
[2025-07-19T21:02:35.820+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=91, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.820+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=91),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/91] for update
[2025-07-19T21:02:35.820+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.827+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/85/.2.delta.e55aa510-8046-45d5-b394-ac5131562a2d.TID688.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/85/2.delta
[2025-07-19T21:02:35.830+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=85),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/85] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/85/2.delta
[2025-07-19T21:02:35.834+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 85 (task 688, attempt 0, stage 7.0)
[2025-07-19T21:02:35.837+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/86/.2.delta.40e6e000-7a15-426d-9493-25757473df86.TID689.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/86/2.delta
[2025-07-19T21:02:35.837+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=86),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/86] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/86/2.delta
[2025-07-19T21:02:35.837+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 86 (task 689, attempt 0, stage 7.0)
[2025-07-19T21:02:35.838+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/84/.2.delta.e5894336-f53f-49b3-b286-9c006015b61b.TID687.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/84/2.delta
[2025-07-19T21:02:35.838+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=84),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/84] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/84/2.delta
[2025-07-19T21:02:35.840+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/87/.2.delta.93246689-b60e-4e92-ada3-39d0a616c4cd.TID690.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/87/2.delta
[2025-07-19T21:02:35.840+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=87),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/87] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/87/2.delta
[2025-07-19T21:02:35.841+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 84 (task 687, attempt 0, stage 7.0)
[2025-07-19T21:02:35.841+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 87 (task 690, attempt 0, stage 7.0)
[2025-07-19T21:02:35.842+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 85 (task 688, attempt 0, stage 7.0)
[2025-07-19T21:02:35.842+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 85.0 in stage 7.0 (TID 688). 5872 bytes result sent to driver
[2025-07-19T21:02:35.842+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/91/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/91/.2.delta.97b81bc0-58ff-4818-bc88-6bfa2d2c5e04.TID694.tmp
[2025-07-19T21:02:35.842+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 86 (task 689, attempt 0, stage 7.0)
[2025-07-19T21:02:35.843+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 86.0 in stage 7.0 (TID 689). 5872 bytes result sent to driver
[2025-07-19T21:02:35.843+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 92.0 in stage 7.0 (TID 695) (8b44f3d35cfa, executor driver, partition 92, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.843+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 93.0 in stage 7.0 (TID 696) (8b44f3d35cfa, executor driver, partition 93, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.843+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 93.0 in stage 7.0 (TID 696)
[2025-07-19T21:02:35.844+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 92.0 in stage 7.0 (TID 695)
[2025-07-19T21:02:35.844+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 84 (task 687, attempt 0, stage 7.0)
[2025-07-19T21:02:35.845+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 84.0 in stage 7.0 (TID 687). 5872 bytes result sent to driver
[2025-07-19T21:02:35.845+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.847+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.847+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.849+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.850+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 87 (task 690, attempt 0, stage 7.0)
[2025-07-19T21:02:35.850+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 94.0 in stage 7.0 (TID 697) (8b44f3d35cfa, executor driver, partition 94, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.851+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 87.0 in stage 7.0 (TID 690). 5872 bytes result sent to driver
[2025-07-19T21:02:35.852+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 86.0 in stage 7.0 (TID 689) in 97 ms on 8b44f3d35cfa (executor driver) (85/200)
[2025-07-19T21:02:35.853+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 85.0 in stage 7.0 (TID 688) in 101 ms on 8b44f3d35cfa (executor driver) (86/200)
[2025-07-19T21:02:35.854+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 84.0 in stage 7.0 (TID 687) in 104 ms on 8b44f3d35cfa (executor driver) (87/200)
[2025-07-19T21:02:35.855+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 94.0 in stage 7.0 (TID 697)
[2025-07-19T21:02:35.855+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d4c0d8d
[2025-07-19T21:02:35.856+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=93, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.856+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=93),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/93] for update
[2025-07-19T21:02:35.857+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 95.0 in stage 7.0 (TID 698) (8b44f3d35cfa, executor driver, partition 95, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.858+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/88/.2.delta.bcab8b3d-5892-419b-a563-5ce3bcdcb70f.TID691.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/88/2.delta
[2025-07-19T21:02:35.859+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=88),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/88] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/88/2.delta
[2025-07-19T21:02:35.859+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 88 (task 691, attempt 0, stage 7.0)
[2025-07-19T21:02:35.859+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 87.0 in stage 7.0 (TID 690) in 91 ms on 8b44f3d35cfa (executor driver) (88/200)
[2025-07-19T21:02:35.859+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.861+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.862+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.862+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@70de7e5f
[2025-07-19T21:02:35.862+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=94, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.862+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=94),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/94] for update
[2025-07-19T21:02:35.863+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 95.0 in stage 7.0 (TID 698)
[2025-07-19T21:02:35.863+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/90/.2.delta.59586262-2d9a-4122-9a3a-e5bcca42129f.TID693.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/90/2.delta
[2025-07-19T21:02:35.863+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=90),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/90] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/90/2.delta
[2025-07-19T21:02:35.863+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ce57e0b
[2025-07-19T21:02:35.863+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.863+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.864+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 90 (task 693, attempt 0, stage 7.0)
[2025-07-19T21:02:35.864+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=92, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.864+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=92),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/92] for update
[2025-07-19T21:02:35.864+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.864+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 88 (task 691, attempt 0, stage 7.0)
[2025-07-19T21:02:35.864+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 88.0 in stage 7.0 (TID 691). 5872 bytes result sent to driver
[2025-07-19T21:02:35.865+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.866+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 96.0 in stage 7.0 (TID 699) (8b44f3d35cfa, executor driver, partition 96, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.866+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 96.0 in stage 7.0 (TID 699)
[2025-07-19T21:02:35.866+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28e4f713
[2025-07-19T21:02:35.866+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 88.0 in stage 7.0 (TID 691) in 76 ms on 8b44f3d35cfa (executor driver) (89/200)
[2025-07-19T21:02:35.866+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/89/.2.delta.1a6cda3b-fa87-4298-9db9-eb1ecccd2400.TID692.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/89/2.delta
[2025-07-19T21:02:35.867+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=89),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/89] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/89/2.delta
[2025-07-19T21:02:35.869+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.869+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=95, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.870+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 89 (task 692, attempt 0, stage 7.0)
[2025-07-19T21:02:35.870+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.870+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=95),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/95] for update
[2025-07-19T21:02:35.870+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@70d2b7b8
[2025-07-19T21:02:35.871+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.872+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 90 (task 693, attempt 0, stage 7.0)
[2025-07-19T21:02:35.873+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 90.0 in stage 7.0 (TID 693). 5872 bytes result sent to driver
[2025-07-19T21:02:35.873+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 97.0 in stage 7.0 (TID 700) (8b44f3d35cfa, executor driver, partition 97, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.873+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 97.0 in stage 7.0 (TID 700)
[2025-07-19T21:02:35.873+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=96, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.874+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=96),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/96] for update
[2025-07-19T21:02:35.874+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 90.0 in stage 7.0 (TID 693) in 61 ms on 8b44f3d35cfa (executor driver) (90/200)
[2025-07-19T21:02:35.874+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/93/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/93/.2.delta.8cb7b3f1-ccbe-4793-a890-4790b57b2301.TID696.tmp
[2025-07-19T21:02:35.874+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.874+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 89 (task 692, attempt 0, stage 7.0)
[2025-07-19T21:02:35.874+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 89.0 in stage 7.0 (TID 692). 5872 bytes result sent to driver
[2025-07-19T21:02:35.874+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 98.0 in stage 7.0 (TID 701) (8b44f3d35cfa, executor driver, partition 98, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.875+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 98.0 in stage 7.0 (TID 701)
[2025-07-19T21:02:35.875+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 89.0 in stage 7.0 (TID 692) in 75 ms on 8b44f3d35cfa (executor driver) (91/200)
[2025-07-19T21:02:35.875+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/94/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/94/.2.delta.d0ceaee4-7b8a-46e8-ae73-544ff8846612.TID697.tmp
[2025-07-19T21:02:35.876+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.876+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.877+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.878+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5120b2ba
[2025-07-19T21:02:35.879+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=98, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.879+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=98),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/98] for update
[2025-07-19T21:02:35.879+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:35.880+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/95/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/95/.2.delta.d031d1f5-2472-4620-9752-9aa41056903d.TID698.tmp
[2025-07-19T21:02:35.880+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.880+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/92/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/92/.2.delta.df60d438-d19d-4237-aa7c-6a14dc9a3be4.TID695.tmp
[2025-07-19T21:02:35.881+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47cbc71
[2025-07-19T21:02:35.881+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=97, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.882+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=97),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/97] for update
[2025-07-19T21:02:35.882+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.883+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/96/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/96/.2.delta.a9ff400c-94ab-4830-83d2-8d4f67b33043.TID699.tmp
[2025-07-19T21:02:35.883+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/98/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/98/.2.delta.bc425e6a-5ba4-40f0-a179-4b2f3d1d533d.TID701.tmp
[2025-07-19T21:02:35.883+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/97/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/97/.2.delta.f6341c88-9839-4f53-a9c2-8e27172bf26e.TID700.tmp
[2025-07-19T21:02:35.884+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/91/.2.delta.97b81bc0-58ff-4818-bc88-6bfa2d2c5e04.TID694.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/91/2.delta
[2025-07-19T21:02:35.885+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=91),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/91] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/91/2.delta
[2025-07-19T21:02:35.885+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 91 (task 694, attempt 0, stage 7.0)
[2025-07-19T21:02:35.892+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 91 (task 694, attempt 0, stage 7.0)
[2025-07-19T21:02:35.892+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 91.0 in stage 7.0 (TID 694). 5872 bytes result sent to driver
[2025-07-19T21:02:35.894+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 99.0 in stage 7.0 (TID 702) (8b44f3d35cfa, executor driver, partition 99, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.895+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 99.0 in stage 7.0 (TID 702)
[2025-07-19T21:02:35.895+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 91.0 in stage 7.0 (TID 694) in 81 ms on 8b44f3d35cfa (executor driver) (92/200)
[2025-07-19T21:02:35.896+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.897+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.898+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40862659
[2025-07-19T21:02:35.898+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=99, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.898+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=99),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/99] for update
[2025-07-19T21:02:35.903+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.905+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/94/.2.delta.d0ceaee4-7b8a-46e8-ae73-544ff8846612.TID697.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/94/2.delta
[2025-07-19T21:02:35.905+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=94),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/94] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/94/2.delta
[2025-07-19T21:02:35.909+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 94 (task 697, attempt 0, stage 7.0)
[2025-07-19T21:02:35.910+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/92/.2.delta.df60d438-d19d-4237-aa7c-6a14dc9a3be4.TID695.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/92/2.delta
[2025-07-19T21:02:35.911+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=92),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/92] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/92/2.delta
[2025-07-19T21:02:35.912+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 92 (task 695, attempt 0, stage 7.0)
[2025-07-19T21:02:35.913+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 92 (task 695, attempt 0, stage 7.0)
[2025-07-19T21:02:35.914+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/95/.2.delta.d031d1f5-2472-4620-9752-9aa41056903d.TID698.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/95/2.delta
[2025-07-19T21:02:35.916+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 92.0 in stage 7.0 (TID 695). 5829 bytes result sent to driver
[2025-07-19T21:02:35.917+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=95),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/95] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/95/2.delta
[2025-07-19T21:02:35.918+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 95 (task 698, attempt 0, stage 7.0)
[2025-07-19T21:02:35.920+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 100.0 in stage 7.0 (TID 703) (8b44f3d35cfa, executor driver, partition 100, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.920+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 92.0 in stage 7.0 (TID 695) in 74 ms on 8b44f3d35cfa (executor driver) (93/200)
[2025-07-19T21:02:35.921+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 100.0 in stage 7.0 (TID 703)
[2025-07-19T21:02:35.921+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/93/.2.delta.8cb7b3f1-ccbe-4793-a890-4790b57b2301.TID696.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/93/2.delta
[2025-07-19T21:02:35.922+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=93),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/93] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/93/2.delta
[2025-07-19T21:02:35.922+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 93 (task 696, attempt 0, stage 7.0)
[2025-07-19T21:02:35.923+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/97/.2.delta.f6341c88-9839-4f53-a9c2-8e27172bf26e.TID700.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/97/2.delta
[2025-07-19T21:02:35.923+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=97),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/97] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/97/2.delta
[2025-07-19T21:02:35.923+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/99/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/99/.2.delta.b7eef543-0fa7-43d9-8409-9da4c09a198c.TID702.tmp
[2025-07-19T21:02:35.924+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 97 (task 700, attempt 0, stage 7.0)
[2025-07-19T21:02:35.926+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.926+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.927+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@46db1f82
[2025-07-19T21:02:35.927+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 94 (task 697, attempt 0, stage 7.0)
[2025-07-19T21:02:35.927+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 94.0 in stage 7.0 (TID 697). 5829 bytes result sent to driver
[2025-07-19T21:02:35.928+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=100, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.929+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=100),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/100] for update
[2025-07-19T21:02:35.929+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 101.0 in stage 7.0 (TID 704) (8b44f3d35cfa, executor driver, partition 101, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.930+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 95 (task 698, attempt 0, stage 7.0)
[2025-07-19T21:02:35.930+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 95.0 in stage 7.0 (TID 698). 5829 bytes result sent to driver
[2025-07-19T21:02:35.932+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/96/.2.delta.a9ff400c-94ab-4830-83d2-8d4f67b33043.TID699.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/96/2.delta
[2025-07-19T21:02:35.933+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=96),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/96] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/96/2.delta
[2025-07-19T21:02:35.933+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 102.0 in stage 7.0 (TID 705) (8b44f3d35cfa, executor driver, partition 102, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.934+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 94.0 in stage 7.0 (TID 697) in 83 ms on 8b44f3d35cfa (executor driver) (94/200)
[2025-07-19T21:02:35.934+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 102.0 in stage 7.0 (TID 705)
[2025-07-19T21:02:35.935+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 95.0 in stage 7.0 (TID 698) in 81 ms on 8b44f3d35cfa (executor driver) (95/200)
[2025-07-19T21:02:35.935+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.935+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 96 (task 699, attempt 0, stage 7.0)
[2025-07-19T21:02:35.936+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/98/.2.delta.bc425e6a-5ba4-40f0-a179-4b2f3d1d533d.TID701.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/98/2.delta
[2025-07-19T21:02:35.936+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=98),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/98] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/98/2.delta
[2025-07-19T21:02:35.936+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 98 (task 701, attempt 0, stage 7.0)
[2025-07-19T21:02:35.936+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 93 (task 696, attempt 0, stage 7.0)
[2025-07-19T21:02:35.936+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.937+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.937+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22104cc9
[2025-07-19T21:02:35.937+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 97 (task 700, attempt 0, stage 7.0)
[2025-07-19T21:02:35.938+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=102, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.939+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=102),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/102] for update
[2025-07-19T21:02:35.939+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 97.0 in stage 7.0 (TID 700). 5829 bytes result sent to driver
[2025-07-19T21:02:35.939+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.940+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 97.0 in stage 7.0 (TID 700) in 76 ms on 8b44f3d35cfa (executor driver) (96/200)
[2025-07-19T21:02:35.941+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 103.0 in stage 7.0 (TID 706) (8b44f3d35cfa, executor driver, partition 103, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.941+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 101.0 in stage 7.0 (TID 704)
[2025-07-19T21:02:35.942+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 93.0 in stage 7.0 (TID 696). 5829 bytes result sent to driver
[2025-07-19T21:02:35.942+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 98 (task 701, attempt 0, stage 7.0)
[2025-07-19T21:02:35.943+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 98.0 in stage 7.0 (TID 701). 5829 bytes result sent to driver
[2025-07-19T21:02:35.944+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 103.0 in stage 7.0 (TID 706)
[2025-07-19T21:02:35.945+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/102/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/102/.2.delta.47867bc6-055f-4116-a443-3ab7a700f0dc.TID705.tmp
[2025-07-19T21:02:35.947+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 96 (task 699, attempt 0, stage 7.0)
[2025-07-19T21:02:35.950+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.951+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.951+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 96.0 in stage 7.0 (TID 699). 5829 bytes result sent to driver
[2025-07-19T21:02:35.952+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/100/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/100/.2.delta.26bd9d28-c49e-46b2-83e4-386313e8863d.TID703.tmp
[2025-07-19T21:02:35.952+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.953+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 104.0 in stage 7.0 (TID 707) (8b44f3d35cfa, executor driver, partition 104, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.954+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 104.0 in stage 7.0 (TID 707)
[2025-07-19T21:02:35.955+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19897101
[2025-07-19T21:02:35.956+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 105.0 in stage 7.0 (TID 708) (8b44f3d35cfa, executor driver, partition 105, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.956+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 106.0 in stage 7.0 (TID 709) (8b44f3d35cfa, executor driver, partition 106, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.957+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.958+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.959+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 105.0 in stage 7.0 (TID 708)
[2025-07-19T21:02:35.960+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=101, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.962+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=101),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/101] for update
[2025-07-19T21:02:35.963+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.963+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:35.964+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.965+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 93.0 in stage 7.0 (TID 696) in 105 ms on 8b44f3d35cfa (executor driver) (97/200)
[2025-07-19T21:02:35.966+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68d452b9
[2025-07-19T21:02:35.966+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/99/.2.delta.b7eef543-0fa7-43d9-8409-9da4c09a198c.TID702.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/99/2.delta
[2025-07-19T21:02:35.967+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=99),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/99] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/99/2.delta
[2025-07-19T21:02:35.967+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 106.0 in stage 7.0 (TID 709)
[2025-07-19T21:02:35.967+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 96.0 in stage 7.0 (TID 699) in 96 ms on 8b44f3d35cfa (executor driver) (98/200)
[2025-07-19T21:02:35.967+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 98.0 in stage 7.0 (TID 701) in 88 ms on 8b44f3d35cfa (executor driver) (99/200)
[2025-07-19T21:02:35.968+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=105, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.969+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=105),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/105] for update
[2025-07-19T21:02:35.970+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 99 (task 702, attempt 0, stage 7.0)
[2025-07-19T21:02:35.970+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@465bd78e
[2025-07-19T21:02:35.970+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=104, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.971+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d59b294
[2025-07-19T21:02:35.971+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=104),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/104] for update
[2025-07-19T21:02:35.971+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.971+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.971+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=103, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.971+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=103),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/103] for update
[2025-07-19T21:02:35.971+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.971+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.971+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.971+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ad8864f
[2025-07-19T21:02:35.972+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=106, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.972+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=106),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/106] for update
[2025-07-19T21:02:35.972+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.973+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 99 (task 702, attempt 0, stage 7.0)
[2025-07-19T21:02:35.974+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 99.0 in stage 7.0 (TID 702). 5829 bytes result sent to driver
[2025-07-19T21:02:35.974+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 107.0 in stage 7.0 (TID 710) (8b44f3d35cfa, executor driver, partition 107, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.974+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 99.0 in stage 7.0 (TID 702) in 66 ms on 8b44f3d35cfa (executor driver) (100/200)
[2025-07-19T21:02:35.974+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 107.0 in stage 7.0 (TID 710)
[2025-07-19T21:02:35.974+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.975+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.975+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.975+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@608c8272
[2025-07-19T21:02:35.975+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=107, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.975+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=107),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/107] for update
[2025-07-19T21:02:35.975+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.975+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/101/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/101/.2.delta.55827d9d-b1ed-4bfd-a9bc-39d9351d7756.TID704.tmp
[2025-07-19T21:02:35.975+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/106/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/106/.2.delta.196dcf88-38c2-47d9-afca-bfd662463043.TID709.tmp
[2025-07-19T21:02:35.975+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/104/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/104/.2.delta.92ce77be-b1b3-4278-94f9-cb7a8632fc83.TID707.tmp
[2025-07-19T21:02:35.975+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/103/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/103/.2.delta.0f1427cb-1761-4bbc-99d3-30d67ae7b400.TID706.tmp
[2025-07-19T21:02:35.975+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/105/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/105/.2.delta.e7384a5d-dc80-43fc-b0d8-6313a6d20b6f.TID708.tmp
[2025-07-19T21:02:35.981+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/100/.2.delta.26bd9d28-c49e-46b2-83e4-386313e8863d.TID703.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/100/2.delta
[2025-07-19T21:02:35.981+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=100),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/100] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/100/2.delta
[2025-07-19T21:02:35.981+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 100 (task 703, attempt 0, stage 7.0)
[2025-07-19T21:02:35.982+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/107/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/107/.2.delta.0c5113df-2f53-450c-bbce-3f28b95dad19.TID710.tmp
[2025-07-19T21:02:35.984+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 100 (task 703, attempt 0, stage 7.0)
[2025-07-19T21:02:35.985+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 100.0 in stage 7.0 (TID 703). 5829 bytes result sent to driver
[2025-07-19T21:02:35.985+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 108.0 in stage 7.0 (TID 711) (8b44f3d35cfa, executor driver, partition 108, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.986+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 100.0 in stage 7.0 (TID 703) in 74 ms on 8b44f3d35cfa (executor driver) (101/200)
[2025-07-19T21:02:35.986+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 108.0 in stage 7.0 (TID 711)
[2025-07-19T21:02:35.989+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:35.990+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:35.990+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1fc96b96
[2025-07-19T21:02:35.993+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=108, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:35.994+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=108),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/108] for update
[2025-07-19T21:02:35.994+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/102/.2.delta.47867bc6-055f-4116-a443-3ab7a700f0dc.TID705.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/102/2.delta
[2025-07-19T21:02:35.995+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=102),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/102] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/102/2.delta
[2025-07-19T21:02:35.996+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Commit authorized for partition 102 (task 705, attempt 0, stage 7.0)
[2025-07-19T21:02:35.997+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:35.997+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO DataWritingSparkTask: Committed partition 102 (task 705, attempt 0, stage 7.0)
[2025-07-19T21:02:35.997+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Finished task 102.0 in stage 7.0 (TID 705). 5829 bytes result sent to driver
[2025-07-19T21:02:35.998+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Starting task 109.0 in stage 7.0 (TID 712) (8b44f3d35cfa, executor driver, partition 109, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:35.998+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO Executor: Running task 109.0 in stage 7.0 (TID 712)
[2025-07-19T21:02:35.999+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO TaskSetManager: Finished task 102.0 in stage 7.0 (TID 705) in 72 ms on 8b44f3d35cfa (executor driver) (102/200)
[2025-07-19T21:02:36.000+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.001+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.001+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@94ed882
[2025-07-19T21:02:36.002+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=109, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.002+0000] {subprocess.py:93} INFO - 25/07/19 21:02:35 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=109),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/109] for update
[2025-07-19T21:02:36.003+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.004+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/108/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/108/.2.delta.a13f53c5-ef4e-4c48-a786-0a18f7a90d71.TID711.tmp
[2025-07-19T21:02:36.010+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/109/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/109/.2.delta.fb200e4a-8bd6-4f04-b27e-e3f5ede841b5.TID712.tmp
[2025-07-19T21:02:36.012+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/101/.2.delta.55827d9d-b1ed-4bfd-a9bc-39d9351d7756.TID704.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/101/2.delta
[2025-07-19T21:02:36.013+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=101),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/101] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/101/2.delta
[2025-07-19T21:02:36.014+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 101 (task 704, attempt 0, stage 7.0)
[2025-07-19T21:02:36.014+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/106/.2.delta.196dcf88-38c2-47d9-afca-bfd662463043.TID709.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/106/2.delta
[2025-07-19T21:02:36.014+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=106),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/106] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/106/2.delta
[2025-07-19T21:02:36.015+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 106 (task 709, attempt 0, stage 7.0)
[2025-07-19T21:02:36.018+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 106 (task 709, attempt 0, stage 7.0)
[2025-07-19T21:02:36.021+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 101 (task 704, attempt 0, stage 7.0)
[2025-07-19T21:02:36.021+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 106.0 in stage 7.0 (TID 709). 5829 bytes result sent to driver
[2025-07-19T21:02:36.022+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 110.0 in stage 7.0 (TID 713) (8b44f3d35cfa, executor driver, partition 110, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.022+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 101.0 in stage 7.0 (TID 704). 5829 bytes result sent to driver
[2025-07-19T21:02:36.023+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/104/.2.delta.92ce77be-b1b3-4278-94f9-cb7a8632fc83.TID707.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/104/2.delta
[2025-07-19T21:02:36.023+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=104),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/104] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/104/2.delta
[2025-07-19T21:02:36.024+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 104 (task 707, attempt 0, stage 7.0)
[2025-07-19T21:02:36.024+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/105/.2.delta.e7384a5d-dc80-43fc-b0d8-6313a6d20b6f.TID708.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/105/2.delta
[2025-07-19T21:02:36.025+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=105),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/105] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/105/2.delta
[2025-07-19T21:02:36.026+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 106.0 in stage 7.0 (TID 709) in 76 ms on 8b44f3d35cfa (executor driver) (103/200)
[2025-07-19T21:02:36.026+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 110.0 in stage 7.0 (TID 713)
[2025-07-19T21:02:36.027+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 105 (task 708, attempt 0, stage 7.0)
[2025-07-19T21:02:36.027+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 111.0 in stage 7.0 (TID 714) (8b44f3d35cfa, executor driver, partition 111, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.028+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/103/.2.delta.0f1427cb-1761-4bbc-99d3-30d67ae7b400.TID706.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/103/2.delta
[2025-07-19T21:02:36.029+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=103),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/103] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/103/2.delta
[2025-07-19T21:02:36.030+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 103 (task 706, attempt 0, stage 7.0)
[2025-07-19T21:02:36.030+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 101.0 in stage 7.0 (TID 704) in 101 ms on 8b44f3d35cfa (executor driver) (104/200)
[2025-07-19T21:02:36.031+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 104 (task 707, attempt 0, stage 7.0)
[2025-07-19T21:02:36.031+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 104.0 in stage 7.0 (TID 707). 5829 bytes result sent to driver
[2025-07-19T21:02:36.032+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 111.0 in stage 7.0 (TID 714)
[2025-07-19T21:02:36.032+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 112.0 in stage 7.0 (TID 715) (8b44f3d35cfa, executor driver, partition 112, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.032+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 112.0 in stage 7.0 (TID 715)
[2025-07-19T21:02:36.032+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.033+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.033+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 104.0 in stage 7.0 (TID 707) in 92 ms on 8b44f3d35cfa (executor driver) (105/200)
[2025-07-19T21:02:36.033+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 103 (task 706, attempt 0, stage 7.0)
[2025-07-19T21:02:36.034+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 103.0 in stage 7.0 (TID 706). 5829 bytes result sent to driver
[2025-07-19T21:02:36.034+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 113.0 in stage 7.0 (TID 716) (8b44f3d35cfa, executor driver, partition 113, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.035+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 103.0 in stage 7.0 (TID 706) in 98 ms on 8b44f3d35cfa (executor driver) (106/200)
[2025-07-19T21:02:36.035+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.035+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.035+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.036+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.036+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 113.0 in stage 7.0 (TID 716)
[2025-07-19T21:02:36.036+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/107/.2.delta.0c5113df-2f53-450c-bbce-3f28b95dad19.TID710.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/107/2.delta
[2025-07-19T21:02:36.036+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=107),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/107] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/107/2.delta
[2025-07-19T21:02:36.036+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 107 (task 710, attempt 0, stage 7.0)
[2025-07-19T21:02:36.036+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 105 (task 708, attempt 0, stage 7.0)
[2025-07-19T21:02:36.036+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.037+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.037+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1de35a79
[2025-07-19T21:02:36.041+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 105.0 in stage 7.0 (TID 708). 5915 bytes result sent to driver
[2025-07-19T21:02:36.042+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=110, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.042+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=110),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/110] for update
[2025-07-19T21:02:36.045+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 107 (task 710, attempt 0, stage 7.0)
[2025-07-19T21:02:36.050+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 114.0 in stage 7.0 (TID 717) (8b44f3d35cfa, executor driver, partition 114, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.052+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 107.0 in stage 7.0 (TID 710). 5915 bytes result sent to driver
[2025-07-19T21:02:36.053+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 114.0 in stage 7.0 (TID 717)
[2025-07-19T21:02:36.053+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 105.0 in stage 7.0 (TID 708) in 106 ms on 8b44f3d35cfa (executor driver) (107/200)
[2025-07-19T21:02:36.055+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.056+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 115.0 in stage 7.0 (TID 718) (8b44f3d35cfa, executor driver, partition 115, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.056+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 107.0 in stage 7.0 (TID 710) in 92 ms on 8b44f3d35cfa (executor driver) (108/200)
[2025-07-19T21:02:36.056+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 115.0 in stage 7.0 (TID 718)
[2025-07-19T21:02:36.057+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54b1fc7d
[2025-07-19T21:02:36.057+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/108/.2.delta.a13f53c5-ef4e-4c48-a786-0a18f7a90d71.TID711.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/108/2.delta
[2025-07-19T21:02:36.057+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=108),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/108] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/108/2.delta
[2025-07-19T21:02:36.058+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=113, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.058+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=113),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/113] for update
[2025-07-19T21:02:36.059+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.059+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.060+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.060+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:36.061+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 108 (task 711, attempt 0, stage 7.0)
[2025-07-19T21:02:36.061+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1bc36ce5
[2025-07-19T21:02:36.062+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.062+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=111, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.062+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=111),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/111] for update
[2025-07-19T21:02:36.062+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ff16589
[2025-07-19T21:02:36.062+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 108 (task 711, attempt 0, stage 7.0)
[2025-07-19T21:02:36.063+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=112, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.063+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.064+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=112),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/112] for update
[2025-07-19T21:02:36.065+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 108.0 in stage 7.0 (TID 711). 5872 bytes result sent to driver
[2025-07-19T21:02:36.065+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 116.0 in stage 7.0 (TID 719) (8b44f3d35cfa, executor driver, partition 116, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.065+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 108.0 in stage 7.0 (TID 711) in 79 ms on 8b44f3d35cfa (executor driver) (109/200)
[2025-07-19T21:02:36.065+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.065+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@51c84857
[2025-07-19T21:02:36.065+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 116.0 in stage 7.0 (TID 719)
[2025-07-19T21:02:36.066+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=114, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.066+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=114),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/114] for update
[2025-07-19T21:02:36.068+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/109/.2.delta.fb200e4a-8bd6-4f04-b27e-e3f5ede841b5.TID712.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/109/2.delta
[2025-07-19T21:02:36.069+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=109),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/109] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/109/2.delta
[2025-07-19T21:02:36.070+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 109 (task 712, attempt 0, stage 7.0)
[2025-07-19T21:02:36.070+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.070+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f01a985
[2025-07-19T21:02:36.071+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.072+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.072+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=115, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.072+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=115),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/115] for update
[2025-07-19T21:02:36.072+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/111/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/111/.2.delta.6fc36610-2a25-41d7-92a3-6b21f8b60688.TID714.tmp
[2025-07-19T21:02:36.072+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f7bf31e
[2025-07-19T21:02:36.073+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=116, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.073+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=116),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/116] for update
[2025-07-19T21:02:36.075+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 109 (task 712, attempt 0, stage 7.0)
[2025-07-19T21:02:36.075+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.076+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 109.0 in stage 7.0 (TID 712). 5872 bytes result sent to driver
[2025-07-19T21:02:36.076+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 117.0 in stage 7.0 (TID 720) (8b44f3d35cfa, executor driver, partition 117, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.078+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 117.0 in stage 7.0 (TID 720)
[2025-07-19T21:02:36.078+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 109.0 in stage 7.0 (TID 712) in 80 ms on 8b44f3d35cfa (executor driver) (110/200)
[2025-07-19T21:02:36.078+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.079+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.079+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.080+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a2affac
[2025-07-19T21:02:36.081+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/113/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/113/.2.delta.0b477578-0c8b-4e40-9606-15ce2c46efcb.TID716.tmp
[2025-07-19T21:02:36.083+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=117, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.084+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=117),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/117] for update
[2025-07-19T21:02:36.084+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.084+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/110/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/110/.2.delta.6850bbbc-187a-4843-b70a-3cffb27e0a77.TID713.tmp
[2025-07-19T21:02:36.088+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/112/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/112/.2.delta.fc4dae69-91d4-43d6-8fd5-ca932188bf4d.TID715.tmp
[2025-07-19T21:02:36.091+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/117/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/117/.2.delta.d60a8432-c342-49c1-98a0-e00412c7ec25.TID720.tmp
[2025-07-19T21:02:36.093+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/116/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/116/.2.delta.5f9f1ab8-62f5-4399-952b-7c84942b882f.TID719.tmp
[2025-07-19T21:02:36.094+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/115/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/115/.2.delta.3cc5a30d-3d47-40a2-a4db-e3a8ced95880.TID718.tmp
[2025-07-19T21:02:36.094+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/114/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/114/.2.delta.7c9971f4-ab6d-480e-a94a-56561f2affd7.TID717.tmp
[2025-07-19T21:02:36.128+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/111/.2.delta.6fc36610-2a25-41d7-92a3-6b21f8b60688.TID714.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/111/2.delta
[2025-07-19T21:02:36.129+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=111),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/111] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/111/2.delta
[2025-07-19T21:02:36.131+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 111 (task 714, attempt 0, stage 7.0)
[2025-07-19T21:02:36.131+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/113/.2.delta.0b477578-0c8b-4e40-9606-15ce2c46efcb.TID716.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/113/2.delta
[2025-07-19T21:02:36.132+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=113),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/113] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/113/2.delta
[2025-07-19T21:02:36.134+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 113 (task 716, attempt 0, stage 7.0)
[2025-07-19T21:02:36.136+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 111 (task 714, attempt 0, stage 7.0)
[2025-07-19T21:02:36.137+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 111.0 in stage 7.0 (TID 714). 5872 bytes result sent to driver
[2025-07-19T21:02:36.139+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 118.0 in stage 7.0 (TID 721) (8b44f3d35cfa, executor driver, partition 118, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.140+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 118.0 in stage 7.0 (TID 721)
[2025-07-19T21:02:36.140+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 111.0 in stage 7.0 (TID 714) in 115 ms on 8b44f3d35cfa (executor driver) (111/200)
[2025-07-19T21:02:36.140+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 113 (task 716, attempt 0, stage 7.0)
[2025-07-19T21:02:36.140+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/110/.2.delta.6850bbbc-187a-4843-b70a-3cffb27e0a77.TID713.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/110/2.delta
[2025-07-19T21:02:36.140+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=110),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/110] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/110/2.delta
[2025-07-19T21:02:36.141+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/117/.2.delta.d60a8432-c342-49c1-98a0-e00412c7ec25.TID720.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/117/2.delta
[2025-07-19T21:02:36.141+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=117),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/117] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/117/2.delta
[2025-07-19T21:02:36.142+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 110 (task 713, attempt 0, stage 7.0)
[2025-07-19T21:02:36.142+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 113.0 in stage 7.0 (TID 716). 5872 bytes result sent to driver
[2025-07-19T21:02:36.143+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.143+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.144+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 117 (task 720, attempt 0, stage 7.0)
[2025-07-19T21:02:36.144+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 119.0 in stage 7.0 (TID 722) (8b44f3d35cfa, executor driver, partition 119, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.144+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 113.0 in stage 7.0 (TID 716) in 110 ms on 8b44f3d35cfa (executor driver) (112/200)
[2025-07-19T21:02:36.144+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 119.0 in stage 7.0 (TID 722)
[2025-07-19T21:02:36.145+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.145+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.145+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@158384e9
[2025-07-19T21:02:36.145+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/116/.2.delta.5f9f1ab8-62f5-4399-952b-7c84942b882f.TID719.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/116/2.delta
[2025-07-19T21:02:36.146+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=116),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/116] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/116/2.delta
[2025-07-19T21:02:36.147+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 116 (task 719, attempt 0, stage 7.0)
[2025-07-19T21:02:36.147+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=118, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.148+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=118),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/118] for update
[2025-07-19T21:02:36.148+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/112/.2.delta.fc4dae69-91d4-43d6-8fd5-ca932188bf4d.TID715.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/112/2.delta
[2025-07-19T21:02:36.150+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 117 (task 720, attempt 0, stage 7.0)
[2025-07-19T21:02:36.150+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=112),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/112] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/112/2.delta
[2025-07-19T21:02:36.152+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 110 (task 713, attempt 0, stage 7.0)
[2025-07-19T21:02:36.153+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/115/.2.delta.3cc5a30d-3d47-40a2-a4db-e3a8ced95880.TID718.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/115/2.delta
[2025-07-19T21:02:36.154+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=115),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/115] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/115/2.delta
[2025-07-19T21:02:36.154+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 115 (task 718, attempt 0, stage 7.0)
[2025-07-19T21:02:36.155+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 117.0 in stage 7.0 (TID 720). 5829 bytes result sent to driver
[2025-07-19T21:02:36.156+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 110.0 in stage 7.0 (TID 713). 5872 bytes result sent to driver
[2025-07-19T21:02:36.156+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2dd5a701
[2025-07-19T21:02:36.157+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 120.0 in stage 7.0 (TID 723) (8b44f3d35cfa, executor driver, partition 120, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.157+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 120.0 in stage 7.0 (TID 723)
[2025-07-19T21:02:36.158+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=119, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.158+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=119),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/119] for update
[2025-07-19T21:02:36.158+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 112 (task 715, attempt 0, stage 7.0)
[2025-07-19T21:02:36.158+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 121.0 in stage 7.0 (TID 724) (8b44f3d35cfa, executor driver, partition 121, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.158+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 110.0 in stage 7.0 (TID 713) in 127 ms on 8b44f3d35cfa (executor driver) (113/200)
[2025-07-19T21:02:36.159+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 117.0 in stage 7.0 (TID 720) in 72 ms on 8b44f3d35cfa (executor driver) (114/200)
[2025-07-19T21:02:36.159+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 116 (task 719, attempt 0, stage 7.0)
[2025-07-19T21:02:36.160+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.160+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 116.0 in stage 7.0 (TID 719). 5829 bytes result sent to driver
[2025-07-19T21:02:36.161+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.161+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.161+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 121.0 in stage 7.0 (TID 724)
[2025-07-19T21:02:36.162+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 122.0 in stage 7.0 (TID 725) (8b44f3d35cfa, executor driver, partition 122, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.162+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 115 (task 718, attempt 0, stage 7.0)
[2025-07-19T21:02:36.162+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 122.0 in stage 7.0 (TID 725)
[2025-07-19T21:02:36.162+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 115.0 in stage 7.0 (TID 718). 5829 bytes result sent to driver
[2025-07-19T21:02:36.162+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 123.0 in stage 7.0 (TID 726) (8b44f3d35cfa, executor driver, partition 123, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.163+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 123.0 in stage 7.0 (TID 726)
[2025-07-19T21:02:36.163+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.163+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.164+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23d61916
[2025-07-19T21:02:36.164+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 115.0 in stage 7.0 (TID 718) in 101 ms on 8b44f3d35cfa (executor driver) (115/200)
[2025-07-19T21:02:36.165+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=120, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.166+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=120),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/120] for update
[2025-07-19T21:02:36.166+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.167+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.167+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.169+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.170+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 112 (task 715, attempt 0, stage 7.0)
[2025-07-19T21:02:36.170+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.170+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 112.0 in stage 7.0 (TID 715). 5872 bytes result sent to driver
[2025-07-19T21:02:36.171+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.171+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 124.0 in stage 7.0 (TID 727) (8b44f3d35cfa, executor driver, partition 124, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.172+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 124.0 in stage 7.0 (TID 727)
[2025-07-19T21:02:36.172+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 112.0 in stage 7.0 (TID 715) in 127 ms on 8b44f3d35cfa (executor driver) (116/200)
[2025-07-19T21:02:36.172+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 116.0 in stage 7.0 (TID 719) in 93 ms on 8b44f3d35cfa (executor driver) (117/200)
[2025-07-19T21:02:36.173+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20d195e5
[2025-07-19T21:02:36.173+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=123, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.173+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=123),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/123] for update
[2025-07-19T21:02:36.174+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d60ec0a
[2025-07-19T21:02:36.175+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=121, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.176+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=121),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/121] for update
[2025-07-19T21:02:36.176+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.176+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.177+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.177+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.177+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@870b4e2
[2025-07-19T21:02:36.177+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=124, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.177+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/118/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/118/.2.delta.0e10b4ca-e788-4688-b5db-46c596b1ebf9.TID721.tmp
[2025-07-19T21:02:36.177+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/114/.2.delta.7c9971f4-ab6d-480e-a94a-56561f2affd7.TID717.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/114/2.delta
[2025-07-19T21:02:36.177+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=114),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/114] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/114/2.delta
[2025-07-19T21:02:36.177+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=124),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/124] for update
[2025-07-19T21:02:36.177+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d9f12e9
[2025-07-19T21:02:36.177+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=122, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.178+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=122),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/122] for update
[2025-07-19T21:02:36.178+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 114 (task 717, attempt 0, stage 7.0)
[2025-07-19T21:02:36.178+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.178+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/120/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/120/.2.delta.84bc334a-8203-4cc1-8c67-f94792300062.TID723.tmp
[2025-07-19T21:02:36.178+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.178+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 114 (task 717, attempt 0, stage 7.0)
[2025-07-19T21:02:36.178+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/121/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/121/.2.delta.42658663-b813-4edd-b55c-4b64b699360f.TID724.tmp
[2025-07-19T21:02:36.178+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/119/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/119/.2.delta.532ea67c-8a01-4c7b-b2f4-d9916da8cc85.TID722.tmp
[2025-07-19T21:02:36.178+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 114.0 in stage 7.0 (TID 717). 5829 bytes result sent to driver
[2025-07-19T21:02:36.179+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 125.0 in stage 7.0 (TID 728) (8b44f3d35cfa, executor driver, partition 125, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.179+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/123/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/123/.2.delta.6b253521-d670-4548-a85e-308356fbe960.TID726.tmp
[2025-07-19T21:02:36.179+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 125.0 in stage 7.0 (TID 728)
[2025-07-19T21:02:36.179+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 114.0 in stage 7.0 (TID 717) in 128 ms on 8b44f3d35cfa (executor driver) (118/200)
[2025-07-19T21:02:36.179+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.179+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.179+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@49a0db5
[2025-07-19T21:02:36.180+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=125, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.181+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=125),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/125] for update
[2025-07-19T21:02:36.181+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/122/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/122/.2.delta.aa3a7276-a961-4baf-b2b6-e477c303b472.TID725.tmp
[2025-07-19T21:02:36.181+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/124/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/124/.2.delta.9f85b5e4-3954-40ed-9fe5-b299bceb20f1.TID727.tmp
[2025-07-19T21:02:36.181+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.191+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/125/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/125/.2.delta.d28b74c0-5e71-42dc-9bbe-462eb6adf7f7.TID728.tmp
[2025-07-19T21:02:36.201+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/120/.2.delta.84bc334a-8203-4cc1-8c67-f94792300062.TID723.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/120/2.delta
[2025-07-19T21:02:36.202+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=120),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/120] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/120/2.delta
[2025-07-19T21:02:36.202+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 120 (task 723, attempt 0, stage 7.0)
[2025-07-19T21:02:36.207+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 120 (task 723, attempt 0, stage 7.0)
[2025-07-19T21:02:36.208+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 120.0 in stage 7.0 (TID 723). 5829 bytes result sent to driver
[2025-07-19T21:02:36.208+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 126.0 in stage 7.0 (TID 729) (8b44f3d35cfa, executor driver, partition 126, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.208+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 126.0 in stage 7.0 (TID 729)
[2025-07-19T21:02:36.208+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 120.0 in stage 7.0 (TID 723) in 63 ms on 8b44f3d35cfa (executor driver) (119/200)
[2025-07-19T21:02:36.208+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/122/.2.delta.aa3a7276-a961-4baf-b2b6-e477c303b472.TID725.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/122/2.delta
[2025-07-19T21:02:36.209+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=122),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/122] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/122/2.delta
[2025-07-19T21:02:36.209+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 122 (task 725, attempt 0, stage 7.0)
[2025-07-19T21:02:36.211+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/119/.2.delta.532ea67c-8a01-4c7b-b2f4-d9916da8cc85.TID722.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/119/2.delta
[2025-07-19T21:02:36.212+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=119),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/119] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/119/2.delta
[2025-07-19T21:02:36.213+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/123/.2.delta.6b253521-d670-4548-a85e-308356fbe960.TID726.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/123/2.delta
[2025-07-19T21:02:36.214+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=123),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/123] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/123/2.delta
[2025-07-19T21:02:36.215+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 119 (task 722, attempt 0, stage 7.0)
[2025-07-19T21:02:36.215+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.216+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.217+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 123 (task 726, attempt 0, stage 7.0)
[2025-07-19T21:02:36.217+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31ebf86c
[2025-07-19T21:02:36.218+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/124/.2.delta.9f85b5e4-3954-40ed-9fe5-b299bceb20f1.TID727.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/124/2.delta
[2025-07-19T21:02:36.218+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=124),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/124] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/124/2.delta
[2025-07-19T21:02:36.219+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=126, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.219+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=126),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/126] for update
[2025-07-19T21:02:36.220+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/118/.2.delta.0e10b4ca-e788-4688-b5db-46c596b1ebf9.TID721.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/118/2.delta
[2025-07-19T21:02:36.220+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=118),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/118] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/118/2.delta
[2025-07-19T21:02:36.220+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 124 (task 727, attempt 0, stage 7.0)
[2025-07-19T21:02:36.221+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 118 (task 721, attempt 0, stage 7.0)
[2025-07-19T21:02:36.221+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 119 (task 722, attempt 0, stage 7.0)
[2025-07-19T21:02:36.221+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.221+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 119.0 in stage 7.0 (TID 722). 5829 bytes result sent to driver
[2025-07-19T21:02:36.221+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 127.0 in stage 7.0 (TID 730) (8b44f3d35cfa, executor driver, partition 127, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.222+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 119.0 in stage 7.0 (TID 722) in 77 ms on 8b44f3d35cfa (executor driver) (120/200)
[2025-07-19T21:02:36.223+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 124 (task 727, attempt 0, stage 7.0)
[2025-07-19T21:02:36.223+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 123 (task 726, attempt 0, stage 7.0)
[2025-07-19T21:02:36.223+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 127.0 in stage 7.0 (TID 730)
[2025-07-19T21:02:36.223+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 123.0 in stage 7.0 (TID 726). 5786 bytes result sent to driver
[2025-07-19T21:02:36.224+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.225+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 118 (task 721, attempt 0, stage 7.0)
[2025-07-19T21:02:36.228+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 124.0 in stage 7.0 (TID 727). 5872 bytes result sent to driver
[2025-07-19T21:02:36.228+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 118.0 in stage 7.0 (TID 721). 5829 bytes result sent to driver
[2025-07-19T21:02:36.228+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 128.0 in stage 7.0 (TID 731) (8b44f3d35cfa, executor driver, partition 128, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.229+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 129.0 in stage 7.0 (TID 732) (8b44f3d35cfa, executor driver, partition 129, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.229+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 130.0 in stage 7.0 (TID 733) (8b44f3d35cfa, executor driver, partition 130, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.229+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 129.0 in stage 7.0 (TID 732)
[2025-07-19T21:02:36.229+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 130.0 in stage 7.0 (TID 733)
[2025-07-19T21:02:36.231+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.232+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:36.232+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 123.0 in stage 7.0 (TID 726) in 72 ms on 8b44f3d35cfa (executor driver) (121/200)
[2025-07-19T21:02:36.233+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 124.0 in stage 7.0 (TID 727) in 69 ms on 8b44f3d35cfa (executor driver) (122/200)
[2025-07-19T21:02:36.233+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.234+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 118.0 in stage 7.0 (TID 721) in 86 ms on 8b44f3d35cfa (executor driver) (123/200)
[2025-07-19T21:02:36.235+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.235+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 128.0 in stage 7.0 (TID 731)
[2025-07-19T21:02:36.235+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.236+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 122 (task 725, attempt 0, stage 7.0)
[2025-07-19T21:02:36.236+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 122.0 in stage 7.0 (TID 725). 5829 bytes result sent to driver
[2025-07-19T21:02:36.238+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28e9311b
[2025-07-19T21:02:36.238+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.239+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.239+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=127, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.240+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=127),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/127] for update
[2025-07-19T21:02:36.240+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@70e0a59b
[2025-07-19T21:02:36.241+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/121/.2.delta.42658663-b813-4edd-b55c-4b64b699360f.TID724.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/121/2.delta
[2025-07-19T21:02:36.241+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=121),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/121] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/121/2.delta
[2025-07-19T21:02:36.241+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 131.0 in stage 7.0 (TID 734) (8b44f3d35cfa, executor driver, partition 131, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.241+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=128, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.241+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=128),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/128] for update
[2025-07-19T21:02:36.241+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 121 (task 724, attempt 0, stage 7.0)
[2025-07-19T21:02:36.241+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.241+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/126/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/126/.2.delta.a880ae1a-dbe4-4ed4-b372-745117edeca1.TID729.tmp
[2025-07-19T21:02:36.241+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.241+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 122.0 in stage 7.0 (TID 725) in 79 ms on 8b44f3d35cfa (executor driver) (124/200)
[2025-07-19T21:02:36.242+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 131.0 in stage 7.0 (TID 734)
[2025-07-19T21:02:36.242+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@676b740d
[2025-07-19T21:02:36.242+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.242+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.242+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=129, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.242+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=129),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/129] for update
[2025-07-19T21:02:36.242+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 121 (task 724, attempt 0, stage 7.0)
[2025-07-19T21:02:36.242+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3995dca6
[2025-07-19T21:02:36.243+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 121.0 in stage 7.0 (TID 724). 5829 bytes result sent to driver
[2025-07-19T21:02:36.243+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 132.0 in stage 7.0 (TID 735) (8b44f3d35cfa, executor driver, partition 132, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.243+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.243+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 132.0 in stage 7.0 (TID 735)
[2025-07-19T21:02:36.243+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 121.0 in stage 7.0 (TID 724) in 89 ms on 8b44f3d35cfa (executor driver) (125/200)
[2025-07-19T21:02:36.243+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=130, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.243+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=130),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/130] for update
[2025-07-19T21:02:36.243+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.244+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.244+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c6509c
[2025-07-19T21:02:36.244+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.244+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=132, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.244+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=132),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/132] for update
[2025-07-19T21:02:36.244+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@18ab4d8f
[2025-07-19T21:02:36.244+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.244+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/128/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/128/.2.delta.b497cea3-3bac-4322-88de-f0894cac7781.TID731.tmp
[2025-07-19T21:02:36.245+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=131, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.245+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=131),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/131] for update
[2025-07-19T21:02:36.245+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.245+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/125/.2.delta.d28b74c0-5e71-42dc-9bbe-462eb6adf7f7.TID728.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/125/2.delta
[2025-07-19T21:02:36.245+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=125),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/125] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/125/2.delta
[2025-07-19T21:02:36.245+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/129/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/129/.2.delta.2cb444ce-9341-4336-ad02-c0f1acb6b499.TID732.tmp
[2025-07-19T21:02:36.246+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 125 (task 728, attempt 0, stage 7.0)
[2025-07-19T21:02:36.247+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/130/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/130/.2.delta.f37658af-54fa-42f3-8719-b67a6c78a6ab.TID733.tmp
[2025-07-19T21:02:36.250+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 125 (task 728, attempt 0, stage 7.0)
[2025-07-19T21:02:36.250+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 125.0 in stage 7.0 (TID 728). 5829 bytes result sent to driver
[2025-07-19T21:02:36.253+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 133.0 in stage 7.0 (TID 736) (8b44f3d35cfa, executor driver, partition 133, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.253+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 125.0 in stage 7.0 (TID 728) in 83 ms on 8b44f3d35cfa (executor driver) (126/200)
[2025-07-19T21:02:36.254+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 133.0 in stage 7.0 (TID 736)
[2025-07-19T21:02:36.255+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/131/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/131/.2.delta.027928ca-a089-4cf7-99d4-8ef21c266caf.TID734.tmp
[2025-07-19T21:02:36.256+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/127/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/127/.2.delta.fa5331fe-cce2-4be2-8f93-51bb9b3cfe71.TID730.tmp
[2025-07-19T21:02:36.256+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.256+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.256+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/132/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/132/.2.delta.5ba76636-1d5c-49c1-ae99-f0f95d874d59.TID735.tmp
[2025-07-19T21:02:36.256+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6076ff97
[2025-07-19T21:02:36.262+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=133, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.263+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=133),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/133] for update
[2025-07-19T21:02:36.263+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.275+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/133/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/133/.2.delta.1d369c6f-820b-4ee5-a435-65fe2d075165.TID736.tmp
[2025-07-19T21:02:36.277+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/126/.2.delta.a880ae1a-dbe4-4ed4-b372-745117edeca1.TID729.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/126/2.delta
[2025-07-19T21:02:36.277+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=126),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/126] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/126/2.delta
[2025-07-19T21:02:36.278+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 126 (task 729, attempt 0, stage 7.0)
[2025-07-19T21:02:36.283+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 126 (task 729, attempt 0, stage 7.0)
[2025-07-19T21:02:36.285+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 126.0 in stage 7.0 (TID 729). 5829 bytes result sent to driver
[2025-07-19T21:02:36.286+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 134.0 in stage 7.0 (TID 737) (8b44f3d35cfa, executor driver, partition 134, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.286+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 126.0 in stage 7.0 (TID 729) in 77 ms on 8b44f3d35cfa (executor driver) (127/200)
[2025-07-19T21:02:36.287+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 134.0 in stage 7.0 (TID 737)
[2025-07-19T21:02:36.292+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.293+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.294+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@48aa7652
[2025-07-19T21:02:36.296+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=134, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.296+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=134),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/134] for update
[2025-07-19T21:02:36.298+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.307+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/128/.2.delta.b497cea3-3bac-4322-88de-f0894cac7781.TID731.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/128/2.delta
[2025-07-19T21:02:36.307+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=128),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/128] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/128/2.delta
[2025-07-19T21:02:36.308+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 128 (task 731, attempt 0, stage 7.0)
[2025-07-19T21:02:36.312+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/129/.2.delta.2cb444ce-9341-4336-ad02-c0f1acb6b499.TID732.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/129/2.delta
[2025-07-19T21:02:36.312+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=129),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/129] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/129/2.delta
[2025-07-19T21:02:36.313+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 129 (task 732, attempt 0, stage 7.0)
[2025-07-19T21:02:36.313+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/131/.2.delta.027928ca-a089-4cf7-99d4-8ef21c266caf.TID734.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/131/2.delta
[2025-07-19T21:02:36.313+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=131),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/131] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/131/2.delta
[2025-07-19T21:02:36.315+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 131 (task 734, attempt 0, stage 7.0)
[2025-07-19T21:02:36.315+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 128 (task 731, attempt 0, stage 7.0)
[2025-07-19T21:02:36.315+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 128.0 in stage 7.0 (TID 731). 5829 bytes result sent to driver
[2025-07-19T21:02:36.318+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 128.0 in stage 7.0 (TID 731) in 95 ms on 8b44f3d35cfa (executor driver) (128/200)
[2025-07-19T21:02:36.319+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 135.0 in stage 7.0 (TID 738) (8b44f3d35cfa, executor driver, partition 135, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.319+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 135.0 in stage 7.0 (TID 738)
[2025-07-19T21:02:36.320+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 131 (task 734, attempt 0, stage 7.0)
[2025-07-19T21:02:36.320+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 131.0 in stage 7.0 (TID 734). 5829 bytes result sent to driver
[2025-07-19T21:02:36.320+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 129 (task 732, attempt 0, stage 7.0)
[2025-07-19T21:02:36.321+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.323+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 129.0 in stage 7.0 (TID 732). 5829 bytes result sent to driver
[2025-07-19T21:02:36.324+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.324+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 136.0 in stage 7.0 (TID 739) (8b44f3d35cfa, executor driver, partition 136, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.325+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 137.0 in stage 7.0 (TID 740) (8b44f3d35cfa, executor driver, partition 137, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.326+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 131.0 in stage 7.0 (TID 734) in 96 ms on 8b44f3d35cfa (executor driver) (129/200)
[2025-07-19T21:02:36.326+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 137.0 in stage 7.0 (TID 740)
[2025-07-19T21:02:36.326+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 129.0 in stage 7.0 (TID 732) in 101 ms on 8b44f3d35cfa (executor driver) (130/200)
[2025-07-19T21:02:36.327+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/134/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/134/.2.delta.b6c59810-2af4-4e6b-a6ea-d9e2ef55a165.TID737.tmp
[2025-07-19T21:02:36.327+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20f2a0d2
[2025-07-19T21:02:36.328+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/130/.2.delta.f37658af-54fa-42f3-8719-b67a6c78a6ab.TID733.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/130/2.delta
[2025-07-19T21:02:36.328+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=130),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/130] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/130/2.delta
[2025-07-19T21:02:36.329+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=135, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.330+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=135),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/135] for update
[2025-07-19T21:02:36.330+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.332+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.334+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/127/.2.delta.fa5331fe-cce2-4be2-8f93-51bb9b3cfe71.TID730.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/127/2.delta
[2025-07-19T21:02:36.334+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=127),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/127] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/127/2.delta
[2025-07-19T21:02:36.337+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.339+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 127 (task 730, attempt 0, stage 7.0)
[2025-07-19T21:02:36.340+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@37bfd8c
[2025-07-19T21:02:36.344+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 136.0 in stage 7.0 (TID 739)
[2025-07-19T21:02:36.344+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 130 (task 733, attempt 0, stage 7.0)
[2025-07-19T21:02:36.345+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.345+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.346+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=137, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.346+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=137),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/137] for update
[2025-07-19T21:02:36.348+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 127 (task 730, attempt 0, stage 7.0)
[2025-07-19T21:02:36.348+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.349+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 127.0 in stage 7.0 (TID 730). 5829 bytes result sent to driver
[2025-07-19T21:02:36.349+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/132/.2.delta.5ba76636-1d5c-49c1-ae99-f0f95d874d59.TID735.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/132/2.delta
[2025-07-19T21:02:36.349+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=132),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/132] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/132/2.delta
[2025-07-19T21:02:36.349+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 130 (task 733, attempt 0, stage 7.0)
[2025-07-19T21:02:36.350+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 130.0 in stage 7.0 (TID 733). 5786 bytes result sent to driver
[2025-07-19T21:02:36.352+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 138.0 in stage 7.0 (TID 741) (8b44f3d35cfa, executor driver, partition 138, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.353+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 139.0 in stage 7.0 (TID 742) (8b44f3d35cfa, executor driver, partition 139, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.354+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 132 (task 735, attempt 0, stage 7.0)
[2025-07-19T21:02:36.355+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 139.0 in stage 7.0 (TID 742)
[2025-07-19T21:02:36.355+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5af20fa5
[2025-07-19T21:02:36.356+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 138.0 in stage 7.0 (TID 741)
[2025-07-19T21:02:36.356+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.356+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.357+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 127.0 in stage 7.0 (TID 730) in 120 ms on 8b44f3d35cfa (executor driver) (131/200)
[2025-07-19T21:02:36.358+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 130.0 in stage 7.0 (TID 733) in 117 ms on 8b44f3d35cfa (executor driver) (132/200)
[2025-07-19T21:02:36.359+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=136, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.360+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.360+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 132 (task 735, attempt 0, stage 7.0)
[2025-07-19T21:02:36.360+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 132.0 in stage 7.0 (TID 735). 5829 bytes result sent to driver
[2025-07-19T21:02:36.361+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=136),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/136] for update
[2025-07-19T21:02:36.362+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T21:02:36.362+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 140.0 in stage 7.0 (TID 743) (8b44f3d35cfa, executor driver, partition 140, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.363+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 132.0 in stage 7.0 (TID 735) in 107 ms on 8b44f3d35cfa (executor driver) (133/200)
[2025-07-19T21:02:36.364+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@682501d4
[2025-07-19T21:02:36.364+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 140.0 in stage 7.0 (TID 743)
[2025-07-19T21:02:36.367+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/133/.2.delta.1d369c6f-820b-4ee5-a435-65fe2d075165.TID736.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/133/2.delta
[2025-07-19T21:02:36.367+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=133),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/133] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/133/2.delta
[2025-07-19T21:02:36.367+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/137/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/137/.2.delta.0dbc664b-546e-447c-a1bb-16410b44aced.TID740.tmp
[2025-07-19T21:02:36.367+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 133 (task 736, attempt 0, stage 7.0)
[2025-07-19T21:02:36.367+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.367+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.368+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.368+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=139, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.368+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=139),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/139] for update
[2025-07-19T21:02:36.368+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.368+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 133 (task 736, attempt 0, stage 7.0)
[2025-07-19T21:02:36.369+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 133.0 in stage 7.0 (TID 736). 5829 bytes result sent to driver
[2025-07-19T21:02:36.369+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/135/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/135/.2.delta.a5f9c760-ca20-4ad1-ba30-1e2898d2fec7.TID738.tmp
[2025-07-19T21:02:36.369+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 141.0 in stage 7.0 (TID 744) (8b44f3d35cfa, executor driver, partition 141, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.369+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 141.0 in stage 7.0 (TID 744)
[2025-07-19T21:02:36.369+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 133.0 in stage 7.0 (TID 736) in 99 ms on 8b44f3d35cfa (executor driver) (134/200)
[2025-07-19T21:02:36.369+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5b037377
[2025-07-19T21:02:36.370+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=140, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.371+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=140),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/140] for update
[2025-07-19T21:02:36.371+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.371+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.371+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T21:02:36.372+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23414d01
[2025-07-19T21:02:36.372+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=138, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.372+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=138),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/138] for update
[2025-07-19T21:02:36.373+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/136/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/136/.2.delta.c9b431a2-bc97-46bc-99bc-67ea27d588b5.TID739.tmp
[2025-07-19T21:02:36.373+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@beca824
[2025-07-19T21:02:36.373+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=141, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.374+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=141),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/141] for update
[2025-07-19T21:02:36.374+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/139/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/139/.2.delta.e78e5f95-19eb-4ce7-bea9-7e6aaf598653.TID742.tmp
[2025-07-19T21:02:36.374+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.375+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.375+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/141/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/141/.2.delta.b184e5cf-9ab6-4ac2-ab23-50ba5d2de4d8.TID744.tmp
[2025-07-19T21:02:36.376+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/138/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/138/.2.delta.fe00c028-3b56-4213-920a-f7e65b9b3878.TID741.tmp
[2025-07-19T21:02:36.376+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/140/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/140/.2.delta.30cf2a4e-5477-4d0b-ae88-fb86ea39bb2e.TID743.tmp
[2025-07-19T21:02:36.378+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/134/.2.delta.b6c59810-2af4-4e6b-a6ea-d9e2ef55a165.TID737.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/134/2.delta
[2025-07-19T21:02:36.378+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=134),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/134] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/134/2.delta
[2025-07-19T21:02:36.379+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 134 (task 737, attempt 0, stage 7.0)
[2025-07-19T21:02:36.382+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 134 (task 737, attempt 0, stage 7.0)
[2025-07-19T21:02:36.385+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 134.0 in stage 7.0 (TID 737). 5829 bytes result sent to driver
[2025-07-19T21:02:36.389+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 142.0 in stage 7.0 (TID 745) (8b44f3d35cfa, executor driver, partition 142, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.390+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 142.0 in stage 7.0 (TID 745)
[2025-07-19T21:02:36.391+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 134.0 in stage 7.0 (TID 737) in 102 ms on 8b44f3d35cfa (executor driver) (135/200)
[2025-07-19T21:02:36.391+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.391+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.391+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@308f77c4
[2025-07-19T21:02:36.392+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=142, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.392+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=142),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/142] for update
[2025-07-19T21:02:36.393+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.403+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/135/.2.delta.a5f9c760-ca20-4ad1-ba30-1e2898d2fec7.TID738.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/135/2.delta
[2025-07-19T21:02:36.405+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=135),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/135] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/135/2.delta
[2025-07-19T21:02:36.406+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 135 (task 738, attempt 0, stage 7.0)
[2025-07-19T21:02:36.407+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 135 (task 738, attempt 0, stage 7.0)
[2025-07-19T21:02:36.407+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 135.0 in stage 7.0 (TID 738). 5829 bytes result sent to driver
[2025-07-19T21:02:36.408+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 143.0 in stage 7.0 (TID 746) (8b44f3d35cfa, executor driver, partition 143, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.409+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 135.0 in stage 7.0 (TID 738) in 93 ms on 8b44f3d35cfa (executor driver) (136/200)
[2025-07-19T21:02:36.409+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 143.0 in stage 7.0 (TID 746)
[2025-07-19T21:02:36.409+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/142/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/142/.2.delta.7d76aade-c5bd-4201-ae59-94489bfb695d.TID745.tmp
[2025-07-19T21:02:36.410+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.410+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.412+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@591b4a56
[2025-07-19T21:02:36.413+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=143, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.413+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=143),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/143] for update
[2025-07-19T21:02:36.414+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.415+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/137/.2.delta.0dbc664b-546e-447c-a1bb-16410b44aced.TID740.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/137/2.delta
[2025-07-19T21:02:36.415+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=137),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/137] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/137/2.delta
[2025-07-19T21:02:36.416+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 137 (task 740, attempt 0, stage 7.0)
[2025-07-19T21:02:36.422+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 137 (task 740, attempt 0, stage 7.0)
[2025-07-19T21:02:36.423+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 137.0 in stage 7.0 (TID 740). 5829 bytes result sent to driver
[2025-07-19T21:02:36.424+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/139/.2.delta.e78e5f95-19eb-4ce7-bea9-7e6aaf598653.TID742.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/139/2.delta
[2025-07-19T21:02:36.424+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=139),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/139] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/139/2.delta
[2025-07-19T21:02:36.424+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 144.0 in stage 7.0 (TID 747) (8b44f3d35cfa, executor driver, partition 144, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.425+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 144.0 in stage 7.0 (TID 747)
[2025-07-19T21:02:36.425+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 139 (task 742, attempt 0, stage 7.0)
[2025-07-19T21:02:36.425+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/136/.2.delta.c9b431a2-bc97-46bc-99bc-67ea27d588b5.TID739.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/136/2.delta
[2025-07-19T21:02:36.425+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.426+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=136),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/136] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/136/2.delta
[2025-07-19T21:02:36.427+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.427+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3602be0e
[2025-07-19T21:02:36.428+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 136 (task 739, attempt 0, stage 7.0)
[2025-07-19T21:02:36.428+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 137.0 in stage 7.0 (TID 740) in 104 ms on 8b44f3d35cfa (executor driver) (137/200)
[2025-07-19T21:02:36.428+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=144, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.429+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=144),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/144] for update
[2025-07-19T21:02:36.430+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 139 (task 742, attempt 0, stage 7.0)
[2025-07-19T21:02:36.430+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.431+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 139.0 in stage 7.0 (TID 742). 5829 bytes result sent to driver
[2025-07-19T21:02:36.431+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/143/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/143/.2.delta.74ce6ac0-085e-4d07-af7b-3fd85a22f8fc.TID746.tmp
[2025-07-19T21:02:36.431+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 145.0 in stage 7.0 (TID 748) (8b44f3d35cfa, executor driver, partition 145, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.431+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 145.0 in stage 7.0 (TID 748)
[2025-07-19T21:02:36.431+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 136 (task 739, attempt 0, stage 7.0)
[2025-07-19T21:02:36.433+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 136.0 in stage 7.0 (TID 739). 5829 bytes result sent to driver
[2025-07-19T21:02:36.434+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 139.0 in stage 7.0 (TID 742) in 97 ms on 8b44f3d35cfa (executor driver) (138/200)
[2025-07-19T21:02:36.434+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 146.0 in stage 7.0 (TID 749) (8b44f3d35cfa, executor driver, partition 146, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.435+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.435+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.435+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 136.0 in stage 7.0 (TID 739) in 112 ms on 8b44f3d35cfa (executor driver) (139/200)
[2025-07-19T21:02:36.435+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c6fd03f
[2025-07-19T21:02:36.436+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 146.0 in stage 7.0 (TID 749)
[2025-07-19T21:02:36.436+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=145, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.437+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=145),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/145] for update
[2025-07-19T21:02:36.438+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.438+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.438+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.439+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@276b44a5
[2025-07-19T21:02:36.439+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=146, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.440+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=146),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/146] for update
[2025-07-19T21:02:36.440+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/138/.2.delta.fe00c028-3b56-4213-920a-f7e65b9b3878.TID741.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/138/2.delta
[2025-07-19T21:02:36.440+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=138),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/138] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/138/2.delta
[2025-07-19T21:02:36.440+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 138 (task 741, attempt 0, stage 7.0)
[2025-07-19T21:02:36.440+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.441+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/140/.2.delta.30cf2a4e-5477-4d0b-ae88-fb86ea39bb2e.TID743.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/140/2.delta
[2025-07-19T21:02:36.441+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=140),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/140] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/140/2.delta
[2025-07-19T21:02:36.443+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/144/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/144/.2.delta.fb7d265e-a951-48d4-a2ee-705b8546f43c.TID747.tmp
[2025-07-19T21:02:36.443+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 140 (task 743, attempt 0, stage 7.0)
[2025-07-19T21:02:36.445+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/141/.2.delta.b184e5cf-9ab6-4ac2-ab23-50ba5d2de4d8.TID744.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/141/2.delta
[2025-07-19T21:02:36.446+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=141),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/141] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/141/2.delta
[2025-07-19T21:02:36.447+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 141 (task 744, attempt 0, stage 7.0)
[2025-07-19T21:02:36.448+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 138 (task 741, attempt 0, stage 7.0)
[2025-07-19T21:02:36.448+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 138.0 in stage 7.0 (TID 741). 5872 bytes result sent to driver
[2025-07-19T21:02:36.449+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 147.0 in stage 7.0 (TID 750) (8b44f3d35cfa, executor driver, partition 147, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.450+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 147.0 in stage 7.0 (TID 750)
[2025-07-19T21:02:36.450+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 140 (task 743, attempt 0, stage 7.0)
[2025-07-19T21:02:36.451+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 140.0 in stage 7.0 (TID 743). 5872 bytes result sent to driver
[2025-07-19T21:02:36.451+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 148.0 in stage 7.0 (TID 751) (8b44f3d35cfa, executor driver, partition 148, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.452+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 140.0 in stage 7.0 (TID 743) in 110 ms on 8b44f3d35cfa (executor driver) (140/200)
[2025-07-19T21:02:36.452+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 138.0 in stage 7.0 (TID 741) in 117 ms on 8b44f3d35cfa (executor driver) (141/200)
[2025-07-19T21:02:36.452+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 141 (task 744, attempt 0, stage 7.0)
[2025-07-19T21:02:36.452+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 148.0 in stage 7.0 (TID 751)
[2025-07-19T21:02:36.453+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 141.0 in stage 7.0 (TID 744). 5872 bytes result sent to driver
[2025-07-19T21:02:36.454+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 149.0 in stage 7.0 (TID 752) (8b44f3d35cfa, executor driver, partition 149, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.454+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.455+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.455+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/145/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/145/.2.delta.db98d88d-4a59-4ce2-8a0a-dc5f9bb2bb96.TID748.tmp
[2025-07-19T21:02:36.455+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 141.0 in stage 7.0 (TID 744) in 102 ms on 8b44f3d35cfa (executor driver) (142/200)
[2025-07-19T21:02:36.455+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.455+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 149.0 in stage 7.0 (TID 752)
[2025-07-19T21:02:36.455+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.456+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2fbe12dd
[2025-07-19T21:02:36.456+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=147, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.456+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=147),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/147] for update
[2025-07-19T21:02:36.457+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.457+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@461de96a
[2025-07-19T21:02:36.458+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=148, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.458+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=148),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/148] for update
[2025-07-19T21:02:36.459+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.460+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.460+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.460+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/146/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/146/.2.delta.8971c6fc-b1a0-41a5-b376-3717c1ba0098.TID749.tmp
[2025-07-19T21:02:36.461+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@67abd969
[2025-07-19T21:02:36.462+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=149, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.462+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=149),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/149] for update
[2025-07-19T21:02:36.462+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.469+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/147/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/147/.2.delta.31796b67-3ac7-4927-885d-65430cc69d25.TID750.tmp
[2025-07-19T21:02:36.469+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/142/.2.delta.7d76aade-c5bd-4201-ae59-94489bfb695d.TID745.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/142/2.delta
[2025-07-19T21:02:36.469+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=142),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/142] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/142/2.delta
[2025-07-19T21:02:36.470+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/148/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/148/.2.delta.b3f6d7eb-284c-4b56-a224-b50727521ba7.TID751.tmp
[2025-07-19T21:02:36.470+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 142 (task 745, attempt 0, stage 7.0)
[2025-07-19T21:02:36.470+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/149/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/149/.2.delta.6a402312-edc1-4e5e-b238-2c5d2fbf49c0.TID752.tmp
[2025-07-19T21:02:36.475+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 142 (task 745, attempt 0, stage 7.0)
[2025-07-19T21:02:36.477+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 142.0 in stage 7.0 (TID 745). 5872 bytes result sent to driver
[2025-07-19T21:02:36.477+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 150.0 in stage 7.0 (TID 753) (8b44f3d35cfa, executor driver, partition 150, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.478+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 150.0 in stage 7.0 (TID 753)
[2025-07-19T21:02:36.479+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 142.0 in stage 7.0 (TID 745) in 94 ms on 8b44f3d35cfa (executor driver) (143/200)
[2025-07-19T21:02:36.479+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.480+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.480+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@13cb6b48
[2025-07-19T21:02:36.481+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=150, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.482+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=150),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/150] for update
[2025-07-19T21:02:36.482+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.485+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/143/.2.delta.74ce6ac0-085e-4d07-af7b-3fd85a22f8fc.TID746.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/143/2.delta
[2025-07-19T21:02:36.485+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=143),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/143] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/143/2.delta
[2025-07-19T21:02:36.486+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 143 (task 746, attempt 0, stage 7.0)
[2025-07-19T21:02:36.486+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/144/.2.delta.fb7d265e-a951-48d4-a2ee-705b8546f43c.TID747.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/144/2.delta
[2025-07-19T21:02:36.486+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=144),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/144] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/144/2.delta
[2025-07-19T21:02:36.487+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 144 (task 747, attempt 0, stage 7.0)
[2025-07-19T21:02:36.488+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/145/.2.delta.db98d88d-4a59-4ce2-8a0a-dc5f9bb2bb96.TID748.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/145/2.delta
[2025-07-19T21:02:36.489+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=145),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/145] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/145/2.delta
[2025-07-19T21:02:36.490+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 145 (task 748, attempt 0, stage 7.0)
[2025-07-19T21:02:36.490+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/150/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/150/.2.delta.c6105f81-11f5-42c8-aca9-318548cd8e83.TID753.tmp
[2025-07-19T21:02:36.491+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 144 (task 747, attempt 0, stage 7.0)
[2025-07-19T21:02:36.491+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 143 (task 746, attempt 0, stage 7.0)
[2025-07-19T21:02:36.492+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 144.0 in stage 7.0 (TID 747). 5872 bytes result sent to driver
[2025-07-19T21:02:36.493+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 143.0 in stage 7.0 (TID 746). 5872 bytes result sent to driver
[2025-07-19T21:02:36.494+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 151.0 in stage 7.0 (TID 754) (8b44f3d35cfa, executor driver, partition 151, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.494+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 151.0 in stage 7.0 (TID 754)
[2025-07-19T21:02:36.495+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 152.0 in stage 7.0 (TID 755) (8b44f3d35cfa, executor driver, partition 152, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.495+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 152.0 in stage 7.0 (TID 755)
[2025-07-19T21:02:36.499+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 144.0 in stage 7.0 (TID 747) in 78 ms on 8b44f3d35cfa (executor driver) (144/200)
[2025-07-19T21:02:36.500+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 143.0 in stage 7.0 (TID 746) in 90 ms on 8b44f3d35cfa (executor driver) (145/200)
[2025-07-19T21:02:36.501+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.501+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 145 (task 748, attempt 0, stage 7.0)
[2025-07-19T21:02:36.502+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.502+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:36.503+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:36.504+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 145.0 in stage 7.0 (TID 748). 5872 bytes result sent to driver
[2025-07-19T21:02:36.504+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d8f60a2
[2025-07-19T21:02:36.504+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/146/.2.delta.8971c6fc-b1a0-41a5-b376-3717c1ba0098.TID749.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/146/2.delta
[2025-07-19T21:02:36.505+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=146),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/146] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/146/2.delta
[2025-07-19T21:02:36.505+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 146 (task 749, attempt 0, stage 7.0)
[2025-07-19T21:02:36.506+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 153.0 in stage 7.0 (TID 756) (8b44f3d35cfa, executor driver, partition 153, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.507+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 145.0 in stage 7.0 (TID 748) in 76 ms on 8b44f3d35cfa (executor driver) (146/200)
[2025-07-19T21:02:36.507+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=152, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.508+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=152),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/152] for update
[2025-07-19T21:02:36.509+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 153.0 in stage 7.0 (TID 756)
[2025-07-19T21:02:36.510+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.510+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.511+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.512+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ee1be05
[2025-07-19T21:02:36.512+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=151, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.514+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=151),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/151] for update
[2025-07-19T21:02:36.515+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.515+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@144bb1d4
[2025-07-19T21:02:36.516+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 146 (task 749, attempt 0, stage 7.0)
[2025-07-19T21:02:36.516+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 146.0 in stage 7.0 (TID 749). 5872 bytes result sent to driver
[2025-07-19T21:02:36.517+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 154.0 in stage 7.0 (TID 757) (8b44f3d35cfa, executor driver, partition 154, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.517+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=153, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.518+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=153),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/153] for update
[2025-07-19T21:02:36.519+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/148/.2.delta.b3f6d7eb-284c-4b56-a224-b50727521ba7.TID751.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/148/2.delta
[2025-07-19T21:02:36.519+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=148),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/148] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/148/2.delta
[2025-07-19T21:02:36.519+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 154.0 in stage 7.0 (TID 757)
[2025-07-19T21:02:36.520+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 146.0 in stage 7.0 (TID 749) in 82 ms on 8b44f3d35cfa (executor driver) (147/200)
[2025-07-19T21:02:36.520+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 148 (task 751, attempt 0, stage 7.0)
[2025-07-19T21:02:36.521+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/147/.2.delta.31796b67-3ac7-4927-885d-65430cc69d25.TID750.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/147/2.delta
[2025-07-19T21:02:36.522+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/149/.2.delta.6a402312-edc1-4e5e-b238-2c5d2fbf49c0.TID752.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/149/2.delta
[2025-07-19T21:02:36.522+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=147),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/147] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/147/2.delta
[2025-07-19T21:02:36.523+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=149),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/149] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/149/2.delta
[2025-07-19T21:02:36.524+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 149 (task 752, attempt 0, stage 7.0)
[2025-07-19T21:02:36.526+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 147 (task 750, attempt 0, stage 7.0)
[2025-07-19T21:02:36.527+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.528+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.529+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.529+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@70a18df4
[2025-07-19T21:02:36.529+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/152/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/152/.2.delta.b39fb734-af56-4558-97d1-bc9a4fb8c750.TID755.tmp
[2025-07-19T21:02:36.530+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 148 (task 751, attempt 0, stage 7.0)
[2025-07-19T21:02:36.530+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=154, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.530+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=154),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/154] for update
[2025-07-19T21:02:36.530+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 148.0 in stage 7.0 (TID 751). 5872 bytes result sent to driver
[2025-07-19T21:02:36.531+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 147 (task 750, attempt 0, stage 7.0)
[2025-07-19T21:02:36.531+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/151/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/151/.2.delta.107ba3d4-9e1c-4e52-9b55-5c268a840601.TID754.tmp
[2025-07-19T21:02:36.532+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 148.0 in stage 7.0 (TID 751) in 73 ms on 8b44f3d35cfa (executor driver) (148/200)
[2025-07-19T21:02:36.532+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 155.0 in stage 7.0 (TID 758) (8b44f3d35cfa, executor driver, partition 155, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.532+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 147.0 in stage 7.0 (TID 750). 5872 bytes result sent to driver
[2025-07-19T21:02:36.532+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 149 (task 752, attempt 0, stage 7.0)
[2025-07-19T21:02:36.533+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 155.0 in stage 7.0 (TID 758)
[2025-07-19T21:02:36.533+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.534+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 149.0 in stage 7.0 (TID 752). 5872 bytes result sent to driver
[2025-07-19T21:02:36.535+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 156.0 in stage 7.0 (TID 759) (8b44f3d35cfa, executor driver, partition 156, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.535+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 147.0 in stage 7.0 (TID 750) in 77 ms on 8b44f3d35cfa (executor driver) (149/200)
[2025-07-19T21:02:36.535+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 157.0 in stage 7.0 (TID 760) (8b44f3d35cfa, executor driver, partition 157, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.536+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 156.0 in stage 7.0 (TID 759)
[2025-07-19T21:02:36.536+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 149.0 in stage 7.0 (TID 752) in 73 ms on 8b44f3d35cfa (executor driver) (150/200)
[2025-07-19T21:02:36.536+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.537+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.537+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.537+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.538+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 157.0 in stage 7.0 (TID 760)
[2025-07-19T21:02:36.539+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.540+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.540+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a7b0f18
[2025-07-19T21:02:36.541+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=156, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.541+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=156),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/156] for update
[2025-07-19T21:02:36.541+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4569f0dc
[2025-07-19T21:02:36.542+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.542+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=157, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.542+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=157),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/157] for update
[2025-07-19T21:02:36.542+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.542+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@9a55e4d
[2025-07-19T21:02:36.543+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=155, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.544+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=155),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/155] for update
[2025-07-19T21:02:36.544+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/154/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/154/.2.delta.aa3197f3-13d8-48b9-885c-76627b2d1cb1.TID757.tmp
[2025-07-19T21:02:36.545+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/153/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/153/.2.delta.37492bda-0239-420a-b316-8f609a6d8fbb.TID756.tmp
[2025-07-19T21:02:36.545+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.545+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/157/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/157/.2.delta.a4314cc1-9851-45c6-8126-8a0161bc8bef.TID760.tmp
[2025-07-19T21:02:36.546+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/156/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/156/.2.delta.622d5b4b-5485-4099-90bd-ee49f40b9010.TID759.tmp
[2025-07-19T21:02:36.548+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/150/.2.delta.c6105f81-11f5-42c8-aca9-318548cd8e83.TID753.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/150/2.delta
[2025-07-19T21:02:36.549+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=150),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/150] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/150/2.delta
[2025-07-19T21:02:36.552+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 150 (task 753, attempt 0, stage 7.0)
[2025-07-19T21:02:36.553+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/155/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/155/.2.delta.50678a6a-61b9-43cf-a096-3e8d3cd0c836.TID758.tmp
[2025-07-19T21:02:36.553+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 150 (task 753, attempt 0, stage 7.0)
[2025-07-19T21:02:36.553+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 150.0 in stage 7.0 (TID 753). 5872 bytes result sent to driver
[2025-07-19T21:02:36.554+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 158.0 in stage 7.0 (TID 761) (8b44f3d35cfa, executor driver, partition 158, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.554+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 150.0 in stage 7.0 (TID 753) in 73 ms on 8b44f3d35cfa (executor driver) (151/200)
[2025-07-19T21:02:36.554+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 158.0 in stage 7.0 (TID 761)
[2025-07-19T21:02:36.554+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.554+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.554+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d6e9823
[2025-07-19T21:02:36.554+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=158, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.554+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=158),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/158] for update
[2025-07-19T21:02:36.556+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.562+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/152/.2.delta.b39fb734-af56-4558-97d1-bc9a4fb8c750.TID755.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/152/2.delta
[2025-07-19T21:02:36.563+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=152),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/152] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/152/2.delta
[2025-07-19T21:02:36.564+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 152 (task 755, attempt 0, stage 7.0)
[2025-07-19T21:02:36.566+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/158/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/158/.2.delta.a2c89a3f-cea5-4a20-a276-47f956820190.TID761.tmp
[2025-07-19T21:02:36.568+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 152 (task 755, attempt 0, stage 7.0)
[2025-07-19T21:02:36.569+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 152.0 in stage 7.0 (TID 755). 5872 bytes result sent to driver
[2025-07-19T21:02:36.570+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 159.0 in stage 7.0 (TID 762) (8b44f3d35cfa, executor driver, partition 159, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.570+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 159.0 in stage 7.0 (TID 762)
[2025-07-19T21:02:36.571+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 152.0 in stage 7.0 (TID 755) in 77 ms on 8b44f3d35cfa (executor driver) (152/200)
[2025-07-19T21:02:36.572+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/151/.2.delta.107ba3d4-9e1c-4e52-9b55-5c268a840601.TID754.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/151/2.delta
[2025-07-19T21:02:36.574+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=151),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/151] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/151/2.delta
[2025-07-19T21:02:36.574+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.574+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.574+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 151 (task 754, attempt 0, stage 7.0)
[2025-07-19T21:02:36.574+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@128aa641
[2025-07-19T21:02:36.574+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=159, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.575+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=159),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/159] for update
[2025-07-19T21:02:36.575+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.575+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/153/.2.delta.37492bda-0239-420a-b316-8f609a6d8fbb.TID756.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/153/2.delta
[2025-07-19T21:02:36.575+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=153),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/153] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/153/2.delta
[2025-07-19T21:02:36.575+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 153 (task 756, attempt 0, stage 7.0)
[2025-07-19T21:02:36.575+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 151 (task 754, attempt 0, stage 7.0)
[2025-07-19T21:02:36.577+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 151.0 in stage 7.0 (TID 754). 5872 bytes result sent to driver
[2025-07-19T21:02:36.581+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/154/.2.delta.aa3197f3-13d8-48b9-885c-76627b2d1cb1.TID757.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/154/2.delta
[2025-07-19T21:02:36.582+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=154),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/154] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/154/2.delta
[2025-07-19T21:02:36.583+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/157/.2.delta.a4314cc1-9851-45c6-8126-8a0161bc8bef.TID760.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/157/2.delta
[2025-07-19T21:02:36.584+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=157),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/157] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/157/2.delta
[2025-07-19T21:02:36.585+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 153 (task 756, attempt 0, stage 7.0)
[2025-07-19T21:02:36.585+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 160.0 in stage 7.0 (TID 763) (8b44f3d35cfa, executor driver, partition 160, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.585+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 154 (task 757, attempt 0, stage 7.0)
[2025-07-19T21:02:36.586+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 157 (task 760, attempt 0, stage 7.0)
[2025-07-19T21:02:36.586+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 153.0 in stage 7.0 (TID 756). 5872 bytes result sent to driver
[2025-07-19T21:02:36.586+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 160.0 in stage 7.0 (TID 763)
[2025-07-19T21:02:36.587+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 151.0 in stage 7.0 (TID 754) in 91 ms on 8b44f3d35cfa (executor driver) (153/200)
[2025-07-19T21:02:36.587+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/156/.2.delta.622d5b4b-5485-4099-90bd-ee49f40b9010.TID759.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/156/2.delta
[2025-07-19T21:02:36.588+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=156),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/156] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/156/2.delta
[2025-07-19T21:02:36.588+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 153.0 in stage 7.0 (TID 756) in 79 ms on 8b44f3d35cfa (executor driver) (154/200)
[2025-07-19T21:02:36.589+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 161.0 in stage 7.0 (TID 764) (8b44f3d35cfa, executor driver, partition 161, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.589+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 156 (task 759, attempt 0, stage 7.0)
[2025-07-19T21:02:36.590+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 161.0 in stage 7.0 (TID 764)
[2025-07-19T21:02:36.591+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/159/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/159/.2.delta.daf582f2-22c9-4c1b-9e8c-c51f16d5f858.TID762.tmp
[2025-07-19T21:02:36.592+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 157 (task 760, attempt 0, stage 7.0)
[2025-07-19T21:02:36.593+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 157.0 in stage 7.0 (TID 760). 5829 bytes result sent to driver
[2025-07-19T21:02:36.593+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/155/.2.delta.50678a6a-61b9-43cf-a096-3e8d3cd0c836.TID758.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/155/2.delta
[2025-07-19T21:02:36.593+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=155),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/155] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/155/2.delta
[2025-07-19T21:02:36.593+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 154 (task 757, attempt 0, stage 7.0)
[2025-07-19T21:02:36.594+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 162.0 in stage 7.0 (TID 765) (8b44f3d35cfa, executor driver, partition 162, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.594+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 154.0 in stage 7.0 (TID 757). 5829 bytes result sent to driver
[2025-07-19T21:02:36.594+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.594+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.595+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 163.0 in stage 7.0 (TID 766) (8b44f3d35cfa, executor driver, partition 163, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.596+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 154.0 in stage 7.0 (TID 757) in 76 ms on 8b44f3d35cfa (executor driver) (155/200)
[2025-07-19T21:02:36.596+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 156 (task 759, attempt 0, stage 7.0)
[2025-07-19T21:02:36.596+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 163.0 in stage 7.0 (TID 766)
[2025-07-19T21:02:36.597+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 162.0 in stage 7.0 (TID 765)
[2025-07-19T21:02:36.597+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 156.0 in stage 7.0 (TID 759). 5786 bytes result sent to driver
[2025-07-19T21:02:36.598+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 157.0 in stage 7.0 (TID 760) in 64 ms on 8b44f3d35cfa (executor driver) (156/200)
[2025-07-19T21:02:36.598+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.598+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.599+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.602+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.602+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.605+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.606+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@11c03c13
[2025-07-19T21:02:36.606+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 164.0 in stage 7.0 (TID 767) (8b44f3d35cfa, executor driver, partition 164, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.608+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 164.0 in stage 7.0 (TID 767)
[2025-07-19T21:02:36.613+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=160, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.614+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=160),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/160] for update
[2025-07-19T21:02:36.615+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 156.0 in stage 7.0 (TID 759) in 68 ms on 8b44f3d35cfa (executor driver) (157/200)
[2025-07-19T21:02:36.616+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.617+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.618+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.619+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a2a0dc
[2025-07-19T21:02:36.620+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 155 (task 758, attempt 0, stage 7.0)
[2025-07-19T21:02:36.621+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=162, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.621+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=162),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/162] for update
[2025-07-19T21:02:36.626+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@32b538
[2025-07-19T21:02:36.629+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.630+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=163, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.631+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=163),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/163] for update
[2025-07-19T21:02:36.631+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 155 (task 758, attempt 0, stage 7.0)
[2025-07-19T21:02:36.632+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 155.0 in stage 7.0 (TID 758). 5829 bytes result sent to driver
[2025-07-19T21:02:36.633+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/160/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/160/.2.delta.a9d205e1-6caf-484b-bf22-5abdf358aed4.TID763.tmp
[2025-07-19T21:02:36.633+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 165.0 in stage 7.0 (TID 768) (8b44f3d35cfa, executor driver, partition 165, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.634+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 165.0 in stage 7.0 (TID 768)
[2025-07-19T21:02:36.635+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 155.0 in stage 7.0 (TID 758) in 78 ms on 8b44f3d35cfa (executor driver) (158/200)
[2025-07-19T21:02:36.635+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@50300ae0
[2025-07-19T21:02:36.636+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.636+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=161, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.637+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=161),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/161] for update
[2025-07-19T21:02:36.637+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.639+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.639+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35f9a5ae
[2025-07-19T21:02:36.640+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.642+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=165, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.644+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=165),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/165] for update
[2025-07-19T21:02:36.644+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.645+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25cf2e55
[2025-07-19T21:02:36.646+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=164, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.649+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=164),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/164] for update
[2025-07-19T21:02:36.650+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/162/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/162/.2.delta.f0f7d6cb-7ff2-4cc6-aa83-2cf8e12d62f1.TID765.tmp
[2025-07-19T21:02:36.650+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.651+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/158/.2.delta.a2c89a3f-cea5-4a20-a276-47f956820190.TID761.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/158/2.delta
[2025-07-19T21:02:36.651+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=158),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/158] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/158/2.delta
[2025-07-19T21:02:36.651+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 158 (task 761, attempt 0, stage 7.0)
[2025-07-19T21:02:36.651+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/164/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/164/.2.delta.6f57c1e7-51f5-4873-9809-75f3d8097171.TID767.tmp
[2025-07-19T21:02:36.652+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/161/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/161/.2.delta.913011e4-0f45-40b5-bff8-ef53e4e7a773.TID764.tmp
[2025-07-19T21:02:36.652+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/163/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/163/.2.delta.10fe079f-7bcb-4614-aa21-a887662f6737.TID766.tmp
[2025-07-19T21:02:36.652+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 158 (task 761, attempt 0, stage 7.0)
[2025-07-19T21:02:36.652+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 158.0 in stage 7.0 (TID 761). 5829 bytes result sent to driver
[2025-07-19T21:02:36.652+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 166.0 in stage 7.0 (TID 769) (8b44f3d35cfa, executor driver, partition 166, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.652+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 158.0 in stage 7.0 (TID 761) in 81 ms on 8b44f3d35cfa (executor driver) (159/200)
[2025-07-19T21:02:36.653+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 166.0 in stage 7.0 (TID 769)
[2025-07-19T21:02:36.654+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/159/.2.delta.daf582f2-22c9-4c1b-9e8c-c51f16d5f858.TID762.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/159/2.delta
[2025-07-19T21:02:36.655+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=159),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/159] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/159/2.delta
[2025-07-19T21:02:36.656+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 159 (task 762, attempt 0, stage 7.0)
[2025-07-19T21:02:36.657+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/165/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/165/.2.delta.9ca126a6-aaa0-4785-beff-f0a4820b6d4e.TID768.tmp
[2025-07-19T21:02:36.657+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 159 (task 762, attempt 0, stage 7.0)
[2025-07-19T21:02:36.658+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 159.0 in stage 7.0 (TID 762). 5829 bytes result sent to driver
[2025-07-19T21:02:36.658+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 167.0 in stage 7.0 (TID 770) (8b44f3d35cfa, executor driver, partition 167, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.658+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 167.0 in stage 7.0 (TID 770)
[2025-07-19T21:02:36.658+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 159.0 in stage 7.0 (TID 762) in 71 ms on 8b44f3d35cfa (executor driver) (160/200)
[2025-07-19T21:02:36.659+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.659+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.659+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@216cde98
[2025-07-19T21:02:36.659+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=166, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.659+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=166),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/166] for update
[2025-07-19T21:02:36.659+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.659+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:36.660+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71816e72
[2025-07-19T21:02:36.660+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=167, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.660+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=167),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/167] for update
[2025-07-19T21:02:36.660+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.660+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.667+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/167/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/167/.2.delta.df6cf845-cfb3-4d87-9182-e0355916b276.TID770.tmp
[2025-07-19T21:02:36.669+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/166/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/166/.2.delta.1ae2af6c-a92c-41e5-9326-a5592723482c.TID769.tmp
[2025-07-19T21:02:36.669+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/160/.2.delta.a9d205e1-6caf-484b-bf22-5abdf358aed4.TID763.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/160/2.delta
[2025-07-19T21:02:36.670+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=160),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/160] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/160/2.delta
[2025-07-19T21:02:36.670+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 160 (task 763, attempt 0, stage 7.0)
[2025-07-19T21:02:36.676+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 160 (task 763, attempt 0, stage 7.0)
[2025-07-19T21:02:36.677+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 160.0 in stage 7.0 (TID 763). 5829 bytes result sent to driver
[2025-07-19T21:02:36.677+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 168.0 in stage 7.0 (TID 771) (8b44f3d35cfa, executor driver, partition 168, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.678+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 168.0 in stage 7.0 (TID 771)
[2025-07-19T21:02:36.678+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 160.0 in stage 7.0 (TID 763) in 97 ms on 8b44f3d35cfa (executor driver) (161/200)
[2025-07-19T21:02:36.678+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/162/.2.delta.f0f7d6cb-7ff2-4cc6-aa83-2cf8e12d62f1.TID765.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/162/2.delta
[2025-07-19T21:02:36.679+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=162),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/162] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/162/2.delta
[2025-07-19T21:02:36.680+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 162 (task 765, attempt 0, stage 7.0)
[2025-07-19T21:02:36.681+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.681+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.684+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 162 (task 765, attempt 0, stage 7.0)
[2025-07-19T21:02:36.685+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@44e445cd
[2025-07-19T21:02:36.687+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 162.0 in stage 7.0 (TID 765). 5829 bytes result sent to driver
[2025-07-19T21:02:36.689+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=168, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.691+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=168),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/168] for update
[2025-07-19T21:02:36.695+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 169.0 in stage 7.0 (TID 772) (8b44f3d35cfa, executor driver, partition 169, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.697+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 162.0 in stage 7.0 (TID 765) in 99 ms on 8b44f3d35cfa (executor driver) (162/200)
[2025-07-19T21:02:36.698+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 169.0 in stage 7.0 (TID 772)
[2025-07-19T21:02:36.698+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/163/.2.delta.10fe079f-7bcb-4614-aa21-a887662f6737.TID766.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/163/2.delta
[2025-07-19T21:02:36.699+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=163),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/163] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/163/2.delta
[2025-07-19T21:02:36.700+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 163 (task 766, attempt 0, stage 7.0)
[2025-07-19T21:02:36.700+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.700+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/164/.2.delta.6f57c1e7-51f5-4873-9809-75f3d8097171.TID767.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/164/2.delta
[2025-07-19T21:02:36.700+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 163 (task 766, attempt 0, stage 7.0)
[2025-07-19T21:02:36.700+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=164),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/164] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/164/2.delta
[2025-07-19T21:02:36.700+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 163.0 in stage 7.0 (TID 766). 5829 bytes result sent to driver
[2025-07-19T21:02:36.700+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 164 (task 767, attempt 0, stage 7.0)
[2025-07-19T21:02:36.700+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.701+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2025-07-19T21:02:36.701+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@95b5194
[2025-07-19T21:02:36.701+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=169, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.701+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=169),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/169] for update
[2025-07-19T21:02:36.701+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/165/.2.delta.9ca126a6-aaa0-4785-beff-f0a4820b6d4e.TID768.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/165/2.delta
[2025-07-19T21:02:36.701+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=165),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/165] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/165/2.delta
[2025-07-19T21:02:36.701+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 170.0 in stage 7.0 (TID 773) (8b44f3d35cfa, executor driver, partition 170, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.701+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 165 (task 768, attempt 0, stage 7.0)
[2025-07-19T21:02:36.701+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/161/.2.delta.913011e4-0f45-40b5-bff8-ef53e4e7a773.TID764.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/161/2.delta
[2025-07-19T21:02:36.701+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=161),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/161] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/161/2.delta
[2025-07-19T21:02:36.703+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 170.0 in stage 7.0 (TID 773)
[2025-07-19T21:02:36.704+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 163.0 in stage 7.0 (TID 766) in 113 ms on 8b44f3d35cfa (executor driver) (163/200)
[2025-07-19T21:02:36.704+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 161 (task 764, attempt 0, stage 7.0)
[2025-07-19T21:02:36.705+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.710+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 165 (task 768, attempt 0, stage 7.0)
[2025-07-19T21:02:36.710+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 165.0 in stage 7.0 (TID 768). 5829 bytes result sent to driver
[2025-07-19T21:02:36.710+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.711+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.711+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 164 (task 767, attempt 0, stage 7.0)
[2025-07-19T21:02:36.711+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 171.0 in stage 7.0 (TID 774) (8b44f3d35cfa, executor driver, partition 171, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.712+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 164.0 in stage 7.0 (TID 767). 5829 bytes result sent to driver
[2025-07-19T21:02:36.712+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56b4802b
[2025-07-19T21:02:36.712+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 172.0 in stage 7.0 (TID 775) (8b44f3d35cfa, executor driver, partition 172, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.712+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 172.0 in stage 7.0 (TID 775)
[2025-07-19T21:02:36.714+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=170, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.714+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=170),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/170] for update
[2025-07-19T21:02:36.715+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 161 (task 764, attempt 0, stage 7.0)
[2025-07-19T21:02:36.715+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 165.0 in stage 7.0 (TID 768) in 109 ms on 8b44f3d35cfa (executor driver) (164/200)
[2025-07-19T21:02:36.715+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 164.0 in stage 7.0 (TID 767) in 118 ms on 8b44f3d35cfa (executor driver) (165/200)
[2025-07-19T21:02:36.715+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 171.0 in stage 7.0 (TID 774)
[2025-07-19T21:02:36.716+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.716+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.716+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.717+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.717+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.717+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 161.0 in stage 7.0 (TID 764). 5829 bytes result sent to driver
[2025-07-19T21:02:36.718+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 173.0 in stage 7.0 (TID 776) (8b44f3d35cfa, executor driver, partition 173, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.718+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/168/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/168/.2.delta.3066549a-74b1-4bd8-9a03-3e8d536ec517.TID771.tmp
[2025-07-19T21:02:36.718+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@551d5a14
[2025-07-19T21:02:36.718+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 161.0 in stage 7.0 (TID 764) in 131 ms on 8b44f3d35cfa (executor driver) (166/200)
[2025-07-19T21:02:36.719+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=171, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.719+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=171),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/171] for update
[2025-07-19T21:02:36.719+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 173.0 in stage 7.0 (TID 776)
[2025-07-19T21:02:36.719+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/166/.2.delta.1ae2af6c-a92c-41e5-9326-a5592723482c.TID769.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/166/2.delta
[2025-07-19T21:02:36.719+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=166),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/166] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/166/2.delta
[2025-07-19T21:02:36.719+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.719+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.721+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 166 (task 769, attempt 0, stage 7.0)
[2025-07-19T21:02:36.721+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.721+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/170/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/170/.2.delta.6f1b9394-5704-4d9b-a39b-bcf45b43174c.TID773.tmp
[2025-07-19T21:02:36.722+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/169/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/169/.2.delta.61d2567f-46b9-4e35-b6e8-3444284d776d.TID772.tmp
[2025-07-19T21:02:36.724+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6da75596
[2025-07-19T21:02:36.730+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/167/.2.delta.df6cf845-cfb3-4d87-9182-e0355916b276.TID770.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/167/2.delta
[2025-07-19T21:02:36.731+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=167),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/167] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/167/2.delta
[2025-07-19T21:02:36.731+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=173, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.731+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 166 (task 769, attempt 0, stage 7.0)
[2025-07-19T21:02:36.732+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=173),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/173] for update
[2025-07-19T21:02:36.732+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 166.0 in stage 7.0 (TID 769). 5829 bytes result sent to driver
[2025-07-19T21:02:36.733+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 167 (task 770, attempt 0, stage 7.0)
[2025-07-19T21:02:36.733+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 174.0 in stage 7.0 (TID 777) (8b44f3d35cfa, executor driver, partition 174, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.734+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 166.0 in stage 7.0 (TID 769) in 98 ms on 8b44f3d35cfa (executor driver) (167/200)
[2025-07-19T21:02:36.734+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e3a05e5
[2025-07-19T21:02:36.735+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=172, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.736+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=172),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/172] for update
[2025-07-19T21:02:36.736+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.736+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.736+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 174.0 in stage 7.0 (TID 777)
[2025-07-19T21:02:36.736+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.738+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.738+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a6d6e26
[2025-07-19T21:02:36.738+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=174, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.738+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=174),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/174] for update
[2025-07-19T21:02:36.738+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.738+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 167 (task 770, attempt 0, stage 7.0)
[2025-07-19T21:02:36.738+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 167.0 in stage 7.0 (TID 770). 5829 bytes result sent to driver
[2025-07-19T21:02:36.739+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 167.0 in stage 7.0 (TID 770) in 99 ms on 8b44f3d35cfa (executor driver) (168/200)
[2025-07-19T21:02:36.740+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 175.0 in stage 7.0 (TID 778) (8b44f3d35cfa, executor driver, partition 175, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.740+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 175.0 in stage 7.0 (TID 778)
[2025-07-19T21:02:36.747+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.747+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.747+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4fe794d8
[2025-07-19T21:02:36.747+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=175, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.747+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=175),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/175] for update
[2025-07-19T21:02:36.748+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/174/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/174/.2.delta.b2de183a-00e0-4b37-8b6c-282887f35d55.TID777.tmp
[2025-07-19T21:02:36.751+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/171/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/171/.2.delta.fffa7448-d629-44f5-95c6-3713275dfa39.TID774.tmp
[2025-07-19T21:02:36.753+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.754+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/173/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/173/.2.delta.cb7e2aad-963d-4a4e-8aaf-5cc2a8b15e19.TID776.tmp
[2025-07-19T21:02:36.755+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/172/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/172/.2.delta.e4f81d1b-9cbe-4129-9b05-6b560156782d.TID775.tmp
[2025-07-19T21:02:36.764+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/175/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/175/.2.delta.98987568-7629-4244-a52d-ae4d2e88dce0.TID778.tmp
[2025-07-19T21:02:36.776+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/169/.2.delta.61d2567f-46b9-4e35-b6e8-3444284d776d.TID772.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/169/2.delta
[2025-07-19T21:02:36.777+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=169),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/169] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/169/2.delta
[2025-07-19T21:02:36.778+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 169 (task 772, attempt 0, stage 7.0)
[2025-07-19T21:02:36.783+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 169 (task 772, attempt 0, stage 7.0)
[2025-07-19T21:02:36.783+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 169.0 in stage 7.0 (TID 772). 5829 bytes result sent to driver
[2025-07-19T21:02:36.783+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/168/.2.delta.3066549a-74b1-4bd8-9a03-3e8d536ec517.TID771.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/168/2.delta
[2025-07-19T21:02:36.784+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=168),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/168] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/168/2.delta
[2025-07-19T21:02:36.784+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 176.0 in stage 7.0 (TID 779) (8b44f3d35cfa, executor driver, partition 176, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.784+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 169.0 in stage 7.0 (TID 772) in 100 ms on 8b44f3d35cfa (executor driver) (169/200)
[2025-07-19T21:02:36.784+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 176.0 in stage 7.0 (TID 779)
[2025-07-19T21:02:36.785+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 168 (task 771, attempt 0, stage 7.0)
[2025-07-19T21:02:36.789+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.790+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.790+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e908474
[2025-07-19T21:02:36.790+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 168 (task 771, attempt 0, stage 7.0)
[2025-07-19T21:02:36.795+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=176, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.796+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=176),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/176] for update
[2025-07-19T21:02:36.796+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 168.0 in stage 7.0 (TID 771). 5915 bytes result sent to driver
[2025-07-19T21:02:36.798+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 177.0 in stage 7.0 (TID 780) (8b44f3d35cfa, executor driver, partition 177, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.799+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/170/.2.delta.6f1b9394-5704-4d9b-a39b-bcf45b43174c.TID773.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/170/2.delta
[2025-07-19T21:02:36.800+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=170),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/170] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/170/2.delta
[2025-07-19T21:02:36.800+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 168.0 in stage 7.0 (TID 771) in 122 ms on 8b44f3d35cfa (executor driver) (170/200)
[2025-07-19T21:02:36.800+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 170 (task 773, attempt 0, stage 7.0)
[2025-07-19T21:02:36.801+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 177.0 in stage 7.0 (TID 780)
[2025-07-19T21:02:36.802+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.802+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.803+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.805+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/174/.2.delta.b2de183a-00e0-4b37-8b6c-282887f35d55.TID777.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/174/2.delta
[2025-07-19T21:02:36.805+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=174),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/174] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/174/2.delta
[2025-07-19T21:02:36.805+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 174 (task 777, attempt 0, stage 7.0)
[2025-07-19T21:02:36.805+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e5b31dc
[2025-07-19T21:02:36.807+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=177, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.808+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=177),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/177] for update
[2025-07-19T21:02:36.809+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/173/.2.delta.cb7e2aad-963d-4a4e-8aaf-5cc2a8b15e19.TID776.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/173/2.delta
[2025-07-19T21:02:36.810+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=173),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/173] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/173/2.delta
[2025-07-19T21:02:36.810+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.811+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 173 (task 776, attempt 0, stage 7.0)
[2025-07-19T21:02:36.811+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 170 (task 773, attempt 0, stage 7.0)
[2025-07-19T21:02:36.812+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 170.0 in stage 7.0 (TID 773). 5872 bytes result sent to driver
[2025-07-19T21:02:36.812+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 174 (task 777, attempt 0, stage 7.0)
[2025-07-19T21:02:36.814+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 170.0 in stage 7.0 (TID 773) in 116 ms on 8b44f3d35cfa (executor driver) (171/200)
[2025-07-19T21:02:36.814+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 174.0 in stage 7.0 (TID 777). 5872 bytes result sent to driver
[2025-07-19T21:02:36.815+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 178.0 in stage 7.0 (TID 781) (8b44f3d35cfa, executor driver, partition 178, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.815+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 179.0 in stage 7.0 (TID 782) (8b44f3d35cfa, executor driver, partition 179, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.816+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 178.0 in stage 7.0 (TID 781)
[2025-07-19T21:02:36.817+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 174.0 in stage 7.0 (TID 777) in 86 ms on 8b44f3d35cfa (executor driver) (172/200)
[2025-07-19T21:02:36.817+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 179.0 in stage 7.0 (TID 782)
[2025-07-19T21:02:36.818+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.819+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.820+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3fd09a70
[2025-07-19T21:02:36.820+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.820+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:36.821+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 173 (task 776, attempt 0, stage 7.0)
[2025-07-19T21:02:36.821+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=179, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.823+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=179),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/179] for update
[2025-07-19T21:02:36.824+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/172/.2.delta.e4f81d1b-9cbe-4129-9b05-6b560156782d.TID775.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/172/2.delta
[2025-07-19T21:02:36.825+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=172),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/172] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/172/2.delta
[2025-07-19T21:02:36.826+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/175/.2.delta.98987568-7629-4244-a52d-ae4d2e88dce0.TID778.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/175/2.delta
[2025-07-19T21:02:36.827+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=175),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/175] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/175/2.delta
[2025-07-19T21:02:36.827+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 172 (task 775, attempt 0, stage 7.0)
[2025-07-19T21:02:36.827+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 175 (task 778, attempt 0, stage 7.0)
[2025-07-19T21:02:36.828+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@60f146c5
[2025-07-19T21:02:36.828+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/171/.2.delta.fffa7448-d629-44f5-95c6-3713275dfa39.TID774.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/171/2.delta
[2025-07-19T21:02:36.829+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=171),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/171] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/171/2.delta
[2025-07-19T21:02:36.829+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/177/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/177/.2.delta.f36c9f26-982a-471a-8e1a-1225a2e273e9.TID780.tmp
[2025-07-19T21:02:36.829+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 171 (task 774, attempt 0, stage 7.0)
[2025-07-19T21:02:36.830+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 173.0 in stage 7.0 (TID 776). 5872 bytes result sent to driver
[2025-07-19T21:02:36.831+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 180.0 in stage 7.0 (TID 783) (8b44f3d35cfa, executor driver, partition 180, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.831+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/176/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/176/.2.delta.a23e6a22-3b39-44cd-8dba-7ac31a7f4576.TID779.tmp
[2025-07-19T21:02:36.832+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=178, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.832+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 173.0 in stage 7.0 (TID 776) in 109 ms on 8b44f3d35cfa (executor driver) (173/200)
[2025-07-19T21:02:36.832+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=178),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/178] for update
[2025-07-19T21:02:36.833+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 180.0 in stage 7.0 (TID 783)
[2025-07-19T21:02:36.833+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 172 (task 775, attempt 0, stage 7.0)
[2025-07-19T21:02:36.834+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 172.0 in stage 7.0 (TID 775). 5872 bytes result sent to driver
[2025-07-19T21:02:36.834+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 181.0 in stage 7.0 (TID 784) (8b44f3d35cfa, executor driver, partition 181, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.835+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.837+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 175 (task 778, attempt 0, stage 7.0)
[2025-07-19T21:02:36.838+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 172.0 in stage 7.0 (TID 775) in 121 ms on 8b44f3d35cfa (executor driver) (174/200)
[2025-07-19T21:02:36.839+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 181.0 in stage 7.0 (TID 784)
[2025-07-19T21:02:36.839+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 175.0 in stage 7.0 (TID 778). 5872 bytes result sent to driver
[2025-07-19T21:02:36.840+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.841+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 182.0 in stage 7.0 (TID 785) (8b44f3d35cfa, executor driver, partition 182, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.841+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 175.0 in stage 7.0 (TID 778) in 94 ms on 8b44f3d35cfa (executor driver) (175/200)
[2025-07-19T21:02:36.841+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 182.0 in stage 7.0 (TID 785)
[2025-07-19T21:02:36.842+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.842+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:36.842+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 171 (task 774, attempt 0, stage 7.0)
[2025-07-19T21:02:36.843+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 171.0 in stage 7.0 (TID 774). 5829 bytes result sent to driver
[2025-07-19T21:02:36.844+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 183.0 in stage 7.0 (TID 786) (8b44f3d35cfa, executor driver, partition 183, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.846+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ed7b8f4
[2025-07-19T21:02:36.847+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 171.0 in stage 7.0 (TID 774) in 131 ms on 8b44f3d35cfa (executor driver) (176/200)
[2025-07-19T21:02:36.847+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 183.0 in stage 7.0 (TID 786)
[2025-07-19T21:02:36.847+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=180, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.848+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=180),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/180] for update
[2025-07-19T21:02:36.849+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.850+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T21:02:36.850+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.851+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.851+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/178/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/178/.2.delta.f76456c4-c617-4cf7-91a0-b7ab7e996685.TID781.tmp
[2025-07-19T21:02:36.851+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a7ae78e
[2025-07-19T21:02:36.852+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=181, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.852+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=181),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/181] for update
[2025-07-19T21:02:36.853+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.854+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.855+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.855+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.855+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f4b92fc
[2025-07-19T21:02:36.856+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/179/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/179/.2.delta.95c3a4f7-35fc-434c-9475-390bddf8b852.TID782.tmp
[2025-07-19T21:02:36.857+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=182, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.857+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=182),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/182] for update
[2025-07-19T21:02:36.857+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@940a259
[2025-07-19T21:02:36.858+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=183, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.858+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=183),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/183] for update
[2025-07-19T21:02:36.859+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.859+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.859+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/181/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/181/.2.delta.7c6c2e5c-d295-4ce9-ab6f-9ff77ea5a4d6.TID784.tmp
[2025-07-19T21:02:36.863+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/180/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/180/.2.delta.1ef413c4-b10e-47a3-88fc-7bc3e608f9c3.TID783.tmp
[2025-07-19T21:02:36.866+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/182/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/182/.2.delta.16c58ca7-2579-4f06-b904-11fe5f935c94.TID785.tmp
[2025-07-19T21:02:36.866+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/183/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/183/.2.delta.4d1f1828-e250-4ff2-843b-d84e2ec53a6b.TID786.tmp
[2025-07-19T21:02:36.872+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/177/.2.delta.f36c9f26-982a-471a-8e1a-1225a2e273e9.TID780.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/177/2.delta
[2025-07-19T21:02:36.873+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=177),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/177] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/177/2.delta
[2025-07-19T21:02:36.874+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 177 (task 780, attempt 0, stage 7.0)
[2025-07-19T21:02:36.874+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/176/.2.delta.a23e6a22-3b39-44cd-8dba-7ac31a7f4576.TID779.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/176/2.delta
[2025-07-19T21:02:36.874+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=176),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/176] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/176/2.delta
[2025-07-19T21:02:36.875+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 176 (task 779, attempt 0, stage 7.0)
[2025-07-19T21:02:36.880+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 177 (task 780, attempt 0, stage 7.0)
[2025-07-19T21:02:36.881+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 177.0 in stage 7.0 (TID 780). 5872 bytes result sent to driver
[2025-07-19T21:02:36.883+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 176 (task 779, attempt 0, stage 7.0)
[2025-07-19T21:02:36.884+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 176.0 in stage 7.0 (TID 779). 5872 bytes result sent to driver
[2025-07-19T21:02:36.885+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 184.0 in stage 7.0 (TID 787) (8b44f3d35cfa, executor driver, partition 184, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.885+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 185.0 in stage 7.0 (TID 788) (8b44f3d35cfa, executor driver, partition 185, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.885+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 185.0 in stage 7.0 (TID 788)
[2025-07-19T21:02:36.886+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 176.0 in stage 7.0 (TID 779) in 99 ms on 8b44f3d35cfa (executor driver) (177/200)
[2025-07-19T21:02:36.886+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 184.0 in stage 7.0 (TID 787)
[2025-07-19T21:02:36.886+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 177.0 in stage 7.0 (TID 780) in 86 ms on 8b44f3d35cfa (executor driver) (178/200)
[2025-07-19T21:02:36.886+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.886+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.886+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.886+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.887+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7306e58c
[2025-07-19T21:02:36.895+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=184, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.898+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=184),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/184] for update
[2025-07-19T21:02:36.900+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.902+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@46eb6b0e
[2025-07-19T21:02:36.903+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=185, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.904+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=185),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/185] for update
[2025-07-19T21:02:36.905+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.906+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/179/.2.delta.95c3a4f7-35fc-434c-9475-390bddf8b852.TID782.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/179/2.delta
[2025-07-19T21:02:36.906+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=179),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/179] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/179/2.delta
[2025-07-19T21:02:36.908+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 179 (task 782, attempt 0, stage 7.0)
[2025-07-19T21:02:36.913+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/178/.2.delta.f76456c4-c617-4cf7-91a0-b7ab7e996685.TID781.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/178/2.delta
[2025-07-19T21:02:36.914+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=178),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/178] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/178/2.delta
[2025-07-19T21:02:36.914+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 179 (task 782, attempt 0, stage 7.0)
[2025-07-19T21:02:36.915+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 179.0 in stage 7.0 (TID 782). 5829 bytes result sent to driver
[2025-07-19T21:02:36.915+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 178 (task 781, attempt 0, stage 7.0)
[2025-07-19T21:02:36.915+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 186.0 in stage 7.0 (TID 789) (8b44f3d35cfa, executor driver, partition 186, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.915+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 179.0 in stage 7.0 (TID 782) in 103 ms on 8b44f3d35cfa (executor driver) (179/200)
[2025-07-19T21:02:36.916+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 186.0 in stage 7.0 (TID 789)
[2025-07-19T21:02:36.921+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/180/.2.delta.1ef413c4-b10e-47a3-88fc-7bc3e608f9c3.TID783.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/180/2.delta
[2025-07-19T21:02:36.922+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=180),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/180] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/180/2.delta
[2025-07-19T21:02:36.922+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/183/.2.delta.4d1f1828-e250-4ff2-843b-d84e2ec53a6b.TID786.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/183/2.delta
[2025-07-19T21:02:36.923+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=183),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/183] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/183/2.delta
[2025-07-19T21:02:36.925+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 178 (task 781, attempt 0, stage 7.0)
[2025-07-19T21:02:36.926+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 180 (task 783, attempt 0, stage 7.0)
[2025-07-19T21:02:36.927+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 183 (task 786, attempt 0, stage 7.0)
[2025-07-19T21:02:36.929+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.930+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.933+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 178.0 in stage 7.0 (TID 781). 5829 bytes result sent to driver
[2025-07-19T21:02:36.938+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/185/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/185/.2.delta.c07686a4-e9f0-4645-b4db-a93916f1ee27.TID788.tmp
[2025-07-19T21:02:36.939+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/184/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/184/.2.delta.1a14681c-845c-46f8-884b-d4585d92c50a.TID787.tmp
[2025-07-19T21:02:36.939+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 187.0 in stage 7.0 (TID 790) (8b44f3d35cfa, executor driver, partition 187, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.940+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 178.0 in stage 7.0 (TID 781) in 111 ms on 8b44f3d35cfa (executor driver) (180/200)
[2025-07-19T21:02:36.944+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@51bc43d9
[2025-07-19T21:02:36.945+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 187.0 in stage 7.0 (TID 790)
[2025-07-19T21:02:36.946+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=186, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.948+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=186),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/186] for update
[2025-07-19T21:02:36.948+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 180 (task 783, attempt 0, stage 7.0)
[2025-07-19T21:02:36.948+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 180.0 in stage 7.0 (TID 783). 5829 bytes result sent to driver
[2025-07-19T21:02:36.949+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 188.0 in stage 7.0 (TID 791) (8b44f3d35cfa, executor driver, partition 188, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.949+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 188.0 in stage 7.0 (TID 791)
[2025-07-19T21:02:36.949+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 183 (task 786, attempt 0, stage 7.0)
[2025-07-19T21:02:36.949+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 180.0 in stage 7.0 (TID 783) in 103 ms on 8b44f3d35cfa (executor driver) (181/200)
[2025-07-19T21:02:36.949+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 183.0 in stage 7.0 (TID 786). 5829 bytes result sent to driver
[2025-07-19T21:02:36.950+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.950+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 189.0 in stage 7.0 (TID 792) (8b44f3d35cfa, executor driver, partition 189, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.952+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 189.0 in stage 7.0 (TID 792)
[2025-07-19T21:02:36.953+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/182/.2.delta.16c58ca7-2579-4f06-b904-11fe5f935c94.TID785.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/182/2.delta
[2025-07-19T21:02:36.953+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=182),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/182] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/182/2.delta
[2025-07-19T21:02:36.954+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 183.0 in stage 7.0 (TID 786) in 92 ms on 8b44f3d35cfa (executor driver) (182/200)
[2025-07-19T21:02:36.957+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.958+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 182 (task 785, attempt 0, stage 7.0)
[2025-07-19T21:02:36.958+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.958+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/181/.2.delta.7c6c2e5c-d295-4ce9-ab6f-9ff77ea5a4d6.TID784.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/181/2.delta
[2025-07-19T21:02:36.960+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=181),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/181] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/181/2.delta
[2025-07-19T21:02:36.960+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@badee9e
[2025-07-19T21:02:36.961+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 181 (task 784, attempt 0, stage 7.0)
[2025-07-19T21:02:36.962+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=187, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.965+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=187),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/187] for update
[2025-07-19T21:02:36.968+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.968+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.968+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 182 (task 785, attempt 0, stage 7.0)
[2025-07-19T21:02:36.971+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.972+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.973+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 182.0 in stage 7.0 (TID 785). 5829 bytes result sent to driver
[2025-07-19T21:02:36.973+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.974+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 190.0 in stage 7.0 (TID 793) (8b44f3d35cfa, executor driver, partition 190, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.974+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 181 (task 784, attempt 0, stage 7.0)
[2025-07-19T21:02:36.974+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 182.0 in stage 7.0 (TID 785) in 105 ms on 8b44f3d35cfa (executor driver) (183/200)
[2025-07-19T21:02:36.975+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@738c691f
[2025-07-19T21:02:36.975+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 181.0 in stage 7.0 (TID 784). 5829 bytes result sent to driver
[2025-07-19T21:02:36.975+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 190.0 in stage 7.0 (TID 793)
[2025-07-19T21:02:36.975+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 191.0 in stage 7.0 (TID 794) (8b44f3d35cfa, executor driver, partition 191, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.975+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 181.0 in stage 7.0 (TID 784) in 111 ms on 8b44f3d35cfa (executor driver) (184/200)
[2025-07-19T21:02:36.975+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 191.0 in stage 7.0 (TID 794)
[2025-07-19T21:02:36.976+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=189, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.976+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=189),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/189] for update
[2025-07-19T21:02:36.976+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.976+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.976+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:36.976+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:36.976+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.976+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@17c487d
[2025-07-19T21:02:36.976+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=190, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.977+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=190),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/190] for update
[2025-07-19T21:02:36.977+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@8f23a01
[2025-07-19T21:02:36.977+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=188, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.977+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=188),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/188] for update
[2025-07-19T21:02:36.977+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@24a05e81
[2025-07-19T21:02:36.977+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=191, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:36.977+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=191),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/191] for update
[2025-07-19T21:02:36.977+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.978+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.978+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:36.978+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/186/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/186/.2.delta.975a55c1-d937-4daa-8920-cfdb960159d5.TID789.tmp
[2025-07-19T21:02:36.978+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/187/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/187/.2.delta.151345e8-237c-48b6-9f53-78669efe145d.TID790.tmp
[2025-07-19T21:02:36.978+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/189/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/189/.2.delta.6f830ec7-54a3-4fae-902a-58ac2e6828af.TID792.tmp
[2025-07-19T21:02:36.978+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/188/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/188/.2.delta.d2da87cc-7cd5-4744-8f3a-6cbba25105db.TID791.tmp
[2025-07-19T21:02:36.978+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/190/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/190/.2.delta.6393cdf0-776e-434c-ac06-3de0c1085bdb.TID793.tmp
[2025-07-19T21:02:36.978+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/191/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/191/.2.delta.fdaae9de-8069-425b-b170-8efe3041c09c.TID794.tmp
[2025-07-19T21:02:36.987+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/185/.2.delta.c07686a4-e9f0-4645-b4db-a93916f1ee27.TID788.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/185/2.delta
[2025-07-19T21:02:36.988+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/184/.2.delta.1a14681c-845c-46f8-884b-d4585d92c50a.TID787.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/184/2.delta
[2025-07-19T21:02:36.988+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=185),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/185] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/185/2.delta
[2025-07-19T21:02:36.988+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=184),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/184] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/184/2.delta
[2025-07-19T21:02:36.989+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 184 (task 787, attempt 0, stage 7.0)
[2025-07-19T21:02:36.989+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 185 (task 788, attempt 0, stage 7.0)
[2025-07-19T21:02:36.994+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 185 (task 788, attempt 0, stage 7.0)
[2025-07-19T21:02:36.994+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 185.0 in stage 7.0 (TID 788). 5829 bytes result sent to driver
[2025-07-19T21:02:36.996+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 192.0 in stage 7.0 (TID 795) (8b44f3d35cfa, executor driver, partition 192, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.996+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Committed partition 184 (task 787, attempt 0, stage 7.0)
[2025-07-19T21:02:36.997+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Finished task 184.0 in stage 7.0 (TID 787). 5829 bytes result sent to driver
[2025-07-19T21:02:36.997+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 192.0 in stage 7.0 (TID 795)
[2025-07-19T21:02:36.997+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 185.0 in stage 7.0 (TID 788) in 115 ms on 8b44f3d35cfa (executor driver) (185/200)
[2025-07-19T21:02:36.997+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Starting task 193.0 in stage 7.0 (TID 796) (8b44f3d35cfa, executor driver, partition 193, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:36.997+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO Executor: Running task 193.0 in stage 7.0 (TID 796)
[2025-07-19T21:02:36.998+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/186/.2.delta.975a55c1-d937-4daa-8920-cfdb960159d5.TID789.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/186/2.delta
[2025-07-19T21:02:36.999+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=186),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/186] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/186/2.delta
[2025-07-19T21:02:36.999+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO TaskSetManager: Finished task 184.0 in stage 7.0 (TID 787) in 118 ms on 8b44f3d35cfa (executor driver) (186/200)
[2025-07-19T21:02:37.000+0000] {subprocess.py:93} INFO - 25/07/19 21:02:36 INFO DataWritingSparkTask: Commit authorized for partition 186 (task 789, attempt 0, stage 7.0)
[2025-07-19T21:02:37.002+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.002+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.003+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.003+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:37.003+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b7efc72
[2025-07-19T21:02:37.005+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=192, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:37.006+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c4566b3
[2025-07-19T21:02:37.007+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=192),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/192] for update
[2025-07-19T21:02:37.008+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 186 (task 789, attempt 0, stage 7.0)
[2025-07-19T21:02:37.008+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=193, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:37.008+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=193),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/193] for update
[2025-07-19T21:02:37.009+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 186.0 in stage 7.0 (TID 789). 5829 bytes result sent to driver
[2025-07-19T21:02:37.010+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.011+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.013+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 194.0 in stage 7.0 (TID 797) (8b44f3d35cfa, executor driver, partition 194, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.013+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 194.0 in stage 7.0 (TID 797)
[2025-07-19T21:02:37.014+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 186.0 in stage 7.0 (TID 789) in 100 ms on 8b44f3d35cfa (executor driver) (187/200)
[2025-07-19T21:02:37.018+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.019+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.022+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@81a1107
[2025-07-19T21:02:37.023+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=194, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:37.023+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=194),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/194] for update
[2025-07-19T21:02:37.024+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/190/.2.delta.6393cdf0-776e-434c-ac06-3de0c1085bdb.TID793.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/190/2.delta
[2025-07-19T21:02:37.024+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=190),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/190] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/190/2.delta
[2025-07-19T21:02:37.024+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 190 (task 793, attempt 0, stage 7.0)
[2025-07-19T21:02:37.025+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/193/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/193/.2.delta.e1c689b8-70ae-41c6-8820-73c10c406a3e.TID796.tmp
[2025-07-19T21:02:37.025+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/189/.2.delta.6f830ec7-54a3-4fae-902a-58ac2e6828af.TID792.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/189/2.delta
[2025-07-19T21:02:37.025+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=189),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/189] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/189/2.delta
[2025-07-19T21:02:37.026+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.026+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 189 (task 792, attempt 0, stage 7.0)
[2025-07-19T21:02:37.028+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/188/.2.delta.d2da87cc-7cd5-4744-8f3a-6cbba25105db.TID791.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/188/2.delta
[2025-07-19T21:02:37.030+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=188),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/188] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/188/2.delta
[2025-07-19T21:02:37.030+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 188 (task 791, attempt 0, stage 7.0)
[2025-07-19T21:02:37.031+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 189 (task 792, attempt 0, stage 7.0)
[2025-07-19T21:02:37.031+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 190 (task 793, attempt 0, stage 7.0)
[2025-07-19T21:02:37.032+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 190.0 in stage 7.0 (TID 793). 5829 bytes result sent to driver
[2025-07-19T21:02:37.032+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/192/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/192/.2.delta.e7389603-013b-4ac5-9583-92737f2ba1a7.TID795.tmp
[2025-07-19T21:02:37.032+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 189.0 in stage 7.0 (TID 792). 5829 bytes result sent to driver
[2025-07-19T21:02:37.033+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 195.0 in stage 7.0 (TID 798) (8b44f3d35cfa, executor driver, partition 195, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.033+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/187/.2.delta.151345e8-237c-48b6-9f53-78669efe145d.TID790.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/187/2.delta
[2025-07-19T21:02:37.034+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=187),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/187] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/187/2.delta
[2025-07-19T21:02:37.035+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 196.0 in stage 7.0 (TID 799) (8b44f3d35cfa, executor driver, partition 196, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.036+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 187 (task 790, attempt 0, stage 7.0)
[2025-07-19T21:02:37.036+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/191/.2.delta.fdaae9de-8069-425b-b170-8efe3041c09c.TID794.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/191/2.delta
[2025-07-19T21:02:37.037+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=191),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/191] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/191/2.delta
[2025-07-19T21:02:37.037+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 189.0 in stage 7.0 (TID 792) in 105 ms on 8b44f3d35cfa (executor driver) (188/200)
[2025-07-19T21:02:37.037+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 195.0 in stage 7.0 (TID 798)
[2025-07-19T21:02:37.038+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 190.0 in stage 7.0 (TID 793) in 96 ms on 8b44f3d35cfa (executor driver) (189/200)
[2025-07-19T21:02:37.038+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 196.0 in stage 7.0 (TID 799)
[2025-07-19T21:02:37.038+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 191 (task 794, attempt 0, stage 7.0)
[2025-07-19T21:02:37.039+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 188 (task 791, attempt 0, stage 7.0)
[2025-07-19T21:02:37.040+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 188.0 in stage 7.0 (TID 791). 5829 bytes result sent to driver
[2025-07-19T21:02:37.040+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.041+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.041+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 197.0 in stage 7.0 (TID 800) (8b44f3d35cfa, executor driver, partition 197, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.042+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 197.0 in stage 7.0 (TID 800)
[2025-07-19T21:02:37.042+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 188.0 in stage 7.0 (TID 791) in 109 ms on 8b44f3d35cfa (executor driver) (190/200)
[2025-07-19T21:02:37.042+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.042+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.042+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.043+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.043+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@70114b6d
[2025-07-19T21:02:37.043+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=195, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:37.043+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/194/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/194/.2.delta.effc710d-e08a-4a0e-870f-dc9d9f3fc85c.TID797.tmp
[2025-07-19T21:02:37.044+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=195),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/195] for update
[2025-07-19T21:02:37.045+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 187 (task 790, attempt 0, stage 7.0)
[2025-07-19T21:02:37.046+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 187.0 in stage 7.0 (TID 790). 5829 bytes result sent to driver
[2025-07-19T21:02:37.046+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.047+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 198.0 in stage 7.0 (TID 801) (8b44f3d35cfa, executor driver, partition 198, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.047+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4109d9f6
[2025-07-19T21:02:37.047+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=197, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:37.048+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=197),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/197] for update
[2025-07-19T21:02:37.048+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ff3a5a8
[2025-07-19T21:02:37.049+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=196, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:37.049+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=196),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/196] for update
[2025-07-19T21:02:37.049+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.050+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.051+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 187.0 in stage 7.0 (TID 790) in 124 ms on 8b44f3d35cfa (executor driver) (191/200)
[2025-07-19T21:02:37.051+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 191 (task 794, attempt 0, stage 7.0)
[2025-07-19T21:02:37.051+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 191.0 in stage 7.0 (TID 794). 5786 bytes result sent to driver
[2025-07-19T21:02:37.052+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 198.0 in stage 7.0 (TID 801)
[2025-07-19T21:02:37.052+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 199.0 in stage 7.0 (TID 802) (8b44f3d35cfa, executor driver, partition 199, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.052+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 191.0 in stage 7.0 (TID 794) in 114 ms on 8b44f3d35cfa (executor driver) (192/200)
[2025-07-19T21:02:37.052+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 199.0 in stage 7.0 (TID 802)
[2025-07-19T21:02:37.052+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.052+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.055+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1bc89839
[2025-07-19T21:02:37.055+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.059+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:37.059+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=198, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:37.060+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=198),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/198] for update
[2025-07-19T21:02:37.060+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/195/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/195/.2.delta.bc26d1f6-9ecc-4505-887e-e913d742d576.TID798.tmp
[2025-07-19T21:02:37.061+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d892518
[2025-07-19T21:02:37.061+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/196/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/196/.2.delta.499b3a6a-55bd-43a9-85f2-037e5146e04f.TID799.tmp
[2025-07-19T21:02:37.062+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=199, storeName=default ],fe455bb9-f78f-4c5d-a439-a7e861a32bf0) is active
[2025-07-19T21:02:37.062+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=199),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/199] for update
[2025-07-19T21:02:37.063+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.063+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.068+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/197/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/197/.2.delta.a53b2e48-d84e-48d2-8e02-26c8c56b282f.TID800.tmp
[2025-07-19T21:02:37.075+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/199/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/199/.2.delta.b2061757-230f-44a4-aed0-6e031bf50453.TID802.tmp
[2025-07-19T21:02:37.076+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/193/.2.delta.e1c689b8-70ae-41c6-8820-73c10c406a3e.TID796.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/193/2.delta
[2025-07-19T21:02:37.076+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=193),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/193] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/193/2.delta
[2025-07-19T21:02:37.076+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 193 (task 796, attempt 0, stage 7.0)
[2025-07-19T21:02:37.077+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/198/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/198/.2.delta.8beaffba-4de4-4b90-a76c-b9531102d703.TID801.tmp
[2025-07-19T21:02:37.083+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/194/.2.delta.effc710d-e08a-4a0e-870f-dc9d9f3fc85c.TID797.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/194/2.delta
[2025-07-19T21:02:37.084+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=194),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/194] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/194/2.delta
[2025-07-19T21:02:37.086+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/192/.2.delta.e7389603-013b-4ac5-9583-92737f2ba1a7.TID795.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/192/2.delta
[2025-07-19T21:02:37.086+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=192),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/192] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/192/2.delta
[2025-07-19T21:02:37.087+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 194 (task 797, attempt 0, stage 7.0)
[2025-07-19T21:02:37.087+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 192 (task 795, attempt 0, stage 7.0)
[2025-07-19T21:02:37.089+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 193 (task 796, attempt 0, stage 7.0)
[2025-07-19T21:02:37.090+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 193.0 in stage 7.0 (TID 796). 5829 bytes result sent to driver
[2025-07-19T21:02:37.091+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 803) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.091+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 0.0 in stage 9.0 (TID 803)
[2025-07-19T21:02:37.091+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 193.0 in stage 7.0 (TID 796) in 89 ms on 8b44f3d35cfa (executor driver) (193/200)
[2025-07-19T21:02:37.092+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 194 (task 797, attempt 0, stage 7.0)
[2025-07-19T21:02:37.092+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 192 (task 795, attempt 0, stage 7.0)
[2025-07-19T21:02:37.093+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 194.0 in stage 7.0 (TID 797). 5829 bytes result sent to driver
[2025-07-19T21:02:37.093+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 804) (8b44f3d35cfa, executor driver, partition 1, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.094+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 192.0 in stage 7.0 (TID 795). 5829 bytes result sent to driver
[2025-07-19T21:02:37.094+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 1.0 in stage 9.0 (TID 804)
[2025-07-19T21:02:37.095+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 805) (8b44f3d35cfa, executor driver, partition 2, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.095+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 192.0 in stage 7.0 (TID 795) in 96 ms on 8b44f3d35cfa (executor driver) (194/200)
[2025-07-19T21:02:37.096+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 2.0 in stage 9.0 (TID 805)
[2025-07-19T21:02:37.096+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.096+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.097+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 194.0 in stage 7.0 (TID 797) in 80 ms on 8b44f3d35cfa (executor driver) (195/200)
[2025-07-19T21:02:37.098+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.099+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.100+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.101+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.102+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@13b55117
[2025-07-19T21:02:37.104+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=0, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.105+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/0] for update
[2025-07-19T21:02:37.105+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@926afa2
[2025-07-19T21:02:37.106+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.106+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=2, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.106+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/2] for update
[2025-07-19T21:02:37.107+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@75da3535
[2025-07-19T21:02:37.108+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.109+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=1, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.109+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/1] for update
[2025-07-19T21:02:37.110+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.110+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/196/.2.delta.499b3a6a-55bd-43a9-85f2-037e5146e04f.TID799.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/196/2.delta
[2025-07-19T21:02:37.111+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=196),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/196] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/196/2.delta
[2025-07-19T21:02:37.112+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodeGenerator: Code generated in 10.108917 ms
[2025-07-19T21:02:37.113+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 196 (task 799, attempt 0, stage 7.0)
[2025-07-19T21:02:37.113+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 196 (task 799, attempt 0, stage 7.0)
[2025-07-19T21:02:37.114+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 196.0 in stage 7.0 (TID 799). 5829 bytes result sent to driver
[2025-07-19T21:02:37.114+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 806) (8b44f3d35cfa, executor driver, partition 3, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.115+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 3.0 in stage 9.0 (TID 806)
[2025-07-19T21:02:37.115+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 196.0 in stage 7.0 (TID 799) in 84 ms on 8b44f3d35cfa (executor driver) (196/200)
[2025-07-19T21:02:37.117+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/195/.2.delta.bc26d1f6-9ecc-4505-887e-e913d742d576.TID798.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/195/2.delta
[2025-07-19T21:02:37.118+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=195),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/195] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/195/2.delta
[2025-07-19T21:02:37.118+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 195 (task 798, attempt 0, stage 7.0)
[2025-07-19T21:02:37.119+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/0/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/0/.2.delta.5765a525-3a37-451f-8891-7bad0901a0a9.TID803.tmp
[2025-07-19T21:02:37.119+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.119+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.121+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 195 (task 798, attempt 0, stage 7.0)
[2025-07-19T21:02:37.122+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 195.0 in stage 7.0 (TID 798). 5829 bytes result sent to driver
[2025-07-19T21:02:37.123+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/199/.2.delta.b2061757-230f-44a4-aed0-6e031bf50453.TID802.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/199/2.delta
[2025-07-19T21:02:37.124+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/198/.2.delta.8beaffba-4de4-4b90-a76c-b9531102d703.TID801.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/198/2.delta
[2025-07-19T21:02:37.125+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 4.0 in stage 9.0 (TID 807) (8b44f3d35cfa, executor driver, partition 4, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.126+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=198),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/198] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/198/2.delta
[2025-07-19T21:02:37.127+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@362026d2
[2025-07-19T21:02:37.128+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 195.0 in stage 7.0 (TID 798) in 93 ms on 8b44f3d35cfa (executor driver) (197/200)
[2025-07-19T21:02:37.129+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=199),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/199] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/199/2.delta
[2025-07-19T21:02:37.129+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 4.0 in stage 9.0 (TID 807)
[2025-07-19T21:02:37.129+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 198 (task 801, attempt 0, stage 7.0)
[2025-07-19T21:02:37.130+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.130+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.130+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=3, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.131+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/3] for update
[2025-07-19T21:02:37.133+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.134+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 199 (task 802, attempt 0, stage 7.0)
[2025-07-19T21:02:37.135+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 198 (task 801, attempt 0, stage 7.0)
[2025-07-19T21:02:37.135+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/1/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/1/.2.delta.9b9db0be-a97b-4c87-8b04-125393a4437a.TID804.tmp
[2025-07-19T21:02:37.136+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 198.0 in stage 7.0 (TID 801). 5829 bytes result sent to driver
[2025-07-19T21:02:37.136+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/2/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/2/.2.delta.0f00bf62-a510-4890-a442-71bee7c4a613.TID805.tmp
[2025-07-19T21:02:37.137+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 5.0 in stage 9.0 (TID 808) (8b44f3d35cfa, executor driver, partition 5, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.137+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 5.0 in stage 9.0 (TID 808)
[2025-07-19T21:02:37.138+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 198.0 in stage 7.0 (TID 801) in 92 ms on 8b44f3d35cfa (executor driver) (198/200)
[2025-07-19T21:02:37.138+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.140+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.140+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 199 (task 802, attempt 0, stage 7.0)
[2025-07-19T21:02:37.141+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 199.0 in stage 7.0 (TID 802). 5829 bytes result sent to driver
[2025-07-19T21:02:37.141+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 6.0 in stage 9.0 (TID 809) (8b44f3d35cfa, executor driver, partition 6, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.143+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@70b935ae
[2025-07-19T21:02:37.144+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 6.0 in stage 9.0 (TID 809)
[2025-07-19T21:02:37.145+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/197/.2.delta.a53b2e48-d84e-48d2-8e02-26c8c56b282f.TID800.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/197/2.delta
[2025-07-19T21:02:37.146+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=197),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/197] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/state/0/197/2.delta
[2025-07-19T21:02:37.146+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 199.0 in stage 7.0 (TID 802) in 89 ms on 8b44f3d35cfa (executor driver) (199/200)
[2025-07-19T21:02:37.147+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 197 (task 800, attempt 0, stage 7.0)
[2025-07-19T21:02:37.147+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=4, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.149+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.151+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.152+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/4] for update
[2025-07-19T21:02:37.155+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5cc3896c
[2025-07-19T21:02:37.156+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=6, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.157+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/6] for update
[2025-07-19T21:02:37.157+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6694064e
[2025-07-19T21:02:37.158+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=5, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.159+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/5] for update
[2025-07-19T21:02:37.160+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.160+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.161+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 197 (task 800, attempt 0, stage 7.0)
[2025-07-19T21:02:37.161+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 197.0 in stage 7.0 (TID 800). 5829 bytes result sent to driver
[2025-07-19T21:02:37.162+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.162+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 7.0 in stage 9.0 (TID 810) (8b44f3d35cfa, executor driver, partition 7, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.163+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 7.0 in stage 9.0 (TID 810)
[2025-07-19T21:02:37.163+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 197.0 in stage 7.0 (TID 800) in 114 ms on 8b44f3d35cfa (executor driver) (200/200)
[2025-07-19T21:02:37.164+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool
[2025-07-19T21:02:37.165+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DAGScheduler: ResultStage 7 (start at <unknown>:0) finished in 7.007 s
[2025-07-19T21:02:37.166+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-19T21:02:37.166+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
[2025-07-19T21:02:37.167+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DAGScheduler: Job 3 finished: start at <unknown>:0, took 7.110590 s
[2025-07-19T21:02:37.167+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 1, writer: IcebergStreamingWrite(table=my_catalog.bronze.Checkins_raw, format=PARQUET)] is committing.
[2025-07-19T21:02:37.168+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO SparkWrite: Committing epoch 1 for query 857c6a97-8a45-4319-91e0-4d8882460008 in append mode
[2025-07-19T21:02:37.168+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.168+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.169+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74ab1905
[2025-07-19T21:02:37.169+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=7, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.171+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/7] for update
[2025-07-19T21:02:37.171+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/3/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/3/.2.delta.da7c18d6-96ad-4ffd-aba0-1d63258ba0cb.TID806.tmp
[2025-07-19T21:02:37.172+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.172+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/6/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/6/.2.delta.43a21fe6-0217-4af5-a9fa-885b9a68cfe3.TID809.tmp
[2025-07-19T21:02:37.172+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/4/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/4/.2.delta.6520ddfb-1d02-4964-b0a2-cb26c93d6a64.TID807.tmp
[2025-07-19T21:02:37.172+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO SparkWrite: Committing streaming append with 0 new data files to table my_catalog.bronze.Checkins_raw
[2025-07-19T21:02:37.172+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/5/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/5/.2.delta.e71d0fd8-7646-4789-b3b0-4a956f0dd56a.TID808.tmp
[2025-07-19T21:02:37.177+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/7/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/7/.2.delta.91310165-f969-46b9-a218-e029b696b938.TID810.tmp
[2025-07-19T21:02:37.188+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/2/.2.delta.0f00bf62-a510-4890-a442-71bee7c4a613.TID805.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/2/2.delta
[2025-07-19T21:02:37.190+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/2] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/2/2.delta
[2025-07-19T21:02:37.191+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 2 (task 805, attempt 0, stage 9.0)
[2025-07-19T21:02:37.191+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/1/.2.delta.9b9db0be-a97b-4c87-8b04-125393a4437a.TID804.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/1/2.delta
[2025-07-19T21:02:37.191+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/1] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/1/2.delta
[2025-07-19T21:02:37.192+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/0/.2.delta.5765a525-3a37-451f-8891-7bad0901a0a9.TID803.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/0/2.delta
[2025-07-19T21:02:37.192+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/0] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/0/2.delta
[2025-07-19T21:02:37.192+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 1 (task 804, attempt 0, stage 9.0)
[2025-07-19T21:02:37.192+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 803, attempt 0, stage 9.0)
[2025-07-19T21:02:37.195+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 1 (task 804, attempt 0, stage 9.0)
[2025-07-19T21:02:37.196+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 1.0 in stage 9.0 (TID 804). 5829 bytes result sent to driver
[2025-07-19T21:02:37.196+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 8.0 in stage 9.0 (TID 811) (8b44f3d35cfa, executor driver, partition 8, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.197+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 8.0 in stage 9.0 (TID 811)
[2025-07-19T21:02:37.197+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 804) in 104 ms on 8b44f3d35cfa (executor driver) (1/200)
[2025-07-19T21:02:37.198+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 0 (task 803, attempt 0, stage 9.0)
[2025-07-19T21:02:37.198+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 2 (task 805, attempt 0, stage 9.0)
[2025-07-19T21:02:37.199+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 0.0 in stage 9.0 (TID 803). 5829 bytes result sent to driver
[2025-07-19T21:02:37.199+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 2.0 in stage 9.0 (TID 805). 5786 bytes result sent to driver
[2025-07-19T21:02:37.199+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 9.0 in stage 9.0 (TID 812) (8b44f3d35cfa, executor driver, partition 9, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.199+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 9.0 in stage 9.0 (TID 812)
[2025-07-19T21:02:37.200+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.201+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.201+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 10.0 in stage 9.0 (TID 813) (8b44f3d35cfa, executor driver, partition 10, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.202+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.203+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.205+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5411e010
[2025-07-19T21:02:37.206+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=8, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.206+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/8] for update
[2025-07-19T21:02:37.206+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 805) in 111 ms on 8b44f3d35cfa (executor driver) (2/200)
[2025-07-19T21:02:37.206+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 803) in 116 ms on 8b44f3d35cfa (executor driver) (3/200)
[2025-07-19T21:02:37.207+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 10.0 in stage 9.0 (TID 813)
[2025-07-19T21:02:37.207+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.213+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b8a5591
[2025-07-19T21:02:37.214+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=9, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.214+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/9] for update
[2025-07-19T21:02:37.215+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.218+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.222+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:37.223+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/3/.2.delta.da7c18d6-96ad-4ffd-aba0-1d63258ba0cb.TID806.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/3/2.delta
[2025-07-19T21:02:37.223+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/3] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/3/2.delta
[2025-07-19T21:02:37.224+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 3 (task 806, attempt 0, stage 9.0)
[2025-07-19T21:02:37.225+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/6/.2.delta.43a21fe6-0217-4af5-a9fa-885b9a68cfe3.TID809.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/6/2.delta
[2025-07-19T21:02:37.227+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/6] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/6/2.delta
[2025-07-19T21:02:37.227+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/5/.2.delta.e71d0fd8-7646-4789-b3b0-4a956f0dd56a.TID808.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/5/2.delta
[2025-07-19T21:02:37.232+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/5] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/5/2.delta
[2025-07-19T21:02:37.234+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 6 (task 809, attempt 0, stage 9.0)
[2025-07-19T21:02:37.235+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@60227bcb
[2025-07-19T21:02:37.236+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 5 (task 808, attempt 0, stage 9.0)
[2025-07-19T21:02:37.237+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=10, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.238+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=10),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/10] for update
[2025-07-19T21:02:37.239+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 3 (task 806, attempt 0, stage 9.0)
[2025-07-19T21:02:37.241+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/8/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/8/.2.delta.f0a9c45c-e947-45df-89c2-cef750168cc7.TID811.tmp
[2025-07-19T21:02:37.241+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.241+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/4/.2.delta.6520ddfb-1d02-4964-b0a2-cb26c93d6a64.TID807.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/4/2.delta
[2025-07-19T21:02:37.241+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/4] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/4/2.delta
[2025-07-19T21:02:37.241+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 3.0 in stage 9.0 (TID 806). 5872 bytes result sent to driver
[2025-07-19T21:02:37.242+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 11.0 in stage 9.0 (TID 814) (8b44f3d35cfa, executor driver, partition 11, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.242+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 5 (task 808, attempt 0, stage 9.0)
[2025-07-19T21:02:37.242+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 4 (task 807, attempt 0, stage 9.0)
[2025-07-19T21:02:37.242+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 5.0 in stage 9.0 (TID 808). 5872 bytes result sent to driver
[2025-07-19T21:02:37.242+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 806) in 114 ms on 8b44f3d35cfa (executor driver) (4/200)
[2025-07-19T21:02:37.242+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 11.0 in stage 9.0 (TID 814)
[2025-07-19T21:02:37.242+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 6 (task 809, attempt 0, stage 9.0)
[2025-07-19T21:02:37.243+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 12.0 in stage 9.0 (TID 815) (8b44f3d35cfa, executor driver, partition 12, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.243+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 6.0 in stage 9.0 (TID 809). 5872 bytes result sent to driver
[2025-07-19T21:02:37.244+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 12.0 in stage 9.0 (TID 815)
[2025-07-19T21:02:37.244+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 13.0 in stage 9.0 (TID 816) (8b44f3d35cfa, executor driver, partition 13, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.244+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 13.0 in stage 9.0 (TID 816)
[2025-07-19T21:02:37.244+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 5.0 in stage 9.0 (TID 808) in 100 ms on 8b44f3d35cfa (executor driver) (5/200)
[2025-07-19T21:02:37.244+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 6.0 in stage 9.0 (TID 809) in 96 ms on 8b44f3d35cfa (executor driver) (6/200)
[2025-07-19T21:02:37.244+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/10/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/10/.2.delta.06ab9043-c7b7-41e6-abcc-abece5dff32c.TID813.tmp
[2025-07-19T21:02:37.244+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.244+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:37.245+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.245+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:37.245+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4fc4c0a5
[2025-07-19T21:02:37.245+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=13, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.245+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=13),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/13] for update
[2025-07-19T21:02:37.246+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 4 (task 807, attempt 0, stage 9.0)
[2025-07-19T21:02:37.246+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 4.0 in stage 9.0 (TID 807). 5872 bytes result sent to driver
[2025-07-19T21:02:37.246+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 14.0 in stage 9.0 (TID 817) (8b44f3d35cfa, executor driver, partition 14, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.246+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 14.0 in stage 9.0 (TID 817)
[2025-07-19T21:02:37.246+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 4.0 in stage 9.0 (TID 807) in 115 ms on 8b44f3d35cfa (executor driver) (7/200)
[2025-07-19T21:02:37.246+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.247+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.247+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.247+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T21:02:37.247+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/9/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/9/.2.delta.a6794058-b4e4-4be7-bc66-56c6e82bd599.TID812.tmp
[2025-07-19T21:02:37.248+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@234fef94
[2025-07-19T21:02:37.248+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.251+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=11, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.252+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=11),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/11] for update
[2025-07-19T21:02:37.253+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.254+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6779c17a
[2025-07-19T21:02:37.255+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=12, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.258+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=12),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/12] for update
[2025-07-19T21:02:37.258+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.259+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@62630828
[2025-07-19T21:02:37.259+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=14, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.259+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=14),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/14] for update
[2025-07-19T21:02:37.259+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/7/.2.delta.91310165-f969-46b9-a218-e029b696b938.TID810.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/7/2.delta
[2025-07-19T21:02:37.260+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/7] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/7/2.delta
[2025-07-19T21:02:37.262+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 7 (task 810, attempt 0, stage 9.0)
[2025-07-19T21:02:37.263+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.271+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 7 (task 810, attempt 0, stage 9.0)
[2025-07-19T21:02:37.274+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/13/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/13/.2.delta.b1f326df-b5e5-4b87-b991-6df753343877.TID816.tmp
[2025-07-19T21:02:37.275+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 7.0 in stage 9.0 (TID 810). 5872 bytes result sent to driver
[2025-07-19T21:02:37.275+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 15.0 in stage 9.0 (TID 818) (8b44f3d35cfa, executor driver, partition 15, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.276+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 15.0 in stage 9.0 (TID 818)
[2025-07-19T21:02:37.276+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 7.0 in stage 9.0 (TID 810) in 119 ms on 8b44f3d35cfa (executor driver) (8/200)
[2025-07-19T21:02:37.276+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.277+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.277+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71e533ec
[2025-07-19T21:02:37.277+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=15, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.278+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=15),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/15] for update
[2025-07-19T21:02:37.287+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/11/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/11/.2.delta.0fc4f6a1-2d04-405f-b2f7-04842f1d7002.TID814.tmp
[2025-07-19T21:02:37.289+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/14/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/14/.2.delta.2171807b-77bd-44ec-a714-899c7547a7db.TID817.tmp
[2025-07-19T21:02:37.289+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/12/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/12/.2.delta.0e937eff-43dd-4aa5-9001-9c2d553632bc.TID815.tmp
[2025-07-19T21:02:37.290+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.300+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/15/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/15/.2.delta.94e6f37f-361b-4617-9304-e251b3383705.TID818.tmp
[2025-07-19T21:02:37.303+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/10/.2.delta.06ab9043-c7b7-41e6-abcc-abece5dff32c.TID813.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/10/2.delta
[2025-07-19T21:02:37.305+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/8/.2.delta.f0a9c45c-e947-45df-89c2-cef750168cc7.TID811.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/8/2.delta
[2025-07-19T21:02:37.306+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=10),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/10] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/10/2.delta
[2025-07-19T21:02:37.306+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/8] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/8/2.delta
[2025-07-19T21:02:37.307+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 10 (task 813, attempt 0, stage 9.0)
[2025-07-19T21:02:37.308+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 8 (task 811, attempt 0, stage 9.0)
[2025-07-19T21:02:37.308+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 10 (task 813, attempt 0, stage 9.0)
[2025-07-19T21:02:37.309+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 8 (task 811, attempt 0, stage 9.0)
[2025-07-19T21:02:37.310+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 10.0 in stage 9.0 (TID 813). 5872 bytes result sent to driver
[2025-07-19T21:02:37.313+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 8.0 in stage 9.0 (TID 811). 5872 bytes result sent to driver
[2025-07-19T21:02:37.313+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 16.0 in stage 9.0 (TID 819) (8b44f3d35cfa, executor driver, partition 16, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.313+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 17.0 in stage 9.0 (TID 820) (8b44f3d35cfa, executor driver, partition 17, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.313+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 8.0 in stage 9.0 (TID 811) in 116 ms on 8b44f3d35cfa (executor driver) (9/200)
[2025-07-19T21:02:37.314+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 17.0 in stage 9.0 (TID 820)
[2025-07-19T21:02:37.314+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HadoopTableOperations: Committed a new metadata file s3a://warehouse/bronze/Checkins_raw/metadata/v129.metadata.json
[2025-07-19T21:02:37.314+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 16.0 in stage 9.0 (TID 819)
[2025-07-19T21:02:37.314+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 10.0 in stage 9.0 (TID 813) in 111 ms on 8b44f3d35cfa (executor driver) (10/200)
[2025-07-19T21:02:37.316+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.319+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.319+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.319+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.319+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@11d9ca63
[2025-07-19T21:02:37.320+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=17, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.320+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=17),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/17] for update
[2025-07-19T21:02:37.321+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/9/.2.delta.a6794058-b4e4-4be7-bc66-56c6e82bd599.TID812.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/9/2.delta
[2025-07-19T21:02:37.321+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/9] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/9/2.delta
[2025-07-19T21:02:37.322+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 9 (task 812, attempt 0, stage 9.0)
[2025-07-19T21:02:37.322+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@8a63f82
[2025-07-19T21:02:37.322+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.323+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=16, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.323+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=16),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/16] for update
[2025-07-19T21:02:37.325+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.326+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 9 (task 812, attempt 0, stage 9.0)
[2025-07-19T21:02:37.329+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 9.0 in stage 9.0 (TID 812). 5872 bytes result sent to driver
[2025-07-19T21:02:37.330+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 18.0 in stage 9.0 (TID 821) (8b44f3d35cfa, executor driver, partition 18, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.331+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 9.0 in stage 9.0 (TID 812) in 130 ms on 8b44f3d35cfa (executor driver) (11/200)
[2025-07-19T21:02:37.331+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 18.0 in stage 9.0 (TID 821)
[2025-07-19T21:02:37.331+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.331+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.332+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2cfbff7c
[2025-07-19T21:02:37.333+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=18, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.335+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=18),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/18] for update
[2025-07-19T21:02:37.335+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/13/.2.delta.b1f326df-b5e5-4b87-b991-6df753343877.TID816.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/13/2.delta
[2025-07-19T21:02:37.336+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=13),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/13] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/13/2.delta
[2025-07-19T21:02:37.336+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 13 (task 816, attempt 0, stage 9.0)
[2025-07-19T21:02:37.336+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.337+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/14/.2.delta.2171807b-77bd-44ec-a714-899c7547a7db.TID817.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/14/2.delta
[2025-07-19T21:02:37.337+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=14),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/14] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/14/2.delta
[2025-07-19T21:02:37.338+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 14 (task 817, attempt 0, stage 9.0)
[2025-07-19T21:02:37.340+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/17/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/17/.2.delta.de490bce-9de0-412e-bdd5-fd173e90405d.TID820.tmp
[2025-07-19T21:02:37.342+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 13 (task 816, attempt 0, stage 9.0)
[2025-07-19T21:02:37.344+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 14 (task 817, attempt 0, stage 9.0)
[2025-07-19T21:02:37.345+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/16/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/16/.2.delta.c426a80c-722d-4547-8a51-a683f44da3b0.TID819.tmp
[2025-07-19T21:02:37.345+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/12/.2.delta.0e937eff-43dd-4aa5-9001-9c2d553632bc.TID815.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/12/2.delta
[2025-07-19T21:02:37.345+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=12),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/12] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/12/2.delta
[2025-07-19T21:02:37.345+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 14.0 in stage 9.0 (TID 817). 5872 bytes result sent to driver
[2025-07-19T21:02:37.345+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 12 (task 815, attempt 0, stage 9.0)
[2025-07-19T21:02:37.345+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 19.0 in stage 9.0 (TID 822) (8b44f3d35cfa, executor driver, partition 19, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.345+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 14.0 in stage 9.0 (TID 817) in 108 ms on 8b44f3d35cfa (executor driver) (12/200)
[2025-07-19T21:02:37.345+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 13.0 in stage 9.0 (TID 816). 5872 bytes result sent to driver
[2025-07-19T21:02:37.346+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 20.0 in stage 9.0 (TID 823) (8b44f3d35cfa, executor driver, partition 20, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.347+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 20.0 in stage 9.0 (TID 823)
[2025-07-19T21:02:37.347+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 13.0 in stage 9.0 (TID 816) in 118 ms on 8b44f3d35cfa (executor driver) (13/200)
[2025-07-19T21:02:37.350+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.351+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.353+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 12 (task 815, attempt 0, stage 9.0)
[2025-07-19T21:02:37.353+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 19.0 in stage 9.0 (TID 822)
[2025-07-19T21:02:37.353+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/18/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/18/.2.delta.43e598e7-053f-4cb9-a269-e8d7a6c97a91.TID821.tmp
[2025-07-19T21:02:37.353+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/11/.2.delta.0fc4f6a1-2d04-405f-b2f7-04842f1d7002.TID814.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/11/2.delta
[2025-07-19T21:02:37.354+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=11),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/11] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/11/2.delta
[2025-07-19T21:02:37.354+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.355+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.356+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 12.0 in stage 9.0 (TID 815). 5872 bytes result sent to driver
[2025-07-19T21:02:37.357+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 21.0 in stage 9.0 (TID 824) (8b44f3d35cfa, executor driver, partition 21, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.358+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 21.0 in stage 9.0 (TID 824)
[2025-07-19T21:02:37.360+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 11 (task 814, attempt 0, stage 9.0)
[2025-07-19T21:02:37.362+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@67c97442
[2025-07-19T21:02:37.362+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=20, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.363+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=20),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/20] for update
[2025-07-19T21:02:37.363+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 12.0 in stage 9.0 (TID 815) in 129 ms on 8b44f3d35cfa (executor driver) (14/200)
[2025-07-19T21:02:37.363+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.363+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c3be06
[2025-07-19T21:02:37.363+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.363+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:37.363+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 11 (task 814, attempt 0, stage 9.0)
[2025-07-19T21:02:37.364+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=19, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.364+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=19),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/19] for update
[2025-07-19T21:02:37.364+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 11.0 in stage 9.0 (TID 814). 5872 bytes result sent to driver
[2025-07-19T21:02:37.364+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@220a41b1
[2025-07-19T21:02:37.364+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.364+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 22.0 in stage 9.0 (TID 825) (8b44f3d35cfa, executor driver, partition 22, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.364+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=21, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.365+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=21),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/21] for update
[2025-07-19T21:02:37.365+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 11.0 in stage 9.0 (TID 814) in 140 ms on 8b44f3d35cfa (executor driver) (15/200)
[2025-07-19T21:02:37.367+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 22.0 in stage 9.0 (TID 825)
[2025-07-19T21:02:37.369+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.370+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/15/.2.delta.94e6f37f-361b-4617-9304-e251b3383705.TID818.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/15/2.delta
[2025-07-19T21:02:37.370+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=15),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/15] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/15/2.delta
[2025-07-19T21:02:37.371+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 15 (task 818, attempt 0, stage 9.0)
[2025-07-19T21:02:37.372+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.372+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:37.373+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a491a31
[2025-07-19T21:02:37.375+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO SnapshotProducer: Committed snapshot 3393316933098873670 (FastAppend)
[2025-07-19T21:02:37.377+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=22, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.377+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=22),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/22] for update
[2025-07-19T21:02:37.378+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 15 (task 818, attempt 0, stage 9.0)
[2025-07-19T21:02:37.379+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 15.0 in stage 9.0 (TID 818). 5872 bytes result sent to driver
[2025-07-19T21:02:37.379+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 23.0 in stage 9.0 (TID 826) (8b44f3d35cfa, executor driver, partition 23, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.379+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 15.0 in stage 9.0 (TID 818) in 111 ms on 8b44f3d35cfa (executor driver) (16/200)
[2025-07-19T21:02:37.380+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/20/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/20/.2.delta.7acbb926-ac8f-4a4c-8933-1298f195d63b.TID823.tmp
[2025-07-19T21:02:37.380+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.380+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 23.0 in stage 9.0 (TID 826)
[2025-07-19T21:02:37.381+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/21/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/21/.2.delta.fd20f268-4e74-4f57-a155-a70256141bb8.TID824.tmp
[2025-07-19T21:02:37.382+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.384+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.384+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/19/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/19/.2.delta.34298bf8-d6ff-4595-8717-1db275464657.TID822.tmp
[2025-07-19T21:02:37.387+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4fcc7a37
[2025-07-19T21:02:37.389+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=23, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.389+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=23),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/23] for update
[2025-07-19T21:02:37.392+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.397+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/22/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/22/.2.delta.c184601e-ce68-4249-aeca-fb4f839a7f54.TID825.tmp
[2025-07-19T21:02:37.398+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/16/.2.delta.c426a80c-722d-4547-8a51-a683f44da3b0.TID819.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/16/2.delta
[2025-07-19T21:02:37.398+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=16),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/16] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/16/2.delta
[2025-07-19T21:02:37.399+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/17/.2.delta.de490bce-9de0-412e-bdd5-fd173e90405d.TID820.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/17/2.delta
[2025-07-19T21:02:37.400+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=17),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/17] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/17/2.delta
[2025-07-19T21:02:37.401+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 17 (task 820, attempt 0, stage 9.0)
[2025-07-19T21:02:37.401+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 16 (task 819, attempt 0, stage 9.0)
[2025-07-19T21:02:37.404+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/23/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/23/.2.delta.bff9bc28-c79e-45b5-a6a3-5494ffb2da17.TID826.tmp
[2025-07-19T21:02:37.406+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 16 (task 819, attempt 0, stage 9.0)
[2025-07-19T21:02:37.406+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 16.0 in stage 9.0 (TID 819). 5829 bytes result sent to driver
[2025-07-19T21:02:37.407+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 24.0 in stage 9.0 (TID 827) (8b44f3d35cfa, executor driver, partition 24, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.407+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 16.0 in stage 9.0 (TID 819) in 97 ms on 8b44f3d35cfa (executor driver) (17/200)
[2025-07-19T21:02:37.408+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 24.0 in stage 9.0 (TID 827)
[2025-07-19T21:02:37.411+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/18/.2.delta.43e598e7-053f-4cb9-a269-e8d7a6c97a91.TID821.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/18/2.delta
[2025-07-19T21:02:37.411+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=18),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/18] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/18/2.delta
[2025-07-19T21:02:37.413+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 18 (task 821, attempt 0, stage 9.0)
[2025-07-19T21:02:37.413+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 17 (task 820, attempt 0, stage 9.0)
[2025-07-19T21:02:37.414+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 17.0 in stage 9.0 (TID 820). 5829 bytes result sent to driver
[2025-07-19T21:02:37.415+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 25.0 in stage 9.0 (TID 828) (8b44f3d35cfa, executor driver, partition 25, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.416+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 17.0 in stage 9.0 (TID 820) in 101 ms on 8b44f3d35cfa (executor driver) (18/200)
[2025-07-19T21:02:37.416+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 25.0 in stage 9.0 (TID 828)
[2025-07-19T21:02:37.417+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO LoggingMetricsReporter: Received metrics report: CommitReport{tableName=my_catalog.bronze.Checkins_raw, snapshotId=3393316933098873670, sequenceNumber=128, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.247152167S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=null, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=6255}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=null, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=8928}, addedFilesSizeInBytes=null, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=20262697}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}}, metadata={engine-version=3.5.6, app-id=local-1752958935081, engine-name=spark, iceberg-version=Apache Iceberg 1.4.0 (commit 10367c380098c2e06a49521a33681ac7f6c64b2c)}}
[2025-07-19T21:02:37.417+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO SparkWrite: Committed in 247 ms
[2025-07-19T21:02:37.418+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 1, writer: IcebergStreamingWrite(table=my_catalog.bronze.Checkins_raw, format=PARQUET)] committed.
[2025-07-19T21:02:37.418+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.419+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.419+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d376dd5
[2025-07-19T21:02:37.421+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=24, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.421+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=24),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/24] for update
[2025-07-19T21:02:37.422+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 18 (task 821, attempt 0, stage 9.0)
[2025-07-19T21:02:37.422+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 18.0 in stage 9.0 (TID 821). 5829 bytes result sent to driver
[2025-07-19T21:02:37.423+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 26.0 in stage 9.0 (TID 829) (8b44f3d35cfa, executor driver, partition 26, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.424+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 26.0 in stage 9.0 (TID 829)
[2025-07-19T21:02:37.424+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 18.0 in stage 9.0 (TID 821) in 91 ms on 8b44f3d35cfa (executor driver) (19/200)
[2025-07-19T21:02:37.424+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.424+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.426+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:37.426+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b3ec10e
[2025-07-19T21:02:37.426+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=25, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.427+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=25),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/25] for update
[2025-07-19T21:02:37.427+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.427+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.428+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:37.428+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3366aab
[2025-07-19T21:02:37.429+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=26, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.429+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=26),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/26] for update
[2025-07-19T21:02:37.430+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.431+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/commits/1 using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/commits/.1.c6a4db1d-9703-4bcc-b662-b179ea51e66b.tmp
[2025-07-19T21:02:37.433+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/25/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/25/.2.delta.b3b474f5-8aaa-4ee3-8594-54d4e9952c6e.TID828.tmp
[2025-07-19T21:02:37.434+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/24/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/24/.2.delta.4dbb4f63-8e85-46cf-8e7a-0b78926dcfd1.TID827.tmp
[2025-07-19T21:02:37.439+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/21/.2.delta.fd20f268-4e74-4f57-a155-a70256141bb8.TID824.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/21/2.delta
[2025-07-19T21:02:37.440+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=21),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/21] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/21/2.delta
[2025-07-19T21:02:37.440+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 21 (task 824, attempt 0, stage 9.0)
[2025-07-19T21:02:37.442+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/20/.2.delta.7acbb926-ac8f-4a4c-8933-1298f195d63b.TID823.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/20/2.delta
[2025-07-19T21:02:37.444+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=20),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/20] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/20/2.delta
[2025-07-19T21:02:37.444+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 20 (task 823, attempt 0, stage 9.0)
[2025-07-19T21:02:37.445+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/26/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/26/.2.delta.f24e0939-2485-4aa3-88bf-30b2ef910750.TID829.tmp
[2025-07-19T21:02:37.445+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 21 (task 824, attempt 0, stage 9.0)
[2025-07-19T21:02:37.445+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 21.0 in stage 9.0 (TID 824). 5829 bytes result sent to driver
[2025-07-19T21:02:37.447+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 27.0 in stage 9.0 (TID 830) (8b44f3d35cfa, executor driver, partition 27, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.448+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 27.0 in stage 9.0 (TID 830)
[2025-07-19T21:02:37.448+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 20 (task 823, attempt 0, stage 9.0)
[2025-07-19T21:02:37.449+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 21.0 in stage 9.0 (TID 824) in 96 ms on 8b44f3d35cfa (executor driver) (20/200)
[2025-07-19T21:02:37.449+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 20.0 in stage 9.0 (TID 823). 5829 bytes result sent to driver
[2025-07-19T21:02:37.449+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 28.0 in stage 9.0 (TID 831) (8b44f3d35cfa, executor driver, partition 28, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.449+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 28.0 in stage 9.0 (TID 831)
[2025-07-19T21:02:37.450+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.450+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.451+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 20.0 in stage 9.0 (TID 823) in 103 ms on 8b44f3d35cfa (executor driver) (21/200)
[2025-07-19T21:02:37.451+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@405e40dc
[2025-07-19T21:02:37.451+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=27, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.452+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=27),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/27] for update
[2025-07-19T21:02:37.452+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.454+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/19/.2.delta.34298bf8-d6ff-4595-8717-1db275464657.TID822.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/19/2.delta
[2025-07-19T21:02:37.455+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=19),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/19] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/19/2.delta
[2025-07-19T21:02:37.455+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.456+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.456+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 19 (task 822, attempt 0, stage 9.0)
[2025-07-19T21:02:37.456+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53fe6923
[2025-07-19T21:02:37.457+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=28, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.457+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=28),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/28] for update
[2025-07-19T21:02:37.459+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/23/.2.delta.bff9bc28-c79e-45b5-a6a3-5494ffb2da17.TID826.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/23/2.delta
[2025-07-19T21:02:37.459+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=23),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/23] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/23/2.delta
[2025-07-19T21:02:37.460+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.462+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 23 (task 826, attempt 0, stage 9.0)
[2025-07-19T21:02:37.462+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/22/.2.delta.c184601e-ce68-4249-aeca-fb4f839a7f54.TID825.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/22/2.delta
[2025-07-19T21:02:37.462+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=22),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/22] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/22/2.delta
[2025-07-19T21:02:37.463+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 22 (task 825, attempt 0, stage 9.0)
[2025-07-19T21:02:37.463+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 19 (task 822, attempt 0, stage 9.0)
[2025-07-19T21:02:37.463+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 19.0 in stage 9.0 (TID 822). 5829 bytes result sent to driver
[2025-07-19T21:02:37.464+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 29.0 in stage 9.0 (TID 832) (8b44f3d35cfa, executor driver, partition 29, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.464+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 19.0 in stage 9.0 (TID 822) in 119 ms on 8b44f3d35cfa (executor driver) (22/200)
[2025-07-19T21:02:37.464+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 29.0 in stage 9.0 (TID 832)
[2025-07-19T21:02:37.467+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 22 (task 825, attempt 0, stage 9.0)
[2025-07-19T21:02:37.470+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 22.0 in stage 9.0 (TID 825). 5829 bytes result sent to driver
[2025-07-19T21:02:37.472+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 30.0 in stage 9.0 (TID 833) (8b44f3d35cfa, executor driver, partition 30, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.473+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 30.0 in stage 9.0 (TID 833)
[2025-07-19T21:02:37.473+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/28/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/28/.2.delta.0cb6f8e7-28e1-446b-b242-3a41a0a8ef53.TID831.tmp
[2025-07-19T21:02:37.475+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 22.0 in stage 9.0 (TID 825) in 108 ms on 8b44f3d35cfa (executor driver) (23/200)
[2025-07-19T21:02:37.476+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.476+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T21:02:37.477+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39393114
[2025-07-19T21:02:37.477+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 23 (task 826, attempt 0, stage 9.0)
[2025-07-19T21:02:37.477+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/27/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/27/.2.delta.b804db1a-bded-4334-b49b-a5817b49d2bc.TID830.tmp
[2025-07-19T21:02:37.477+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=29, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.478+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=29),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/29] for update
[2025-07-19T21:02:37.481+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 23.0 in stage 9.0 (TID 826). 5829 bytes result sent to driver
[2025-07-19T21:02:37.482+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 31.0 in stage 9.0 (TID 834) (8b44f3d35cfa, executor driver, partition 31, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.482+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 23.0 in stage 9.0 (TID 826) in 98 ms on 8b44f3d35cfa (executor driver) (24/200)
[2025-07-19T21:02:37.483+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 31.0 in stage 9.0 (TID 834)
[2025-07-19T21:02:37.483+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.484+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.484+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.484+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.485+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@753dd210
[2025-07-19T21:02:37.486+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=31, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.486+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=31),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/31] for update
[2025-07-19T21:02:37.486+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.486+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.487+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6da35578
[2025-07-19T21:02:37.487+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=30, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.488+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=30),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/30] for update
[2025-07-19T21:02:37.489+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.489+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/25/.2.delta.b3b474f5-8aaa-4ee3-8594-54d4e9952c6e.TID828.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/25/2.delta
[2025-07-19T21:02:37.490+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=25),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/25] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/25/2.delta
[2025-07-19T21:02:37.490+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 25 (task 828, attempt 0, stage 9.0)
[2025-07-19T21:02:37.490+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/31/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/31/.2.delta.28607e7f-3806-49a0-8b43-06d4d1086c32.TID834.tmp
[2025-07-19T21:02:37.490+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 25 (task 828, attempt 0, stage 9.0)
[2025-07-19T21:02:37.491+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 25.0 in stage 9.0 (TID 828). 5829 bytes result sent to driver
[2025-07-19T21:02:37.491+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 32.0 in stage 9.0 (TID 835) (8b44f3d35cfa, executor driver, partition 32, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.492+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/29/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/29/.2.delta.62af360a-90dc-4ce5-80b3-a03228702d58.TID832.tmp
[2025-07-19T21:02:37.492+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 25.0 in stage 9.0 (TID 828) in 78 ms on 8b44f3d35cfa (executor driver) (25/200)
[2025-07-19T21:02:37.492+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 32.0 in stage 9.0 (TID 835)
[2025-07-19T21:02:37.492+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.493+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.493+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7fc5ae6c
[2025-07-19T21:02:37.494+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=32, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.495+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=32),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/32] for update
[2025-07-19T21:02:37.495+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/commits/.1.c6a4db1d-9703-4bcc-b662-b179ea51e66b.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T21:00:00+00:00/commits/1
[2025-07-19T21:02:37.495+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.496+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/30/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/30/.2.delta.19b71097-18b7-4857-ad2e-b1ef09fa3237.TID833.tmp
[2025-07-19T21:02:37.496+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO MicroBatchExecution: Streaming query made progress: {
[2025-07-19T21:02:37.497+0000] {subprocess.py:93} INFO -   "id" : "857c6a97-8a45-4319-91e0-4d8882460008",
[2025-07-19T21:02:37.497+0000] {subprocess.py:93} INFO -   "runId" : "fe455bb9-f78f-4c5d-a439-a7e861a32bf0",
[2025-07-19T21:02:37.498+0000] {subprocess.py:93} INFO -   "name" : null,
[2025-07-19T21:02:37.498+0000] {subprocess.py:93} INFO -   "timestamp" : "2025-07-19T21:02:29.718Z",
[2025-07-19T21:02:37.498+0000] {subprocess.py:93} INFO -   "batchId" : 1,
[2025-07-19T21:02:37.499+0000] {subprocess.py:93} INFO -   "numInputRows" : 0,
[2025-07-19T21:02:37.499+0000] {subprocess.py:93} INFO -   "inputRowsPerSecond" : 0.0,
[2025-07-19T21:02:37.499+0000] {subprocess.py:93} INFO -   "processedRowsPerSecond" : 0.0,
[2025-07-19T21:02:37.500+0000] {subprocess.py:93} INFO -   "durationMs" : {
[2025-07-19T21:02:37.500+0000] {subprocess.py:93} INFO -     "addBatch" : 7518,
[2025-07-19T21:02:37.500+0000] {subprocess.py:93} INFO -     "commitOffsets" : 80,
[2025-07-19T21:02:37.501+0000] {subprocess.py:93} INFO -     "getBatch" : 0,
[2025-07-19T21:02:37.502+0000] {subprocess.py:93} INFO -     "latestOffset" : 14,
[2025-07-19T21:02:37.503+0000] {subprocess.py:93} INFO -     "queryPlanning" : 62,
[2025-07-19T21:02:37.504+0000] {subprocess.py:93} INFO -     "triggerExecution" : 7774,
[2025-07-19T21:02:37.505+0000] {subprocess.py:93} INFO -     "walCommit" : 84
[2025-07-19T21:02:37.505+0000] {subprocess.py:93} INFO -   },
[2025-07-19T21:02:37.506+0000] {subprocess.py:93} INFO -   "eventTime" : {
[2025-07-19T21:02:37.507+0000] {subprocess.py:93} INFO -     "watermark" : "2025-07-17T20:39:00.000Z"
[2025-07-19T21:02:37.507+0000] {subprocess.py:93} INFO -   },
[2025-07-19T21:02:37.508+0000] {subprocess.py:93} INFO -   "stateOperators" : [ {
[2025-07-19T21:02:37.508+0000] {subprocess.py:93} INFO -     "operatorName" : "dedupe",
[2025-07-19T21:02:37.508+0000] {subprocess.py:93} INFO -     "numRowsTotal" : 234,
[2025-07-19T21:02:37.509+0000] {subprocess.py:93} INFO -     "numRowsUpdated" : 0,
[2025-07-19T21:02:37.509+0000] {subprocess.py:93} INFO -     "allUpdatesTimeMs" : 335,
[2025-07-19T21:02:37.510+0000] {subprocess.py:93} INFO -     "numRowsRemoved" : 0,
[2025-07-19T21:02:37.511+0000] {subprocess.py:93} INFO -     "allRemovalsTimeMs" : 121,
[2025-07-19T21:02:37.511+0000] {subprocess.py:93} INFO -     "commitTimeMs" : 14423,
[2025-07-19T21:02:37.512+0000] {subprocess.py:93} INFO -     "memoryUsedBytes" : 148776,
[2025-07-19T21:02:37.512+0000] {subprocess.py:93} INFO -     "numRowsDroppedByWatermark" : 0,
[2025-07-19T21:02:37.513+0000] {subprocess.py:93} INFO -     "numShufflePartitions" : 200,
[2025-07-19T21:02:37.513+0000] {subprocess.py:93} INFO -     "numStateStoreInstances" : 200,
[2025-07-19T21:02:37.513+0000] {subprocess.py:93} INFO -     "customMetrics" : {
[2025-07-19T21:02:37.513+0000] {subprocess.py:93} INFO -       "loadedMapCacheHitCount" : 200,
[2025-07-19T21:02:37.513+0000] {subprocess.py:93} INFO -       "loadedMapCacheMissCount" : 0,
[2025-07-19T21:02:37.513+0000] {subprocess.py:93} INFO -       "numDroppedDuplicateRows" : 0,
[2025-07-19T21:02:37.513+0000] {subprocess.py:93} INFO -       "stateOnCurrentVersionSizeBytes" : 69528
[2025-07-19T21:02:37.513+0000] {subprocess.py:93} INFO -     }
[2025-07-19T21:02:37.513+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T21:02:37.513+0000] {subprocess.py:93} INFO -   "sources" : [ {
[2025-07-19T21:02:37.514+0000] {subprocess.py:93} INFO -     "description" : "KafkaV2[Subscribe[checkins]]",
[2025-07-19T21:02:37.514+0000] {subprocess.py:93} INFO -     "startOffset" : {
[2025-07-19T21:02:37.515+0000] {subprocess.py:93} INFO -       "checkins" : {
[2025-07-19T21:02:37.515+0000] {subprocess.py:93} INFO -         "0" : 234
[2025-07-19T21:02:37.515+0000] {subprocess.py:93} INFO -       }
[2025-07-19T21:02:37.515+0000] {subprocess.py:93} INFO -     },
[2025-07-19T21:02:37.515+0000] {subprocess.py:93} INFO -     "endOffset" : {
[2025-07-19T21:02:37.515+0000] {subprocess.py:93} INFO -       "checkins" : {
[2025-07-19T21:02:37.515+0000] {subprocess.py:93} INFO -         "0" : 234
[2025-07-19T21:02:37.515+0000] {subprocess.py:93} INFO -       }
[2025-07-19T21:02:37.515+0000] {subprocess.py:93} INFO -     },
[2025-07-19T21:02:37.516+0000] {subprocess.py:93} INFO -     "latestOffset" : {
[2025-07-19T21:02:37.516+0000] {subprocess.py:93} INFO -       "checkins" : {
[2025-07-19T21:02:37.516+0000] {subprocess.py:93} INFO -         "0" : 234
[2025-07-19T21:02:37.516+0000] {subprocess.py:93} INFO -       }
[2025-07-19T21:02:37.516+0000] {subprocess.py:93} INFO -     },
[2025-07-19T21:02:37.516+0000] {subprocess.py:93} INFO -     "numInputRows" : 0,
[2025-07-19T21:02:37.516+0000] {subprocess.py:93} INFO -     "inputRowsPerSecond" : 0.0,
[2025-07-19T21:02:37.516+0000] {subprocess.py:93} INFO -     "processedRowsPerSecond" : 0.0,
[2025-07-19T21:02:37.517+0000] {subprocess.py:93} INFO -     "metrics" : {
[2025-07-19T21:02:37.519+0000] {subprocess.py:93} INFO -       "avgOffsetsBehindLatest" : "0.0",
[2025-07-19T21:02:37.520+0000] {subprocess.py:93} INFO -       "maxOffsetsBehindLatest" : "0",
[2025-07-19T21:02:37.521+0000] {subprocess.py:93} INFO -       "minOffsetsBehindLatest" : "0"
[2025-07-19T21:02:37.521+0000] {subprocess.py:93} INFO -     }
[2025-07-19T21:02:37.522+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T21:02:37.522+0000] {subprocess.py:93} INFO -   "sink" : {
[2025-07-19T21:02:37.523+0000] {subprocess.py:93} INFO -     "description" : "my_catalog.bronze.Checkins_raw",
[2025-07-19T21:02:37.523+0000] {subprocess.py:93} INFO -     "numOutputRows" : 0
[2025-07-19T21:02:37.523+0000] {subprocess.py:93} INFO -   }
[2025-07-19T21:02:37.524+0000] {subprocess.py:93} INFO - }
[2025-07-19T21:02:37.524+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/24/.2.delta.4dbb4f63-8e85-46cf-8e7a-0b78926dcfd1.TID827.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/24/2.delta
[2025-07-19T21:02:37.524+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=24),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/24] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/24/2.delta
[2025-07-19T21:02:37.525+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 24 (task 827, attempt 0, stage 9.0)
[2025-07-19T21:02:37.525+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 24 (task 827, attempt 0, stage 9.0)
[2025-07-19T21:02:37.525+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 24.0 in stage 9.0 (TID 827). 5829 bytes result sent to driver
[2025-07-19T21:02:37.525+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 33.0 in stage 9.0 (TID 836) (8b44f3d35cfa, executor driver, partition 33, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.526+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 24.0 in stage 9.0 (TID 827) in 96 ms on 8b44f3d35cfa (executor driver) (26/200)
[2025-07-19T21:02:37.526+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 33.0 in stage 9.0 (TID 836)
[2025-07-19T21:02:37.527+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.527+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.527+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/32/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/32/.2.delta.db54485f-dce5-4b9f-9dd3-fe0d06a45413.TID835.tmp
[2025-07-19T21:02:37.528+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/26/.2.delta.f24e0939-2485-4aa3-88bf-30b2ef910750.TID829.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/26/2.delta
[2025-07-19T21:02:37.528+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=26),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/26] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/26/2.delta
[2025-07-19T21:02:37.528+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@48f55182
[2025-07-19T21:02:37.528+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=33, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.529+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 26 (task 829, attempt 0, stage 9.0)
[2025-07-19T21:02:37.531+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=33),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/33] for update
[2025-07-19T21:02:37.531+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.531+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 26 (task 829, attempt 0, stage 9.0)
[2025-07-19T21:02:37.532+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 26.0 in stage 9.0 (TID 829). 5829 bytes result sent to driver
[2025-07-19T21:02:37.533+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 34.0 in stage 9.0 (TID 837) (8b44f3d35cfa, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.534+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 26.0 in stage 9.0 (TID 829) in 94 ms on 8b44f3d35cfa (executor driver) (27/200)
[2025-07-19T21:02:37.535+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 34.0 in stage 9.0 (TID 837)
[2025-07-19T21:02:37.536+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/28/.2.delta.0cb6f8e7-28e1-446b-b242-3a41a0a8ef53.TID831.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/28/2.delta
[2025-07-19T21:02:37.536+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=28),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/28] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/28/2.delta
[2025-07-19T21:02:37.537+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 28 (task 831, attempt 0, stage 9.0)
[2025-07-19T21:02:37.538+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.538+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.538+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 28 (task 831, attempt 0, stage 9.0)
[2025-07-19T21:02:37.538+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/33/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/33/.2.delta.a195a5c0-6829-4f20-b4b7-b0f8a989f7c0.TID836.tmp
[2025-07-19T21:02:37.538+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@167fef30
[2025-07-19T21:02:37.538+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=34, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.538+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=34),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/34] for update
[2025-07-19T21:02:37.538+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 28.0 in stage 9.0 (TID 831). 5829 bytes result sent to driver
[2025-07-19T21:02:37.539+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.539+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 35.0 in stage 9.0 (TID 838) (8b44f3d35cfa, executor driver, partition 35, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.539+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 28.0 in stage 9.0 (TID 831) in 72 ms on 8b44f3d35cfa (executor driver) (28/200)
[2025-07-19T21:02:37.539+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 35.0 in stage 9.0 (TID 838)
[2025-07-19T21:02:37.540+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.540+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.540+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/27/.2.delta.b804db1a-bded-4334-b49b-a5817b49d2bc.TID830.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/27/2.delta
[2025-07-19T21:02:37.540+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=27),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/27] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/27/2.delta
[2025-07-19T21:02:37.541+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2343ffd2
[2025-07-19T21:02:37.541+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 27 (task 830, attempt 0, stage 9.0)
[2025-07-19T21:02:37.542+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=35, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.543+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=35),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/35] for update
[2025-07-19T21:02:37.543+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.543+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/31/.2.delta.28607e7f-3806-49a0-8b43-06d4d1086c32.TID834.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/31/2.delta
[2025-07-19T21:02:37.543+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=31),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/31] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/31/2.delta
[2025-07-19T21:02:37.544+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 31 (task 834, attempt 0, stage 9.0)
[2025-07-19T21:02:37.544+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 31 (task 834, attempt 0, stage 9.0)
[2025-07-19T21:02:37.544+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 31.0 in stage 9.0 (TID 834). 5786 bytes result sent to driver
[2025-07-19T21:02:37.545+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 36.0 in stage 9.0 (TID 839) (8b44f3d35cfa, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.545+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/34/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/34/.2.delta.86b2f211-6d75-480e-8428-6eec4bd89393.TID837.tmp
[2025-07-19T21:02:37.545+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 36.0 in stage 9.0 (TID 839)
[2025-07-19T21:02:37.546+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 31.0 in stage 9.0 (TID 834) in 63 ms on 8b44f3d35cfa (executor driver) (29/200)
[2025-07-19T21:02:37.546+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 27 (task 830, attempt 0, stage 9.0)
[2025-07-19T21:02:37.546+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 27.0 in stage 9.0 (TID 830). 5829 bytes result sent to driver
[2025-07-19T21:02:37.546+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 37.0 in stage 9.0 (TID 840) (8b44f3d35cfa, executor driver, partition 37, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.546+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 37.0 in stage 9.0 (TID 840)
[2025-07-19T21:02:37.546+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.546+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.546+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 27.0 in stage 9.0 (TID 830) in 92 ms on 8b44f3d35cfa (executor driver) (30/200)
[2025-07-19T21:02:37.546+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.547+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:37.548+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c779142
[2025-07-19T21:02:37.548+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/35/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/35/.2.delta.5f28d98e-d1bd-4ad9-9b9a-5b700905d9c7.TID838.tmp
[2025-07-19T21:02:37.548+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=36, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.549+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=36),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/36] for update
[2025-07-19T21:02:37.549+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b848384
[2025-07-19T21:02:37.550+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/29/.2.delta.62af360a-90dc-4ce5-80b3-a03228702d58.TID832.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/29/2.delta
[2025-07-19T21:02:37.551+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=29),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/29] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/29/2.delta
[2025-07-19T21:02:37.551+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=37, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.552+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=37),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/37] for update
[2025-07-19T21:02:37.552+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 29 (task 832, attempt 0, stage 9.0)
[2025-07-19T21:02:37.552+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.553+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.553+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 29 (task 832, attempt 0, stage 9.0)
[2025-07-19T21:02:37.554+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 29.0 in stage 9.0 (TID 832). 5829 bytes result sent to driver
[2025-07-19T21:02:37.555+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 38.0 in stage 9.0 (TID 841) (8b44f3d35cfa, executor driver, partition 38, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.556+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 29.0 in stage 9.0 (TID 832) in 85 ms on 8b44f3d35cfa (executor driver) (31/200)
[2025-07-19T21:02:37.556+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 38.0 in stage 9.0 (TID 841)
[2025-07-19T21:02:37.556+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/30/.2.delta.19b71097-18b7-4857-ad2e-b1ef09fa3237.TID833.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/30/2.delta
[2025-07-19T21:02:37.556+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=30),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/30] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/30/2.delta
[2025-07-19T21:02:37.556+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.556+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.557+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73fc657d
[2025-07-19T21:02:37.557+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 30 (task 833, attempt 0, stage 9.0)
[2025-07-19T21:02:37.557+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=38, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.557+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=38),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/38] for update
[2025-07-19T21:02:37.557+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/37/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/37/.2.delta.50feeed7-9e3f-420c-8289-f86f9742a719.TID840.tmp
[2025-07-19T21:02:37.558+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.560+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 30 (task 833, attempt 0, stage 9.0)
[2025-07-19T21:02:37.561+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 30.0 in stage 9.0 (TID 833). 5829 bytes result sent to driver
[2025-07-19T21:02:37.561+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 39.0 in stage 9.0 (TID 842) (8b44f3d35cfa, executor driver, partition 39, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.563+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 30.0 in stage 9.0 (TID 833) in 94 ms on 8b44f3d35cfa (executor driver) (32/200)
[2025-07-19T21:02:37.564+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 39.0 in stage 9.0 (TID 842)
[2025-07-19T21:02:37.565+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/33/.2.delta.a195a5c0-6829-4f20-b4b7-b0f8a989f7c0.TID836.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/33/2.delta
[2025-07-19T21:02:37.565+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=33),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/33] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/33/2.delta
[2025-07-19T21:02:37.566+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 33 (task 836, attempt 0, stage 9.0)
[2025-07-19T21:02:37.577+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.579+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.581+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/32/.2.delta.db54485f-dce5-4b9f-9dd3-fe0d06a45413.TID835.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/32/2.delta
[2025-07-19T21:02:37.582+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=32),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/32] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/32/2.delta
[2025-07-19T21:02:37.582+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/36/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/36/.2.delta.70cb8d04-b3e1-43a9-97b3-2c653b19fb4a.TID839.tmp
[2025-07-19T21:02:37.582+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/38/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/38/.2.delta.112a0a79-5838-491b-a3fd-c9b26f54ad64.TID841.tmp
[2025-07-19T21:02:37.582+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 32 (task 835, attempt 0, stage 9.0)
[2025-07-19T21:02:37.582+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1fe623f6
[2025-07-19T21:02:37.583+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=39, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.583+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=39),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/39] for update
[2025-07-19T21:02:37.584+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.584+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 33 (task 836, attempt 0, stage 9.0)
[2025-07-19T21:02:37.584+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 33.0 in stage 9.0 (TID 836). 5829 bytes result sent to driver
[2025-07-19T21:02:37.584+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 40.0 in stage 9.0 (TID 843) (8b44f3d35cfa, executor driver, partition 40, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.584+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 33.0 in stage 9.0 (TID 836) in 80 ms on 8b44f3d35cfa (executor driver) (33/200)
[2025-07-19T21:02:37.584+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 40.0 in stage 9.0 (TID 843)
[2025-07-19T21:02:37.584+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 32 (task 835, attempt 0, stage 9.0)
[2025-07-19T21:02:37.584+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 32.0 in stage 9.0 (TID 835). 5829 bytes result sent to driver
[2025-07-19T21:02:37.584+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 41.0 in stage 9.0 (TID 844) (8b44f3d35cfa, executor driver, partition 41, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.584+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 32.0 in stage 9.0 (TID 835) in 97 ms on 8b44f3d35cfa (executor driver) (34/200)
[2025-07-19T21:02:37.585+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 41.0 in stage 9.0 (TID 844)
[2025-07-19T21:02:37.585+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/39/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/39/.2.delta.e8b13832-dd31-4927-8ed3-b8e33bab694f.TID842.tmp
[2025-07-19T21:02:37.585+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.585+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.585+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.585+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.586+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e847654
[2025-07-19T21:02:37.587+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=41, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.587+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=41),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/41] for update
[2025-07-19T21:02:37.587+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@60522791
[2025-07-19T21:02:37.587+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=40, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.588+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=40),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/40] for update
[2025-07-19T21:02:37.588+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.590+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.595+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/34/.2.delta.86b2f211-6d75-480e-8428-6eec4bd89393.TID837.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/34/2.delta
[2025-07-19T21:02:37.596+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=34),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/34] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/34/2.delta
[2025-07-19T21:02:37.596+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 34 (task 837, attempt 0, stage 9.0)
[2025-07-19T21:02:37.598+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 34 (task 837, attempt 0, stage 9.0)
[2025-07-19T21:02:37.599+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 34.0 in stage 9.0 (TID 837). 5829 bytes result sent to driver
[2025-07-19T21:02:37.600+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 42.0 in stage 9.0 (TID 845) (8b44f3d35cfa, executor driver, partition 42, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.600+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/41/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/41/.2.delta.6f426704-1d08-4218-8636-25119764fc75.TID844.tmp
[2025-07-19T21:02:37.601+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 34.0 in stage 9.0 (TID 837) in 89 ms on 8b44f3d35cfa (executor driver) (35/200)
[2025-07-19T21:02:37.601+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 42.0 in stage 9.0 (TID 845)
[2025-07-19T21:02:37.603+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.603+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.603+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/40/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/40/.2.delta.8736c036-4f5f-4036-8a57-c8ef1a93a7b0.TID843.tmp
[2025-07-19T21:02:37.604+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/35/.2.delta.5f28d98e-d1bd-4ad9-9b9a-5b700905d9c7.TID838.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/35/2.delta
[2025-07-19T21:02:37.605+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=35),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/35] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/35/2.delta
[2025-07-19T21:02:37.605+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 35 (task 838, attempt 0, stage 9.0)
[2025-07-19T21:02:37.606+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c7f5ab4
[2025-07-19T21:02:37.606+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=42, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.606+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=42),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/42] for update
[2025-07-19T21:02:37.611+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.612+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 35 (task 838, attempt 0, stage 9.0)
[2025-07-19T21:02:37.613+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 35.0 in stage 9.0 (TID 838). 5829 bytes result sent to driver
[2025-07-19T21:02:37.614+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 35.0 in stage 9.0 (TID 838) in 92 ms on 8b44f3d35cfa (executor driver) (36/200)
[2025-07-19T21:02:37.614+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 43.0 in stage 9.0 (TID 846) (8b44f3d35cfa, executor driver, partition 43, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.616+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 43.0 in stage 9.0 (TID 846)
[2025-07-19T21:02:37.617+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/39/.2.delta.e8b13832-dd31-4927-8ed3-b8e33bab694f.TID842.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/39/2.delta
[2025-07-19T21:02:37.617+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=39),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/39] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/39/2.delta
[2025-07-19T21:02:37.617+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.617+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.618+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/37/.2.delta.50feeed7-9e3f-420c-8289-f86f9742a719.TID840.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/37/2.delta
[2025-07-19T21:02:37.619+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=37),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/37] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/37/2.delta
[2025-07-19T21:02:37.619+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 39 (task 842, attempt 0, stage 9.0)
[2025-07-19T21:02:37.619+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 37 (task 840, attempt 0, stage 9.0)
[2025-07-19T21:02:37.620+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6cf6f236
[2025-07-19T21:02:37.620+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=43, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.620+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=43),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/43] for update
[2025-07-19T21:02:37.621+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 37 (task 840, attempt 0, stage 9.0)
[2025-07-19T21:02:37.628+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 39 (task 842, attempt 0, stage 9.0)
[2025-07-19T21:02:37.628+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 37.0 in stage 9.0 (TID 840). 5915 bytes result sent to driver
[2025-07-19T21:02:37.629+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 39.0 in stage 9.0 (TID 842). 5872 bytes result sent to driver
[2025-07-19T21:02:37.629+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 44.0 in stage 9.0 (TID 847) (8b44f3d35cfa, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.629+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 44.0 in stage 9.0 (TID 847)
[2025-07-19T21:02:37.629+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 45.0 in stage 9.0 (TID 848) (8b44f3d35cfa, executor driver, partition 45, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.629+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/42/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/42/.2.delta.63c2e141-28d6-48db-8047-642c1651f976.TID845.tmp
[2025-07-19T21:02:37.629+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 37.0 in stage 9.0 (TID 840) in 90 ms on 8b44f3d35cfa (executor driver) (37/200)
[2025-07-19T21:02:37.629+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/38/.2.delta.112a0a79-5838-491b-a3fd-c9b26f54ad64.TID841.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/38/2.delta
[2025-07-19T21:02:37.629+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=38),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/38] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/38/2.delta
[2025-07-19T21:02:37.630+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 39.0 in stage 9.0 (TID 842) in 66 ms on 8b44f3d35cfa (executor driver) (38/200)
[2025-07-19T21:02:37.631+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 38 (task 841, attempt 0, stage 9.0)
[2025-07-19T21:02:37.631+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 45.0 in stage 9.0 (TID 848)
[2025-07-19T21:02:37.631+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/36/.2.delta.70cb8d04-b3e1-43a9-97b3-2c653b19fb4a.TID839.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/36/2.delta
[2025-07-19T21:02:37.631+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=36),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/36] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/36/2.delta
[2025-07-19T21:02:37.632+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.632+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.632+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.640+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 36 (task 839, attempt 0, stage 9.0)
[2025-07-19T21:02:37.642+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.643+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.643+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@256b4688
[2025-07-19T21:02:37.644+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=44, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.644+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=44),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/44] for update
[2025-07-19T21:02:37.645+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 38 (task 841, attempt 0, stage 9.0)
[2025-07-19T21:02:37.645+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 38.0 in stage 9.0 (TID 841). 5872 bytes result sent to driver
[2025-07-19T21:02:37.646+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 46.0 in stage 9.0 (TID 849) (8b44f3d35cfa, executor driver, partition 46, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.647+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.649+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28ab18b9
[2025-07-19T21:02:37.650+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 46.0 in stage 9.0 (TID 849)
[2025-07-19T21:02:37.650+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 38.0 in stage 9.0 (TID 841) in 91 ms on 8b44f3d35cfa (executor driver) (39/200)
[2025-07-19T21:02:37.653+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=45, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.653+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=45),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/45] for update
[2025-07-19T21:02:37.654+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 36 (task 839, attempt 0, stage 9.0)
[2025-07-19T21:02:37.654+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 36.0 in stage 9.0 (TID 839). 5872 bytes result sent to driver
[2025-07-19T21:02:37.655+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.655+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.656+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4bc43157
[2025-07-19T21:02:37.656+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=46, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.657+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=46),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/46] for update
[2025-07-19T21:02:37.657+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 47.0 in stage 9.0 (TID 850) (8b44f3d35cfa, executor driver, partition 47, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.657+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 36.0 in stage 9.0 (TID 839) in 110 ms on 8b44f3d35cfa (executor driver) (40/200)
[2025-07-19T21:02:37.657+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 47.0 in stage 9.0 (TID 850)
[2025-07-19T21:02:37.658+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.658+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.658+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@62727c7f
[2025-07-19T21:02:37.659+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=47, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.659+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=47),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/47] for update
[2025-07-19T21:02:37.659+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.660+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.660+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.660+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/44/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/44/.2.delta.ec47a26d-81d7-43c4-af31-f27ed9160ca3.TID847.tmp
[2025-07-19T21:02:37.661+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/43/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/43/.2.delta.1359f3ce-6457-41f2-9804-5edde96af170.TID846.tmp
[2025-07-19T21:02:37.669+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/45/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/45/.2.delta.655eeb53-07e6-4ee6-b1b6-b46d441f4160.TID848.tmp
[2025-07-19T21:02:37.670+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/47/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/47/.2.delta.4584c4bd-91e4-4144-afd3-2f3f4fd4a9df.TID850.tmp
[2025-07-19T21:02:37.671+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/41/.2.delta.6f426704-1d08-4218-8636-25119764fc75.TID844.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/41/2.delta
[2025-07-19T21:02:37.671+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=41),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/41] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/41/2.delta
[2025-07-19T21:02:37.673+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/40/.2.delta.8736c036-4f5f-4036-8a57-c8ef1a93a7b0.TID843.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/40/2.delta
[2025-07-19T21:02:37.673+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=40),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/40] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/40/2.delta
[2025-07-19T21:02:37.674+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 41 (task 844, attempt 0, stage 9.0)
[2025-07-19T21:02:37.674+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 40 (task 843, attempt 0, stage 9.0)
[2025-07-19T21:02:37.674+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/46/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/46/.2.delta.f399042e-0d8f-4d41-829f-cca4269124d0.TID849.tmp
[2025-07-19T21:02:37.677+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 41 (task 844, attempt 0, stage 9.0)
[2025-07-19T21:02:37.686+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 40 (task 843, attempt 0, stage 9.0)
[2025-07-19T21:02:37.686+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 40.0 in stage 9.0 (TID 843). 5872 bytes result sent to driver
[2025-07-19T21:02:37.688+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 41.0 in stage 9.0 (TID 844). 5915 bytes result sent to driver
[2025-07-19T21:02:37.689+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 48.0 in stage 9.0 (TID 851) (8b44f3d35cfa, executor driver, partition 48, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.689+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 49.0 in stage 9.0 (TID 852) (8b44f3d35cfa, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.689+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 48.0 in stage 9.0 (TID 851)
[2025-07-19T21:02:37.690+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 49.0 in stage 9.0 (TID 852)
[2025-07-19T21:02:37.690+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 40.0 in stage 9.0 (TID 843) in 108 ms on 8b44f3d35cfa (executor driver) (41/200)
[2025-07-19T21:02:37.690+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 41.0 in stage 9.0 (TID 844) in 106 ms on 8b44f3d35cfa (executor driver) (42/200)
[2025-07-19T21:02:37.693+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.694+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.694+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31cb0bf
[2025-07-19T21:02:37.694+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.697+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 8b44f3d35cfa:38433 in memory (size: 15.9 KiB, free: 434.3 MiB)
[2025-07-19T21:02:37.698+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T21:02:37.699+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=48, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.700+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=48),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/48] for update
[2025-07-19T21:02:37.701+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3a111d5c
[2025-07-19T21:02:37.701+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.701+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=49, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.702+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=49),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/49] for update
[2025-07-19T21:02:37.702+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.704+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/42/.2.delta.63c2e141-28d6-48db-8047-642c1651f976.TID845.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/42/2.delta
[2025-07-19T21:02:37.704+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=42),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/42] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/42/2.delta
[2025-07-19T21:02:37.705+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 42 (task 845, attempt 0, stage 9.0)
[2025-07-19T21:02:37.709+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 42 (task 845, attempt 0, stage 9.0)
[2025-07-19T21:02:37.710+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 42.0 in stage 9.0 (TID 845). 5872 bytes result sent to driver
[2025-07-19T21:02:37.711+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 50.0 in stage 9.0 (TID 853) (8b44f3d35cfa, executor driver, partition 50, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.712+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 8b44f3d35cfa:38433 in memory (size: 29.5 KiB, free: 434.3 MiB)
[2025-07-19T21:02:37.712+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 50.0 in stage 9.0 (TID 853)
[2025-07-19T21:02:37.713+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 42.0 in stage 9.0 (TID 845) in 111 ms on 8b44f3d35cfa (executor driver) (43/200)
[2025-07-19T21:02:37.714+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.715+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.715+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@380a06d8
[2025-07-19T21:02:37.716+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/43/.2.delta.1359f3ce-6457-41f2-9804-5edde96af170.TID846.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/43/2.delta
[2025-07-19T21:02:37.717+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=43),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/43] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/43/2.delta
[2025-07-19T21:02:37.718+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/48/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/48/.2.delta.fcafb418-d3f4-46b1-aca9-2e725ed529d8.TID851.tmp
[2025-07-19T21:02:37.718+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=50, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.718+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=50),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/50] for update
[2025-07-19T21:02:37.718+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/44/.2.delta.ec47a26d-81d7-43c4-af31-f27ed9160ca3.TID847.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/44/2.delta
[2025-07-19T21:02:37.718+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=44),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/44] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/44/2.delta
[2025-07-19T21:02:37.718+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 43 (task 846, attempt 0, stage 9.0)
[2025-07-19T21:02:37.719+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 44 (task 847, attempt 0, stage 9.0)
[2025-07-19T21:02:37.719+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.723+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 43 (task 846, attempt 0, stage 9.0)
[2025-07-19T21:02:37.724+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 43.0 in stage 9.0 (TID 846). 5872 bytes result sent to driver
[2025-07-19T21:02:37.725+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/49/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/49/.2.delta.9b35e5a5-2eff-4333-b3a3-872c0d85b969.TID852.tmp
[2025-07-19T21:02:37.726+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 51.0 in stage 9.0 (TID 854) (8b44f3d35cfa, executor driver, partition 51, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.727+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 51.0 in stage 9.0 (TID 854)
[2025-07-19T21:02:37.728+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 43.0 in stage 9.0 (TID 846) in 112 ms on 8b44f3d35cfa (executor driver) (44/200)
[2025-07-19T21:02:37.730+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 44 (task 847, attempt 0, stage 9.0)
[2025-07-19T21:02:37.730+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 44.0 in stage 9.0 (TID 847). 5872 bytes result sent to driver
[2025-07-19T21:02:37.731+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 52.0 in stage 9.0 (TID 855) (8b44f3d35cfa, executor driver, partition 52, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.731+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.731+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.731+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 52.0 in stage 9.0 (TID 855)
[2025-07-19T21:02:37.732+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 44.0 in stage 9.0 (TID 847) in 101 ms on 8b44f3d35cfa (executor driver) (45/200)
[2025-07-19T21:02:37.733+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 8b44f3d35cfa:38433 in memory (size: 35.4 KiB, free: 434.3 MiB)
[2025-07-19T21:02:37.734+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3167516c
[2025-07-19T21:02:37.735+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=51, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.735+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=51),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/51] for update
[2025-07-19T21:02:37.735+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.735+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.735+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c125f10
[2025-07-19T21:02:37.735+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=52, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.736+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=52),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/52] for update
[2025-07-19T21:02:37.736+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.740+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/47/.2.delta.4584c4bd-91e4-4144-afd3-2f3f4fd4a9df.TID850.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/47/2.delta
[2025-07-19T21:02:37.741+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=47),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/47] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/47/2.delta
[2025-07-19T21:02:37.741+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/45/.2.delta.655eeb53-07e6-4ee6-b1b6-b46d441f4160.TID848.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/45/2.delta
[2025-07-19T21:02:37.743+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=45),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/45] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/45/2.delta
[2025-07-19T21:02:37.743+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/46/.2.delta.f399042e-0d8f-4d41-829f-cca4269124d0.TID849.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/46/2.delta
[2025-07-19T21:02:37.744+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=46),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/46] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/46/2.delta
[2025-07-19T21:02:37.744+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 45 (task 848, attempt 0, stage 9.0)
[2025-07-19T21:02:37.745+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/50/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/50/.2.delta.3a44837f-f10a-469c-b57a-5d6ad24bddd7.TID853.tmp
[2025-07-19T21:02:37.746+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.746+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 46 (task 849, attempt 0, stage 9.0)
[2025-07-19T21:02:37.746+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 47 (task 850, attempt 0, stage 9.0)
[2025-07-19T21:02:37.747+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 46 (task 849, attempt 0, stage 9.0)
[2025-07-19T21:02:37.747+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 45 (task 848, attempt 0, stage 9.0)
[2025-07-19T21:02:37.747+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 45.0 in stage 9.0 (TID 848). 5872 bytes result sent to driver
[2025-07-19T21:02:37.747+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 46.0 in stage 9.0 (TID 849). 5829 bytes result sent to driver
[2025-07-19T21:02:37.747+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 53.0 in stage 9.0 (TID 856) (8b44f3d35cfa, executor driver, partition 53, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.748+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 54.0 in stage 9.0 (TID 857) (8b44f3d35cfa, executor driver, partition 54, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.748+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 53.0 in stage 9.0 (TID 856)
[2025-07-19T21:02:37.749+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 54.0 in stage 9.0 (TID 857)
[2025-07-19T21:02:37.750+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 45.0 in stage 9.0 (TID 848) in 119 ms on 8b44f3d35cfa (executor driver) (46/200)
[2025-07-19T21:02:37.750+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 46.0 in stage 9.0 (TID 849) in 109 ms on 8b44f3d35cfa (executor driver) (47/200)
[2025-07-19T21:02:37.751+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.751+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.752+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@16ab208b
[2025-07-19T21:02:37.755+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.756+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=54, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.756+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=54),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/54] for update
[2025-07-19T21:02:37.757+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:37.757+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.757+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 47 (task 850, attempt 0, stage 9.0)
[2025-07-19T21:02:37.758+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@938c95f
[2025-07-19T21:02:37.759+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 47.0 in stage 9.0 (TID 850). 5829 bytes result sent to driver
[2025-07-19T21:02:37.759+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=53, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.759+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=53),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/53] for update
[2025-07-19T21:02:37.759+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.759+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/51/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/51/.2.delta.efae1c38-280c-4104-b950-bd6ef1e9275b.TID854.tmp
[2025-07-19T21:02:37.760+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 55.0 in stage 9.0 (TID 858) (8b44f3d35cfa, executor driver, partition 55, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.760+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 55.0 in stage 9.0 (TID 858)
[2025-07-19T21:02:37.760+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 47.0 in stage 9.0 (TID 850) in 115 ms on 8b44f3d35cfa (executor driver) (48/200)
[2025-07-19T21:02:37.761+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/52/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/52/.2.delta.ac0cfa3e-2845-42f6-b673-3a1fa3f16ac7.TID855.tmp
[2025-07-19T21:02:37.762+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.762+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.762+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ad7438c
[2025-07-19T21:02:37.769+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=55, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.770+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=55),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/55] for update
[2025-07-19T21:02:37.770+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.770+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/54/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/54/.2.delta.3733b724-0e6c-45b7-9836-8f9c75b11f1c.TID857.tmp
[2025-07-19T21:02:37.776+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/53/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/53/.2.delta.b7c95ff8-c87c-4fae-8720-417cafce59c0.TID856.tmp
[2025-07-19T21:02:37.780+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/48/.2.delta.fcafb418-d3f4-46b1-aca9-2e725ed529d8.TID851.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/48/2.delta
[2025-07-19T21:02:37.780+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=48),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/48] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/48/2.delta
[2025-07-19T21:02:37.780+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 48 (task 851, attempt 0, stage 9.0)
[2025-07-19T21:02:37.782+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 48 (task 851, attempt 0, stage 9.0)
[2025-07-19T21:02:37.785+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 48.0 in stage 9.0 (TID 851). 5829 bytes result sent to driver
[2025-07-19T21:02:37.786+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 56.0 in stage 9.0 (TID 859) (8b44f3d35cfa, executor driver, partition 56, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.787+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 56.0 in stage 9.0 (TID 859)
[2025-07-19T21:02:37.788+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/49/.2.delta.9b35e5a5-2eff-4333-b3a3-872c0d85b969.TID852.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/49/2.delta
[2025-07-19T21:02:37.789+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=49),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/49] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/49/2.delta
[2025-07-19T21:02:37.790+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/55/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/55/.2.delta.a644ba52-8fe3-4c54-a306-1d860a861b05.TID858.tmp
[2025-07-19T21:02:37.791+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.793+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.793+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 48.0 in stage 9.0 (TID 851) in 101 ms on 8b44f3d35cfa (executor driver) (49/200)
[2025-07-19T21:02:37.794+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 49 (task 852, attempt 0, stage 9.0)
[2025-07-19T21:02:37.794+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56c01761
[2025-07-19T21:02:37.794+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=56, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.794+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=56),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/56] for update
[2025-07-19T21:02:37.796+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 49 (task 852, attempt 0, stage 9.0)
[2025-07-19T21:02:37.798+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.798+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 49.0 in stage 9.0 (TID 852). 5829 bytes result sent to driver
[2025-07-19T21:02:37.798+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 57.0 in stage 9.0 (TID 860) (8b44f3d35cfa, executor driver, partition 57, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.799+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 57.0 in stage 9.0 (TID 860)
[2025-07-19T21:02:37.801+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 49.0 in stage 9.0 (TID 852) in 111 ms on 8b44f3d35cfa (executor driver) (50/200)
[2025-07-19T21:02:37.801+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.801+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.802+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ca1f7b8
[2025-07-19T21:02:37.802+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=57, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.802+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=57),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/57] for update
[2025-07-19T21:02:37.803+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.813+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/50/.2.delta.3a44837f-f10a-469c-b57a-5d6ad24bddd7.TID853.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/50/2.delta
[2025-07-19T21:02:37.814+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=50),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/50] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/50/2.delta
[2025-07-19T21:02:37.814+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 50 (task 853, attempt 0, stage 9.0)
[2025-07-19T21:02:37.815+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/56/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/56/.2.delta.10df3f9f-d8d4-4f0a-9e18-38b44a286cff.TID859.tmp
[2025-07-19T21:02:37.817+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 50 (task 853, attempt 0, stage 9.0)
[2025-07-19T21:02:37.818+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/51/.2.delta.efae1c38-280c-4104-b950-bd6ef1e9275b.TID854.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/51/2.delta
[2025-07-19T21:02:37.819+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=51),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/51] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/51/2.delta
[2025-07-19T21:02:37.821+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 51 (task 854, attempt 0, stage 9.0)
[2025-07-19T21:02:37.822+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 50.0 in stage 9.0 (TID 853). 5829 bytes result sent to driver
[2025-07-19T21:02:37.822+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 58.0 in stage 9.0 (TID 861) (8b44f3d35cfa, executor driver, partition 58, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.823+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 58.0 in stage 9.0 (TID 861)
[2025-07-19T21:02:37.825+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/54/.2.delta.3733b724-0e6c-45b7-9836-8f9c75b11f1c.TID857.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/54/2.delta
[2025-07-19T21:02:37.826+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=54),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/54] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/54/2.delta
[2025-07-19T21:02:37.829+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 50.0 in stage 9.0 (TID 853) in 107 ms on 8b44f3d35cfa (executor driver) (51/200)
[2025-07-19T21:02:37.829+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 54 (task 857, attempt 0, stage 9.0)
[2025-07-19T21:02:37.829+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/57/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/57/.2.delta.9a0b9a2a-54bb-4661-965a-3d11f472ae7f.TID860.tmp
[2025-07-19T21:02:37.831+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 51 (task 854, attempt 0, stage 9.0)
[2025-07-19T21:02:37.831+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.831+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.831+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 51.0 in stage 9.0 (TID 854). 5829 bytes result sent to driver
[2025-07-19T21:02:37.832+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 51.0 in stage 9.0 (TID 854) in 99 ms on 8b44f3d35cfa (executor driver) (52/200)
[2025-07-19T21:02:37.832+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 59.0 in stage 9.0 (TID 862) (8b44f3d35cfa, executor driver, partition 59, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.832+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 59.0 in stage 9.0 (TID 862)
[2025-07-19T21:02:37.834+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 54 (task 857, attempt 0, stage 9.0)
[2025-07-19T21:02:37.835+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 54.0 in stage 9.0 (TID 857). 5829 bytes result sent to driver
[2025-07-19T21:02:37.836+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4cc332da
[2025-07-19T21:02:37.836+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 60.0 in stage 9.0 (TID 863) (8b44f3d35cfa, executor driver, partition 60, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.837+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.837+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.838+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=58, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.839+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=58),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/58] for update
[2025-07-19T21:02:37.840+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 54.0 in stage 9.0 (TID 857) in 80 ms on 8b44f3d35cfa (executor driver) (53/200)
[2025-07-19T21:02:37.841+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 60.0 in stage 9.0 (TID 863)
[2025-07-19T21:02:37.842+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@13fbf5f
[2025-07-19T21:02:37.843+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.844+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=59, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.845+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=59),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/59] for update
[2025-07-19T21:02:37.846+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.846+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.847+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7dc274d6
[2025-07-19T21:02:37.847+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.847+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/52/.2.delta.ac0cfa3e-2845-42f6-b673-3a1fa3f16ac7.TID855.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/52/2.delta
[2025-07-19T21:02:37.848+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=52),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/52] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/52/2.delta
[2025-07-19T21:02:37.849+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 52 (task 855, attempt 0, stage 9.0)
[2025-07-19T21:02:37.849+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=60, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.849+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=60),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/60] for update
[2025-07-19T21:02:37.850+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.851+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/53/.2.delta.b7c95ff8-c87c-4fae-8720-417cafce59c0.TID856.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/53/2.delta
[2025-07-19T21:02:37.851+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=53),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/53] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/53/2.delta
[2025-07-19T21:02:37.852+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 53 (task 856, attempt 0, stage 9.0)
[2025-07-19T21:02:37.852+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 52 (task 855, attempt 0, stage 9.0)
[2025-07-19T21:02:37.852+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 52.0 in stage 9.0 (TID 855). 5829 bytes result sent to driver
[2025-07-19T21:02:37.853+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 61.0 in stage 9.0 (TID 864) (8b44f3d35cfa, executor driver, partition 61, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.853+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/58/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/58/.2.delta.e12729c1-580c-4d3f-9aff-16d67000afcb.TID861.tmp
[2025-07-19T21:02:37.853+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 52.0 in stage 9.0 (TID 855) in 116 ms on 8b44f3d35cfa (executor driver) (54/200)
[2025-07-19T21:02:37.853+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 53 (task 856, attempt 0, stage 9.0)
[2025-07-19T21:02:37.855+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/55/.2.delta.a644ba52-8fe3-4c54-a306-1d860a861b05.TID858.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/55/2.delta
[2025-07-19T21:02:37.856+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=55),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/55] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/55/2.delta
[2025-07-19T21:02:37.857+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 61.0 in stage 9.0 (TID 864)
[2025-07-19T21:02:37.857+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 55 (task 858, attempt 0, stage 9.0)
[2025-07-19T21:02:37.858+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 53.0 in stage 9.0 (TID 856). 5829 bytes result sent to driver
[2025-07-19T21:02:37.858+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 62.0 in stage 9.0 (TID 865) (8b44f3d35cfa, executor driver, partition 62, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.859+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/59/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/59/.2.delta.e183c9d3-4050-4b02-8073-1c21d138c4ce.TID862.tmp
[2025-07-19T21:02:37.860+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 62.0 in stage 9.0 (TID 865)
[2025-07-19T21:02:37.860+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 53.0 in stage 9.0 (TID 856) in 104 ms on 8b44f3d35cfa (executor driver) (55/200)
[2025-07-19T21:02:37.860+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.860+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.861+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.861+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.861+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/60/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/60/.2.delta.bba5ef48-ea1f-4017-8064-71e96df4636d.TID863.tmp
[2025-07-19T21:02:37.861+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 55 (task 858, attempt 0, stage 9.0)
[2025-07-19T21:02:37.862+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 55.0 in stage 9.0 (TID 858). 5829 bytes result sent to driver
[2025-07-19T21:02:37.862+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 63.0 in stage 9.0 (TID 866) (8b44f3d35cfa, executor driver, partition 63, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.862+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 63.0 in stage 9.0 (TID 866)
[2025-07-19T21:02:37.863+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@9c605b7
[2025-07-19T21:02:37.863+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=61, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.863+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=61),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/61] for update
[2025-07-19T21:02:37.864+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.864+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.865+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 55.0 in stage 9.0 (TID 858) in 98 ms on 8b44f3d35cfa (executor driver) (56/200)
[2025-07-19T21:02:37.865+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2bd805b4
[2025-07-19T21:02:37.865+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=63, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.865+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=63),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/63] for update
[2025-07-19T21:02:37.867+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.867+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6924a754
[2025-07-19T21:02:37.868+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.868+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=62, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.869+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=62),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/62] for update
[2025-07-19T21:02:37.869+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.870+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/61/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/61/.2.delta.52bce292-a560-444d-b742-5984dccc908b.TID864.tmp
[2025-07-19T21:02:37.872+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/63/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/63/.2.delta.d99556e5-05eb-42d7-8731-d52a7064c174.TID866.tmp
[2025-07-19T21:02:37.872+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/56/.2.delta.10df3f9f-d8d4-4f0a-9e18-38b44a286cff.TID859.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/56/2.delta
[2025-07-19T21:02:37.873+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=56),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/56] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/56/2.delta
[2025-07-19T21:02:37.873+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 56 (task 859, attempt 0, stage 9.0)
[2025-07-19T21:02:37.876+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/62/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/62/.2.delta.b29a0dca-7bb5-4131-95f6-1d2da29c9867.TID865.tmp
[2025-07-19T21:02:37.877+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 56 (task 859, attempt 0, stage 9.0)
[2025-07-19T21:02:37.878+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 56.0 in stage 9.0 (TID 859). 5829 bytes result sent to driver
[2025-07-19T21:02:37.878+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 64.0 in stage 9.0 (TID 867) (8b44f3d35cfa, executor driver, partition 64, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.879+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 56.0 in stage 9.0 (TID 859) in 92 ms on 8b44f3d35cfa (executor driver) (57/200)
[2025-07-19T21:02:37.881+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 64.0 in stage 9.0 (TID 867)
[2025-07-19T21:02:37.881+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.881+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.882+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@529f5e2a
[2025-07-19T21:02:37.882+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/57/.2.delta.9a0b9a2a-54bb-4661-965a-3d11f472ae7f.TID860.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/57/2.delta
[2025-07-19T21:02:37.883+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=57),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/57] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/57/2.delta
[2025-07-19T21:02:37.883+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=64, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.883+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=64),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/64] for update
[2025-07-19T21:02:37.884+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 57 (task 860, attempt 0, stage 9.0)
[2025-07-19T21:02:37.889+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.889+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 57 (task 860, attempt 0, stage 9.0)
[2025-07-19T21:02:37.889+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 57.0 in stage 9.0 (TID 860). 5829 bytes result sent to driver
[2025-07-19T21:02:37.891+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 65.0 in stage 9.0 (TID 868) (8b44f3d35cfa, executor driver, partition 65, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.892+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 65.0 in stage 9.0 (TID 868)
[2025-07-19T21:02:37.895+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 57.0 in stage 9.0 (TID 860) in 95 ms on 8b44f3d35cfa (executor driver) (58/200)
[2025-07-19T21:02:37.895+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.896+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.899+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/59/.2.delta.e183c9d3-4050-4b02-8073-1c21d138c4ce.TID862.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/59/2.delta
[2025-07-19T21:02:37.900+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=59),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/59] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/59/2.delta
[2025-07-19T21:02:37.900+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4dc424a
[2025-07-19T21:02:37.901+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 59 (task 862, attempt 0, stage 9.0)
[2025-07-19T21:02:37.901+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=65, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.901+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=65),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/65] for update
[2025-07-19T21:02:37.902+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/64/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/64/.2.delta.c99036a8-8062-4c4a-899b-7b0dc811d98f.TID867.tmp
[2025-07-19T21:02:37.902+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/58/.2.delta.e12729c1-580c-4d3f-9aff-16d67000afcb.TID861.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/58/2.delta
[2025-07-19T21:02:37.903+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=58),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/58] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/58/2.delta
[2025-07-19T21:02:37.903+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.904+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 58 (task 861, attempt 0, stage 9.0)
[2025-07-19T21:02:37.905+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 59 (task 862, attempt 0, stage 9.0)
[2025-07-19T21:02:37.907+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 59.0 in stage 9.0 (TID 862). 5829 bytes result sent to driver
[2025-07-19T21:02:37.908+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 66.0 in stage 9.0 (TID 869) (8b44f3d35cfa, executor driver, partition 66, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.910+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 58 (task 861, attempt 0, stage 9.0)
[2025-07-19T21:02:37.911+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 66.0 in stage 9.0 (TID 869)
[2025-07-19T21:02:37.911+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 58.0 in stage 9.0 (TID 861). 5829 bytes result sent to driver
[2025-07-19T21:02:37.911+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 67.0 in stage 9.0 (TID 870) (8b44f3d35cfa, executor driver, partition 67, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.911+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 67.0 in stage 9.0 (TID 870)
[2025-07-19T21:02:37.911+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.911+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.912+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 58.0 in stage 9.0 (TID 861) in 96 ms on 8b44f3d35cfa (executor driver) (59/200)
[2025-07-19T21:02:37.912+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6586cde4
[2025-07-19T21:02:37.912+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=66, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.912+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 59.0 in stage 9.0 (TID 862) in 90 ms on 8b44f3d35cfa (executor driver) (60/200)
[2025-07-19T21:02:37.912+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=66),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/66] for update
[2025-07-19T21:02:37.916+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.917+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.918+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.918+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c33b841
[2025-07-19T21:02:37.918+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=67, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.919+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=67),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/67] for update
[2025-07-19T21:02:37.919+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.920+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/65/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/65/.2.delta.5ce9037a-1e50-40e7-96f7-f7a2b971c98e.TID868.tmp
[2025-07-19T21:02:37.920+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/60/.2.delta.bba5ef48-ea1f-4017-8064-71e96df4636d.TID863.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/60/2.delta
[2025-07-19T21:02:37.921+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=60),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/60] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/60/2.delta
[2025-07-19T21:02:37.921+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/61/.2.delta.52bce292-a560-444d-b742-5984dccc908b.TID864.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/61/2.delta
[2025-07-19T21:02:37.921+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=61),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/61] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/61/2.delta
[2025-07-19T21:02:37.921+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 61 (task 864, attempt 0, stage 9.0)
[2025-07-19T21:02:37.923+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 60 (task 863, attempt 0, stage 9.0)
[2025-07-19T21:02:37.926+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 61 (task 864, attempt 0, stage 9.0)
[2025-07-19T21:02:37.927+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 61.0 in stage 9.0 (TID 864). 5829 bytes result sent to driver
[2025-07-19T21:02:37.927+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/63/.2.delta.d99556e5-05eb-42d7-8731-d52a7064c174.TID866.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/63/2.delta
[2025-07-19T21:02:37.928+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=63),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/63] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/63/2.delta
[2025-07-19T21:02:37.928+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 60 (task 863, attempt 0, stage 9.0)
[2025-07-19T21:02:37.928+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 63 (task 866, attempt 0, stage 9.0)
[2025-07-19T21:02:37.928+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 60.0 in stage 9.0 (TID 863). 5829 bytes result sent to driver
[2025-07-19T21:02:37.928+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 68.0 in stage 9.0 (TID 871) (8b44f3d35cfa, executor driver, partition 68, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.930+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/62/.2.delta.b29a0dca-7bb5-4131-95f6-1d2da29c9867.TID865.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/62/2.delta
[2025-07-19T21:02:37.932+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=62),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/62] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/62/2.delta
[2025-07-19T21:02:37.933+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 61.0 in stage 9.0 (TID 864) in 88 ms on 8b44f3d35cfa (executor driver) (61/200)
[2025-07-19T21:02:37.934+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 62 (task 865, attempt 0, stage 9.0)
[2025-07-19T21:02:37.935+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 68.0 in stage 9.0 (TID 871)
[2025-07-19T21:02:37.937+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 69.0 in stage 9.0 (TID 872) (8b44f3d35cfa, executor driver, partition 69, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.937+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 60.0 in stage 9.0 (TID 863) in 105 ms on 8b44f3d35cfa (executor driver) (62/200)
[2025-07-19T21:02:37.938+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 69.0 in stage 9.0 (TID 872)
[2025-07-19T21:02:37.942+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/66/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/66/.2.delta.7fa5d160-4cc6-429c-a364-fe91ff22bfc6.TID869.tmp
[2025-07-19T21:02:37.943+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 63 (task 866, attempt 0, stage 9.0)
[2025-07-19T21:02:37.944+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/67/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/67/.2.delta.499652ed-64a3-4635-a4db-3257321eecce.TID870.tmp
[2025-07-19T21:02:37.945+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.947+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 63.0 in stage 9.0 (TID 866). 5829 bytes result sent to driver
[2025-07-19T21:02:37.948+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.949+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.949+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.950+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73834ee0
[2025-07-19T21:02:37.950+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 70.0 in stage 9.0 (TID 873) (8b44f3d35cfa, executor driver, partition 70, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.950+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 70.0 in stage 9.0 (TID 873)
[2025-07-19T21:02:37.950+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=69, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.951+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=69),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/69] for update
[2025-07-19T21:02:37.951+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 62 (task 865, attempt 0, stage 9.0)
[2025-07-19T21:02:37.951+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 62.0 in stage 9.0 (TID 865). 5829 bytes result sent to driver
[2025-07-19T21:02:37.952+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 63.0 in stage 9.0 (TID 866) in 85 ms on 8b44f3d35cfa (executor driver) (63/200)
[2025-07-19T21:02:37.952+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 71.0 in stage 9.0 (TID 874) (8b44f3d35cfa, executor driver, partition 71, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.952+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.953+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.953+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 62.0 in stage 9.0 (TID 865) in 92 ms on 8b44f3d35cfa (executor driver) (64/200)
[2025-07-19T21:02:37.953+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4eb22cdc
[2025-07-19T21:02:37.954+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=68, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.954+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=68),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/68] for update
[2025-07-19T21:02:37.954+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.954+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.955+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 71.0 in stage 9.0 (TID 874)
[2025-07-19T21:02:37.955+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.955+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.955+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3dda7d71
[2025-07-19T21:02:37.956+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=71, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.956+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=71),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/71] for update
[2025-07-19T21:02:37.958+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55d5a72b
[2025-07-19T21:02:37.959+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=70, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.960+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=70),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/70] for update
[2025-07-19T21:02:37.960+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.960+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.960+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/69/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/69/.2.delta.78571cf4-cc50-4f4a-813b-418ec7da28f0.TID872.tmp
[2025-07-19T21:02:37.960+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/68/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/68/.2.delta.2f031090-f669-4be0-a317-a4c107c23d9c.TID871.tmp
[2025-07-19T21:02:37.961+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/64/.2.delta.c99036a8-8062-4c4a-899b-7b0dc811d98f.TID867.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/64/2.delta
[2025-07-19T21:02:37.962+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=64),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/64] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/64/2.delta
[2025-07-19T21:02:37.962+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 64 (task 867, attempt 0, stage 9.0)
[2025-07-19T21:02:37.963+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/70/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/70/.2.delta.8609e674-d811-403a-a6b9-48161bd57fac.TID873.tmp
[2025-07-19T21:02:37.963+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/71/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/71/.2.delta.c2d165e1-76d3-4b4d-935e-9c5d9866c365.TID874.tmp
[2025-07-19T21:02:37.965+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 64 (task 867, attempt 0, stage 9.0)
[2025-07-19T21:02:37.967+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 64.0 in stage 9.0 (TID 867). 5829 bytes result sent to driver
[2025-07-19T21:02:37.968+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 72.0 in stage 9.0 (TID 875) (8b44f3d35cfa, executor driver, partition 72, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.968+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 72.0 in stage 9.0 (TID 875)
[2025-07-19T21:02:37.969+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.969+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.970+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 64.0 in stage 9.0 (TID 867) in 91 ms on 8b44f3d35cfa (executor driver) (65/200)
[2025-07-19T21:02:37.974+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/65/.2.delta.5ce9037a-1e50-40e7-96f7-f7a2b971c98e.TID868.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/65/2.delta
[2025-07-19T21:02:37.975+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=65),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/65] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/65/2.delta
[2025-07-19T21:02:37.975+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 65 (task 868, attempt 0, stage 9.0)
[2025-07-19T21:02:37.975+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@239c1251
[2025-07-19T21:02:37.976+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=72, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.976+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=72),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/72] for update
[2025-07-19T21:02:37.976+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.979+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 65 (task 868, attempt 0, stage 9.0)
[2025-07-19T21:02:37.980+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 65.0 in stage 9.0 (TID 868). 5829 bytes result sent to driver
[2025-07-19T21:02:37.980+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 73.0 in stage 9.0 (TID 876) (8b44f3d35cfa, executor driver, partition 73, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.980+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 73.0 in stage 9.0 (TID 876)
[2025-07-19T21:02:37.981+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 65.0 in stage 9.0 (TID 868) in 90 ms on 8b44f3d35cfa (executor driver) (66/200)
[2025-07-19T21:02:37.985+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.986+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.987+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2a054b25
[2025-07-19T21:02:37.988+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/66/.2.delta.7fa5d160-4cc6-429c-a364-fe91ff22bfc6.TID869.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/66/2.delta
[2025-07-19T21:02:37.988+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=66),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/66] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/66/2.delta
[2025-07-19T21:02:37.988+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 66 (task 869, attempt 0, stage 9.0)
[2025-07-19T21:02:37.989+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=73, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:37.990+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/72/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/72/.2.delta.d5c98bcf-ff35-4c31-a4a2-788ff8fdab82.TID875.tmp
[2025-07-19T21:02:37.990+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=73),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/73] for update
[2025-07-19T21:02:37.991+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 66 (task 869, attempt 0, stage 9.0)
[2025-07-19T21:02:37.991+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 66.0 in stage 9.0 (TID 869). 5829 bytes result sent to driver
[2025-07-19T21:02:37.992+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 74.0 in stage 9.0 (TID 877) (8b44f3d35cfa, executor driver, partition 74, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:37.994+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:37.995+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 66.0 in stage 9.0 (TID 869) in 84 ms on 8b44f3d35cfa (executor driver) (67/200)
[2025-07-19T21:02:37.995+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 74.0 in stage 9.0 (TID 877)
[2025-07-19T21:02:37.995+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/67/.2.delta.499652ed-64a3-4635-a4db-3257321eecce.TID870.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/67/2.delta
[2025-07-19T21:02:37.996+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=67),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/67] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/67/2.delta
[2025-07-19T21:02:37.997+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Commit authorized for partition 67 (task 870, attempt 0, stage 9.0)
[2025-07-19T21:02:37.997+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:37.998+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:37.998+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO DataWritingSparkTask: Committed partition 67 (task 870, attempt 0, stage 9.0)
[2025-07-19T21:02:37.999+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Finished task 67.0 in stage 9.0 (TID 870). 5829 bytes result sent to driver
[2025-07-19T21:02:37.999+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2cb638d9
[2025-07-19T21:02:38.000+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Starting task 75.0 in stage 9.0 (TID 878) (8b44f3d35cfa, executor driver, partition 75, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.001+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO TaskSetManager: Finished task 67.0 in stage 9.0 (TID 870) in 88 ms on 8b44f3d35cfa (executor driver) (68/200)
[2025-07-19T21:02:38.002+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO Executor: Running task 75.0 in stage 9.0 (TID 878)
[2025-07-19T21:02:38.002+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=74, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.002+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=74),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/74] for update
[2025-07-19T21:02:38.002+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.002+0000] {subprocess.py:93} INFO - 25/07/19 21:02:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.002+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.003+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/69/.2.delta.78571cf4-cc50-4f4a-813b-418ec7da28f0.TID872.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/69/2.delta
[2025-07-19T21:02:38.004+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=69),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/69] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/69/2.delta
[2025-07-19T21:02:38.005+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d0ede75
[2025-07-19T21:02:38.005+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=75, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.005+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=75),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/75] for update
[2025-07-19T21:02:38.007+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.009+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 69 (task 872, attempt 0, stage 9.0)
[2025-07-19T21:02:38.010+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/73/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/73/.2.delta.70b676f4-c52d-433a-9fae-5dfae4a03651.TID876.tmp
[2025-07-19T21:02:38.010+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/70/.2.delta.8609e674-d811-403a-a6b9-48161bd57fac.TID873.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/70/2.delta
[2025-07-19T21:02:38.011+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=70),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/70] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/70/2.delta
[2025-07-19T21:02:38.011+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 69 (task 872, attempt 0, stage 9.0)
[2025-07-19T21:02:38.012+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 70 (task 873, attempt 0, stage 9.0)
[2025-07-19T21:02:38.013+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 69.0 in stage 9.0 (TID 872). 5829 bytes result sent to driver
[2025-07-19T21:02:38.013+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 76.0 in stage 9.0 (TID 879) (8b44f3d35cfa, executor driver, partition 76, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.014+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 69.0 in stage 9.0 (TID 872) in 82 ms on 8b44f3d35cfa (executor driver) (69/200)
[2025-07-19T21:02:38.014+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 76.0 in stage 9.0 (TID 879)
[2025-07-19T21:02:38.015+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 70 (task 873, attempt 0, stage 9.0)
[2025-07-19T21:02:38.015+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/68/.2.delta.2f031090-f669-4be0-a317-a4c107c23d9c.TID871.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/68/2.delta
[2025-07-19T21:02:38.016+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=68),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/68] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/68/2.delta
[2025-07-19T21:02:38.017+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/71/.2.delta.c2d165e1-76d3-4b4d-935e-9c5d9866c365.TID874.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/71/2.delta
[2025-07-19T21:02:38.017+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=71),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/71] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/71/2.delta
[2025-07-19T21:02:38.018+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 70.0 in stage 9.0 (TID 873). 5829 bytes result sent to driver
[2025-07-19T21:02:38.020+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 68 (task 871, attempt 0, stage 9.0)
[2025-07-19T21:02:38.021+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 71 (task 874, attempt 0, stage 9.0)
[2025-07-19T21:02:38.021+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.022+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.023+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 77.0 in stage 9.0 (TID 880) (8b44f3d35cfa, executor driver, partition 77, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.024+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 77.0 in stage 9.0 (TID 880)
[2025-07-19T21:02:38.027+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 70.0 in stage 9.0 (TID 873) in 83 ms on 8b44f3d35cfa (executor driver) (70/200)
[2025-07-19T21:02:38.027+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/74/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/74/.2.delta.feb7434f-af49-4d9e-ac6d-ca752e69abf0.TID877.tmp
[2025-07-19T21:02:38.028+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 68 (task 871, attempt 0, stage 9.0)
[2025-07-19T21:02:38.029+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@76a2b035
[2025-07-19T21:02:38.029+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.030+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:38.030+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=76, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.030+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=76),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/76] for update
[2025-07-19T21:02:38.031+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 71 (task 874, attempt 0, stage 9.0)
[2025-07-19T21:02:38.031+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 68.0 in stage 9.0 (TID 871). 5829 bytes result sent to driver
[2025-07-19T21:02:38.031+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/75/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/75/.2.delta.4fa52836-dc48-4a75-9928-30c5f0096a8a.TID878.tmp
[2025-07-19T21:02:38.031+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.031+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 71.0 in stage 9.0 (TID 874). 5829 bytes result sent to driver
[2025-07-19T21:02:38.031+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 78.0 in stage 9.0 (TID 881) (8b44f3d35cfa, executor driver, partition 78, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.031+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 79.0 in stage 9.0 (TID 882) (8b44f3d35cfa, executor driver, partition 79, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.032+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3b422575
[2025-07-19T21:02:38.033+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 78.0 in stage 9.0 (TID 881)
[2025-07-19T21:02:38.033+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=77, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.035+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=77),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/77] for update
[2025-07-19T21:02:38.035+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.039+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 71.0 in stage 9.0 (TID 874) in 101 ms on 8b44f3d35cfa (executor driver) (71/200)
[2025-07-19T21:02:38.041+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 79.0 in stage 9.0 (TID 882)
[2025-07-19T21:02:38.041+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 68.0 in stage 9.0 (TID 871) in 114 ms on 8b44f3d35cfa (executor driver) (72/200)
[2025-07-19T21:02:38.042+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.043+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:38.043+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f3e1880
[2025-07-19T21:02:38.045+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=78, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.045+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=78),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/78] for update
[2025-07-19T21:02:38.046+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.047+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.047+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.049+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a662b59
[2025-07-19T21:02:38.050+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=79, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.050+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=79),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/79] for update
[2025-07-19T21:02:38.050+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/76/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/76/.2.delta.fe99d955-148c-40b4-8753-73c5ea63dd7a.TID879.tmp
[2025-07-19T21:02:38.052+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.055+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/72/.2.delta.d5c98bcf-ff35-4c31-a4a2-788ff8fdab82.TID875.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/72/2.delta
[2025-07-19T21:02:38.055+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=72),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/72] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/72/2.delta
[2025-07-19T21:02:38.056+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 72 (task 875, attempt 0, stage 9.0)
[2025-07-19T21:02:38.057+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/77/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/77/.2.delta.d685ce8c-9746-43fa-ab46-fdca55f79c56.TID880.tmp
[2025-07-19T21:02:38.060+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 72 (task 875, attempt 0, stage 9.0)
[2025-07-19T21:02:38.061+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/78/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/78/.2.delta.1f5c0b45-bf83-4a84-a8dd-4920da731b9c.TID881.tmp
[2025-07-19T21:02:38.061+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 72.0 in stage 9.0 (TID 875). 5872 bytes result sent to driver
[2025-07-19T21:02:38.063+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 80.0 in stage 9.0 (TID 883) (8b44f3d35cfa, executor driver, partition 80, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.064+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 72.0 in stage 9.0 (TID 875) in 98 ms on 8b44f3d35cfa (executor driver) (73/200)
[2025-07-19T21:02:38.064+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 80.0 in stage 9.0 (TID 883)
[2025-07-19T21:02:38.068+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/79/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/79/.2.delta.38eb412b-cf8f-408a-bf3f-8f180d5f92c8.TID882.tmp
[2025-07-19T21:02:38.069+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.070+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.070+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f86aa7b
[2025-07-19T21:02:38.071+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=80, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.073+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=80),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/80] for update
[2025-07-19T21:02:38.073+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.081+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/73/.2.delta.70b676f4-c52d-433a-9fae-5dfae4a03651.TID876.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/73/2.delta
[2025-07-19T21:02:38.082+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=73),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/73] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/73/2.delta
[2025-07-19T21:02:38.083+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 73 (task 876, attempt 0, stage 9.0)
[2025-07-19T21:02:38.086+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 73 (task 876, attempt 0, stage 9.0)
[2025-07-19T21:02:38.088+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 73.0 in stage 9.0 (TID 876). 5872 bytes result sent to driver
[2025-07-19T21:02:38.089+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/80/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/80/.2.delta.8d19e6e5-994c-4a5e-9d0f-8292b027ae4a.TID883.tmp
[2025-07-19T21:02:38.089+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 81.0 in stage 9.0 (TID 884) (8b44f3d35cfa, executor driver, partition 81, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.090+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 73.0 in stage 9.0 (TID 876) in 106 ms on 8b44f3d35cfa (executor driver) (74/200)
[2025-07-19T21:02:38.090+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 81.0 in stage 9.0 (TID 884)
[2025-07-19T21:02:38.099+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.100+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.101+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/74/.2.delta.feb7434f-af49-4d9e-ac6d-ca752e69abf0.TID877.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/74/2.delta
[2025-07-19T21:02:38.102+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=74),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/74] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/74/2.delta
[2025-07-19T21:02:38.104+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 74 (task 877, attempt 0, stage 9.0)
[2025-07-19T21:02:38.105+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d201e86
[2025-07-19T21:02:38.105+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=81, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.106+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=81),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/81] for update
[2025-07-19T21:02:38.108+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 74 (task 877, attempt 0, stage 9.0)
[2025-07-19T21:02:38.109+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.109+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 74.0 in stage 9.0 (TID 877). 5872 bytes result sent to driver
[2025-07-19T21:02:38.109+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 82.0 in stage 9.0 (TID 885) (8b44f3d35cfa, executor driver, partition 82, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.110+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/75/.2.delta.4fa52836-dc48-4a75-9928-30c5f0096a8a.TID878.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/75/2.delta
[2025-07-19T21:02:38.114+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=75),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/75] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/75/2.delta
[2025-07-19T21:02:38.115+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 74.0 in stage 9.0 (TID 877) in 113 ms on 8b44f3d35cfa (executor driver) (75/200)
[2025-07-19T21:02:38.115+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 75 (task 878, attempt 0, stage 9.0)
[2025-07-19T21:02:38.115+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 82.0 in stage 9.0 (TID 885)
[2025-07-19T21:02:38.115+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.115+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.115+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@34dd0e1b
[2025-07-19T21:02:38.115+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=82, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.115+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=82),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/82] for update
[2025-07-19T21:02:38.116+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/76/.2.delta.fe99d955-148c-40b4-8753-73c5ea63dd7a.TID879.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/76/2.delta
[2025-07-19T21:02:38.116+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=76),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/76] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/76/2.delta
[2025-07-19T21:02:38.116+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 76 (task 879, attempt 0, stage 9.0)
[2025-07-19T21:02:38.116+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.116+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 75 (task 878, attempt 0, stage 9.0)
[2025-07-19T21:02:38.116+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 75.0 in stage 9.0 (TID 878). 5872 bytes result sent to driver
[2025-07-19T21:02:38.116+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 83.0 in stage 9.0 (TID 886) (8b44f3d35cfa, executor driver, partition 83, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.116+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 75.0 in stage 9.0 (TID 878) in 116 ms on 8b44f3d35cfa (executor driver) (76/200)
[2025-07-19T21:02:38.117+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 83.0 in stage 9.0 (TID 886)
[2025-07-19T21:02:38.122+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/77/.2.delta.d685ce8c-9746-43fa-ab46-fdca55f79c56.TID880.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/77/2.delta
[2025-07-19T21:02:38.124+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=77),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/77] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/77/2.delta
[2025-07-19T21:02:38.125+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 77 (task 880, attempt 0, stage 9.0)
[2025-07-19T21:02:38.125+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.126+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.127+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@10513cc6
[2025-07-19T21:02:38.128+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/79/.2.delta.38eb412b-cf8f-408a-bf3f-8f180d5f92c8.TID882.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/79/2.delta
[2025-07-19T21:02:38.128+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=79),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/79] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/79/2.delta
[2025-07-19T21:02:38.129+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/78/.2.delta.1f5c0b45-bf83-4a84-a8dd-4920da731b9c.TID881.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/78/2.delta
[2025-07-19T21:02:38.130+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=78),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/78] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/78/2.delta
[2025-07-19T21:02:38.131+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=83, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.132+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=83),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/83] for update
[2025-07-19T21:02:38.132+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 76 (task 879, attempt 0, stage 9.0)
[2025-07-19T21:02:38.134+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 76.0 in stage 9.0 (TID 879). 5872 bytes result sent to driver
[2025-07-19T21:02:38.135+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 84.0 in stage 9.0 (TID 887) (8b44f3d35cfa, executor driver, partition 84, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.135+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 78 (task 881, attempt 0, stage 9.0)
[2025-07-19T21:02:38.135+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.135+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 76.0 in stage 9.0 (TID 879) in 114 ms on 8b44f3d35cfa (executor driver) (77/200)
[2025-07-19T21:02:38.135+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 79 (task 882, attempt 0, stage 9.0)
[2025-07-19T21:02:38.135+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/81/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/81/.2.delta.b833b671-699c-4015-8e3f-883e99cc7625.TID884.tmp
[2025-07-19T21:02:38.136+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 77 (task 880, attempt 0, stage 9.0)
[2025-07-19T21:02:38.136+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 77.0 in stage 9.0 (TID 880). 5872 bytes result sent to driver
[2025-07-19T21:02:38.136+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 85.0 in stage 9.0 (TID 888) (8b44f3d35cfa, executor driver, partition 85, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.136+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 85.0 in stage 9.0 (TID 888)
[2025-07-19T21:02:38.136+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 78 (task 881, attempt 0, stage 9.0)
[2025-07-19T21:02:38.137+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 78.0 in stage 9.0 (TID 881). 5872 bytes result sent to driver
[2025-07-19T21:02:38.139+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 79 (task 882, attempt 0, stage 9.0)
[2025-07-19T21:02:38.142+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 79.0 in stage 9.0 (TID 882). 5872 bytes result sent to driver
[2025-07-19T21:02:38.143+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 84.0 in stage 9.0 (TID 887)
[2025-07-19T21:02:38.144+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 77.0 in stage 9.0 (TID 880) in 114 ms on 8b44f3d35cfa (executor driver) (78/200)
[2025-07-19T21:02:38.145+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/82/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/82/.2.delta.c73542ca-71f3-4b62-ac26-840d0590f8d4.TID885.tmp
[2025-07-19T21:02:38.145+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.147+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.149+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 86.0 in stage 9.0 (TID 889) (8b44f3d35cfa, executor driver, partition 86, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.149+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.149+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.150+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 87.0 in stage 9.0 (TID 890) (8b44f3d35cfa, executor driver, partition 87, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.150+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1e2b316b
[2025-07-19T21:02:38.150+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=85, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.150+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 86.0 in stage 9.0 (TID 889)
[2025-07-19T21:02:38.150+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 87.0 in stage 9.0 (TID 890)
[2025-07-19T21:02:38.151+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=85),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/85] for update
[2025-07-19T21:02:38.151+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.151+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 79.0 in stage 9.0 (TID 882) in 110 ms on 8b44f3d35cfa (executor driver) (79/200)
[2025-07-19T21:02:38.151+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 78.0 in stage 9.0 (TID 881) in 112 ms on 8b44f3d35cfa (executor driver) (80/200)
[2025-07-19T21:02:38.151+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74e99af3
[2025-07-19T21:02:38.151+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=84, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.151+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=84),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/84] for update
[2025-07-19T21:02:38.151+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.151+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:38.151+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.151+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.152+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7ea185dc
[2025-07-19T21:02:38.152+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=86, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.152+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=86),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/86] for update
[2025-07-19T21:02:38.152+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.152+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55ce922b
[2025-07-19T21:02:38.152+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=87, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.153+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=87),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/87] for update
[2025-07-19T21:02:38.153+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.153+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.153+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/80/.2.delta.8d19e6e5-994c-4a5e-9d0f-8292b027ae4a.TID883.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/80/2.delta
[2025-07-19T21:02:38.154+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=80),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/80] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/80/2.delta
[2025-07-19T21:02:38.154+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 80 (task 883, attempt 0, stage 9.0)
[2025-07-19T21:02:38.155+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/83/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/83/.2.delta.4d73117a-83d9-4fe2-bb53-6e3b5624d28a.TID886.tmp
[2025-07-19T21:02:38.156+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/85/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/85/.2.delta.75e52669-3a5b-4ce4-9cfe-afde15883090.TID888.tmp
[2025-07-19T21:02:38.157+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 80 (task 883, attempt 0, stage 9.0)
[2025-07-19T21:02:38.157+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/84/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/84/.2.delta.1a9a164c-c3dc-46dc-923a-7f15aa5a4efa.TID887.tmp
[2025-07-19T21:02:38.157+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/86/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/86/.2.delta.9c5f0221-a74d-434b-88b1-4035e30cdef6.TID889.tmp
[2025-07-19T21:02:38.158+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 80.0 in stage 9.0 (TID 883). 5872 bytes result sent to driver
[2025-07-19T21:02:38.158+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/87/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/87/.2.delta.60663a60-3c9f-447f-a2ce-3e7e64caa2ac.TID890.tmp
[2025-07-19T21:02:38.158+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 88.0 in stage 9.0 (TID 891) (8b44f3d35cfa, executor driver, partition 88, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.159+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 88.0 in stage 9.0 (TID 891)
[2025-07-19T21:02:38.159+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 80.0 in stage 9.0 (TID 883) in 95 ms on 8b44f3d35cfa (executor driver) (81/200)
[2025-07-19T21:02:38.161+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.162+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.162+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1e3f7c0b
[2025-07-19T21:02:38.163+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=88, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.163+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=88),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/88] for update
[2025-07-19T21:02:38.163+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.173+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/88/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/88/.2.delta.48173c69-4f90-4262-9313-75650b208f4a.TID891.tmp
[2025-07-19T21:02:38.179+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/82/.2.delta.c73542ca-71f3-4b62-ac26-840d0590f8d4.TID885.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/82/2.delta
[2025-07-19T21:02:38.181+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=82),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/82] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/82/2.delta
[2025-07-19T21:02:38.181+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/81/.2.delta.b833b671-699c-4015-8e3f-883e99cc7625.TID884.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/81/2.delta
[2025-07-19T21:02:38.182+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=81),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/81] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/81/2.delta
[2025-07-19T21:02:38.182+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 82 (task 885, attempt 0, stage 9.0)
[2025-07-19T21:02:38.184+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 81 (task 884, attempt 0, stage 9.0)
[2025-07-19T21:02:38.187+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 82 (task 885, attempt 0, stage 9.0)
[2025-07-19T21:02:38.189+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 81 (task 884, attempt 0, stage 9.0)
[2025-07-19T21:02:38.190+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 82.0 in stage 9.0 (TID 885). 5872 bytes result sent to driver
[2025-07-19T21:02:38.190+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 81.0 in stage 9.0 (TID 884). 5872 bytes result sent to driver
[2025-07-19T21:02:38.190+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/83/.2.delta.4d73117a-83d9-4fe2-bb53-6e3b5624d28a.TID886.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/83/2.delta
[2025-07-19T21:02:38.190+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=83),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/83] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/83/2.delta
[2025-07-19T21:02:38.191+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 83 (task 886, attempt 0, stage 9.0)
[2025-07-19T21:02:38.191+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 89.0 in stage 9.0 (TID 892) (8b44f3d35cfa, executor driver, partition 89, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.191+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 90.0 in stage 9.0 (TID 893) (8b44f3d35cfa, executor driver, partition 90, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.191+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 90.0 in stage 9.0 (TID 893)
[2025-07-19T21:02:38.191+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 81.0 in stage 9.0 (TID 884) in 101 ms on 8b44f3d35cfa (executor driver) (82/200)
[2025-07-19T21:02:38.191+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 82.0 in stage 9.0 (TID 885) in 84 ms on 8b44f3d35cfa (executor driver) (83/200)
[2025-07-19T21:02:38.191+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 89.0 in stage 9.0 (TID 892)
[2025-07-19T21:02:38.191+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.192+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.192+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 83 (task 886, attempt 0, stage 9.0)
[2025-07-19T21:02:38.192+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@48f5f0
[2025-07-19T21:02:38.192+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.192+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.192+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 83.0 in stage 9.0 (TID 886). 5872 bytes result sent to driver
[2025-07-19T21:02:38.192+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=90, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.193+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=90),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/90] for update
[2025-07-19T21:02:38.193+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 83.0 in stage 9.0 (TID 886) in 76 ms on 8b44f3d35cfa (executor driver) (84/200)
[2025-07-19T21:02:38.193+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 91.0 in stage 9.0 (TID 894) (8b44f3d35cfa, executor driver, partition 91, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.193+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 91.0 in stage 9.0 (TID 894)
[2025-07-19T21:02:38.193+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.194+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a7bcbab
[2025-07-19T21:02:38.194+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.194+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.194+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=89, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.194+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=89),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/89] for update
[2025-07-19T21:02:38.195+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.195+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/87/.2.delta.60663a60-3c9f-447f-a2ce-3e7e64caa2ac.TID890.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/87/2.delta
[2025-07-19T21:02:38.196+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=87),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/87] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/87/2.delta
[2025-07-19T21:02:38.196+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 87 (task 890, attempt 0, stage 9.0)
[2025-07-19T21:02:38.196+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/84/.2.delta.1a9a164c-c3dc-46dc-923a-7f15aa5a4efa.TID887.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/84/2.delta
[2025-07-19T21:02:38.196+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=84),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/84] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/84/2.delta
[2025-07-19T21:02:38.196+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63bf9d6f
[2025-07-19T21:02:38.196+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=91, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.196+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=91),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/91] for update
[2025-07-19T21:02:38.199+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.200+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 84 (task 887, attempt 0, stage 9.0)
[2025-07-19T21:02:38.201+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 87 (task 890, attempt 0, stage 9.0)
[2025-07-19T21:02:38.201+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 87.0 in stage 9.0 (TID 890). 5829 bytes result sent to driver
[2025-07-19T21:02:38.201+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/90/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/90/.2.delta.0477087b-c222-40ea-b0cc-40c62529b943.TID893.tmp
[2025-07-19T21:02:38.201+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 84 (task 887, attempt 0, stage 9.0)
[2025-07-19T21:02:38.202+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/86/.2.delta.9c5f0221-a74d-434b-88b1-4035e30cdef6.TID889.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/86/2.delta
[2025-07-19T21:02:38.202+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=86),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/86] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/86/2.delta
[2025-07-19T21:02:38.203+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/85/.2.delta.75e52669-3a5b-4ce4-9cfe-afde15883090.TID888.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/85/2.delta
[2025-07-19T21:02:38.205+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=85),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/85] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/85/2.delta
[2025-07-19T21:02:38.206+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 92.0 in stage 9.0 (TID 895) (8b44f3d35cfa, executor driver, partition 92, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.206+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 85 (task 888, attempt 0, stage 9.0)
[2025-07-19T21:02:38.207+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 86 (task 889, attempt 0, stage 9.0)
[2025-07-19T21:02:38.208+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 87.0 in stage 9.0 (TID 890) in 70 ms on 8b44f3d35cfa (executor driver) (85/200)
[2025-07-19T21:02:38.209+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 84.0 in stage 9.0 (TID 887). 5872 bytes result sent to driver
[2025-07-19T21:02:38.209+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 93.0 in stage 9.0 (TID 896) (8b44f3d35cfa, executor driver, partition 93, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.210+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 86 (task 889, attempt 0, stage 9.0)
[2025-07-19T21:02:38.210+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 93.0 in stage 9.0 (TID 896)
[2025-07-19T21:02:38.210+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 86.0 in stage 9.0 (TID 889). 5829 bytes result sent to driver
[2025-07-19T21:02:38.211+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 85 (task 888, attempt 0, stage 9.0)
[2025-07-19T21:02:38.212+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 92.0 in stage 9.0 (TID 895)
[2025-07-19T21:02:38.212+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 94.0 in stage 9.0 (TID 897) (8b44f3d35cfa, executor driver, partition 94, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.212+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 85.0 in stage 9.0 (TID 888). 5829 bytes result sent to driver
[2025-07-19T21:02:38.213+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 94.0 in stage 9.0 (TID 897)
[2025-07-19T21:02:38.213+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 84.0 in stage 9.0 (TID 887) in 81 ms on 8b44f3d35cfa (executor driver) (86/200)
[2025-07-19T21:02:38.213+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 86.0 in stage 9.0 (TID 889) in 74 ms on 8b44f3d35cfa (executor driver) (87/200)
[2025-07-19T21:02:38.214+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 95.0 in stage 9.0 (TID 898) (8b44f3d35cfa, executor driver, partition 95, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.214+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 85.0 in stage 9.0 (TID 888) in 77 ms on 8b44f3d35cfa (executor driver) (88/200)
[2025-07-19T21:02:38.216+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 95.0 in stage 9.0 (TID 898)
[2025-07-19T21:02:38.217+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.218+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.219+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.219+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.220+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/89/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/89/.2.delta.762bf1f6-675d-4af8-b472-56f84ca379fb.TID892.tmp
[2025-07-19T21:02:38.220+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.220+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.220+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a49d0c2
[2025-07-19T21:02:38.220+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=94, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.221+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=94),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/94] for update
[2025-07-19T21:02:38.221+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/88/.2.delta.48173c69-4f90-4262-9313-75650b208f4a.TID891.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/88/2.delta
[2025-07-19T21:02:38.221+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=88),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/88] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/88/2.delta
[2025-07-19T21:02:38.221+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/91/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/91/.2.delta.2438f106-8132-4ef5-b3b7-3e6d12eab66f.TID894.tmp
[2025-07-19T21:02:38.221+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 88 (task 891, attempt 0, stage 9.0)
[2025-07-19T21:02:38.221+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.221+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:38.221+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.221+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f1dc495
[2025-07-19T21:02:38.221+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=92, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.221+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=92),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/92] for update
[2025-07-19T21:02:38.222+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 88 (task 891, attempt 0, stage 9.0)
[2025-07-19T21:02:38.222+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4386416e
[2025-07-19T21:02:38.222+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=93, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.222+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=93),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/93] for update
[2025-07-19T21:02:38.222+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 88.0 in stage 9.0 (TID 891). 5829 bytes result sent to driver
[2025-07-19T21:02:38.222+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 96.0 in stage 9.0 (TID 899) (8b44f3d35cfa, executor driver, partition 96, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.222+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 88.0 in stage 9.0 (TID 891) in 63 ms on 8b44f3d35cfa (executor driver) (89/200)
[2025-07-19T21:02:38.222+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.222+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 96.0 in stage 9.0 (TID 899)
[2025-07-19T21:02:38.222+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d18dd61
[2025-07-19T21:02:38.222+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.223+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.223+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.225+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=95, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.226+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=95),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/95] for update
[2025-07-19T21:02:38.227+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22832020
[2025-07-19T21:02:38.228+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.228+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=96, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.230+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=96),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/96] for update
[2025-07-19T21:02:38.231+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.235+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/93/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/93/.2.delta.8ff9038c-25dd-4c98-9df9-f8459e37e1e8.TID896.tmp
[2025-07-19T21:02:38.235+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/94/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/94/.2.delta.fb128bc1-a3ea-46fe-af09-7b412b9a363f.TID897.tmp
[2025-07-19T21:02:38.238+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/92/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/92/.2.delta.f73094ff-a719-4fd2-a027-2cad90a62ef9.TID895.tmp
[2025-07-19T21:02:38.239+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/96/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/96/.2.delta.6edb2493-d4c8-4b31-b86d-046efe79a9ea.TID899.tmp
[2025-07-19T21:02:38.241+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/95/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/95/.2.delta.ec8d676a-62b5-418f-9bee-8606dfff8221.TID898.tmp
[2025-07-19T21:02:38.252+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/90/.2.delta.0477087b-c222-40ea-b0cc-40c62529b943.TID893.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/90/2.delta
[2025-07-19T21:02:38.252+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=90),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/90] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/90/2.delta
[2025-07-19T21:02:38.253+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 90 (task 893, attempt 0, stage 9.0)
[2025-07-19T21:02:38.259+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 90 (task 893, attempt 0, stage 9.0)
[2025-07-19T21:02:38.260+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 90.0 in stage 9.0 (TID 893). 5829 bytes result sent to driver
[2025-07-19T21:02:38.260+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 97.0 in stage 9.0 (TID 900) (8b44f3d35cfa, executor driver, partition 97, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.261+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 90.0 in stage 9.0 (TID 893) in 76 ms on 8b44f3d35cfa (executor driver) (90/200)
[2025-07-19T21:02:38.261+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 97.0 in stage 9.0 (TID 900)
[2025-07-19T21:02:38.264+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.265+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.266+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/91/.2.delta.2438f106-8132-4ef5-b3b7-3e6d12eab66f.TID894.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/91/2.delta
[2025-07-19T21:02:38.267+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=91),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/91] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/91/2.delta
[2025-07-19T21:02:38.267+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 91 (task 894, attempt 0, stage 9.0)
[2025-07-19T21:02:38.267+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/89/.2.delta.762bf1f6-675d-4af8-b472-56f84ca379fb.TID892.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/89/2.delta
[2025-07-19T21:02:38.267+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=89),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/89] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/89/2.delta
[2025-07-19T21:02:38.267+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 89 (task 892, attempt 0, stage 9.0)
[2025-07-19T21:02:38.268+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 91 (task 894, attempt 0, stage 9.0)
[2025-07-19T21:02:38.270+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@37566d62
[2025-07-19T21:02:38.271+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 91.0 in stage 9.0 (TID 894). 5829 bytes result sent to driver
[2025-07-19T21:02:38.272+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 98.0 in stage 9.0 (TID 901) (8b44f3d35cfa, executor driver, partition 98, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.272+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 91.0 in stage 9.0 (TID 894) in 81 ms on 8b44f3d35cfa (executor driver) (91/200)
[2025-07-19T21:02:38.272+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=97, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.273+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=97),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/97] for update
[2025-07-19T21:02:38.273+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 89 (task 892, attempt 0, stage 9.0)
[2025-07-19T21:02:38.274+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 89.0 in stage 9.0 (TID 892). 5829 bytes result sent to driver
[2025-07-19T21:02:38.274+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 98.0 in stage 9.0 (TID 901)
[2025-07-19T21:02:38.274+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.274+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 99.0 in stage 9.0 (TID 902) (8b44f3d35cfa, executor driver, partition 99, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.274+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 89.0 in stage 9.0 (TID 892) in 87 ms on 8b44f3d35cfa (executor driver) (92/200)
[2025-07-19T21:02:38.274+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.275+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.276+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74826bd8
[2025-07-19T21:02:38.276+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 99.0 in stage 9.0 (TID 902)
[2025-07-19T21:02:38.278+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=98, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.279+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=98),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/98] for update
[2025-07-19T21:02:38.279+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.280+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.280+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.281+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f9462d3
[2025-07-19T21:02:38.281+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=99, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.281+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=99),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/99] for update
[2025-07-19T21:02:38.281+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.281+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/97/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/97/.2.delta.ad302165-ee29-4d06-97d4-c0563b4fc1da.TID900.tmp
[2025-07-19T21:02:38.285+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/92/.2.delta.f73094ff-a719-4fd2-a027-2cad90a62ef9.TID895.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/92/2.delta
[2025-07-19T21:02:38.286+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=92),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/92] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/92/2.delta
[2025-07-19T21:02:38.286+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/94/.2.delta.fb128bc1-a3ea-46fe-af09-7b412b9a363f.TID897.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/94/2.delta
[2025-07-19T21:02:38.287+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=94),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/94] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/94/2.delta
[2025-07-19T21:02:38.287+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/95/.2.delta.ec8d676a-62b5-418f-9bee-8606dfff8221.TID898.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/95/2.delta
[2025-07-19T21:02:38.287+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=95),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/95] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/95/2.delta
[2025-07-19T21:02:38.288+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 94 (task 897, attempt 0, stage 9.0)
[2025-07-19T21:02:38.288+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 95 (task 898, attempt 0, stage 9.0)
[2025-07-19T21:02:38.289+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/98/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/98/.2.delta.e90b654e-366c-405a-b229-4ea306929239.TID901.tmp
[2025-07-19T21:02:38.289+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 92 (task 895, attempt 0, stage 9.0)
[2025-07-19T21:02:38.289+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/96/.2.delta.6edb2493-d4c8-4b31-b86d-046efe79a9ea.TID899.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/96/2.delta
[2025-07-19T21:02:38.290+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=96),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/96] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/96/2.delta
[2025-07-19T21:02:38.291+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 94 (task 897, attempt 0, stage 9.0)
[2025-07-19T21:02:38.293+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 94.0 in stage 9.0 (TID 897). 5786 bytes result sent to driver
[2025-07-19T21:02:38.295+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/99/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/99/.2.delta.7d9e78b3-a62a-4c10-bd35-8f06495640ee.TID902.tmp
[2025-07-19T21:02:38.297+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 96 (task 899, attempt 0, stage 9.0)
[2025-07-19T21:02:38.297+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 95 (task 898, attempt 0, stage 9.0)
[2025-07-19T21:02:38.298+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 100.0 in stage 9.0 (TID 903) (8b44f3d35cfa, executor driver, partition 100, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.298+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 92 (task 895, attempt 0, stage 9.0)
[2025-07-19T21:02:38.299+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 100.0 in stage 9.0 (TID 903)
[2025-07-19T21:02:38.300+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 92.0 in stage 9.0 (TID 895). 5829 bytes result sent to driver
[2025-07-19T21:02:38.300+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 101.0 in stage 9.0 (TID 904) (8b44f3d35cfa, executor driver, partition 101, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.300+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 95.0 in stage 9.0 (TID 898). 5829 bytes result sent to driver
[2025-07-19T21:02:38.300+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.300+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.301+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 101.0 in stage 9.0 (TID 904)
[2025-07-19T21:02:38.301+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 102.0 in stage 9.0 (TID 905) (8b44f3d35cfa, executor driver, partition 102, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.302+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5b145cb6
[2025-07-19T21:02:38.303+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=100, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.304+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=100),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/100] for update
[2025-07-19T21:02:38.304+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 92.0 in stage 9.0 (TID 895) in 100 ms on 8b44f3d35cfa (executor driver) (93/200)
[2025-07-19T21:02:38.305+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/93/.2.delta.8ff9038c-25dd-4c98-9df9-f8459e37e1e8.TID896.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/93/2.delta
[2025-07-19T21:02:38.306+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=93),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/93] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/93/2.delta
[2025-07-19T21:02:38.306+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 93 (task 896, attempt 0, stage 9.0)
[2025-07-19T21:02:38.306+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 96 (task 899, attempt 0, stage 9.0)
[2025-07-19T21:02:38.307+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.307+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.307+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 102.0 in stage 9.0 (TID 905)
[2025-07-19T21:02:38.307+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.308+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 94.0 in stage 9.0 (TID 897) in 98 ms on 8b44f3d35cfa (executor driver) (94/200)
[2025-07-19T21:02:38.308+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 95.0 in stage 9.0 (TID 898) in 98 ms on 8b44f3d35cfa (executor driver) (95/200)
[2025-07-19T21:02:38.308+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 96.0 in stage 9.0 (TID 899). 5829 bytes result sent to driver
[2025-07-19T21:02:38.308+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 103.0 in stage 9.0 (TID 906) (8b44f3d35cfa, executor driver, partition 103, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.308+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 96.0 in stage 9.0 (TID 899) in 88 ms on 8b44f3d35cfa (executor driver) (96/200)
[2025-07-19T21:02:38.309+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@522a1653
[2025-07-19T21:02:38.309+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 93 (task 896, attempt 0, stage 9.0)
[2025-07-19T21:02:38.309+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 103.0 in stage 9.0 (TID 906)
[2025-07-19T21:02:38.310+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 93.0 in stage 9.0 (TID 896). 5829 bytes result sent to driver
[2025-07-19T21:02:38.310+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=101, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.311+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 104.0 in stage 9.0 (TID 907) (8b44f3d35cfa, executor driver, partition 104, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.311+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=101),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/101] for update
[2025-07-19T21:02:38.312+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 104.0 in stage 9.0 (TID 907)
[2025-07-19T21:02:38.312+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 93.0 in stage 9.0 (TID 896) in 106 ms on 8b44f3d35cfa (executor driver) (97/200)
[2025-07-19T21:02:38.314+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.315+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.315+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.316+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@115dfad3
[2025-07-19T21:02:38.317+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=103, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.317+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=103),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/103] for update
[2025-07-19T21:02:38.317+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.317+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.318+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.318+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:38.318+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.318+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a5df9b8
[2025-07-19T21:02:38.318+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=104, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.318+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=104),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/104] for update
[2025-07-19T21:02:38.320+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f5b41bc
[2025-07-19T21:02:38.321+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.321+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=102, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.322+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=102),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/102] for update
[2025-07-19T21:02:38.323+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.323+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/101/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/101/.2.delta.766e2db0-d4b9-4e8f-b14c-e86e784a924e.TID904.tmp
[2025-07-19T21:02:38.325+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/100/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/100/.2.delta.4ea767f0-b4f2-4e34-a7c4-89da4c77bb33.TID903.tmp
[2025-07-19T21:02:38.327+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/103/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/103/.2.delta.34712b0d-0bdf-4b9d-9fb3-5f1f56d0e07e.TID906.tmp
[2025-07-19T21:02:38.330+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/97/.2.delta.ad302165-ee29-4d06-97d4-c0563b4fc1da.TID900.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/97/2.delta
[2025-07-19T21:02:38.331+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=97),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/97] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/97/2.delta
[2025-07-19T21:02:38.331+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 97 (task 900, attempt 0, stage 9.0)
[2025-07-19T21:02:38.334+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/102/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/102/.2.delta.b3df1ec8-bb96-4ebb-b336-506f82f4c092.TID905.tmp
[2025-07-19T21:02:38.337+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/98/.2.delta.e90b654e-366c-405a-b229-4ea306929239.TID901.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/98/2.delta
[2025-07-19T21:02:38.337+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=98),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/98] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/98/2.delta
[2025-07-19T21:02:38.338+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 98 (task 901, attempt 0, stage 9.0)
[2025-07-19T21:02:38.338+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/99/.2.delta.7d9e78b3-a62a-4c10-bd35-8f06495640ee.TID902.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/99/2.delta
[2025-07-19T21:02:38.338+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=99),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/99] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/99/2.delta
[2025-07-19T21:02:38.339+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 97 (task 900, attempt 0, stage 9.0)
[2025-07-19T21:02:38.339+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 97.0 in stage 9.0 (TID 900). 5829 bytes result sent to driver
[2025-07-19T21:02:38.339+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 105.0 in stage 9.0 (TID 908) (8b44f3d35cfa, executor driver, partition 105, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.339+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 105.0 in stage 9.0 (TID 908)
[2025-07-19T21:02:38.340+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 97.0 in stage 9.0 (TID 900) in 79 ms on 8b44f3d35cfa (executor driver) (98/200)
[2025-07-19T21:02:38.340+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 99 (task 902, attempt 0, stage 9.0)
[2025-07-19T21:02:38.342+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/104/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/104/.2.delta.feea80f4-e148-41ab-90ca-e5346ac65b38.TID907.tmp
[2025-07-19T21:02:38.343+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 98 (task 901, attempt 0, stage 9.0)
[2025-07-19T21:02:38.346+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.347+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T21:02:38.348+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 99 (task 902, attempt 0, stage 9.0)
[2025-07-19T21:02:38.348+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 99.0 in stage 9.0 (TID 902). 5829 bytes result sent to driver
[2025-07-19T21:02:38.348+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 98.0 in stage 9.0 (TID 901). 5829 bytes result sent to driver
[2025-07-19T21:02:38.348+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 106.0 in stage 9.0 (TID 909) (8b44f3d35cfa, executor driver, partition 106, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.349+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 107.0 in stage 9.0 (TID 910) (8b44f3d35cfa, executor driver, partition 107, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.349+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 107.0 in stage 9.0 (TID 910)
[2025-07-19T21:02:38.349+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 106.0 in stage 9.0 (TID 909)
[2025-07-19T21:02:38.349+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 99.0 in stage 9.0 (TID 902) in 75 ms on 8b44f3d35cfa (executor driver) (99/200)
[2025-07-19T21:02:38.350+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 98.0 in stage 9.0 (TID 901) in 79 ms on 8b44f3d35cfa (executor driver) (100/200)
[2025-07-19T21:02:38.350+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@66ce7bf6
[2025-07-19T21:02:38.351+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=105, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.352+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=105),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/105] for update
[2025-07-19T21:02:38.353+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.353+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:38.356+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.357+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.360+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:38.361+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@250e8d79
[2025-07-19T21:02:38.361+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=106, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.362+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=106),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/106] for update
[2025-07-19T21:02:38.362+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@49717dfc
[2025-07-19T21:02:38.363+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=107, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.363+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=107),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/107] for update
[2025-07-19T21:02:38.364+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.366+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.371+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/106/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/106/.2.delta.7be116fe-14ef-4ee6-8bf4-c550088c5754.TID909.tmp
[2025-07-19T21:02:38.374+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/105/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/105/.2.delta.1a6e5e7c-fe62-4ab4-b53d-c464d47ad572.TID908.tmp
[2025-07-19T21:02:38.375+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/101/.2.delta.766e2db0-d4b9-4e8f-b14c-e86e784a924e.TID904.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/101/2.delta
[2025-07-19T21:02:38.375+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=101),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/101] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/101/2.delta
[2025-07-19T21:02:38.375+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/103/.2.delta.34712b0d-0bdf-4b9d-9fb3-5f1f56d0e07e.TID906.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/103/2.delta
[2025-07-19T21:02:38.376+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=103),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/103] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/103/2.delta
[2025-07-19T21:02:38.376+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 101 (task 904, attempt 0, stage 9.0)
[2025-07-19T21:02:38.376+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 103 (task 906, attempt 0, stage 9.0)
[2025-07-19T21:02:38.377+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/102/.2.delta.b3df1ec8-bb96-4ebb-b336-506f82f4c092.TID905.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/102/2.delta
[2025-07-19T21:02:38.378+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=102),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/102] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/102/2.delta
[2025-07-19T21:02:38.378+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 102 (task 905, attempt 0, stage 9.0)
[2025-07-19T21:02:38.379+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/100/.2.delta.4ea767f0-b4f2-4e34-a7c4-89da4c77bb33.TID903.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/100/2.delta
[2025-07-19T21:02:38.379+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=100),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/100] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/100/2.delta
[2025-07-19T21:02:38.379+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 103 (task 906, attempt 0, stage 9.0)
[2025-07-19T21:02:38.379+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 100 (task 903, attempt 0, stage 9.0)
[2025-07-19T21:02:38.380+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 103.0 in stage 9.0 (TID 906). 5829 bytes result sent to driver
[2025-07-19T21:02:38.386+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 108.0 in stage 9.0 (TID 911) (8b44f3d35cfa, executor driver, partition 108, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.389+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/107/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/107/.2.delta.f20dee87-6794-4471-9a65-2b8ac6ae7900.TID910.tmp
[2025-07-19T21:02:38.390+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 102 (task 905, attempt 0, stage 9.0)
[2025-07-19T21:02:38.390+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 108.0 in stage 9.0 (TID 911)
[2025-07-19T21:02:38.391+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 100 (task 903, attempt 0, stage 9.0)
[2025-07-19T21:02:38.391+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 103.0 in stage 9.0 (TID 906) in 77 ms on 8b44f3d35cfa (executor driver) (101/200)
[2025-07-19T21:02:38.391+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 100.0 in stage 9.0 (TID 903). 5829 bytes result sent to driver
[2025-07-19T21:02:38.392+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 109.0 in stage 9.0 (TID 912) (8b44f3d35cfa, executor driver, partition 109, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.392+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 109.0 in stage 9.0 (TID 912)
[2025-07-19T21:02:38.393+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 102.0 in stage 9.0 (TID 905). 5829 bytes result sent to driver
[2025-07-19T21:02:38.394+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 110.0 in stage 9.0 (TID 913) (8b44f3d35cfa, executor driver, partition 110, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.394+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 110.0 in stage 9.0 (TID 913)
[2025-07-19T21:02:38.395+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 100.0 in stage 9.0 (TID 903) in 89 ms on 8b44f3d35cfa (executor driver) (102/200)
[2025-07-19T21:02:38.397+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 102.0 in stage 9.0 (TID 905) in 86 ms on 8b44f3d35cfa (executor driver) (103/200)
[2025-07-19T21:02:38.397+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 101 (task 904, attempt 0, stage 9.0)
[2025-07-19T21:02:38.398+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.400+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.401+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.402+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.403+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.404+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.405+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 101.0 in stage 9.0 (TID 904). 5829 bytes result sent to driver
[2025-07-19T21:02:38.405+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 111.0 in stage 9.0 (TID 914) (8b44f3d35cfa, executor driver, partition 111, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.406+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@11e7c996
[2025-07-19T21:02:38.406+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 111.0 in stage 9.0 (TID 914)
[2025-07-19T21:02:38.406+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 101.0 in stage 9.0 (TID 904) in 90 ms on 8b44f3d35cfa (executor driver) (104/200)
[2025-07-19T21:02:38.407+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=109, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.407+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=109),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/109] for update
[2025-07-19T21:02:38.407+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.408+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T21:02:38.408+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.409+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@102ce7e7
[2025-07-19T21:02:38.409+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/104/.2.delta.feea80f4-e148-41ab-90ca-e5346ac65b38.TID907.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/104/2.delta
[2025-07-19T21:02:38.412+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=104),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/104] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/104/2.delta
[2025-07-19T21:02:38.412+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 104 (task 907, attempt 0, stage 9.0)
[2025-07-19T21:02:38.413+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=110, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.413+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=110),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/110] for update
[2025-07-19T21:02:38.414+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a2f160e
[2025-07-19T21:02:38.416+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=108, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.416+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=108),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/108] for update
[2025-07-19T21:02:38.416+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.417+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@38223ce9
[2025-07-19T21:02:38.417+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=111, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.417+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=111),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/111] for update
[2025-07-19T21:02:38.418+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.418+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 104 (task 907, attempt 0, stage 9.0)
[2025-07-19T21:02:38.418+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.418+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 104.0 in stage 9.0 (TID 907). 5829 bytes result sent to driver
[2025-07-19T21:02:38.418+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 112.0 in stage 9.0 (TID 915) (8b44f3d35cfa, executor driver, partition 112, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.418+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 112.0 in stage 9.0 (TID 915)
[2025-07-19T21:02:38.419+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 104.0 in stage 9.0 (TID 907) in 96 ms on 8b44f3d35cfa (executor driver) (105/200)
[2025-07-19T21:02:38.419+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/109/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/109/.2.delta.976596b0-a0db-42a3-852e-1862a079e2c5.TID912.tmp
[2025-07-19T21:02:38.420+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.420+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.420+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7792c2a8
[2025-07-19T21:02:38.421+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=112, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.421+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=112),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/112] for update
[2025-07-19T21:02:38.421+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.422+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/108/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/108/.2.delta.c910f524-978b-4ce6-acc4-670f429a3af3.TID911.tmp
[2025-07-19T21:02:38.422+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/111/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/111/.2.delta.5d472628-d646-446c-936b-35d0c8b5b19c.TID914.tmp
[2025-07-19T21:02:38.423+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/110/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/110/.2.delta.8303333d-509f-48c6-93e8-521f16642461.TID913.tmp
[2025-07-19T21:02:38.426+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/106/.2.delta.7be116fe-14ef-4ee6-8bf4-c550088c5754.TID909.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/106/2.delta
[2025-07-19T21:02:38.426+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=106),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/106] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/106/2.delta
[2025-07-19T21:02:38.427+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 106 (task 909, attempt 0, stage 9.0)
[2025-07-19T21:02:38.428+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/112/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/112/.2.delta.2d2e3b05-b577-447b-9132-f3f28dbff36b.TID915.tmp
[2025-07-19T21:02:38.429+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/105/.2.delta.1a6e5e7c-fe62-4ab4-b53d-c464d47ad572.TID908.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/105/2.delta
[2025-07-19T21:02:38.429+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=105),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/105] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/105/2.delta
[2025-07-19T21:02:38.429+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/107/.2.delta.f20dee87-6794-4471-9a65-2b8ac6ae7900.TID910.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/107/2.delta
[2025-07-19T21:02:38.430+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=107),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/107] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/107/2.delta
[2025-07-19T21:02:38.430+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 105 (task 908, attempt 0, stage 9.0)
[2025-07-19T21:02:38.432+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 107 (task 910, attempt 0, stage 9.0)
[2025-07-19T21:02:38.432+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 106 (task 909, attempt 0, stage 9.0)
[2025-07-19T21:02:38.432+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 106.0 in stage 9.0 (TID 909). 5829 bytes result sent to driver
[2025-07-19T21:02:38.433+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 107 (task 910, attempt 0, stage 9.0)
[2025-07-19T21:02:38.434+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 105 (task 908, attempt 0, stage 9.0)
[2025-07-19T21:02:38.434+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 107.0 in stage 9.0 (TID 910). 5829 bytes result sent to driver
[2025-07-19T21:02:38.435+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 113.0 in stage 9.0 (TID 916) (8b44f3d35cfa, executor driver, partition 113, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.436+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 114.0 in stage 9.0 (TID 917) (8b44f3d35cfa, executor driver, partition 114, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.436+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 107.0 in stage 9.0 (TID 910) in 86 ms on 8b44f3d35cfa (executor driver) (106/200)
[2025-07-19T21:02:38.436+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 113.0 in stage 9.0 (TID 916)
[2025-07-19T21:02:38.436+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 106.0 in stage 9.0 (TID 909) in 86 ms on 8b44f3d35cfa (executor driver) (107/200)
[2025-07-19T21:02:38.436+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 114.0 in stage 9.0 (TID 917)
[2025-07-19T21:02:38.437+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 105.0 in stage 9.0 (TID 908). 5829 bytes result sent to driver
[2025-07-19T21:02:38.438+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 115.0 in stage 9.0 (TID 918) (8b44f3d35cfa, executor driver, partition 115, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.440+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 105.0 in stage 9.0 (TID 908) in 98 ms on 8b44f3d35cfa (executor driver) (108/200)
[2025-07-19T21:02:38.440+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 115.0 in stage 9.0 (TID 918)
[2025-07-19T21:02:38.441+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.441+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.441+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.441+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.441+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@149376c6
[2025-07-19T21:02:38.442+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.442+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.443+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=114, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.443+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=114),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/114] for update
[2025-07-19T21:02:38.444+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@fa15b5b
[2025-07-19T21:02:38.444+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=115, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.446+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=115),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/115] for update
[2025-07-19T21:02:38.446+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.446+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.447+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@725f9f98
[2025-07-19T21:02:38.447+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=113, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.447+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=113),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/113] for update
[2025-07-19T21:02:38.448+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.448+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/114/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/114/.2.delta.1ab74b86-e397-4f16-81e3-cc5467b2c7ea.TID917.tmp
[2025-07-19T21:02:38.449+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/115/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/115/.2.delta.6e9a5104-a9c2-4343-9332-9d977e3321a9.TID918.tmp
[2025-07-19T21:02:38.449+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/113/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/113/.2.delta.6aeccbd8-fa14-4663-a425-e108a2267f76.TID916.tmp
[2025-07-19T21:02:38.457+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/109/.2.delta.976596b0-a0db-42a3-852e-1862a079e2c5.TID912.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/109/2.delta
[2025-07-19T21:02:38.458+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=109),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/109] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/109/2.delta
[2025-07-19T21:02:38.458+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/110/.2.delta.8303333d-509f-48c6-93e8-521f16642461.TID913.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/110/2.delta
[2025-07-19T21:02:38.460+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=110),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/110] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/110/2.delta
[2025-07-19T21:02:38.461+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 109 (task 912, attempt 0, stage 9.0)
[2025-07-19T21:02:38.461+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 110 (task 913, attempt 0, stage 9.0)
[2025-07-19T21:02:38.462+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 110 (task 913, attempt 0, stage 9.0)
[2025-07-19T21:02:38.462+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 109 (task 912, attempt 0, stage 9.0)
[2025-07-19T21:02:38.467+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 110.0 in stage 9.0 (TID 913). 5872 bytes result sent to driver
[2025-07-19T21:02:38.468+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/112/.2.delta.2d2e3b05-b577-447b-9132-f3f28dbff36b.TID915.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/112/2.delta
[2025-07-19T21:02:38.468+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=112),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/112] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/112/2.delta
[2025-07-19T21:02:38.471+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 116.0 in stage 9.0 (TID 919) (8b44f3d35cfa, executor driver, partition 116, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.472+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 109.0 in stage 9.0 (TID 912). 5872 bytes result sent to driver
[2025-07-19T21:02:38.473+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 110.0 in stage 9.0 (TID 913) in 88 ms on 8b44f3d35cfa (executor driver) (109/200)
[2025-07-19T21:02:38.474+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 117.0 in stage 9.0 (TID 920) (8b44f3d35cfa, executor driver, partition 117, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.475+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 117.0 in stage 9.0 (TID 920)
[2025-07-19T21:02:38.475+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 109.0 in stage 9.0 (TID 912) in 89 ms on 8b44f3d35cfa (executor driver) (110/200)
[2025-07-19T21:02:38.475+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 112 (task 915, attempt 0, stage 9.0)
[2025-07-19T21:02:38.476+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 116.0 in stage 9.0 (TID 919)
[2025-07-19T21:02:38.477+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.478+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.479+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.479+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.480+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/108/.2.delta.c910f524-978b-4ce6-acc4-670f429a3af3.TID911.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/108/2.delta
[2025-07-19T21:02:38.480+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=108),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/108] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/108/2.delta
[2025-07-19T21:02:38.480+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/111/.2.delta.5d472628-d646-446c-936b-35d0c8b5b19c.TID914.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/111/2.delta
[2025-07-19T21:02:38.481+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=111),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/111] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/111/2.delta
[2025-07-19T21:02:38.481+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 108 (task 911, attempt 0, stage 9.0)
[2025-07-19T21:02:38.483+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 111 (task 914, attempt 0, stage 9.0)
[2025-07-19T21:02:38.485+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20d67ddc
[2025-07-19T21:02:38.485+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=117, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.486+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=117),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/117] for update
[2025-07-19T21:02:38.487+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 112 (task 915, attempt 0, stage 9.0)
[2025-07-19T21:02:38.488+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1453a8c6
[2025-07-19T21:02:38.488+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 112.0 in stage 9.0 (TID 915). 5872 bytes result sent to driver
[2025-07-19T21:02:38.489+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 118.0 in stage 9.0 (TID 921) (8b44f3d35cfa, executor driver, partition 118, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.489+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=116, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.492+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 112.0 in stage 9.0 (TID 915) in 76 ms on 8b44f3d35cfa (executor driver) (111/200)
[2025-07-19T21:02:38.493+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=116),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/116] for update
[2025-07-19T21:02:38.493+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.494+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 118.0 in stage 9.0 (TID 921)
[2025-07-19T21:02:38.495+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.495+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.497+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.498+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 111 (task 914, attempt 0, stage 9.0)
[2025-07-19T21:02:38.499+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 108 (task 911, attempt 0, stage 9.0)
[2025-07-19T21:02:38.500+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 108.0 in stage 9.0 (TID 911). 5872 bytes result sent to driver
[2025-07-19T21:02:38.501+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 111.0 in stage 9.0 (TID 914). 5872 bytes result sent to driver
[2025-07-19T21:02:38.501+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 119.0 in stage 9.0 (TID 922) (8b44f3d35cfa, executor driver, partition 119, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.501+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2db89c9b
[2025-07-19T21:02:38.502+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 119.0 in stage 9.0 (TID 922)
[2025-07-19T21:02:38.502+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 120.0 in stage 9.0 (TID 923) (8b44f3d35cfa, executor driver, partition 120, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.503+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=118, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.504+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=118),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/118] for update
[2025-07-19T21:02:38.504+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 108.0 in stage 9.0 (TID 911) in 106 ms on 8b44f3d35cfa (executor driver) (112/200)
[2025-07-19T21:02:38.505+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 120.0 in stage 9.0 (TID 923)
[2025-07-19T21:02:38.507+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.508+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.508+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.512+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.514+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.515+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 111.0 in stage 9.0 (TID 914) in 105 ms on 8b44f3d35cfa (executor driver) (113/200)
[2025-07-19T21:02:38.516+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@38f89384
[2025-07-19T21:02:38.516+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=120, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.516+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=120),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/120] for update
[2025-07-19T21:02:38.516+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.516+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e0b22e5
[2025-07-19T21:02:38.517+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=119, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.517+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=119),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/119] for update
[2025-07-19T21:02:38.517+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.517+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/115/.2.delta.6e9a5104-a9c2-4343-9332-9d977e3321a9.TID918.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/115/2.delta
[2025-07-19T21:02:38.517+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=115),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/115] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/115/2.delta
[2025-07-19T21:02:38.517+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/117/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/117/.2.delta.c594d1f8-9e26-4c23-9a36-3504d40b89e1.TID920.tmp
[2025-07-19T21:02:38.517+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 115 (task 918, attempt 0, stage 9.0)
[2025-07-19T21:02:38.517+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/113/.2.delta.6aeccbd8-fa14-4663-a425-e108a2267f76.TID916.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/113/2.delta
[2025-07-19T21:02:38.517+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=113),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/113] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/113/2.delta
[2025-07-19T21:02:38.517+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 113 (task 916, attempt 0, stage 9.0)
[2025-07-19T21:02:38.517+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/116/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/116/.2.delta.3145c5f2-aba2-4dc0-a655-fe495b8719dc.TID919.tmp
[2025-07-19T21:02:38.518+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/118/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/118/.2.delta.28aedccf-325b-47a2-afd0-14c5260937e0.TID921.tmp
[2025-07-19T21:02:38.518+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 115 (task 918, attempt 0, stage 9.0)
[2025-07-19T21:02:38.518+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 115.0 in stage 9.0 (TID 918). 5829 bytes result sent to driver
[2025-07-19T21:02:38.518+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 121.0 in stage 9.0 (TID 924) (8b44f3d35cfa, executor driver, partition 121, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.518+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 115.0 in stage 9.0 (TID 918) in 71 ms on 8b44f3d35cfa (executor driver) (114/200)
[2025-07-19T21:02:38.518+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 121.0 in stage 9.0 (TID 924)
[2025-07-19T21:02:38.518+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 113 (task 916, attempt 0, stage 9.0)
[2025-07-19T21:02:38.518+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 113.0 in stage 9.0 (TID 916). 5872 bytes result sent to driver
[2025-07-19T21:02:38.518+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/114/.2.delta.1ab74b86-e397-4f16-81e3-cc5467b2c7ea.TID917.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/114/2.delta
[2025-07-19T21:02:38.518+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=114),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/114] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/114/2.delta
[2025-07-19T21:02:38.518+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.518+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 114 (task 917, attempt 0, stage 9.0)
[2025-07-19T21:02:38.519+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 122.0 in stage 9.0 (TID 925) (8b44f3d35cfa, executor driver, partition 122, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.519+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 113.0 in stage 9.0 (TID 916) in 76 ms on 8b44f3d35cfa (executor driver) (115/200)
[2025-07-19T21:02:38.519+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:38.519+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 122.0 in stage 9.0 (TID 925)
[2025-07-19T21:02:38.519+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c9f8e67
[2025-07-19T21:02:38.519+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=121, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.520+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=121),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/121] for update
[2025-07-19T21:02:38.520+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 114 (task 917, attempt 0, stage 9.0)
[2025-07-19T21:02:38.520+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 114.0 in stage 9.0 (TID 917). 5872 bytes result sent to driver
[2025-07-19T21:02:38.521+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 114.0 in stage 9.0 (TID 917) in 79 ms on 8b44f3d35cfa (executor driver) (116/200)
[2025-07-19T21:02:38.521+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 123.0 in stage 9.0 (TID 926) (8b44f3d35cfa, executor driver, partition 123, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.521+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 123.0 in stage 9.0 (TID 926)
[2025-07-19T21:02:38.521+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/119/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/119/.2.delta.71c9346a-c1df-4668-b89a-4dc327055dc0.TID922.tmp
[2025-07-19T21:02:38.521+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.522+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.522+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.522+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b8be319
[2025-07-19T21:02:38.522+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.523+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.523+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=123, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.524+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=123),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/123] for update
[2025-07-19T21:02:38.528+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/120/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/120/.2.delta.ff8856aa-d433-49c8-a511-bb9bf914e80b.TID923.tmp
[2025-07-19T21:02:38.529+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.529+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@437a43c6
[2025-07-19T21:02:38.530+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=122, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.530+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=122),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/122] for update
[2025-07-19T21:02:38.533+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.544+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/121/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/121/.2.delta.a523913c-c364-40ff-8d72-7baf103e7e1c.TID924.tmp
[2025-07-19T21:02:38.544+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/123/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/123/.2.delta.d8459793-c016-4211-a4dc-b6f356a56275.TID926.tmp
[2025-07-19T21:02:38.544+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/122/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/122/.2.delta.9640d842-de11-489d-a2bb-7af275ffd363.TID925.tmp
[2025-07-19T21:02:38.561+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/118/.2.delta.28aedccf-325b-47a2-afd0-14c5260937e0.TID921.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/118/2.delta
[2025-07-19T21:02:38.561+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=118),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/118] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/118/2.delta
[2025-07-19T21:02:38.561+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 118 (task 921, attempt 0, stage 9.0)
[2025-07-19T21:02:38.565+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 118 (task 921, attempt 0, stage 9.0)
[2025-07-19T21:02:38.567+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/116/.2.delta.3145c5f2-aba2-4dc0-a655-fe495b8719dc.TID919.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/116/2.delta
[2025-07-19T21:02:38.568+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=116),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/116] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/116/2.delta
[2025-07-19T21:02:38.569+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 118.0 in stage 9.0 (TID 921). 5829 bytes result sent to driver
[2025-07-19T21:02:38.570+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 116 (task 919, attempt 0, stage 9.0)
[2025-07-19T21:02:38.571+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 118.0 in stage 9.0 (TID 921) in 87 ms on 8b44f3d35cfa (executor driver) (117/200)
[2025-07-19T21:02:38.571+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 124.0 in stage 9.0 (TID 927) (8b44f3d35cfa, executor driver, partition 124, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.571+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 124.0 in stage 9.0 (TID 927)
[2025-07-19T21:02:38.572+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 116 (task 919, attempt 0, stage 9.0)
[2025-07-19T21:02:38.572+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/119/.2.delta.71c9346a-c1df-4668-b89a-4dc327055dc0.TID922.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/119/2.delta
[2025-07-19T21:02:38.575+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=119),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/119] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/119/2.delta
[2025-07-19T21:02:38.576+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 116.0 in stage 9.0 (TID 919). 5786 bytes result sent to driver
[2025-07-19T21:02:38.576+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.576+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.576+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 119 (task 922, attempt 0, stage 9.0)
[2025-07-19T21:02:38.576+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f5c2b9b
[2025-07-19T21:02:38.576+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=124, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.576+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=124),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/124] for update
[2025-07-19T21:02:38.576+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 125.0 in stage 9.0 (TID 928) (8b44f3d35cfa, executor driver, partition 125, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.576+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 116.0 in stage 9.0 (TID 919) in 101 ms on 8b44f3d35cfa (executor driver) (118/200)
[2025-07-19T21:02:38.577+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 125.0 in stage 9.0 (TID 928)
[2025-07-19T21:02:38.577+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.578+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/120/.2.delta.ff8856aa-d433-49c8-a511-bb9bf914e80b.TID923.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/120/2.delta
[2025-07-19T21:02:38.579+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=120),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/120] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/120/2.delta
[2025-07-19T21:02:38.580+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/117/.2.delta.c594d1f8-9e26-4c23-9a36-3504d40b89e1.TID920.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/117/2.delta
[2025-07-19T21:02:38.580+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=117),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/117] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/117/2.delta
[2025-07-19T21:02:38.581+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 120 (task 923, attempt 0, stage 9.0)
[2025-07-19T21:02:38.582+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 117 (task 920, attempt 0, stage 9.0)
[2025-07-19T21:02:38.582+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 119 (task 922, attempt 0, stage 9.0)
[2025-07-19T21:02:38.582+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 119.0 in stage 9.0 (TID 922). 5829 bytes result sent to driver
[2025-07-19T21:02:38.582+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 126.0 in stage 9.0 (TID 929) (8b44f3d35cfa, executor driver, partition 126, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.583+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 119.0 in stage 9.0 (TID 922) in 97 ms on 8b44f3d35cfa (executor driver) (119/200)
[2025-07-19T21:02:38.583+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 117 (task 920, attempt 0, stage 9.0)
[2025-07-19T21:02:38.585+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.585+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 117.0 in stage 9.0 (TID 920). 5829 bytes result sent to driver
[2025-07-19T21:02:38.586+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T21:02:38.586+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 127.0 in stage 9.0 (TID 930) (8b44f3d35cfa, executor driver, partition 127, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.586+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 117.0 in stage 9.0 (TID 920) in 110 ms on 8b44f3d35cfa (executor driver) (120/200)
[2025-07-19T21:02:38.587+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 120 (task 923, attempt 0, stage 9.0)
[2025-07-19T21:02:38.587+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 120.0 in stage 9.0 (TID 923). 5786 bytes result sent to driver
[2025-07-19T21:02:38.587+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 128.0 in stage 9.0 (TID 931) (8b44f3d35cfa, executor driver, partition 128, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.587+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 120.0 in stage 9.0 (TID 923) in 98 ms on 8b44f3d35cfa (executor driver) (121/200)
[2025-07-19T21:02:38.588+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 126.0 in stage 9.0 (TID 929)
[2025-07-19T21:02:38.591+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 128.0 in stage 9.0 (TID 931)
[2025-07-19T21:02:38.591+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 127.0 in stage 9.0 (TID 930)
[2025-07-19T21:02:38.592+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@603fb445
[2025-07-19T21:02:38.592+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=125, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.592+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=125),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/125] for update
[2025-07-19T21:02:38.592+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.593+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.593+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.594+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.594+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.595+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@21fbd5d0
[2025-07-19T21:02:38.596+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=128, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.597+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=128),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/128] for update
[2025-07-19T21:02:38.597+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.598+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.599+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:38.599+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3037e4e2
[2025-07-19T21:02:38.599+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/124/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/124/.2.delta.ccbf08dd-71c5-4edf-93b7-325a1b1d175b.TID927.tmp
[2025-07-19T21:02:38.600+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=126, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.601+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=126),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/126] for update
[2025-07-19T21:02:38.601+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71185a73
[2025-07-19T21:02:38.601+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/121/.2.delta.a523913c-c364-40ff-8d72-7baf103e7e1c.TID924.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/121/2.delta
[2025-07-19T21:02:38.602+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=121),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/121] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/121/2.delta
[2025-07-19T21:02:38.602+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.602+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=127, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.602+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=127),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/127] for update
[2025-07-19T21:02:38.602+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 121 (task 924, attempt 0, stage 9.0)
[2025-07-19T21:02:38.602+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.602+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 121 (task 924, attempt 0, stage 9.0)
[2025-07-19T21:02:38.602+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 121.0 in stage 9.0 (TID 924). 5829 bytes result sent to driver
[2025-07-19T21:02:38.604+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/123/.2.delta.d8459793-c016-4211-a4dc-b6f356a56275.TID926.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/123/2.delta
[2025-07-19T21:02:38.604+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=123),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/123] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/123/2.delta
[2025-07-19T21:02:38.604+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 129.0 in stage 9.0 (TID 932) (8b44f3d35cfa, executor driver, partition 129, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.604+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 129.0 in stage 9.0 (TID 932)
[2025-07-19T21:02:38.605+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 121.0 in stage 9.0 (TID 924) in 92 ms on 8b44f3d35cfa (executor driver) (122/200)
[2025-07-19T21:02:38.605+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 123 (task 926, attempt 0, stage 9.0)
[2025-07-19T21:02:38.605+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/125/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/125/.2.delta.0b5eb99d-0f6f-4214-82a1-e825102fd8f7.TID928.tmp
[2025-07-19T21:02:38.605+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.605+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.605+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/122/.2.delta.9640d842-de11-489d-a2bb-7af275ffd363.TID925.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/122/2.delta
[2025-07-19T21:02:38.605+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=122),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/122] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/122/2.delta
[2025-07-19T21:02:38.606+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e8a8bd5
[2025-07-19T21:02:38.606+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 122 (task 925, attempt 0, stage 9.0)
[2025-07-19T21:02:38.607+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=129, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.607+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=129),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/129] for update
[2025-07-19T21:02:38.607+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 123 (task 926, attempt 0, stage 9.0)
[2025-07-19T21:02:38.607+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 123.0 in stage 9.0 (TID 926). 5786 bytes result sent to driver
[2025-07-19T21:02:38.607+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/128/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/128/.2.delta.b2b3621e-edd7-4e0c-a0de-b2e0bb32b565.TID931.tmp
[2025-07-19T21:02:38.607+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 130.0 in stage 9.0 (TID 933) (8b44f3d35cfa, executor driver, partition 130, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.608+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 123.0 in stage 9.0 (TID 926) in 91 ms on 8b44f3d35cfa (executor driver) (123/200)
[2025-07-19T21:02:38.608+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 130.0 in stage 9.0 (TID 933)
[2025-07-19T21:02:38.608+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/127/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/127/.2.delta.c6da7cc8-1a88-4fe3-8fee-aca4fa324282.TID930.tmp
[2025-07-19T21:02:38.609+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/126/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/126/.2.delta.e7c17e3f-b016-4b26-98ba-7236fe23d991.TID929.tmp
[2025-07-19T21:02:38.609+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.610+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.610+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.610+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 122 (task 925, attempt 0, stage 9.0)
[2025-07-19T21:02:38.611+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 122.0 in stage 9.0 (TID 925). 5829 bytes result sent to driver
[2025-07-19T21:02:38.611+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56a351a4
[2025-07-19T21:02:38.611+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 131.0 in stage 9.0 (TID 934) (8b44f3d35cfa, executor driver, partition 131, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.611+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=130, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.611+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=130),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/130] for update
[2025-07-19T21:02:38.611+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 131.0 in stage 9.0 (TID 934)
[2025-07-19T21:02:38.611+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 122.0 in stage 9.0 (TID 925) in 100 ms on 8b44f3d35cfa (executor driver) (124/200)
[2025-07-19T21:02:38.612+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.613+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.613+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.614+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c9e4fb7
[2025-07-19T21:02:38.614+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=131, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.615+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=131),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/131] for update
[2025-07-19T21:02:38.616+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.619+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/129/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/129/.2.delta.1aa167a5-7247-4366-9a64-e341cca8f1e1.TID932.tmp
[2025-07-19T21:02:38.620+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/130/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/130/.2.delta.12d494ed-c2c9-4210-9aab-afbe9c38d926.TID933.tmp
[2025-07-19T21:02:38.628+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/131/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/131/.2.delta.83b88614-3062-4a44-ad24-4270851b38db.TID934.tmp
[2025-07-19T21:02:38.633+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/127/.2.delta.c6da7cc8-1a88-4fe3-8fee-aca4fa324282.TID930.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/127/2.delta
[2025-07-19T21:02:38.633+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=127),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/127] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/127/2.delta
[2025-07-19T21:02:38.634+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 127 (task 930, attempt 0, stage 9.0)
[2025-07-19T21:02:38.635+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/124/.2.delta.ccbf08dd-71c5-4edf-93b7-325a1b1d175b.TID927.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/124/2.delta
[2025-07-19T21:02:38.635+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=124),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/124] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/124/2.delta
[2025-07-19T21:02:38.636+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 124 (task 927, attempt 0, stage 9.0)
[2025-07-19T21:02:38.637+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 127 (task 930, attempt 0, stage 9.0)
[2025-07-19T21:02:38.637+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 124 (task 927, attempt 0, stage 9.0)
[2025-07-19T21:02:38.637+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 127.0 in stage 9.0 (TID 930). 5829 bytes result sent to driver
[2025-07-19T21:02:38.640+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/125/.2.delta.0b5eb99d-0f6f-4214-82a1-e825102fd8f7.TID928.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/125/2.delta
[2025-07-19T21:02:38.642+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=125),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/125] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/125/2.delta
[2025-07-19T21:02:38.642+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 124.0 in stage 9.0 (TID 927). 5829 bytes result sent to driver
[2025-07-19T21:02:38.643+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 125 (task 928, attempt 0, stage 9.0)
[2025-07-19T21:02:38.644+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 132.0 in stage 9.0 (TID 935) (8b44f3d35cfa, executor driver, partition 132, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.644+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 133.0 in stage 9.0 (TID 936) (8b44f3d35cfa, executor driver, partition 133, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.644+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 127.0 in stage 9.0 (TID 930) in 56 ms on 8b44f3d35cfa (executor driver) (125/200)
[2025-07-19T21:02:38.645+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 132.0 in stage 9.0 (TID 935)
[2025-07-19T21:02:38.646+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 133.0 in stage 9.0 (TID 936)
[2025-07-19T21:02:38.646+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 124.0 in stage 9.0 (TID 927) in 73 ms on 8b44f3d35cfa (executor driver) (126/200)
[2025-07-19T21:02:38.648+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.650+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.650+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.650+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.650+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 125 (task 928, attempt 0, stage 9.0)
[2025-07-19T21:02:38.650+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 125.0 in stage 9.0 (TID 928). 5829 bytes result sent to driver
[2025-07-19T21:02:38.650+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 134.0 in stage 9.0 (TID 937) (8b44f3d35cfa, executor driver, partition 134, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.650+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 125.0 in stage 9.0 (TID 928) in 74 ms on 8b44f3d35cfa (executor driver) (127/200)
[2025-07-19T21:02:38.651+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ac2b351
[2025-07-19T21:02:38.651+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 134.0 in stage 9.0 (TID 937)
[2025-07-19T21:02:38.651+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=132, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.651+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=132),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/132] for update
[2025-07-19T21:02:38.652+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/126/.2.delta.e7c17e3f-b016-4b26-98ba-7236fe23d991.TID929.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/126/2.delta
[2025-07-19T21:02:38.653+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=126),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/126] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/126/2.delta
[2025-07-19T21:02:38.653+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@343e0fda
[2025-07-19T21:02:38.653+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.653+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.653+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.653+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 126 (task 929, attempt 0, stage 9.0)
[2025-07-19T21:02:38.653+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/128/.2.delta.b2b3621e-edd7-4e0c-a0de-b2e0bb32b565.TID931.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/128/2.delta
[2025-07-19T21:02:38.653+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=128),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/128] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/128/2.delta
[2025-07-19T21:02:38.654+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=133, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.654+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=133),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/133] for update
[2025-07-19T21:02:38.654+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 128 (task 931, attempt 0, stage 9.0)
[2025-07-19T21:02:38.656+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 126 (task 929, attempt 0, stage 9.0)
[2025-07-19T21:02:38.657+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 126.0 in stage 9.0 (TID 929). 5829 bytes result sent to driver
[2025-07-19T21:02:38.657+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.658+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 135.0 in stage 9.0 (TID 938) (8b44f3d35cfa, executor driver, partition 135, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.660+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c842f62
[2025-07-19T21:02:38.661+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 126.0 in stage 9.0 (TID 929) in 78 ms on 8b44f3d35cfa (executor driver) (128/200)
[2025-07-19T21:02:38.663+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 135.0 in stage 9.0 (TID 938)
[2025-07-19T21:02:38.664+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 128 (task 931, attempt 0, stage 9.0)
[2025-07-19T21:02:38.664+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/129/.2.delta.1aa167a5-7247-4366-9a64-e341cca8f1e1.TID932.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/129/2.delta
[2025-07-19T21:02:38.667+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=129),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/129] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/129/2.delta
[2025-07-19T21:02:38.668+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 128.0 in stage 9.0 (TID 931). 5829 bytes result sent to driver
[2025-07-19T21:02:38.669+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/130/.2.delta.12d494ed-c2c9-4210-9aab-afbe9c38d926.TID933.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/130/2.delta
[2025-07-19T21:02:38.670+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=130),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/130] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/130/2.delta
[2025-07-19T21:02:38.670+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.671+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.671+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 129 (task 932, attempt 0, stage 9.0)
[2025-07-19T21:02:38.672+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 128.0 in stage 9.0 (TID 931) in 80 ms on 8b44f3d35cfa (executor driver) (129/200)
[2025-07-19T21:02:38.672+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 136.0 in stage 9.0 (TID 939) (8b44f3d35cfa, executor driver, partition 136, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.672+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 136.0 in stage 9.0 (TID 939)
[2025-07-19T21:02:38.673+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=134, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.673+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 130 (task 933, attempt 0, stage 9.0)
[2025-07-19T21:02:38.673+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=134),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/134] for update
[2025-07-19T21:02:38.674+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/132/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/132/.2.delta.8fda4ac7-4e18-4d8c-86bc-c3e9f42231b7.TID935.tmp
[2025-07-19T21:02:38.674+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1313555c
[2025-07-19T21:02:38.675+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=135, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.675+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=135),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/135] for update
[2025-07-19T21:02:38.676+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.676+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.676+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.677+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33c959ed
[2025-07-19T21:02:38.677+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.678+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=136, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.678+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=136),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/136] for update
[2025-07-19T21:02:38.680+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/133/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/133/.2.delta.5a4b104d-5a90-434a-8e6f-beb95eeb7150.TID936.tmp
[2025-07-19T21:02:38.682+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 130 (task 933, attempt 0, stage 9.0)
[2025-07-19T21:02:38.682+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.684+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 129 (task 932, attempt 0, stage 9.0)
[2025-07-19T21:02:38.685+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 129.0 in stage 9.0 (TID 932). 5829 bytes result sent to driver
[2025-07-19T21:02:38.685+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 130.0 in stage 9.0 (TID 933). 5829 bytes result sent to driver
[2025-07-19T21:02:38.687+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 137.0 in stage 9.0 (TID 940) (8b44f3d35cfa, executor driver, partition 137, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.688+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 137.0 in stage 9.0 (TID 940)
[2025-07-19T21:02:38.688+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.688+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.689+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 138.0 in stage 9.0 (TID 941) (8b44f3d35cfa, executor driver, partition 138, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.689+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 130.0 in stage 9.0 (TID 933) in 74 ms on 8b44f3d35cfa (executor driver) (130/200)
[2025-07-19T21:02:38.690+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 129.0 in stage 9.0 (TID 932) in 80 ms on 8b44f3d35cfa (executor driver) (131/200)
[2025-07-19T21:02:38.690+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 138.0 in stage 9.0 (TID 941)
[2025-07-19T21:02:38.693+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.694+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.694+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@67f8d1ca
[2025-07-19T21:02:38.694+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/134/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/134/.2.delta.6008be93-f18d-470c-9451-5d787637494b.TID937.tmp
[2025-07-19T21:02:38.695+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=137, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.695+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=137),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/137] for update
[2025-07-19T21:02:38.696+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.696+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3a25845b
[2025-07-19T21:02:38.697+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=138, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.697+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=138),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/138] for update
[2025-07-19T21:02:38.697+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/136/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/136/.2.delta.3180fe8a-1669-455c-9131-5759b5e35a2b.TID939.tmp
[2025-07-19T21:02:38.699+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/135/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/135/.2.delta.e7510bdb-6fca-490c-8458-fb111ed56900.TID938.tmp
[2025-07-19T21:02:38.700+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/131/.2.delta.83b88614-3062-4a44-ad24-4270851b38db.TID934.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/131/2.delta
[2025-07-19T21:02:38.701+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=131),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/131] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/131/2.delta
[2025-07-19T21:02:38.701+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.701+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 131 (task 934, attempt 0, stage 9.0)
[2025-07-19T21:02:38.702+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 131 (task 934, attempt 0, stage 9.0)
[2025-07-19T21:02:38.702+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 131.0 in stage 9.0 (TID 934). 5829 bytes result sent to driver
[2025-07-19T21:02:38.702+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 139.0 in stage 9.0 (TID 942) (8b44f3d35cfa, executor driver, partition 139, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.703+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 131.0 in stage 9.0 (TID 934) in 86 ms on 8b44f3d35cfa (executor driver) (132/200)
[2025-07-19T21:02:38.703+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/137/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/137/.2.delta.82974e2e-48bf-434b-b3b7-925bfac54b08.TID940.tmp
[2025-07-19T21:02:38.703+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 139.0 in stage 9.0 (TID 942)
[2025-07-19T21:02:38.704+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.704+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.704+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d8e2bb5
[2025-07-19T21:02:38.704+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=139, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.704+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=139),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/139] for update
[2025-07-19T21:02:38.704+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/138/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/138/.2.delta.71ea4c4e-5a26-4420-8a30-86ad58e22b13.TID941.tmp
[2025-07-19T21:02:38.704+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.709+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/139/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/139/.2.delta.d8144fdb-0a09-423c-b102-b3cf4bd8ffd5.TID942.tmp
[2025-07-19T21:02:38.710+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/132/.2.delta.8fda4ac7-4e18-4d8c-86bc-c3e9f42231b7.TID935.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/132/2.delta
[2025-07-19T21:02:38.710+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=132),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/132] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/132/2.delta
[2025-07-19T21:02:38.714+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 132 (task 935, attempt 0, stage 9.0)
[2025-07-19T21:02:38.714+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/133/.2.delta.5a4b104d-5a90-434a-8e6f-beb95eeb7150.TID936.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/133/2.delta
[2025-07-19T21:02:38.715+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=133),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/133] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/133/2.delta
[2025-07-19T21:02:38.716+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 133 (task 936, attempt 0, stage 9.0)
[2025-07-19T21:02:38.716+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 132 (task 935, attempt 0, stage 9.0)
[2025-07-19T21:02:38.716+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 132.0 in stage 9.0 (TID 935). 5829 bytes result sent to driver
[2025-07-19T21:02:38.717+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 132.0 in stage 9.0 (TID 935) in 78 ms on 8b44f3d35cfa (executor driver) (133/200)
[2025-07-19T21:02:38.717+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 140.0 in stage 9.0 (TID 943) (8b44f3d35cfa, executor driver, partition 140, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.720+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 133 (task 936, attempt 0, stage 9.0)
[2025-07-19T21:02:38.720+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 133.0 in stage 9.0 (TID 936). 5829 bytes result sent to driver
[2025-07-19T21:02:38.721+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 141.0 in stage 9.0 (TID 944) (8b44f3d35cfa, executor driver, partition 141, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.721+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 141.0 in stage 9.0 (TID 944)
[2025-07-19T21:02:38.723+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 133.0 in stage 9.0 (TID 936) in 83 ms on 8b44f3d35cfa (executor driver) (134/200)
[2025-07-19T21:02:38.724+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 140.0 in stage 9.0 (TID 943)
[2025-07-19T21:02:38.725+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.726+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.728+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/134/.2.delta.6008be93-f18d-470c-9451-5d787637494b.TID937.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/134/2.delta
[2025-07-19T21:02:38.728+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=134),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/134] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/134/2.delta
[2025-07-19T21:02:38.728+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.728+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.728+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 134 (task 937, attempt 0, stage 9.0)
[2025-07-19T21:02:38.728+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7893e96e
[2025-07-19T21:02:38.729+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=140, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.729+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=140),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/140] for update
[2025-07-19T21:02:38.729+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@57417865
[2025-07-19T21:02:38.730+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.730+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 134 (task 937, attempt 0, stage 9.0)
[2025-07-19T21:02:38.730+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 134.0 in stage 9.0 (TID 937). 5829 bytes result sent to driver
[2025-07-19T21:02:38.730+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=141, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.730+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=141),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/141] for update
[2025-07-19T21:02:38.730+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.730+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 142.0 in stage 9.0 (TID 945) (8b44f3d35cfa, executor driver, partition 142, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.731+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 142.0 in stage 9.0 (TID 945)
[2025-07-19T21:02:38.731+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 134.0 in stage 9.0 (TID 937) in 85 ms on 8b44f3d35cfa (executor driver) (135/200)
[2025-07-19T21:02:38.732+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.733+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.733+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f18b931
[2025-07-19T21:02:38.733+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=142, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.733+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=142),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/142] for update
[2025-07-19T21:02:38.739+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.739+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/136/.2.delta.3180fe8a-1669-455c-9131-5759b5e35a2b.TID939.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/136/2.delta
[2025-07-19T21:02:38.740+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=136),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/136] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/136/2.delta
[2025-07-19T21:02:38.742+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 136 (task 939, attempt 0, stage 9.0)
[2025-07-19T21:02:38.743+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/141/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/141/.2.delta.9f9e5c00-c218-4943-a595-ca6c4afd6fc4.TID944.tmp
[2025-07-19T21:02:38.744+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 136 (task 939, attempt 0, stage 9.0)
[2025-07-19T21:02:38.746+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 136.0 in stage 9.0 (TID 939). 5872 bytes result sent to driver
[2025-07-19T21:02:38.746+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 143.0 in stage 9.0 (TID 946) (8b44f3d35cfa, executor driver, partition 143, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.747+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 143.0 in stage 9.0 (TID 946)
[2025-07-19T21:02:38.748+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 136.0 in stage 9.0 (TID 939) in 84 ms on 8b44f3d35cfa (executor driver) (136/200)
[2025-07-19T21:02:38.748+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/135/.2.delta.e7510bdb-6fca-490c-8458-fb111ed56900.TID938.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/135/2.delta
[2025-07-19T21:02:38.748+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=135),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/135] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/135/2.delta
[2025-07-19T21:02:38.749+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 135 (task 938, attempt 0, stage 9.0)
[2025-07-19T21:02:38.750+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.751+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.752+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/140/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/140/.2.delta.6b804f7c-fd56-4c60-bf71-bccd841f29aa.TID943.tmp
[2025-07-19T21:02:38.752+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4294ba06
[2025-07-19T21:02:38.752+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/137/.2.delta.82974e2e-48bf-434b-b3b7-925bfac54b08.TID940.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/137/2.delta
[2025-07-19T21:02:38.753+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=137),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/137] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/137/2.delta
[2025-07-19T21:02:38.753+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=143, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.754+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=143),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/143] for update
[2025-07-19T21:02:38.754+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 137 (task 940, attempt 0, stage 9.0)
[2025-07-19T21:02:38.755+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/142/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/142/.2.delta.274f9f2c-b449-4f86-8d6a-c2e113b09e9d.TID945.tmp
[2025-07-19T21:02:38.755+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.756+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 137 (task 940, attempt 0, stage 9.0)
[2025-07-19T21:02:38.757+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 135 (task 938, attempt 0, stage 9.0)
[2025-07-19T21:02:38.757+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 135.0 in stage 9.0 (TID 938). 5829 bytes result sent to driver
[2025-07-19T21:02:38.758+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 137.0 in stage 9.0 (TID 940). 5872 bytes result sent to driver
[2025-07-19T21:02:38.758+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 144.0 in stage 9.0 (TID 947) (8b44f3d35cfa, executor driver, partition 144, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.759+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 144.0 in stage 9.0 (TID 947)
[2025-07-19T21:02:38.760+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 145.0 in stage 9.0 (TID 948) (8b44f3d35cfa, executor driver, partition 145, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.760+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 145.0 in stage 9.0 (TID 948)
[2025-07-19T21:02:38.760+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 135.0 in stage 9.0 (TID 938) in 101 ms on 8b44f3d35cfa (executor driver) (137/200)
[2025-07-19T21:02:38.761+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 137.0 in stage 9.0 (TID 940) in 86 ms on 8b44f3d35cfa (executor driver) (138/200)
[2025-07-19T21:02:38.761+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.761+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.762+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.762+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.763+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@76c167e3
[2025-07-19T21:02:38.764+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=144, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.765+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=144),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/144] for update
[2025-07-19T21:02:38.766+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.766+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4de6583d
[2025-07-19T21:02:38.766+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=145, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.767+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=145),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/145] for update
[2025-07-19T21:02:38.767+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.768+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/138/.2.delta.71ea4c4e-5a26-4420-8a30-86ad58e22b13.TID941.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/138/2.delta
[2025-07-19T21:02:38.769+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=138),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/138] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/138/2.delta
[2025-07-19T21:02:38.769+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/143/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/143/.2.delta.f87902b8-2fe8-4aba-93ba-aa186ececfee.TID946.tmp
[2025-07-19T21:02:38.769+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 138 (task 941, attempt 0, stage 9.0)
[2025-07-19T21:02:38.773+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/139/.2.delta.d8144fdb-0a09-423c-b102-b3cf4bd8ffd5.TID942.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/139/2.delta
[2025-07-19T21:02:38.774+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=139),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/139] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/139/2.delta
[2025-07-19T21:02:38.774+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 139 (task 942, attempt 0, stage 9.0)
[2025-07-19T21:02:38.774+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 138 (task 941, attempt 0, stage 9.0)
[2025-07-19T21:02:38.774+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/144/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/144/.2.delta.c0ac3d48-cb9c-4061-af7a-31da35a5fb97.TID947.tmp
[2025-07-19T21:02:38.774+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 138.0 in stage 9.0 (TID 941). 5829 bytes result sent to driver
[2025-07-19T21:02:38.777+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 146.0 in stage 9.0 (TID 949) (8b44f3d35cfa, executor driver, partition 146, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.778+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 146.0 in stage 9.0 (TID 949)
[2025-07-19T21:02:38.780+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 138.0 in stage 9.0 (TID 941) in 104 ms on 8b44f3d35cfa (executor driver) (139/200)
[2025-07-19T21:02:38.780+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/145/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/145/.2.delta.6d48b124-2b31-4d20-bb65-9c90cb38f0af.TID948.tmp
[2025-07-19T21:02:38.781+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.781+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.781+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 139 (task 942, attempt 0, stage 9.0)
[2025-07-19T21:02:38.782+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 139.0 in stage 9.0 (TID 942). 5829 bytes result sent to driver
[2025-07-19T21:02:38.783+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@17f4289c
[2025-07-19T21:02:38.783+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 147.0 in stage 9.0 (TID 950) (8b44f3d35cfa, executor driver, partition 147, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.783+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=146, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.784+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=146),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/146] for update
[2025-07-19T21:02:38.786+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.787+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 147.0 in stage 9.0 (TID 950)
[2025-07-19T21:02:38.788+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.788+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.788+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 139.0 in stage 9.0 (TID 942) in 95 ms on 8b44f3d35cfa (executor driver) (140/200)
[2025-07-19T21:02:38.788+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@483486b1
[2025-07-19T21:02:38.788+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=147, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.789+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=147),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/147] for update
[2025-07-19T21:02:38.790+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.796+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/146/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/146/.2.delta.51ec5d65-ebc8-47ed-9088-170637abfff9.TID949.tmp
[2025-07-19T21:02:38.799+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/141/.2.delta.9f9e5c00-c218-4943-a595-ca6c4afd6fc4.TID944.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/141/2.delta
[2025-07-19T21:02:38.800+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=141),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/141] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/141/2.delta
[2025-07-19T21:02:38.801+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 141 (task 944, attempt 0, stage 9.0)
[2025-07-19T21:02:38.801+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/147/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/147/.2.delta.a82cc100-1509-4cd9-a16e-248e3b37b0ac.TID950.tmp
[2025-07-19T21:02:38.805+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/142/.2.delta.274f9f2c-b449-4f86-8d6a-c2e113b09e9d.TID945.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/142/2.delta
[2025-07-19T21:02:38.806+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=142),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/142] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/142/2.delta
[2025-07-19T21:02:38.807+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 141 (task 944, attempt 0, stage 9.0)
[2025-07-19T21:02:38.808+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 142 (task 945, attempt 0, stage 9.0)
[2025-07-19T21:02:38.808+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 141.0 in stage 9.0 (TID 944). 5829 bytes result sent to driver
[2025-07-19T21:02:38.808+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 148.0 in stage 9.0 (TID 951) (8b44f3d35cfa, executor driver, partition 148, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.809+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 148.0 in stage 9.0 (TID 951)
[2025-07-19T21:02:38.809+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 141.0 in stage 9.0 (TID 944) in 86 ms on 8b44f3d35cfa (executor driver) (141/200)
[2025-07-19T21:02:38.809+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 142 (task 945, attempt 0, stage 9.0)
[2025-07-19T21:02:38.811+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.812+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.812+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/140/.2.delta.6b804f7c-fd56-4c60-bf71-bccd841f29aa.TID943.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/140/2.delta
[2025-07-19T21:02:38.813+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=140),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/140] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/140/2.delta
[2025-07-19T21:02:38.814+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 142.0 in stage 9.0 (TID 945). 5829 bytes result sent to driver
[2025-07-19T21:02:38.815+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 140 (task 943, attempt 0, stage 9.0)
[2025-07-19T21:02:38.816+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 149.0 in stage 9.0 (TID 952) (8b44f3d35cfa, executor driver, partition 149, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.817+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 149.0 in stage 9.0 (TID 952)
[2025-07-19T21:02:38.818+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1024154a
[2025-07-19T21:02:38.818+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 142.0 in stage 9.0 (TID 945) in 83 ms on 8b44f3d35cfa (executor driver) (142/200)
[2025-07-19T21:02:38.818+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=148, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.818+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=148),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/148] for update
[2025-07-19T21:02:38.818+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.818+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.818+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@29755949
[2025-07-19T21:02:38.819+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.819+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=149, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.819+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=149),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/149] for update
[2025-07-19T21:02:38.819+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.819+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 140 (task 943, attempt 0, stage 9.0)
[2025-07-19T21:02:38.827+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/144/.2.delta.c0ac3d48-cb9c-4061-af7a-31da35a5fb97.TID947.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/144/2.delta
[2025-07-19T21:02:38.827+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=144),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/144] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/144/2.delta
[2025-07-19T21:02:38.828+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 140.0 in stage 9.0 (TID 943). 5872 bytes result sent to driver
[2025-07-19T21:02:38.828+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 150.0 in stage 9.0 (TID 953) (8b44f3d35cfa, executor driver, partition 150, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.828+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 140.0 in stage 9.0 (TID 943) in 111 ms on 8b44f3d35cfa (executor driver) (143/200)
[2025-07-19T21:02:38.829+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 150.0 in stage 9.0 (TID 953)
[2025-07-19T21:02:38.829+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 144 (task 947, attempt 0, stage 9.0)
[2025-07-19T21:02:38.830+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.830+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.834+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/149/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/149/.2.delta.9e6f7fb5-57ae-41fc-a4a3-ad1005296a0d.TID952.tmp
[2025-07-19T21:02:38.835+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@72668ea4
[2025-07-19T21:02:38.835+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 144 (task 947, attempt 0, stage 9.0)
[2025-07-19T21:02:38.836+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 144.0 in stage 9.0 (TID 947). 5872 bytes result sent to driver
[2025-07-19T21:02:38.837+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/148/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/148/.2.delta.c07bb7df-6786-4c49-b3c6-b072e915b6fd.TID951.tmp
[2025-07-19T21:02:38.838+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 151.0 in stage 9.0 (TID 954) (8b44f3d35cfa, executor driver, partition 151, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.838+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=150, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.839+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=150),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/150] for update
[2025-07-19T21:02:38.840+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 144.0 in stage 9.0 (TID 947) in 77 ms on 8b44f3d35cfa (executor driver) (144/200)
[2025-07-19T21:02:38.841+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 151.0 in stage 9.0 (TID 954)
[2025-07-19T21:02:38.841+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.841+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.841+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.841+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@753fd154
[2025-07-19T21:02:38.841+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=151, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.842+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=151),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/151] for update
[2025-07-19T21:02:38.842+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/143/.2.delta.f87902b8-2fe8-4aba-93ba-aa186ececfee.TID946.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/143/2.delta
[2025-07-19T21:02:38.844+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=143),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/143] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/143/2.delta
[2025-07-19T21:02:38.844+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.844+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 143 (task 946, attempt 0, stage 9.0)
[2025-07-19T21:02:38.844+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/145/.2.delta.6d48b124-2b31-4d20-bb65-9c90cb38f0af.TID948.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/145/2.delta
[2025-07-19T21:02:38.845+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=145),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/145] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/145/2.delta
[2025-07-19T21:02:38.845+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/146/.2.delta.51ec5d65-ebc8-47ed-9088-170637abfff9.TID949.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/146/2.delta
[2025-07-19T21:02:38.846+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=146),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/146] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/146/2.delta
[2025-07-19T21:02:38.847+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 146 (task 949, attempt 0, stage 9.0)
[2025-07-19T21:02:38.847+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 145 (task 948, attempt 0, stage 9.0)
[2025-07-19T21:02:38.847+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 143 (task 946, attempt 0, stage 9.0)
[2025-07-19T21:02:38.848+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 143.0 in stage 9.0 (TID 946). 5872 bytes result sent to driver
[2025-07-19T21:02:38.848+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/150/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/150/.2.delta.f82cef59-b7a1-49fb-991c-d8ed9711d50e.TID953.tmp
[2025-07-19T21:02:38.849+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 152.0 in stage 9.0 (TID 955) (8b44f3d35cfa, executor driver, partition 152, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.850+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 145 (task 948, attempt 0, stage 9.0)
[2025-07-19T21:02:38.850+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 146 (task 949, attempt 0, stage 9.0)
[2025-07-19T21:02:38.851+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 152.0 in stage 9.0 (TID 955)
[2025-07-19T21:02:38.853+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 145.0 in stage 9.0 (TID 948). 5872 bytes result sent to driver
[2025-07-19T21:02:38.854+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 153.0 in stage 9.0 (TID 956) (8b44f3d35cfa, executor driver, partition 153, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.855+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 145.0 in stage 9.0 (TID 948) in 92 ms on 8b44f3d35cfa (executor driver) (145/200)
[2025-07-19T21:02:38.856+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 146.0 in stage 9.0 (TID 949). 5872 bytes result sent to driver
[2025-07-19T21:02:38.856+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/147/.2.delta.a82cc100-1509-4cd9-a16e-248e3b37b0ac.TID950.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/147/2.delta
[2025-07-19T21:02:38.856+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=147),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/147] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/147/2.delta
[2025-07-19T21:02:38.858+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 154.0 in stage 9.0 (TID 957) (8b44f3d35cfa, executor driver, partition 154, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.858+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 153.0 in stage 9.0 (TID 956)
[2025-07-19T21:02:38.859+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 146.0 in stage 9.0 (TID 949) in 75 ms on 8b44f3d35cfa (executor driver) (146/200)
[2025-07-19T21:02:38.859+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 147 (task 950, attempt 0, stage 9.0)
[2025-07-19T21:02:38.860+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/151/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/151/.2.delta.3f9acd60-8d91-427a-a8ee-9f8a58d55626.TID954.tmp
[2025-07-19T21:02:38.861+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 143.0 in stage 9.0 (TID 946) in 106 ms on 8b44f3d35cfa (executor driver) (147/200)
[2025-07-19T21:02:38.861+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 154.0 in stage 9.0 (TID 957)
[2025-07-19T21:02:38.861+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.862+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.862+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b24de76
[2025-07-19T21:02:38.862+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=152, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.863+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=152),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/152] for update
[2025-07-19T21:02:38.864+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.864+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.865+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 147 (task 950, attempt 0, stage 9.0)
[2025-07-19T21:02:38.865+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.865+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.866+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 147.0 in stage 9.0 (TID 950). 5872 bytes result sent to driver
[2025-07-19T21:02:38.866+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d86ed9e
[2025-07-19T21:02:38.866+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 155.0 in stage 9.0 (TID 958) (8b44f3d35cfa, executor driver, partition 155, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.867+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 155.0 in stage 9.0 (TID 958)
[2025-07-19T21:02:38.867+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 147.0 in stage 9.0 (TID 950) in 74 ms on 8b44f3d35cfa (executor driver) (148/200)
[2025-07-19T21:02:38.867+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.868+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=154, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.868+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=154),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/154] for update
[2025-07-19T21:02:38.869+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.871+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@fef6404
[2025-07-19T21:02:38.871+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=153, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.871+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=153),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/153] for update
[2025-07-19T21:02:38.872+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.872+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.873+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:38.873+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@98667d7
[2025-07-19T21:02:38.874+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=155, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.875+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=155),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/155] for update
[2025-07-19T21:02:38.876+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.878+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/152/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/152/.2.delta.8c39d751-a558-4b1e-b0e2-5a9590ddf6cd.TID955.tmp
[2025-07-19T21:02:38.878+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/149/.2.delta.9e6f7fb5-57ae-41fc-a4a3-ad1005296a0d.TID952.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/149/2.delta
[2025-07-19T21:02:38.878+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=149),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/149] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/149/2.delta
[2025-07-19T21:02:38.878+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 149 (task 952, attempt 0, stage 9.0)
[2025-07-19T21:02:38.879+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/154/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/154/.2.delta.0eee0e71-9509-4b7f-9312-45d87ab1e327.TID957.tmp
[2025-07-19T21:02:38.879+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 149 (task 952, attempt 0, stage 9.0)
[2025-07-19T21:02:38.879+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 149.0 in stage 9.0 (TID 952). 5872 bytes result sent to driver
[2025-07-19T21:02:38.879+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 156.0 in stage 9.0 (TID 959) (8b44f3d35cfa, executor driver, partition 156, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.879+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 156.0 in stage 9.0 (TID 959)
[2025-07-19T21:02:38.880+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 149.0 in stage 9.0 (TID 952) in 65 ms on 8b44f3d35cfa (executor driver) (149/200)
[2025-07-19T21:02:38.880+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/153/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/153/.2.delta.52d3dc47-9f2a-45c2-ab08-2d364eec5ca0.TID956.tmp
[2025-07-19T21:02:38.881+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.881+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.881+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e537829
[2025-07-19T21:02:38.882+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=156, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.882+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=156),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/156] for update
[2025-07-19T21:02:38.883+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.884+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/155/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/155/.2.delta.18cdf207-954b-4261-8418-7f873b4e29f3.TID958.tmp
[2025-07-19T21:02:38.885+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/148/.2.delta.c07bb7df-6786-4c49-b3c6-b072e915b6fd.TID951.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/148/2.delta
[2025-07-19T21:02:38.885+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=148),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/148] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/148/2.delta
[2025-07-19T21:02:38.886+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 148 (task 951, attempt 0, stage 9.0)
[2025-07-19T21:02:38.888+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 148 (task 951, attempt 0, stage 9.0)
[2025-07-19T21:02:38.890+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 148.0 in stage 9.0 (TID 951). 5872 bytes result sent to driver
[2025-07-19T21:02:38.891+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 157.0 in stage 9.0 (TID 960) (8b44f3d35cfa, executor driver, partition 157, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.892+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 157.0 in stage 9.0 (TID 960)
[2025-07-19T21:02:38.892+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 148.0 in stage 9.0 (TID 951) in 83 ms on 8b44f3d35cfa (executor driver) (150/200)
[2025-07-19T21:02:38.892+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/156/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/156/.2.delta.b0f38941-9092-4860-9a7b-047997a2f848.TID959.tmp
[2025-07-19T21:02:38.893+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.894+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.894+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@57e2e660
[2025-07-19T21:02:38.895+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=157, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.895+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=157),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/157] for update
[2025-07-19T21:02:38.896+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.897+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/150/.2.delta.f82cef59-b7a1-49fb-991c-d8ed9711d50e.TID953.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/150/2.delta
[2025-07-19T21:02:38.898+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=150),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/150] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/150/2.delta
[2025-07-19T21:02:38.898+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 150 (task 953, attempt 0, stage 9.0)
[2025-07-19T21:02:38.899+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 150 (task 953, attempt 0, stage 9.0)
[2025-07-19T21:02:38.900+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 150.0 in stage 9.0 (TID 953). 5872 bytes result sent to driver
[2025-07-19T21:02:38.902+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 158.0 in stage 9.0 (TID 961) (8b44f3d35cfa, executor driver, partition 158, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.903+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 158.0 in stage 9.0 (TID 961)
[2025-07-19T21:02:38.904+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 150.0 in stage 9.0 (TID 953) in 73 ms on 8b44f3d35cfa (executor driver) (151/200)
[2025-07-19T21:02:38.904+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.905+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.906+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/151/.2.delta.3f9acd60-8d91-427a-a8ee-9f8a58d55626.TID954.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/151/2.delta
[2025-07-19T21:02:38.907+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=151),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/151] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/151/2.delta
[2025-07-19T21:02:38.908+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a7b89df
[2025-07-19T21:02:38.910+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 151 (task 954, attempt 0, stage 9.0)
[2025-07-19T21:02:38.912+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=158, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.913+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=158),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/158] for update
[2025-07-19T21:02:38.915+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/157/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/157/.2.delta.24ac3685-a042-4a4d-9288-588ff8ce7cf2.TID960.tmp
[2025-07-19T21:02:38.915+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.915+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 151 (task 954, attempt 0, stage 9.0)
[2025-07-19T21:02:38.915+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 151.0 in stage 9.0 (TID 954). 5872 bytes result sent to driver
[2025-07-19T21:02:38.915+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 159.0 in stage 9.0 (TID 962) (8b44f3d35cfa, executor driver, partition 159, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.916+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 151.0 in stage 9.0 (TID 954) in 79 ms on 8b44f3d35cfa (executor driver) (152/200)
[2025-07-19T21:02:38.917+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 159.0 in stage 9.0 (TID 962)
[2025-07-19T21:02:38.918+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.919+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T21:02:38.919+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/152/.2.delta.8c39d751-a558-4b1e-b0e2-5a9590ddf6cd.TID955.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/152/2.delta
[2025-07-19T21:02:38.920+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=152),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/152] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/152/2.delta
[2025-07-19T21:02:38.922+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65ab8e71
[2025-07-19T21:02:38.923+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 152 (task 955, attempt 0, stage 9.0)
[2025-07-19T21:02:38.923+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=159, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.924+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=159),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/159] for update
[2025-07-19T21:02:38.924+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.924+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 152 (task 955, attempt 0, stage 9.0)
[2025-07-19T21:02:38.924+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 152.0 in stage 9.0 (TID 955). 5872 bytes result sent to driver
[2025-07-19T21:02:38.924+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/158/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/158/.2.delta.f65c8aa5-4292-48b9-8207-4e394c36a030.TID961.tmp
[2025-07-19T21:02:38.924+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 160.0 in stage 9.0 (TID 963) (8b44f3d35cfa, executor driver, partition 160, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.925+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 160.0 in stage 9.0 (TID 963)
[2025-07-19T21:02:38.925+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 152.0 in stage 9.0 (TID 955) in 76 ms on 8b44f3d35cfa (executor driver) (153/200)
[2025-07-19T21:02:38.925+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/153/.2.delta.52d3dc47-9f2a-45c2-ab08-2d364eec5ca0.TID956.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/153/2.delta
[2025-07-19T21:02:38.925+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=153),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/153] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/153/2.delta
[2025-07-19T21:02:38.925+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.925+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 153 (task 956, attempt 0, stage 9.0)
[2025-07-19T21:02:38.925+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.926+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e53438c
[2025-07-19T21:02:38.927+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=160, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.927+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=160),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/160] for update
[2025-07-19T21:02:38.927+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/154/.2.delta.0eee0e71-9509-4b7f-9312-45d87ab1e327.TID957.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/154/2.delta
[2025-07-19T21:02:38.928+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=154),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/154] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/154/2.delta
[2025-07-19T21:02:38.928+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 154 (task 957, attempt 0, stage 9.0)
[2025-07-19T21:02:38.929+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 153 (task 956, attempt 0, stage 9.0)
[2025-07-19T21:02:38.929+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.929+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 153.0 in stage 9.0 (TID 956). 5872 bytes result sent to driver
[2025-07-19T21:02:38.929+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 161.0 in stage 9.0 (TID 964) (8b44f3d35cfa, executor driver, partition 161, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.930+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 161.0 in stage 9.0 (TID 964)
[2025-07-19T21:02:38.932+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/156/.2.delta.b0f38941-9092-4860-9a7b-047997a2f848.TID959.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/156/2.delta
[2025-07-19T21:02:38.933+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=156),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/156] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/156/2.delta
[2025-07-19T21:02:38.934+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 154 (task 957, attempt 0, stage 9.0)
[2025-07-19T21:02:38.934+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.934+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.935+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 153.0 in stage 9.0 (TID 956) in 80 ms on 8b44f3d35cfa (executor driver) (154/200)
[2025-07-19T21:02:38.936+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 154.0 in stage 9.0 (TID 957). 5872 bytes result sent to driver
[2025-07-19T21:02:38.936+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43f49b11
[2025-07-19T21:02:38.937+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 162.0 in stage 9.0 (TID 965) (8b44f3d35cfa, executor driver, partition 162, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.937+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=161, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.938+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 154.0 in stage 9.0 (TID 957) in 83 ms on 8b44f3d35cfa (executor driver) (155/200)
[2025-07-19T21:02:38.939+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=161),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/161] for update
[2025-07-19T21:02:38.940+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/159/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/159/.2.delta.c27eaec7-d5a9-4a81-9886-c6301d955468.TID962.tmp
[2025-07-19T21:02:38.940+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 162.0 in stage 9.0 (TID 965)
[2025-07-19T21:02:38.941+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 156 (task 959, attempt 0, stage 9.0)
[2025-07-19T21:02:38.941+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.942+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.942+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.943+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/155/.2.delta.18cdf207-954b-4261-8418-7f873b4e29f3.TID958.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/155/2.delta
[2025-07-19T21:02:38.943+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=155),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/155] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/155/2.delta
[2025-07-19T21:02:38.943+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@29d8b45e
[2025-07-19T21:02:38.944+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 155 (task 958, attempt 0, stage 9.0)
[2025-07-19T21:02:38.944+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/160/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/160/.2.delta.cacbffd3-8b1e-4f07-ab2f-30f78c90b176.TID963.tmp
[2025-07-19T21:02:38.944+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=162, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.945+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=162),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/162] for update
[2025-07-19T21:02:38.945+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 156 (task 959, attempt 0, stage 9.0)
[2025-07-19T21:02:38.946+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 155 (task 958, attempt 0, stage 9.0)
[2025-07-19T21:02:38.946+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 156.0 in stage 9.0 (TID 959). 5829 bytes result sent to driver
[2025-07-19T21:02:38.947+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 155.0 in stage 9.0 (TID 958). 5872 bytes result sent to driver
[2025-07-19T21:02:38.948+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 163.0 in stage 9.0 (TID 966) (8b44f3d35cfa, executor driver, partition 163, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.949+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 156.0 in stage 9.0 (TID 959) in 67 ms on 8b44f3d35cfa (executor driver) (156/200)
[2025-07-19T21:02:38.949+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 163.0 in stage 9.0 (TID 966)
[2025-07-19T21:02:38.949+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.950+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 164.0 in stage 9.0 (TID 967) (8b44f3d35cfa, executor driver, partition 164, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.950+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 155.0 in stage 9.0 (TID 958) in 89 ms on 8b44f3d35cfa (executor driver) (157/200)
[2025-07-19T21:02:38.950+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 164.0 in stage 9.0 (TID 967)
[2025-07-19T21:02:38.951+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.951+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.952+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.952+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.953+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/161/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/161/.2.delta.44997165-01b0-483b-b948-91612ef4de8c.TID964.tmp
[2025-07-19T21:02:38.953+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@50bec803
[2025-07-19T21:02:38.953+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=163, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.954+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=163),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/163] for update
[2025-07-19T21:02:38.955+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@13c5b729
[2025-07-19T21:02:38.958+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=164, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.958+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=164),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/164] for update
[2025-07-19T21:02:38.960+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.962+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.962+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/157/.2.delta.24ac3685-a042-4a4d-9288-588ff8ce7cf2.TID960.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/157/2.delta
[2025-07-19T21:02:38.962+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=157),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/157] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/157/2.delta
[2025-07-19T21:02:38.962+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 157 (task 960, attempt 0, stage 9.0)
[2025-07-19T21:02:38.962+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 157 (task 960, attempt 0, stage 9.0)
[2025-07-19T21:02:38.962+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 157.0 in stage 9.0 (TID 960). 5829 bytes result sent to driver
[2025-07-19T21:02:38.963+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/162/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/162/.2.delta.483dd107-a701-4057-a9e4-5c0cf13cbd99.TID965.tmp
[2025-07-19T21:02:38.963+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 165.0 in stage 9.0 (TID 968) (8b44f3d35cfa, executor driver, partition 165, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.963+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 165.0 in stage 9.0 (TID 968)
[2025-07-19T21:02:38.963+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 157.0 in stage 9.0 (TID 960) in 70 ms on 8b44f3d35cfa (executor driver) (158/200)
[2025-07-19T21:02:38.964+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.964+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:38.964+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/164/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/164/.2.delta.5d60e028-48de-4f5d-a8a3-f7593d4575d2.TID967.tmp
[2025-07-19T21:02:38.965+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/163/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/163/.2.delta.57f14084-4a9b-4da5-8a8d-a8a194793de9.TID966.tmp
[2025-07-19T21:02:38.966+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ead26d0
[2025-07-19T21:02:38.966+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=165, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.967+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=165),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/165] for update
[2025-07-19T21:02:38.967+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/158/.2.delta.f65c8aa5-4292-48b9-8207-4e394c36a030.TID961.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/158/2.delta
[2025-07-19T21:02:38.967+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=158),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/158] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/158/2.delta
[2025-07-19T21:02:38.968+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.968+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 158 (task 961, attempt 0, stage 9.0)
[2025-07-19T21:02:38.969+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 158 (task 961, attempt 0, stage 9.0)
[2025-07-19T21:02:38.969+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 158.0 in stage 9.0 (TID 961). 5829 bytes result sent to driver
[2025-07-19T21:02:38.969+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 166.0 in stage 9.0 (TID 969) (8b44f3d35cfa, executor driver, partition 166, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.970+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 158.0 in stage 9.0 (TID 961) in 66 ms on 8b44f3d35cfa (executor driver) (159/200)
[2025-07-19T21:02:38.970+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 166.0 in stage 9.0 (TID 969)
[2025-07-19T21:02:38.971+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.972+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.973+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/159/.2.delta.c27eaec7-d5a9-4a81-9886-c6301d955468.TID962.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/159/2.delta
[2025-07-19T21:02:38.973+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=159),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/159] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/159/2.delta
[2025-07-19T21:02:38.973+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 159 (task 962, attempt 0, stage 9.0)
[2025-07-19T21:02:38.973+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/165/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/165/.2.delta.7eb00a84-6d4e-4181-a5a2-9647e3607524.TID968.tmp
[2025-07-19T21:02:38.973+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1761774c
[2025-07-19T21:02:38.973+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=166, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.975+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=166),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/166] for update
[2025-07-19T21:02:38.976+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 159 (task 962, attempt 0, stage 9.0)
[2025-07-19T21:02:38.976+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 159.0 in stage 9.0 (TID 962). 5829 bytes result sent to driver
[2025-07-19T21:02:38.976+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.976+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 167.0 in stage 9.0 (TID 970) (8b44f3d35cfa, executor driver, partition 167, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.976+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 167.0 in stage 9.0 (TID 970)
[2025-07-19T21:02:38.976+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 159.0 in stage 9.0 (TID 962) in 64 ms on 8b44f3d35cfa (executor driver) (160/200)
[2025-07-19T21:02:38.978+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.979+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.979+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@76e69a7c
[2025-07-19T21:02:38.979+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=167, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.980+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=167),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/167] for update
[2025-07-19T21:02:38.982+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.982+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/160/.2.delta.cacbffd3-8b1e-4f07-ab2f-30f78c90b176.TID963.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/160/2.delta
[2025-07-19T21:02:38.982+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=160),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/160] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/160/2.delta
[2025-07-19T21:02:38.982+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 160 (task 963, attempt 0, stage 9.0)
[2025-07-19T21:02:38.986+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 160 (task 963, attempt 0, stage 9.0)
[2025-07-19T21:02:38.988+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/166/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/166/.2.delta.a03368d9-e6ee-42c0-b39d-708b7dc9a36c.TID969.tmp
[2025-07-19T21:02:38.989+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 160.0 in stage 9.0 (TID 963). 5829 bytes result sent to driver
[2025-07-19T21:02:38.990+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 168.0 in stage 9.0 (TID 971) (8b44f3d35cfa, executor driver, partition 168, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:38.990+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 160.0 in stage 9.0 (TID 963) in 65 ms on 8b44f3d35cfa (executor driver) (161/200)
[2025-07-19T21:02:38.990+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 168.0 in stage 9.0 (TID 971)
[2025-07-19T21:02:38.990+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:38.990+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:38.991+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53d0ba37
[2025-07-19T21:02:38.992+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=168, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:38.993+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/162/.2.delta.483dd107-a701-4057-a9e4-5c0cf13cbd99.TID965.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/162/2.delta
[2025-07-19T21:02:38.993+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=168),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/168] for update
[2025-07-19T21:02:38.993+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=162),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/162] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/162/2.delta
[2025-07-19T21:02:38.994+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 162 (task 965, attempt 0, stage 9.0)
[2025-07-19T21:02:38.996+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/167/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/167/.2.delta.f9da4bd7-f295-4731-98b2-23a46109c10f.TID970.tmp
[2025-07-19T21:02:38.997+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/163/.2.delta.57f14084-4a9b-4da5-8a8d-a8a194793de9.TID966.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/163/2.delta
[2025-07-19T21:02:38.998+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=163),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/163] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/163/2.delta
[2025-07-19T21:02:38.999+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:38.999+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 163 (task 966, attempt 0, stage 9.0)
[2025-07-19T21:02:39.000+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/161/.2.delta.44997165-01b0-483b-b948-91612ef4de8c.TID964.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/161/2.delta
[2025-07-19T21:02:39.000+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=161),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/161] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/161/2.delta
[2025-07-19T21:02:39.001+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Commit authorized for partition 161 (task 964, attempt 0, stage 9.0)
[2025-07-19T21:02:39.002+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 163 (task 966, attempt 0, stage 9.0)
[2025-07-19T21:02:39.002+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 162 (task 965, attempt 0, stage 9.0)
[2025-07-19T21:02:39.003+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 162.0 in stage 9.0 (TID 965). 5829 bytes result sent to driver
[2025-07-19T21:02:39.003+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 163.0 in stage 9.0 (TID 966). 5829 bytes result sent to driver
[2025-07-19T21:02:39.003+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 169.0 in stage 9.0 (TID 972) (8b44f3d35cfa, executor driver, partition 169, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:39.004+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 170.0 in stage 9.0 (TID 973) (8b44f3d35cfa, executor driver, partition 170, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:39.004+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 170.0 in stage 9.0 (TID 973)
[2025-07-19T21:02:39.005+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 169.0 in stage 9.0 (TID 972)
[2025-07-19T21:02:39.006+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 163.0 in stage 9.0 (TID 966) in 54 ms on 8b44f3d35cfa (executor driver) (162/200)
[2025-07-19T21:02:39.006+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 162.0 in stage 9.0 (TID 965) in 64 ms on 8b44f3d35cfa (executor driver) (163/200)
[2025-07-19T21:02:39.006+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO DataWritingSparkTask: Committed partition 161 (task 964, attempt 0, stage 9.0)
[2025-07-19T21:02:39.006+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Finished task 161.0 in stage 9.0 (TID 964). 5829 bytes result sent to driver
[2025-07-19T21:02:39.007+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Starting task 171.0 in stage 9.0 (TID 974) (8b44f3d35cfa, executor driver, partition 171, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:39.007+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:39.007+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:39.008+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO Executor: Running task 171.0 in stage 9.0 (TID 974)
[2025-07-19T21:02:39.008+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO TaskSetManager: Finished task 161.0 in stage 9.0 (TID 964) in 70 ms on 8b44f3d35cfa (executor driver) (164/200)
[2025-07-19T21:02:39.009+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:39.010+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:39.011+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4fca22bf
[2025-07-19T21:02:39.011+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:39.011+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:39.011+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=169, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:39.012+0000] {subprocess.py:93} INFO - 25/07/19 21:02:38 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=169),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/169] for update
[2025-07-19T21:02:39.012+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@32c32ae6
[2025-07-19T21:02:39.012+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:39.013+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=171, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:39.014+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=171),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/171] for update
[2025-07-19T21:02:39.014+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:39.014+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/168/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/168/.2.delta.ad10f20b-9e2d-48a0-858e-d97a6ac065de.TID971.tmp
[2025-07-19T21:02:39.015+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@14fdd124
[2025-07-19T21:02:39.015+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=170, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:39.015+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=170),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/170] for update
[2025-07-19T21:02:39.016+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/164/.2.delta.5d60e028-48de-4f5d-a8a3-f7593d4575d2.TID967.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/164/2.delta
[2025-07-19T21:02:39.017+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=164),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/164] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/164/2.delta
[2025-07-19T21:02:39.017+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Commit authorized for partition 164 (task 967, attempt 0, stage 9.0)
[2025-07-19T21:02:39.017+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:39.017+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/165/.2.delta.7eb00a84-6d4e-4181-a5a2-9647e3607524.TID968.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/165/2.delta
[2025-07-19T21:02:39.018+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=165),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/165] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/165/2.delta
[2025-07-19T21:02:39.019+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Committed partition 164 (task 967, attempt 0, stage 9.0)
[2025-07-19T21:02:39.020+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Finished task 164.0 in stage 9.0 (TID 967). 5829 bytes result sent to driver
[2025-07-19T21:02:39.021+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Starting task 172.0 in stage 9.0 (TID 975) (8b44f3d35cfa, executor driver, partition 172, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:39.021+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Commit authorized for partition 165 (task 968, attempt 0, stage 9.0)
[2025-07-19T21:02:39.021+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/169/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/169/.2.delta.574c7f36-0ec6-4238-98ae-c68ee08dbe33.TID972.tmp
[2025-07-19T21:02:39.021+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Finished task 164.0 in stage 9.0 (TID 967) in 70 ms on 8b44f3d35cfa (executor driver) (165/200)
[2025-07-19T21:02:39.021+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Running task 172.0 in stage 9.0 (TID 975)
[2025-07-19T21:02:39.021+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/171/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/171/.2.delta.1246edec-7b62-4aa1-aba8-f4ad96afc9fb.TID974.tmp
[2025-07-19T21:02:39.021+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:39.021+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:39.021+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Committed partition 165 (task 968, attempt 0, stage 9.0)
[2025-07-19T21:02:39.022+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c03871e
[2025-07-19T21:02:39.022+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Finished task 165.0 in stage 9.0 (TID 968). 5829 bytes result sent to driver
[2025-07-19T21:02:39.022+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Starting task 173.0 in stage 9.0 (TID 976) (8b44f3d35cfa, executor driver, partition 173, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:39.023+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=172, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:39.024+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=172),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/172] for update
[2025-07-19T21:02:39.024+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Running task 173.0 in stage 9.0 (TID 976)
[2025-07-19T21:02:39.024+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:39.024+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Finished task 165.0 in stage 9.0 (TID 968) in 63 ms on 8b44f3d35cfa (executor driver) (166/200)
[2025-07-19T21:02:39.024+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/170/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/170/.2.delta.7842013d-aac8-4f3f-8985-6ce1deaafa31.TID973.tmp
[2025-07-19T21:02:39.025+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:39.026+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:39.026+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@78a99eb7
[2025-07-19T21:02:39.027+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=173, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:39.028+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=173),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/173] for update
[2025-07-19T21:02:39.028+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:39.029+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/166/.2.delta.a03368d9-e6ee-42c0-b39d-708b7dc9a36c.TID969.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/166/2.delta
[2025-07-19T21:02:39.029+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=166),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/166] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/166/2.delta
[2025-07-19T21:02:39.030+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Commit authorized for partition 166 (task 969, attempt 0, stage 9.0)
[2025-07-19T21:02:39.030+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/172/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/172/.2.delta.358118ec-6ee8-4223-8fe8-e33310e4c6a3.TID975.tmp
[2025-07-19T21:02:39.030+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Committed partition 166 (task 969, attempt 0, stage 9.0)
[2025-07-19T21:02:39.031+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Finished task 166.0 in stage 9.0 (TID 969). 5829 bytes result sent to driver
[2025-07-19T21:02:39.031+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Starting task 174.0 in stage 9.0 (TID 977) (8b44f3d35cfa, executor driver, partition 174, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:39.032+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Running task 174.0 in stage 9.0 (TID 977)
[2025-07-19T21:02:39.032+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Finished task 166.0 in stage 9.0 (TID 969) in 66 ms on 8b44f3d35cfa (executor driver) (167/200)
[2025-07-19T21:02:39.034+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:39.034+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:39.034+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/167/.2.delta.f9da4bd7-f295-4731-98b2-23a46109c10f.TID970.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/167/2.delta
[2025-07-19T21:02:39.034+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=167),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/167] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/167/2.delta
[2025-07-19T21:02:39.034+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@11620097
[2025-07-19T21:02:39.034+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/173/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/173/.2.delta.d9275649-366c-4574-8166-5d63a1b11f21.TID976.tmp
[2025-07-19T21:02:39.035+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=174, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:39.035+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=174),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/174] for update
[2025-07-19T21:02:39.036+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Commit authorized for partition 167 (task 970, attempt 0, stage 9.0)
[2025-07-19T21:02:39.036+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:39.039+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Committed partition 167 (task 970, attempt 0, stage 9.0)
[2025-07-19T21:02:39.039+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Finished task 167.0 in stage 9.0 (TID 970). 5829 bytes result sent to driver
[2025-07-19T21:02:39.040+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Starting task 175.0 in stage 9.0 (TID 978) (8b44f3d35cfa, executor driver, partition 175, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:39.042+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Running task 175.0 in stage 9.0 (TID 978)
[2025-07-19T21:02:39.045+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Finished task 167.0 in stage 9.0 (TID 970) in 65 ms on 8b44f3d35cfa (executor driver) (168/200)
[2025-07-19T21:02:39.046+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/168/.2.delta.ad10f20b-9e2d-48a0-858e-d97a6ac065de.TID971.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/168/2.delta
[2025-07-19T21:02:39.046+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=168),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/168] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/168/2.delta
[2025-07-19T21:02:39.047+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Commit authorized for partition 168 (task 971, attempt 0, stage 9.0)
[2025-07-19T21:02:39.047+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:39.047+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:39.048+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2bb0983a
[2025-07-19T21:02:39.049+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=175, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:39.049+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=175),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/175] for update
[2025-07-19T21:02:39.050+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:39.050+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/174/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/174/.2.delta.3ff4e37b-f3c8-424c-a5b2-9ffa4ab983c5.TID977.tmp
[2025-07-19T21:02:39.051+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Committed partition 168 (task 971, attempt 0, stage 9.0)
[2025-07-19T21:02:39.051+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/169/.2.delta.574c7f36-0ec6-4238-98ae-c68ee08dbe33.TID972.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/169/2.delta
[2025-07-19T21:02:39.051+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=169),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/169] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/169/2.delta
[2025-07-19T21:02:39.051+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Finished task 168.0 in stage 9.0 (TID 971). 5829 bytes result sent to driver
[2025-07-19T21:02:39.052+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Commit authorized for partition 169 (task 972, attempt 0, stage 9.0)
[2025-07-19T21:02:39.054+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Finished task 168.0 in stage 9.0 (TID 971) in 63 ms on 8b44f3d35cfa (executor driver) (169/200)
[2025-07-19T21:02:39.054+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Starting task 176.0 in stage 9.0 (TID 979) (8b44f3d35cfa, executor driver, partition 176, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:39.054+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Running task 176.0 in stage 9.0 (TID 979)
[2025-07-19T21:02:39.055+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Committed partition 169 (task 972, attempt 0, stage 9.0)
[2025-07-19T21:02:39.056+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:39.056+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:39.056+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Finished task 169.0 in stage 9.0 (TID 972). 5829 bytes result sent to driver
[2025-07-19T21:02:39.057+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Starting task 177.0 in stage 9.0 (TID 980) (8b44f3d35cfa, executor driver, partition 177, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:39.058+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Running task 177.0 in stage 9.0 (TID 980)
[2025-07-19T21:02:39.060+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Finished task 169.0 in stage 9.0 (TID 972) in 58 ms on 8b44f3d35cfa (executor driver) (170/200)
[2025-07-19T21:02:39.061+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@46ab39b1
[2025-07-19T21:02:39.062+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/170/.2.delta.7842013d-aac8-4f3f-8985-6ce1deaafa31.TID973.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/170/2.delta
[2025-07-19T21:02:39.063+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=170),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/170] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/170/2.delta
[2025-07-19T21:02:39.063+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=176, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:39.064+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=176),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/176] for update
[2025-07-19T21:02:39.064+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Commit authorized for partition 170 (task 973, attempt 0, stage 9.0)
[2025-07-19T21:02:39.065+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:39.065+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:39.066+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:39.066+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7027ad
[2025-07-19T21:02:39.066+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=177, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:39.066+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=177),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/177] for update
[2025-07-19T21:02:39.066+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:39.066+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/171/.2.delta.1246edec-7b62-4aa1-aba8-f4ad96afc9fb.TID974.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/171/2.delta
[2025-07-19T21:02:39.067+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=171),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/171] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/171/2.delta
[2025-07-19T21:02:39.067+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Commit authorized for partition 171 (task 974, attempt 0, stage 9.0)
[2025-07-19T21:02:39.067+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/175/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/175/.2.delta.c2a600aa-f865-4eab-862c-9752196e4ad3.TID978.tmp
[2025-07-19T21:02:39.067+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Committed partition 170 (task 973, attempt 0, stage 9.0)
[2025-07-19T21:02:39.069+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Finished task 170.0 in stage 9.0 (TID 973). 5829 bytes result sent to driver
[2025-07-19T21:02:39.069+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Starting task 178.0 in stage 9.0 (TID 981) (8b44f3d35cfa, executor driver, partition 178, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:39.069+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Committed partition 171 (task 974, attempt 0, stage 9.0)
[2025-07-19T21:02:39.070+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Running task 178.0 in stage 9.0 (TID 981)
[2025-07-19T21:02:39.070+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Finished task 171.0 in stage 9.0 (TID 974). 5829 bytes result sent to driver
[2025-07-19T21:02:39.070+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Finished task 170.0 in stage 9.0 (TID 973) in 67 ms on 8b44f3d35cfa (executor driver) (171/200)
[2025-07-19T21:02:39.071+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:39.072+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:39.073+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Starting task 179.0 in stage 9.0 (TID 982) (8b44f3d35cfa, executor driver, partition 179, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:39.074+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Running task 179.0 in stage 9.0 (TID 982)
[2025-07-19T21:02:39.075+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@222b309b
[2025-07-19T21:02:39.076+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/176/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/176/.2.delta.682a30a8-0760-4ddf-9886-8cfabc855079.TID979.tmp
[2025-07-19T21:02:39.076+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=178, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:39.077+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=178),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/178] for update
[2025-07-19T21:02:39.077+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Finished task 171.0 in stage 9.0 (TID 974) in 68 ms on 8b44f3d35cfa (executor driver) (172/200)
[2025-07-19T21:02:39.078+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:39.079+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:39.079+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/172/.2.delta.358118ec-6ee8-4223-8fe8-e33310e4c6a3.TID975.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/172/2.delta
[2025-07-19T21:02:39.079+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=172),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/172] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/172/2.delta
[2025-07-19T21:02:39.079+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@41a213e9
[2025-07-19T21:02:39.081+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=179, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:39.081+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=179),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/179] for update
[2025-07-19T21:02:39.081+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Commit authorized for partition 172 (task 975, attempt 0, stage 9.0)
[2025-07-19T21:02:39.081+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:39.082+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:39.082+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/173/.2.delta.d9275649-366c-4574-8166-5d63a1b11f21.TID976.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/173/2.delta
[2025-07-19T21:02:39.083+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=173),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/173] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/173/2.delta
[2025-07-19T21:02:39.083+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Commit authorized for partition 173 (task 976, attempt 0, stage 9.0)
[2025-07-19T21:02:39.083+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/177/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/177/.2.delta.fb650f02-e7ae-4027-895f-d4f1a21c1495.TID980.tmp
[2025-07-19T21:02:39.083+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Committed partition 172 (task 975, attempt 0, stage 9.0)
[2025-07-19T21:02:39.084+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Finished task 172.0 in stage 9.0 (TID 975). 5829 bytes result sent to driver
[2025-07-19T21:02:39.085+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Starting task 180.0 in stage 9.0 (TID 983) (8b44f3d35cfa, executor driver, partition 180, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:39.085+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Finished task 172.0 in stage 9.0 (TID 975) in 66 ms on 8b44f3d35cfa (executor driver) (173/200)
[2025-07-19T21:02:39.086+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Running task 180.0 in stage 9.0 (TID 983)
[2025-07-19T21:02:39.086+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Committed partition 173 (task 976, attempt 0, stage 9.0)
[2025-07-19T21:02:39.087+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Finished task 173.0 in stage 9.0 (TID 976). 5829 bytes result sent to driver
[2025-07-19T21:02:39.087+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Starting task 181.0 in stage 9.0 (TID 984) (8b44f3d35cfa, executor driver, partition 181, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:39.087+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Running task 181.0 in stage 9.0 (TID 984)
[2025-07-19T21:02:39.088+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Finished task 173.0 in stage 9.0 (TID 976) in 64 ms on 8b44f3d35cfa (executor driver) (174/200)
[2025-07-19T21:02:39.088+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:39.088+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:39.088+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:39.089+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:39.089+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19762780
[2025-07-19T21:02:39.089+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/178/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/178/.2.delta.c60715d6-9bfb-4a5e-a67e-50e3caaba188.TID981.tmp
[2025-07-19T21:02:39.089+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/179/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/179/.2.delta.047bf691-a522-4c01-af93-f9d187d4e3b1.TID982.tmp
[2025-07-19T21:02:39.089+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=180, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:39.089+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=180),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/180] for update
[2025-07-19T21:02:39.089+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:39.090+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7feeaf23
[2025-07-19T21:02:39.090+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=181, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:39.090+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=181),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/181] for update
[2025-07-19T21:02:39.090+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:39.100+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/180/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/180/.2.delta.d261920e-2bc3-4249-aa9e-4d882151f81c.TID983.tmp
[2025-07-19T21:02:39.102+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/174/.2.delta.3ff4e37b-f3c8-424c-a5b2-9ffa4ab983c5.TID977.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/174/2.delta
[2025-07-19T21:02:39.102+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=174),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/174] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/174/2.delta
[2025-07-19T21:02:39.103+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Commit authorized for partition 174 (task 977, attempt 0, stage 9.0)
[2025-07-19T21:02:39.106+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/175/.2.delta.c2a600aa-f865-4eab-862c-9752196e4ad3.TID978.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/175/2.delta
[2025-07-19T21:02:39.107+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=175),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/175] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/175/2.delta
[2025-07-19T21:02:39.108+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Committed partition 174 (task 977, attempt 0, stage 9.0)
[2025-07-19T21:02:39.109+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Commit authorized for partition 175 (task 978, attempt 0, stage 9.0)
[2025-07-19T21:02:39.109+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/181/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/181/.2.delta.a6617514-f6a2-42b0-9a5b-8a00966b727c.TID984.tmp
[2025-07-19T21:02:39.109+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Finished task 174.0 in stage 9.0 (TID 977). 5829 bytes result sent to driver
[2025-07-19T21:02:39.110+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Finished task 174.0 in stage 9.0 (TID 977) in 80 ms on 8b44f3d35cfa (executor driver) (175/200)
[2025-07-19T21:02:39.110+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Starting task 182.0 in stage 9.0 (TID 985) (8b44f3d35cfa, executor driver, partition 182, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:39.110+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Running task 182.0 in stage 9.0 (TID 985)
[2025-07-19T21:02:39.112+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:39.113+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:39.114+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Committed partition 175 (task 978, attempt 0, stage 9.0)
[2025-07-19T21:02:39.114+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Finished task 175.0 in stage 9.0 (TID 978). 5829 bytes result sent to driver
[2025-07-19T21:02:39.114+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Starting task 183.0 in stage 9.0 (TID 986) (8b44f3d35cfa, executor driver, partition 183, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:39.115+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7495bf8d
[2025-07-19T21:02:39.117+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Running task 183.0 in stage 9.0 (TID 986)
[2025-07-19T21:02:39.118+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Finished task 175.0 in stage 9.0 (TID 978) in 74 ms on 8b44f3d35cfa (executor driver) (176/200)
[2025-07-19T21:02:39.118+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/176/.2.delta.682a30a8-0760-4ddf-9886-8cfabc855079.TID979.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/176/2.delta
[2025-07-19T21:02:39.119+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=176),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/176] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/176/2.delta
[2025-07-19T21:02:39.119+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Commit authorized for partition 176 (task 979, attempt 0, stage 9.0)
[2025-07-19T21:02:39.120+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=182, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:39.120+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:39.121+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:39.121+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=182),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/182] for update
[2025-07-19T21:02:39.123+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@131d1787
[2025-07-19T21:02:39.123+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:39.124+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=183, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:39.124+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=183),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/183] for update
[2025-07-19T21:02:39.125+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:39.126+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Committed partition 176 (task 979, attempt 0, stage 9.0)
[2025-07-19T21:02:39.126+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Finished task 176.0 in stage 9.0 (TID 979). 5829 bytes result sent to driver
[2025-07-19T21:02:39.127+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Starting task 184.0 in stage 9.0 (TID 987) (8b44f3d35cfa, executor driver, partition 184, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:39.128+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Running task 184.0 in stage 9.0 (TID 987)
[2025-07-19T21:02:39.129+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Finished task 176.0 in stage 9.0 (TID 979) in 72 ms on 8b44f3d35cfa (executor driver) (177/200)
[2025-07-19T21:02:39.129+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/177/.2.delta.fb650f02-e7ae-4027-895f-d4f1a21c1495.TID980.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/177/2.delta
[2025-07-19T21:02:39.129+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=177),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/177] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/177/2.delta
[2025-07-19T21:02:39.129+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Commit authorized for partition 177 (task 980, attempt 0, stage 9.0)
[2025-07-19T21:02:39.130+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:39.131+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:39.132+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/178/.2.delta.c60715d6-9bfb-4a5e-a67e-50e3caaba188.TID981.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/178/2.delta
[2025-07-19T21:02:39.133+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=178),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/178] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/178/2.delta
[2025-07-19T21:02:39.133+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Commit authorized for partition 178 (task 981, attempt 0, stage 9.0)
[2025-07-19T21:02:39.133+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@166f91a9
[2025-07-19T21:02:39.133+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=184, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:39.133+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=184),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/184] for update
[2025-07-19T21:02:39.134+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Committed partition 178 (task 981, attempt 0, stage 9.0)
[2025-07-19T21:02:39.134+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Committed partition 177 (task 980, attempt 0, stage 9.0)
[2025-07-19T21:02:39.135+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/182/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/182/.2.delta.35ffa659-c947-4787-abc4-b166bd88c276.TID985.tmp
[2025-07-19T21:02:39.136+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Finished task 178.0 in stage 9.0 (TID 981). 5829 bytes result sent to driver
[2025-07-19T21:02:39.136+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Finished task 177.0 in stage 9.0 (TID 980). 5829 bytes result sent to driver
[2025-07-19T21:02:39.137+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:39.137+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Starting task 185.0 in stage 9.0 (TID 988) (8b44f3d35cfa, executor driver, partition 185, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:39.137+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Starting task 186.0 in stage 9.0 (TID 989) (8b44f3d35cfa, executor driver, partition 186, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:39.137+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Running task 185.0 in stage 9.0 (TID 988)
[2025-07-19T21:02:39.138+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Finished task 178.0 in stage 9.0 (TID 981) in 67 ms on 8b44f3d35cfa (executor driver) (178/200)
[2025-07-19T21:02:39.138+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/183/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/183/.2.delta.6eda4213-8a3c-4e95-bd90-ec4517a5fc32.TID986.tmp
[2025-07-19T21:02:39.138+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Running task 186.0 in stage 9.0 (TID 989)
[2025-07-19T21:02:39.138+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Finished task 177.0 in stage 9.0 (TID 980) in 77 ms on 8b44f3d35cfa (executor driver) (179/200)
[2025-07-19T21:02:39.138+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/179/.2.delta.047bf691-a522-4c01-af93-f9d187d4e3b1.TID982.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/179/2.delta
[2025-07-19T21:02:39.138+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=179),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/179] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/179/2.delta
[2025-07-19T21:02:39.139+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Commit authorized for partition 179 (task 982, attempt 0, stage 9.0)
[2025-07-19T21:02:39.140+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:39.141+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:39.141+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:39.141+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:39.141+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@447af94f
[2025-07-19T21:02:39.142+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=185, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:39.143+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=185),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/185] for update
[2025-07-19T21:02:39.144+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Committed partition 179 (task 982, attempt 0, stage 9.0)
[2025-07-19T21:02:39.145+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5709c9a3
[2025-07-19T21:02:39.146+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=186, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:39.146+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=186),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/186] for update
[2025-07-19T21:02:39.147+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Finished task 179.0 in stage 9.0 (TID 982). 5829 bytes result sent to driver
[2025-07-19T21:02:39.147+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Starting task 187.0 in stage 9.0 (TID 990) (8b44f3d35cfa, executor driver, partition 187, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:39.148+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:39.149+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Running task 187.0 in stage 9.0 (TID 990)
[2025-07-19T21:02:39.149+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Finished task 179.0 in stage 9.0 (TID 982) in 72 ms on 8b44f3d35cfa (executor driver) (180/200)
[2025-07-19T21:02:39.149+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:39.149+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:39.149+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:39.150+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63227445
[2025-07-19T21:02:39.150+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=187, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:39.151+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/180/.2.delta.d261920e-2bc3-4249-aa9e-4d882151f81c.TID983.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/180/2.delta
[2025-07-19T21:02:39.152+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=187),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/187] for update
[2025-07-19T21:02:39.153+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=180),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/180] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/180/2.delta
[2025-07-19T21:02:39.154+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Commit authorized for partition 180 (task 983, attempt 0, stage 9.0)
[2025-07-19T21:02:39.154+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:39.154+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/184/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/184/.2.delta.c85f53e2-f507-4c8b-819d-1e2106b9f587.TID987.tmp
[2025-07-19T21:02:39.154+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/185/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/185/.2.delta.f2345994-8d05-4149-9968-f9dbb091f488.TID988.tmp
[2025-07-19T21:02:39.154+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/186/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/186/.2.delta.ba2e0039-2769-45ac-befe-5ccc97abb33f.TID989.tmp
[2025-07-19T21:02:39.155+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Committed partition 180 (task 983, attempt 0, stage 9.0)
[2025-07-19T21:02:39.155+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Finished task 180.0 in stage 9.0 (TID 983). 5829 bytes result sent to driver
[2025-07-19T21:02:39.155+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Starting task 188.0 in stage 9.0 (TID 991) (8b44f3d35cfa, executor driver, partition 188, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:39.155+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Finished task 180.0 in stage 9.0 (TID 983) in 71 ms on 8b44f3d35cfa (executor driver) (181/200)
[2025-07-19T21:02:39.156+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Running task 188.0 in stage 9.0 (TID 991)
[2025-07-19T21:02:39.156+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:39.156+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:39.156+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/181/.2.delta.a6617514-f6a2-42b0-9a5b-8a00966b727c.TID984.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/181/2.delta
[2025-07-19T21:02:39.157+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=181),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/181] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/181/2.delta
[2025-07-19T21:02:39.157+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Commit authorized for partition 181 (task 984, attempt 0, stage 9.0)
[2025-07-19T21:02:39.157+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@69c6c2f0
[2025-07-19T21:02:39.157+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=188, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:39.157+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=188),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/188] for update
[2025-07-19T21:02:39.158+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/187/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/187/.2.delta.ac43c0b7-db0b-449d-95ee-c6307189e8e2.TID990.tmp
[2025-07-19T21:02:39.158+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:39.158+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Committed partition 181 (task 984, attempt 0, stage 9.0)
[2025-07-19T21:02:39.158+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Finished task 181.0 in stage 9.0 (TID 984). 5829 bytes result sent to driver
[2025-07-19T21:02:39.161+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Starting task 189.0 in stage 9.0 (TID 992) (8b44f3d35cfa, executor driver, partition 189, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:39.161+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Finished task 181.0 in stage 9.0 (TID 984) in 79 ms on 8b44f3d35cfa (executor driver) (182/200)
[2025-07-19T21:02:39.162+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Running task 189.0 in stage 9.0 (TID 992)
[2025-07-19T21:02:39.165+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/188/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/188/.2.delta.0af74c72-c5c5-47ce-811e-69f51b4f38f1.TID991.tmp
[2025-07-19T21:02:39.166+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:39.166+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:39.167+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ceb5bd3
[2025-07-19T21:02:39.167+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=189, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:39.167+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=189),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/189] for update
[2025-07-19T21:02:39.168+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:39.177+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/183/.2.delta.6eda4213-8a3c-4e95-bd90-ec4517a5fc32.TID986.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/183/2.delta
[2025-07-19T21:02:39.178+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=183),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/183] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/183/2.delta
[2025-07-19T21:02:39.178+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Commit authorized for partition 183 (task 986, attempt 0, stage 9.0)
[2025-07-19T21:02:39.180+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/182/.2.delta.35ffa659-c947-4787-abc4-b166bd88c276.TID985.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/182/2.delta
[2025-07-19T21:02:39.181+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=182),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/182] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/182/2.delta
[2025-07-19T21:02:39.182+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Commit authorized for partition 182 (task 985, attempt 0, stage 9.0)
[2025-07-19T21:02:39.182+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Committed partition 183 (task 986, attempt 0, stage 9.0)
[2025-07-19T21:02:39.183+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Finished task 183.0 in stage 9.0 (TID 986). 5872 bytes result sent to driver
[2025-07-19T21:02:39.184+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Starting task 190.0 in stage 9.0 (TID 993) (8b44f3d35cfa, executor driver, partition 190, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:39.185+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Finished task 183.0 in stage 9.0 (TID 986) in 70 ms on 8b44f3d35cfa (executor driver) (183/200)
[2025-07-19T21:02:39.186+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Running task 190.0 in stage 9.0 (TID 993)
[2025-07-19T21:02:39.186+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/189/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/189/.2.delta.33742d0c-b50e-4797-b038-cb9456abc112.TID992.tmp
[2025-07-19T21:02:39.186+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/184/.2.delta.c85f53e2-f507-4c8b-819d-1e2106b9f587.TID987.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/184/2.delta
[2025-07-19T21:02:39.186+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=184),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/184] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/184/2.delta
[2025-07-19T21:02:39.186+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Committed partition 182 (task 985, attempt 0, stage 9.0)
[2025-07-19T21:02:39.186+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Finished task 182.0 in stage 9.0 (TID 985). 5872 bytes result sent to driver
[2025-07-19T21:02:39.187+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Commit authorized for partition 184 (task 987, attempt 0, stage 9.0)
[2025-07-19T21:02:39.187+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Starting task 191.0 in stage 9.0 (TID 994) (8b44f3d35cfa, executor driver, partition 191, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:39.187+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Finished task 182.0 in stage 9.0 (TID 985) in 77 ms on 8b44f3d35cfa (executor driver) (184/200)
[2025-07-19T21:02:39.187+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Running task 191.0 in stage 9.0 (TID 994)
[2025-07-19T21:02:39.187+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:39.188+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:39.188+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:39.188+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:39.190+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Committed partition 184 (task 987, attempt 0, stage 9.0)
[2025-07-19T21:02:39.191+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Finished task 184.0 in stage 9.0 (TID 987). 5872 bytes result sent to driver
[2025-07-19T21:02:39.191+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/187/.2.delta.ac43c0b7-db0b-449d-95ee-c6307189e8e2.TID990.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/187/2.delta
[2025-07-19T21:02:39.192+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=187),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/187] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/187/2.delta
[2025-07-19T21:02:39.194+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Starting task 192.0 in stage 9.0 (TID 995) (8b44f3d35cfa, executor driver, partition 192, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:39.194+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Commit authorized for partition 187 (task 990, attempt 0, stage 9.0)
[2025-07-19T21:02:39.194+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Finished task 184.0 in stage 9.0 (TID 987) in 71 ms on 8b44f3d35cfa (executor driver) (185/200)
[2025-07-19T21:02:39.194+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Running task 192.0 in stage 9.0 (TID 995)
[2025-07-19T21:02:39.195+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e668583
[2025-07-19T21:02:39.195+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=190, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:39.195+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=190),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/190] for update
[2025-07-19T21:02:39.196+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/185/.2.delta.f2345994-8d05-4149-9968-f9dbb091f488.TID988.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/185/2.delta
[2025-07-19T21:02:39.196+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=185),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/185] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/185/2.delta
[2025-07-19T21:02:39.196+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Commit authorized for partition 185 (task 988, attempt 0, stage 9.0)
[2025-07-19T21:02:39.196+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:39.196+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:39.196+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:39.196+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56cc63f3
[2025-07-19T21:02:39.196+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=192, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:39.197+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=192),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/192] for update
[2025-07-19T21:02:39.198+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a939047
[2025-07-19T21:02:39.199+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=191, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:39.201+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=191),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/191] for update
[2025-07-19T21:02:39.202+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Committed partition 185 (task 988, attempt 0, stage 9.0)
[2025-07-19T21:02:39.203+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Committed partition 187 (task 990, attempt 0, stage 9.0)
[2025-07-19T21:02:39.204+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Finished task 187.0 in stage 9.0 (TID 990). 5872 bytes result sent to driver
[2025-07-19T21:02:39.204+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/186/.2.delta.ba2e0039-2769-45ac-befe-5ccc97abb33f.TID989.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/186/2.delta
[2025-07-19T21:02:39.205+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=186),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/186] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/186/2.delta
[2025-07-19T21:02:39.206+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Starting task 193.0 in stage 9.0 (TID 996) (8b44f3d35cfa, executor driver, partition 193, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:39.207+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Finished task 185.0 in stage 9.0 (TID 988). 5872 bytes result sent to driver
[2025-07-19T21:02:39.207+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Running task 193.0 in stage 9.0 (TID 996)
[2025-07-19T21:02:39.208+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:39.208+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:39.208+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Commit authorized for partition 186 (task 989, attempt 0, stage 9.0)
[2025-07-19T21:02:39.208+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:39.208+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Finished task 187.0 in stage 9.0 (TID 990) in 65 ms on 8b44f3d35cfa (executor driver) (186/200)
[2025-07-19T21:02:39.208+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:39.208+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Starting task 194.0 in stage 9.0 (TID 997) (8b44f3d35cfa, executor driver, partition 194, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:39.208+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Running task 194.0 in stage 9.0 (TID 997)
[2025-07-19T21:02:39.208+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5835ebef
[2025-07-19T21:02:39.208+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Finished task 185.0 in stage 9.0 (TID 988) in 75 ms on 8b44f3d35cfa (executor driver) (187/200)
[2025-07-19T21:02:39.209+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=193, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:39.209+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=193),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/193] for update
[2025-07-19T21:02:39.209+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Committed partition 186 (task 989, attempt 0, stage 9.0)
[2025-07-19T21:02:39.211+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Finished task 186.0 in stage 9.0 (TID 989). 5872 bytes result sent to driver
[2025-07-19T21:02:39.211+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Starting task 195.0 in stage 9.0 (TID 998) (8b44f3d35cfa, executor driver, partition 195, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:39.212+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Running task 195.0 in stage 9.0 (TID 998)
[2025-07-19T21:02:39.212+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Finished task 186.0 in stage 9.0 (TID 989) in 78 ms on 8b44f3d35cfa (executor driver) (188/200)
[2025-07-19T21:02:39.212+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:39.212+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:39.212+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/190/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/190/.2.delta.db99b664-2679-42bd-a3c9-54e0cedd1cf4.TID993.tmp
[2025-07-19T21:02:39.212+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:39.213+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:39.213+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d838a71
[2025-07-19T21:02:39.213+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:39.214+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=194, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:39.214+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=194),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/194] for update
[2025-07-19T21:02:39.215+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2019d34b
[2025-07-19T21:02:39.215+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=195, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:39.216+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=195),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/195] for update
[2025-07-19T21:02:39.216+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:39.216+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:39.217+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/192/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/192/.2.delta.a6712338-c6af-4ac6-8600-d8dbfd84ba03.TID995.tmp
[2025-07-19T21:02:39.217+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/191/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/191/.2.delta.408e96db-3d80-415f-9594-c75c24e30b21.TID994.tmp
[2025-07-19T21:02:39.223+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/193/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/193/.2.delta.fbe0afd1-32fc-483f-be66-d909e4148310.TID996.tmp
[2025-07-19T21:02:39.224+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/188/.2.delta.0af74c72-c5c5-47ce-811e-69f51b4f38f1.TID991.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/188/2.delta
[2025-07-19T21:02:39.224+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=188),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/188] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/188/2.delta
[2025-07-19T21:02:39.225+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Commit authorized for partition 188 (task 991, attempt 0, stage 9.0)
[2025-07-19T21:02:39.227+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/195/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/195/.2.delta.d5c9863e-bced-4a48-a1ec-169e00bb8afd.TID998.tmp
[2025-07-19T21:02:39.227+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/194/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/194/.2.delta.cc82b2b7-971c-4fc7-bc56-1b71e79a9e82.TID997.tmp
[2025-07-19T21:02:39.228+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Committed partition 188 (task 991, attempt 0, stage 9.0)
[2025-07-19T21:02:39.229+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Finished task 188.0 in stage 9.0 (TID 991). 5872 bytes result sent to driver
[2025-07-19T21:02:39.229+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Starting task 196.0 in stage 9.0 (TID 999) (8b44f3d35cfa, executor driver, partition 196, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:39.229+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Running task 196.0 in stage 9.0 (TID 999)
[2025-07-19T21:02:39.230+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Finished task 188.0 in stage 9.0 (TID 991) in 80 ms on 8b44f3d35cfa (executor driver) (189/200)
[2025-07-19T21:02:39.231+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:39.232+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T21:02:39.232+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c2ccd2f
[2025-07-19T21:02:39.232+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=196, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:39.234+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=196),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/196] for update
[2025-07-19T21:02:39.235+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:39.241+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/189/.2.delta.33742d0c-b50e-4797-b038-cb9456abc112.TID992.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/189/2.delta
[2025-07-19T21:02:39.242+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=189),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/189] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/189/2.delta
[2025-07-19T21:02:39.244+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Commit authorized for partition 189 (task 992, attempt 0, stage 9.0)
[2025-07-19T21:02:39.244+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Committed partition 189 (task 992, attempt 0, stage 9.0)
[2025-07-19T21:02:39.247+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Finished task 189.0 in stage 9.0 (TID 992). 5872 bytes result sent to driver
[2025-07-19T21:02:39.248+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Starting task 197.0 in stage 9.0 (TID 1000) (8b44f3d35cfa, executor driver, partition 197, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:39.248+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Running task 197.0 in stage 9.0 (TID 1000)
[2025-07-19T21:02:39.248+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/196/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/196/.2.delta.0ecdcc56-e234-4d8c-9549-4bc4b0105abc.TID999.tmp
[2025-07-19T21:02:39.249+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Finished task 189.0 in stage 9.0 (TID 992) in 93 ms on 8b44f3d35cfa (executor driver) (190/200)
[2025-07-19T21:02:39.249+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:39.249+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:39.249+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@297f770b
[2025-07-19T21:02:39.257+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=197, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:39.258+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=197),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/197] for update
[2025-07-19T21:02:39.260+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/190/.2.delta.db99b664-2679-42bd-a3c9-54e0cedd1cf4.TID993.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/190/2.delta
[2025-07-19T21:02:39.260+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=190),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/190] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/190/2.delta
[2025-07-19T21:02:39.260+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Commit authorized for partition 190 (task 993, attempt 0, stage 9.0)
[2025-07-19T21:02:39.260+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:39.265+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Committed partition 190 (task 993, attempt 0, stage 9.0)
[2025-07-19T21:02:39.265+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Finished task 190.0 in stage 9.0 (TID 993). 5829 bytes result sent to driver
[2025-07-19T21:02:39.266+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Starting task 198.0 in stage 9.0 (TID 1001) (8b44f3d35cfa, executor driver, partition 198, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:39.266+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Finished task 190.0 in stage 9.0 (TID 993) in 81 ms on 8b44f3d35cfa (executor driver) (191/200)
[2025-07-19T21:02:39.266+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Running task 198.0 in stage 9.0 (TID 1001)
[2025-07-19T21:02:39.266+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/191/.2.delta.408e96db-3d80-415f-9594-c75c24e30b21.TID994.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/191/2.delta
[2025-07-19T21:02:39.267+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=191),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/191] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/191/2.delta
[2025-07-19T21:02:39.267+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Commit authorized for partition 191 (task 994, attempt 0, stage 9.0)
[2025-07-19T21:02:39.269+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/195/.2.delta.d5c9863e-bced-4a48-a1ec-169e00bb8afd.TID998.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/195/2.delta
[2025-07-19T21:02:39.270+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=195),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/195] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/195/2.delta
[2025-07-19T21:02:39.273+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:39.274+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:39.274+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Committed partition 191 (task 994, attempt 0, stage 9.0)
[2025-07-19T21:02:39.275+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Finished task 191.0 in stage 9.0 (TID 994). 5829 bytes result sent to driver
[2025-07-19T21:02:39.276+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Commit authorized for partition 195 (task 998, attempt 0, stage 9.0)
[2025-07-19T21:02:39.277+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d12446d
[2025-07-19T21:02:39.278+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Starting task 199.0 in stage 9.0 (TID 1002) (8b44f3d35cfa, executor driver, partition 199, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T21:02:39.278+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Running task 199.0 in stage 9.0 (TID 1002)
[2025-07-19T21:02:39.279+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Finished task 191.0 in stage 9.0 (TID 994) in 84 ms on 8b44f3d35cfa (executor driver) (192/200)
[2025-07-19T21:02:39.280+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=198, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:39.280+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=198),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/198] for update
[2025-07-19T21:02:39.281+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:39.281+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Committed partition 195 (task 998, attempt 0, stage 9.0)
[2025-07-19T21:02:39.281+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T21:02:39.282+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T21:02:39.282+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Finished task 195.0 in stage 9.0 (TID 998). 5829 bytes result sent to driver
[2025-07-19T21:02:39.282+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/192/.2.delta.a6712338-c6af-4ac6-8600-d8dbfd84ba03.TID995.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/192/2.delta
[2025-07-19T21:02:39.282+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/197/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/197/.2.delta.44f59800-7d53-487b-af22-4819164461ce.TID1000.tmp
[2025-07-19T21:02:39.283+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=192),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/192] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/192/2.delta
[2025-07-19T21:02:39.283+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a744f2b
[2025-07-19T21:02:39.283+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/194/.2.delta.cc82b2b7-971c-4fc7-bc56-1b71e79a9e82.TID997.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/194/2.delta
[2025-07-19T21:02:39.284+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=194),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/194] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/194/2.delta
[2025-07-19T21:02:39.284+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Commit authorized for partition 192 (task 995, attempt 0, stage 9.0)
[2025-07-19T21:02:39.284+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Finished task 195.0 in stage 9.0 (TID 998) in 70 ms on 8b44f3d35cfa (executor driver) (193/200)
[2025-07-19T21:02:39.284+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state, operatorId=0, partitionId=199, storeName=default ],07295437-5b62-45a1-8005-3d2155adaa4b) is active
[2025-07-19T21:02:39.284+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=199),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/199] for update
[2025-07-19T21:02:39.285+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Commit authorized for partition 194 (task 997, attempt 0, stage 9.0)
[2025-07-19T21:02:39.285+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/193/.2.delta.fbe0afd1-32fc-483f-be66-d909e4148310.TID996.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/193/2.delta
[2025-07-19T21:02:39.286+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=193),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/193] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/193/2.delta
[2025-07-19T21:02:39.286+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Commit authorized for partition 193 (task 996, attempt 0, stage 9.0)
[2025-07-19T21:02:39.286+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T21:02:39.287+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Committed partition 193 (task 996, attempt 0, stage 9.0)
[2025-07-19T21:02:39.287+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Finished task 193.0 in stage 9.0 (TID 996). 5829 bytes result sent to driver
[2025-07-19T21:02:39.288+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Finished task 193.0 in stage 9.0 (TID 996) in 84 ms on 8b44f3d35cfa (executor driver) (194/200)
[2025-07-19T21:02:39.288+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/198/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/198/.2.delta.dc11ef3d-ba64-470b-8d39-9db26033a20e.TID1001.tmp
[2025-07-19T21:02:39.288+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Committed partition 192 (task 995, attempt 0, stage 9.0)
[2025-07-19T21:02:39.288+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Finished task 192.0 in stage 9.0 (TID 995). 5829 bytes result sent to driver
[2025-07-19T21:02:39.288+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Committed partition 194 (task 997, attempt 0, stage 9.0)
[2025-07-19T21:02:39.288+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Finished task 194.0 in stage 9.0 (TID 997). 5829 bytes result sent to driver
[2025-07-19T21:02:39.288+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Finished task 192.0 in stage 9.0 (TID 995) in 96 ms on 8b44f3d35cfa (executor driver) (195/200)
[2025-07-19T21:02:39.289+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Finished task 194.0 in stage 9.0 (TID 997) in 85 ms on 8b44f3d35cfa (executor driver) (196/200)
[2025-07-19T21:02:39.293+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/199/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/199/.2.delta.ca4bb9f1-2183-4870-82a1-153a29dbf1a8.TID1002.tmp
[2025-07-19T21:02:39.295+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/196/.2.delta.0ecdcc56-e234-4d8c-9549-4bc4b0105abc.TID999.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/196/2.delta
[2025-07-19T21:02:39.295+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=196),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/196] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/196/2.delta
[2025-07-19T21:02:39.296+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Commit authorized for partition 196 (task 999, attempt 0, stage 9.0)
[2025-07-19T21:02:39.299+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/197/.2.delta.44f59800-7d53-487b-af22-4819164461ce.TID1000.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/197/2.delta
[2025-07-19T21:02:39.299+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=197),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/197] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/197/2.delta
[2025-07-19T21:02:39.299+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Commit authorized for partition 197 (task 1000, attempt 0, stage 9.0)
[2025-07-19T21:02:39.301+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Committed partition 196 (task 999, attempt 0, stage 9.0)
[2025-07-19T21:02:39.302+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Finished task 196.0 in stage 9.0 (TID 999). 5829 bytes result sent to driver
[2025-07-19T21:02:39.302+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Committed partition 197 (task 1000, attempt 0, stage 9.0)
[2025-07-19T21:02:39.302+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Finished task 197.0 in stage 9.0 (TID 1000). 5829 bytes result sent to driver
[2025-07-19T21:02:39.302+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Finished task 197.0 in stage 9.0 (TID 1000) in 57 ms on 8b44f3d35cfa (executor driver) (197/200)
[2025-07-19T21:02:39.302+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Finished task 196.0 in stage 9.0 (TID 999) in 79 ms on 8b44f3d35cfa (executor driver) (198/200)
[2025-07-19T21:02:39.308+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/198/.2.delta.dc11ef3d-ba64-470b-8d39-9db26033a20e.TID1001.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/198/2.delta
[2025-07-19T21:02:39.308+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=198),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/198] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/198/2.delta
[2025-07-19T21:02:39.308+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Commit authorized for partition 198 (task 1001, attempt 0, stage 9.0)
[2025-07-19T21:02:39.310+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/199/.2.delta.ca4bb9f1-2183-4870-82a1-153a29dbf1a8.TID1002.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/199/2.delta
[2025-07-19T21:02:39.310+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=199),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/199] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/state/0/199/2.delta
[2025-07-19T21:02:39.310+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Commit authorized for partition 199 (task 1002, attempt 0, stage 9.0)
[2025-07-19T21:02:39.310+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Committed partition 198 (task 1001, attempt 0, stage 9.0)
[2025-07-19T21:02:39.311+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Finished task 198.0 in stage 9.0 (TID 1001). 5829 bytes result sent to driver
[2025-07-19T21:02:39.311+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Finished task 198.0 in stage 9.0 (TID 1001) in 47 ms on 8b44f3d35cfa (executor driver) (199/200)
[2025-07-19T21:02:39.312+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DataWritingSparkTask: Committed partition 199 (task 1002, attempt 0, stage 9.0)
[2025-07-19T21:02:39.312+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO Executor: Finished task 199.0 in stage 9.0 (TID 1002). 5829 bytes result sent to driver
[2025-07-19T21:02:39.313+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSetManager: Finished task 199.0 in stage 9.0 (TID 1002) in 44 ms on 8b44f3d35cfa (executor driver) (200/200)
[2025-07-19T21:02:39.313+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool
[2025-07-19T21:02:39.313+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DAGScheduler: ResultStage 9 (start at <unknown>:0) finished in 3.681 s
[2025-07-19T21:02:39.314+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-19T21:02:39.314+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
[2025-07-19T21:02:39.314+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO DAGScheduler: Job 4 finished: start at <unknown>:0, took 3.738795 s
[2025-07-19T21:02:39.314+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 1, writer: IcebergStreamingWrite(table=my_catalog.bronze.Feedback_raw, format=PARQUET)] is committing.
[2025-07-19T21:02:39.314+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO SparkWrite: Committing epoch 1 for query 30463049-c973-45be-97a0-fdd3d358740a in append mode
[2025-07-19T21:02:39.319+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO SparkWrite: Committing streaming append with 0 new data files to table my_catalog.bronze.Feedback_raw
[2025-07-19T21:02:39.360+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO HadoopTableOperations: Committed a new metadata file s3a://warehouse/bronze/Feedback_raw/metadata/v129.metadata.json
[2025-07-19T21:02:39.379+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO SnapshotProducer: Committed snapshot 59931381111168593 (FastAppend)
[2025-07-19T21:02:39.397+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO LoggingMetricsReporter: Received metrics report: CommitReport{tableName=my_catalog.bronze.Feedback_raw, snapshotId=59931381111168593, sequenceNumber=128, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.0763835S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=null, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=6406}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=null, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=8928}, addedFilesSizeInBytes=null, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=18464384}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}}, metadata={engine-version=3.5.6, app-id=local-1752958935081, engine-name=spark, iceberg-version=Apache Iceberg 1.4.0 (commit 10367c380098c2e06a49521a33681ac7f6c64b2c)}}
[2025-07-19T21:02:39.397+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO SparkWrite: Committed in 77 ms
[2025-07-19T21:02:39.398+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 1, writer: IcebergStreamingWrite(table=my_catalog.bronze.Feedback_raw, format=PARQUET)] committed.
[2025-07-19T21:02:39.401+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/commits/1 using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/commits/.1.f898e8f2-cc94-4f07-ac83-9f9861bbeb2f.tmp
[2025-07-19T21:02:39.415+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/commits/.1.f898e8f2-cc94-4f07-ac83-9f9861bbeb2f.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T21:00:00+00:00/commits/1
[2025-07-19T21:02:39.416+0000] {subprocess.py:93} INFO - 25/07/19 21:02:39 INFO MicroBatchExecution: Streaming query made progress: {
[2025-07-19T21:02:39.416+0000] {subprocess.py:93} INFO -   "id" : "30463049-c973-45be-97a0-fdd3d358740a",
[2025-07-19T21:02:39.416+0000] {subprocess.py:93} INFO -   "runId" : "07295437-5b62-45a1-8005-3d2155adaa4b",
[2025-07-19T21:02:39.416+0000] {subprocess.py:93} INFO -   "name" : null,
[2025-07-19T21:02:39.416+0000] {subprocess.py:93} INFO -   "timestamp" : "2025-07-19T21:02:35.183Z",
[2025-07-19T21:02:39.417+0000] {subprocess.py:93} INFO -   "batchId" : 1,
[2025-07-19T21:02:39.417+0000] {subprocess.py:93} INFO -   "numInputRows" : 0,
[2025-07-19T21:02:39.417+0000] {subprocess.py:93} INFO -   "inputRowsPerSecond" : 0.0,
[2025-07-19T21:02:39.417+0000] {subprocess.py:93} INFO -   "processedRowsPerSecond" : 0.0,
[2025-07-19T21:02:39.417+0000] {subprocess.py:93} INFO -   "durationMs" : {
[2025-07-19T21:02:39.417+0000] {subprocess.py:93} INFO -     "addBatch" : 4036,
[2025-07-19T21:02:39.417+0000] {subprocess.py:93} INFO -     "commitOffsets" : 19,
[2025-07-19T21:02:39.418+0000] {subprocess.py:93} INFO -     "getBatch" : 0,
[2025-07-19T21:02:39.418+0000] {subprocess.py:93} INFO -     "latestOffset" : 18,
[2025-07-19T21:02:39.418+0000] {subprocess.py:93} INFO -     "queryPlanning" : 52,
[2025-07-19T21:02:39.418+0000] {subprocess.py:93} INFO -     "triggerExecution" : 4231,
[2025-07-19T21:02:39.418+0000] {subprocess.py:93} INFO -     "walCommit" : 101
[2025-07-19T21:02:39.418+0000] {subprocess.py:93} INFO -   },
[2025-07-19T21:02:39.418+0000] {subprocess.py:93} INFO -   "eventTime" : {
[2025-07-19T21:02:39.418+0000] {subprocess.py:93} INFO -     "watermark" : "2025-07-17T21:02:08.000Z"
[2025-07-19T21:02:39.418+0000] {subprocess.py:93} INFO -   },
[2025-07-19T21:02:39.418+0000] {subprocess.py:93} INFO -   "stateOperators" : [ {
[2025-07-19T21:02:39.419+0000] {subprocess.py:93} INFO -     "operatorName" : "dedupe",
[2025-07-19T21:02:39.419+0000] {subprocess.py:93} INFO -     "numRowsTotal" : 234,
[2025-07-19T21:02:39.419+0000] {subprocess.py:93} INFO -     "numRowsUpdated" : 0,
[2025-07-19T21:02:39.419+0000] {subprocess.py:93} INFO -     "allUpdatesTimeMs" : 168,
[2025-07-19T21:02:39.419+0000] {subprocess.py:93} INFO -     "numRowsRemoved" : 0,
[2025-07-19T21:02:39.419+0000] {subprocess.py:93} INFO -     "allRemovalsTimeMs" : 83,
[2025-07-19T21:02:39.419+0000] {subprocess.py:93} INFO -     "commitTimeMs" : 13388,
[2025-07-19T21:02:39.419+0000] {subprocess.py:93} INFO -     "memoryUsedBytes" : 149256,
[2025-07-19T21:02:39.419+0000] {subprocess.py:93} INFO -     "numRowsDroppedByWatermark" : 0,
[2025-07-19T21:02:39.419+0000] {subprocess.py:93} INFO -     "numShufflePartitions" : 200,
[2025-07-19T21:02:39.419+0000] {subprocess.py:93} INFO -     "numStateStoreInstances" : 200,
[2025-07-19T21:02:39.419+0000] {subprocess.py:93} INFO -     "customMetrics" : {
[2025-07-19T21:02:39.419+0000] {subprocess.py:93} INFO -       "loadedMapCacheHitCount" : 200,
[2025-07-19T21:02:39.419+0000] {subprocess.py:93} INFO -       "loadedMapCacheMissCount" : 0,
[2025-07-19T21:02:39.420+0000] {subprocess.py:93} INFO -       "numDroppedDuplicateRows" : 0,
[2025-07-19T21:02:39.420+0000] {subprocess.py:93} INFO -       "stateOnCurrentVersionSizeBytes" : 69288
[2025-07-19T21:02:39.420+0000] {subprocess.py:93} INFO -     }
[2025-07-19T21:02:39.420+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T21:02:39.420+0000] {subprocess.py:93} INFO -   "sources" : [ {
[2025-07-19T21:02:39.420+0000] {subprocess.py:93} INFO -     "description" : "KafkaV2[Subscribe[feedback]]",
[2025-07-19T21:02:39.420+0000] {subprocess.py:93} INFO -     "startOffset" : {
[2025-07-19T21:02:39.420+0000] {subprocess.py:93} INFO -       "feedback" : {
[2025-07-19T21:02:39.420+0000] {subprocess.py:93} INFO -         "0" : 234
[2025-07-19T21:02:39.420+0000] {subprocess.py:93} INFO -       }
[2025-07-19T21:02:39.420+0000] {subprocess.py:93} INFO -     },
[2025-07-19T21:02:39.421+0000] {subprocess.py:93} INFO -     "endOffset" : {
[2025-07-19T21:02:39.421+0000] {subprocess.py:93} INFO -       "feedback" : {
[2025-07-19T21:02:39.421+0000] {subprocess.py:93} INFO -         "0" : 234
[2025-07-19T21:02:39.421+0000] {subprocess.py:93} INFO -       }
[2025-07-19T21:02:39.421+0000] {subprocess.py:93} INFO -     },
[2025-07-19T21:02:39.421+0000] {subprocess.py:93} INFO -     "latestOffset" : {
[2025-07-19T21:02:39.421+0000] {subprocess.py:93} INFO -       "feedback" : {
[2025-07-19T21:02:39.421+0000] {subprocess.py:93} INFO -         "0" : 234
[2025-07-19T21:02:39.421+0000] {subprocess.py:93} INFO -       }
[2025-07-19T21:02:39.421+0000] {subprocess.py:93} INFO -     },
[2025-07-19T21:02:39.421+0000] {subprocess.py:93} INFO -     "numInputRows" : 0,
[2025-07-19T21:02:39.421+0000] {subprocess.py:93} INFO -     "inputRowsPerSecond" : 0.0,
[2025-07-19T21:02:39.421+0000] {subprocess.py:93} INFO -     "processedRowsPerSecond" : 0.0,
[2025-07-19T21:02:39.421+0000] {subprocess.py:93} INFO -     "metrics" : {
[2025-07-19T21:02:39.422+0000] {subprocess.py:93} INFO -       "avgOffsetsBehindLatest" : "0.0",
[2025-07-19T21:02:39.422+0000] {subprocess.py:93} INFO -       "maxOffsetsBehindLatest" : "0",
[2025-07-19T21:02:39.422+0000] {subprocess.py:93} INFO -       "minOffsetsBehindLatest" : "0"
[2025-07-19T21:02:39.422+0000] {subprocess.py:93} INFO -     }
[2025-07-19T21:02:39.422+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T21:02:39.422+0000] {subprocess.py:93} INFO -   "sink" : {
[2025-07-19T21:02:39.422+0000] {subprocess.py:93} INFO -     "description" : "my_catalog.bronze.Feedback_raw",
[2025-07-19T21:02:39.422+0000] {subprocess.py:93} INFO -     "numOutputRows" : 0
[2025-07-19T21:02:39.422+0000] {subprocess.py:93} INFO -   }
[2025-07-19T21:02:39.422+0000] {subprocess.py:93} INFO - }
[2025-07-19T21:02:42.166+0000] {subprocess.py:93} INFO - 25/07/19 21:02:42 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T21:02:47.506+0000] {subprocess.py:93} INFO - 25/07/19 21:02:47 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T21:02:49.416+0000] {subprocess.py:93} INFO - 25/07/19 21:02:49 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T21:02:52.166+0000] {subprocess.py:93} INFO - 25/07/19 21:02:52 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T21:02:57.521+0000] {subprocess.py:93} INFO - 25/07/19 21:02:57 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T21:02:59.426+0000] {subprocess.py:93} INFO - 25/07/19 21:02:59 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T21:03:02.164+0000] {subprocess.py:93} INFO - 25/07/19 21:03:02 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T21:03:07.531+0000] {subprocess.py:93} INFO - 25/07/19 21:03:07 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T21:03:09.434+0000] {subprocess.py:93} INFO - 25/07/19 21:03:09 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T21:03:12.176+0000] {subprocess.py:93} INFO - 25/07/19 21:03:12 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T21:03:17.538+0000] {subprocess.py:93} INFO - 25/07/19 21:03:17 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T21:03:18.688+0000] {subprocess.py:93} INFO - 25/07/19 21:03:18 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-5e160dd6-92fc-4677-b523-b14859d09e7e-1454210137-executor-2, groupId=spark-kafka-source-5e160dd6-92fc-4677-b523-b14859d09e7e-1454210137-executor] Resetting generation and member id due to: consumer pro-actively leaving the group
[2025-07-19T21:03:18.688+0000] {subprocess.py:93} INFO - 25/07/19 21:03:18 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-5e160dd6-92fc-4677-b523-b14859d09e7e-1454210137-executor-2, groupId=spark-kafka-source-5e160dd6-92fc-4677-b523-b14859d09e7e-1454210137-executor] Request joining group due to: consumer pro-actively leaving the group
[2025-07-19T21:03:18.693+0000] {subprocess.py:93} INFO - 25/07/19 21:03:18 INFO Metrics: Metrics scheduler closed
[2025-07-19T21:03:18.694+0000] {subprocess.py:93} INFO - 25/07/19 21:03:18 INFO Metrics: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[2025-07-19T21:03:18.694+0000] {subprocess.py:93} INFO - 25/07/19 21:03:18 INFO Metrics: Metrics reporters closed
[2025-07-19T21:03:18.698+0000] {subprocess.py:93} INFO - 25/07/19 21:03:18 INFO AppInfoParser: App info kafka.consumer for consumer-spark-kafka-source-5e160dd6-92fc-4677-b523-b14859d09e7e-1454210137-executor-2 unregistered
[2025-07-19T21:03:18.698+0000] {subprocess.py:93} INFO - 25/07/19 21:03:18 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-ddf60d79-58fd-40c4-95ff-4219c515ff0a--71257894-executor-3, groupId=spark-kafka-source-ddf60d79-58fd-40c4-95ff-4219c515ff0a--71257894-executor] Resetting generation and member id due to: consumer pro-actively leaving the group
[2025-07-19T21:03:18.699+0000] {subprocess.py:93} INFO - 25/07/19 21:03:18 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-ddf60d79-58fd-40c4-95ff-4219c515ff0a--71257894-executor-3, groupId=spark-kafka-source-ddf60d79-58fd-40c4-95ff-4219c515ff0a--71257894-executor] Request joining group due to: consumer pro-actively leaving the group
[2025-07-19T21:03:18.699+0000] {subprocess.py:93} INFO - 25/07/19 21:03:18 INFO Metrics: Metrics scheduler closed
[2025-07-19T21:03:18.699+0000] {subprocess.py:93} INFO - 25/07/19 21:03:18 INFO Metrics: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[2025-07-19T21:03:18.699+0000] {subprocess.py:93} INFO - 25/07/19 21:03:18 INFO Metrics: Metrics reporters closed
[2025-07-19T21:03:18.699+0000] {subprocess.py:93} INFO - 25/07/19 21:03:18 INFO AppInfoParser: App info kafka.consumer for consumer-spark-kafka-source-ddf60d79-58fd-40c4-95ff-4219c515ff0a--71257894-executor-3 unregistered
[2025-07-19T21:03:18.699+0000] {subprocess.py:93} INFO - 25/07/19 21:03:18 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-2bd68d88-049e-43cb-ab08-0df98b53357a-906712184-executor-1, groupId=spark-kafka-source-2bd68d88-049e-43cb-ab08-0df98b53357a-906712184-executor] Resetting generation and member id due to: consumer pro-actively leaving the group
[2025-07-19T21:03:18.700+0000] {subprocess.py:93} INFO - 25/07/19 21:03:18 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-2bd68d88-049e-43cb-ab08-0df98b53357a-906712184-executor-1, groupId=spark-kafka-source-2bd68d88-049e-43cb-ab08-0df98b53357a-906712184-executor] Request joining group due to: consumer pro-actively leaving the group
[2025-07-19T21:03:18.700+0000] {subprocess.py:93} INFO - 25/07/19 21:03:18 INFO Metrics: Metrics scheduler closed
[2025-07-19T21:03:18.700+0000] {subprocess.py:93} INFO - 25/07/19 21:03:18 INFO Metrics: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[2025-07-19T21:03:18.700+0000] {subprocess.py:93} INFO - 25/07/19 21:03:18 INFO Metrics: Metrics reporters closed
[2025-07-19T21:03:18.700+0000] {subprocess.py:93} INFO - 25/07/19 21:03:18 INFO AppInfoParser: App info kafka.consumer for consumer-spark-kafka-source-2bd68d88-049e-43cb-ab08-0df98b53357a-906712184-executor-1 unregistered
[2025-07-19T21:03:18.701+0000] {subprocess.py:93} INFO - 25/07/19 21:03:18 INFO SparkContext: Invoking stop() from shutdown hook
[2025-07-19T21:03:18.701+0000] {subprocess.py:93} INFO - 25/07/19 21:03:18 INFO SparkContext: SparkContext is stopping with exitCode 0.
[2025-07-19T21:03:18.711+0000] {subprocess.py:93} INFO - 25/07/19 21:03:18 INFO SparkUI: Stopped Spark web UI at http://8b44f3d35cfa:4041
[2025-07-19T21:03:18.723+0000] {subprocess.py:93} INFO - 25/07/19 21:03:18 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2025-07-19T21:03:18.762+0000] {subprocess.py:93} INFO - 25/07/19 21:03:18 INFO MemoryStore: MemoryStore cleared
[2025-07-19T21:03:18.762+0000] {subprocess.py:93} INFO - 25/07/19 21:03:18 INFO BlockManager: BlockManager stopped
[2025-07-19T21:03:18.769+0000] {subprocess.py:93} INFO - 25/07/19 21:03:18 INFO BlockManagerMaster: BlockManagerMaster stopped
[2025-07-19T21:03:18.774+0000] {subprocess.py:93} INFO - 25/07/19 21:03:18 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2025-07-19T21:03:18.796+0000] {subprocess.py:93} INFO - 25/07/19 21:03:18 INFO SparkContext: Successfully stopped SparkContext
[2025-07-19T21:03:18.796+0000] {subprocess.py:93} INFO - 25/07/19 21:03:18 INFO ShutdownHookManager: Shutdown hook called
[2025-07-19T21:03:18.796+0000] {subprocess.py:93} INFO - 25/07/19 21:03:18 INFO ShutdownHookManager: Deleting directory /tmp/spark-b5a29bae-c866-47bc-9811-3cf9658abc0a/pyspark-6d0cd951-5072-424e-8a80-8efefcb8819c
[2025-07-19T21:03:18.805+0000] {subprocess.py:93} INFO - 25/07/19 21:03:18 INFO ShutdownHookManager: Deleting directory /tmp/spark-84669a36-444f-40bd-9d20-17db747f5143
[2025-07-19T21:03:18.812+0000] {subprocess.py:93} INFO - 25/07/19 21:03:18 INFO ShutdownHookManager: Deleting directory /tmp/spark-b5a29bae-c866-47bc-9811-3cf9658abc0a
[2025-07-19T21:03:18.860+0000] {subprocess.py:93} INFO - 25/07/19 21:03:18 INFO MetricsSystemImpl: Stopping s3a-file-system metrics system...
[2025-07-19T21:03:18.861+0000] {subprocess.py:93} INFO - 25/07/19 21:03:18 INFO MetricsSystemImpl: s3a-file-system metrics system stopped.
[2025-07-19T21:03:18.862+0000] {subprocess.py:93} INFO - 25/07/19 21:03:18 INFO MetricsSystemImpl: s3a-file-system metrics system shutdown complete.
[2025-07-19T21:03:19.332+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2025-07-19T21:03:19.367+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=restaurant_pipeline, task_id=stream_to_bronze, execution_date=20250719T210000, start_date=20250719T210212, end_date=20250719T210319
[2025-07-19T21:03:19.424+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2025-07-19T21:03:19.488+0000] {taskinstance.py:2778} INFO - 1 downstream tasks scheduled from follow-on schedule check
