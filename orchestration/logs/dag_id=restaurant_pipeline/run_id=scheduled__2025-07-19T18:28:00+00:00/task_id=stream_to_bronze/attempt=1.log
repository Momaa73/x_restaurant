[2025-07-19T18:30:07.106+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: restaurant_pipeline.stream_to_bronze scheduled__2025-07-19T18:28:00+00:00 [queued]>
[2025-07-19T18:30:07.110+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: restaurant_pipeline.stream_to_bronze scheduled__2025-07-19T18:28:00+00:00 [queued]>
[2025-07-19T18:30:07.110+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2025-07-19T18:30:07.115+0000] {taskinstance.py:1382} INFO - Executing <Task(BashOperator): stream_to_bronze> on 2025-07-19 18:28:00+00:00
[2025-07-19T18:30:07.117+0000] {standard_task_runner.py:57} INFO - Started process 972 to run task
[2025-07-19T18:30:07.119+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'restaurant_pipeline', 'stream_to_bronze', 'scheduled__2025-07-19T18:28:00+00:00', '--job-id', '994', '--raw', '--subdir', 'DAGS_FOLDER/restaurant_pipeline.py', '--cfg-path', '/tmp/tmp2bpsvbxn']
[2025-07-19T18:30:07.120+0000] {standard_task_runner.py:85} INFO - Job 994: Subtask stream_to_bronze
[2025-07-19T18:30:07.141+0000] {task_command.py:416} INFO - Running <TaskInstance: restaurant_pipeline.stream_to_bronze scheduled__2025-07-19T18:28:00+00:00 [running]> on host e3f5d8fc4eef
[2025-07-19T18:30:07.177+0000] {taskinstance.py:1662} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='moran' AIRFLOW_CTX_DAG_ID='restaurant_pipeline' AIRFLOW_CTX_TASK_ID='stream_to_bronze' AIRFLOW_CTX_EXECUTION_DATE='2025-07-19T18:28:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-07-19T18:28:00+00:00'
[2025-07-19T18:30:07.177+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-07-19T18:30:07.178+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', "docker exec -e AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-07-19T18:28:00+00:00' spark-iceberg spark-submit /home/iceberg/spark/stream_to_bronze.py"]
[2025-07-19T18:30:07.181+0000] {subprocess.py:86} INFO - Output:
[2025-07-19T18:30:08.491+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 INFO SparkContext: Running Spark version 3.5.6
[2025-07-19T18:30:08.492+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 INFO SparkContext: OS info Linux, 6.10.14-linuxkit, aarch64
[2025-07-19T18:30:08.493+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 INFO SparkContext: Java version 17.0.15
[2025-07-19T18:30:08.506+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 INFO ResourceUtils: ==============================================================
[2025-07-19T18:30:08.506+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 INFO ResourceUtils: No custom resources configured for spark.driver.
[2025-07-19T18:30:08.507+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 INFO ResourceUtils: ==============================================================
[2025-07-19T18:30:08.507+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 INFO SparkContext: Submitted application: StreamToBronze
[2025-07-19T18:30:08.516+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-07-19T18:30:08.520+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 INFO ResourceProfile: Limiting resource is cpu
[2025-07-19T18:30:08.521+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2025-07-19T18:30:08.545+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 INFO SecurityManager: Changing view acls to: root,spark
[2025-07-19T18:30:08.546+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 INFO SecurityManager: Changing modify acls to: root,spark
[2025-07-19T18:30:08.546+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 INFO SecurityManager: Changing view acls groups to:
[2025-07-19T18:30:08.546+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 INFO SecurityManager: Changing modify acls groups to:
[2025-07-19T18:30:08.546+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
[2025-07-19T18:30:08.574+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2025-07-19T18:30:08.695+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 INFO Utils: Successfully started service 'sparkDriver' on port 38595.
[2025-07-19T18:30:08.708+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 INFO SparkEnv: Registering MapOutputTracker
[2025-07-19T18:30:08.730+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 INFO SparkEnv: Registering BlockManagerMaster
[2025-07-19T18:30:08.740+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-07-19T18:30:08.741+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2025-07-19T18:30:08.741+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2025-07-19T18:30:08.752+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c0d0d00d-adba-45c9-a3d2-19189419e03e
[2025-07-19T18:30:08.758+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2025-07-19T18:30:08.765+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 INFO SparkEnv: Registering OutputCommitCoordinator
[2025-07-19T18:30:08.818+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[2025-07-19T18:30:08.841+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[2025-07-19T18:30:08.844+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 INFO Utils: Successfully started service 'SparkUI' on port 4041.
[2025-07-19T18:30:08.885+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 INFO Executor: Starting executor ID driver on host 8b44f3d35cfa
[2025-07-19T18:30:08.886+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 INFO Executor: OS info Linux, 6.10.14-linuxkit, aarch64
[2025-07-19T18:30:08.886+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 INFO Executor: Java version 17.0.15
[2025-07-19T18:30:08.888+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
[2025-07-19T18:30:08.889+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@77b05ecd for default.
[2025-07-19T18:30:08.896+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40517.
[2025-07-19T18:30:08.897+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 INFO NettyBlockTransferService: Server created on 8b44f3d35cfa:40517
[2025-07-19T18:30:08.897+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-07-19T18:30:08.905+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 8b44f3d35cfa, 40517, None)
[2025-07-19T18:30:08.905+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 INFO BlockManagerMasterEndpoint: Registering block manager 8b44f3d35cfa:40517 with 434.4 MiB RAM, BlockManagerId(driver, 8b44f3d35cfa, 40517, None)
[2025-07-19T18:30:08.909+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 8b44f3d35cfa, 40517, None)
[2025-07-19T18:30:08.910+0000] {subprocess.py:93} INFO - 25/07/19 18:30:08 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 8b44f3d35cfa, 40517, None)
[2025-07-19T18:30:09.105+0000] {subprocess.py:93} INFO - 25/07/19 18:30:09 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-07-19T18:30:09.108+0000] {subprocess.py:93} INFO - 25/07/19 18:30:09 INFO SharedState: Warehouse path is 'file:/app/spark-warehouse'.
[2025-07-19T18:30:09.987+0000] {subprocess.py:93} INFO - 25/07/19 18:30:09 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
[2025-07-19T18:30:09.994+0000] {subprocess.py:93} INFO - 25/07/19 18:30:09 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
[2025-07-19T18:30:09.994+0000] {subprocess.py:93} INFO - 25/07/19 18:30:09 INFO MetricsSystemImpl: s3a-file-system metrics system started
[2025-07-19T18:30:10.514+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO BaseMetastoreCatalog: Table loaded by catalog: my_catalog.bronze.Reservations_raw
[2025-07-19T18:30:10.525+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
[2025-07-19T18:30:10.551+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO ResolveWriteToStream: Checkpoint root /tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00 resolved to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00.
[2025-07-19T18:30:10.551+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
[2025-07-19T18:30:10.581+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/metadata using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/.metadata.f76469ee-61b4-4488-8705-f999da7f1378.tmp
[2025-07-19T18:30:10.628+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/.metadata.f76469ee-61b4-4488-8705-f999da7f1378.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/metadata
[2025-07-19T18:30:10.645+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO MicroBatchExecution: Starting [id = 2a1d3ae4-6012-45da-96cc-6bbf43f14340, runId = b8eee2e2-0960-4f84-b369-9c0543e84c2b]. Use file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00 to store the query checkpoint.
[2025-07-19T18:30:10.651+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO MicroBatchExecution: Reading table [org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@eaa5919] from DataSourceV2 named 'kafka' [org.apache.spark.sql.kafka010.KafkaSourceProvider@479a4974]
[2025-07-19T18:30:10.670+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO OffsetSeqLog: BatchIds found from listing:
[2025-07-19T18:30:10.670+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO OffsetSeqLog: BatchIds found from listing:
[2025-07-19T18:30:10.671+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO MicroBatchExecution: Starting new streaming query.
[2025-07-19T18:30:10.672+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO MicroBatchExecution: Stream started from {}
[2025-07-19T18:30:10.745+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO BaseMetastoreCatalog: Table loaded by catalog: my_catalog.bronze.Checkins_raw
[2025-07-19T18:30:10.747+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO ResolveWriteToStream: Checkpoint root /tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00 resolved to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00.
[2025-07-19T18:30:10.747+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
[2025-07-19T18:30:10.755+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/metadata using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/.metadata.3cccc95d-cb47-46fe-8581-01743c318bf3.tmp
[2025-07-19T18:30:10.767+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/.metadata.3cccc95d-cb47-46fe-8581-01743c318bf3.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/metadata
[2025-07-19T18:30:10.772+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO MicroBatchExecution: Starting [id = 987ca175-704b-42a6-8146-d1b15494abbf, runId = e7c2576d-5139-486e-a3a4-0d60a8d676b4]. Use file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00 to store the query checkpoint.
[2025-07-19T18:30:10.774+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO MicroBatchExecution: Reading table [org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@7508827c] from DataSourceV2 named 'kafka' [org.apache.spark.sql.kafka010.KafkaSourceProvider@7bcf6375]
[2025-07-19T18:30:10.775+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO OffsetSeqLog: BatchIds found from listing:
[2025-07-19T18:30:10.775+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO OffsetSeqLog: BatchIds found from listing:
[2025-07-19T18:30:10.775+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO MicroBatchExecution: Starting new streaming query.
[2025-07-19T18:30:10.776+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO MicroBatchExecution: Stream started from {}
[2025-07-19T18:30:10.869+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO AdminClientConfig: AdminClientConfig values:
[2025-07-19T18:30:10.870+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-19T18:30:10.870+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-07-19T18:30:10.871+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-19T18:30:10.871+0000] {subprocess.py:93} INFO - 	client.id =
[2025-07-19T18:30:10.871+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 300000
[2025-07-19T18:30:10.872+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-19T18:30:10.872+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-19T18:30:10.872+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-19T18:30:10.873+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-19T18:30:10.873+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-19T18:30:10.873+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-19T18:30:10.873+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-19T18:30:10.874+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-19T18:30:10.874+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-19T18:30:10.874+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-19T18:30:10.874+0000] {subprocess.py:93} INFO - 	retries = 2147483647
[2025-07-19T18:30:10.876+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-19T18:30:10.876+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-19T18:30:10.876+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-19T18:30:10.876+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-19T18:30:10.877+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-19T18:30:10.877+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-19T18:30:10.877+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-19T18:30:10.877+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-19T18:30:10.877+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-19T18:30:10.877+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-19T18:30:10.877+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-19T18:30:10.877+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-19T18:30:10.877+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-19T18:30:10.877+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-19T18:30:10.878+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-19T18:30:10.878+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-19T18:30:10.878+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-19T18:30:10.878+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-19T18:30:10.878+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-19T18:30:10.878+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-19T18:30:10.878+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-19T18:30:10.878+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-19T18:30:10.879+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-19T18:30:10.879+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-19T18:30:10.879+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-19T18:30:10.879+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-19T18:30:10.879+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-19T18:30:10.880+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-19T18:30:10.880+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-19T18:30:10.880+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-19T18:30:10.880+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-19T18:30:10.880+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-19T18:30:10.881+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-19T18:30:10.881+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-19T18:30:10.881+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-19T18:30:10.881+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-19T18:30:10.881+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-19T18:30:10.881+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-19T18:30:10.881+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-19T18:30:10.882+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-19T18:30:10.882+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-19T18:30:10.882+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-19T18:30:10.882+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-19T18:30:10.882+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-19T18:30:10.883+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-19T18:30:10.883+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-19T18:30:10.883+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-19T18:30:10.883+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-19T18:30:10.883+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-19T18:30:10.884+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-19T18:30:10.884+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-19T18:30:10.884+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-19T18:30:10.884+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-19T18:30:10.884+0000] {subprocess.py:93} INFO - 
[2025-07-19T18:30:10.884+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO AdminClientConfig: AdminClientConfig values:
[2025-07-19T18:30:10.884+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-19T18:30:10.884+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-07-19T18:30:10.884+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-19T18:30:10.885+0000] {subprocess.py:93} INFO - 	client.id =
[2025-07-19T18:30:10.885+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 300000
[2025-07-19T18:30:10.885+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-19T18:30:10.885+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-19T18:30:10.885+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-19T18:30:10.886+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-19T18:30:10.886+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-19T18:30:10.886+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-19T18:30:10.886+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-19T18:30:10.886+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-19T18:30:10.886+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-19T18:30:10.886+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-19T18:30:10.887+0000] {subprocess.py:93} INFO - 	retries = 2147483647
[2025-07-19T18:30:10.887+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-19T18:30:10.887+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-19T18:30:10.887+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-19T18:30:10.887+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-19T18:30:10.887+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-19T18:30:10.887+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-19T18:30:10.887+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-19T18:30:10.888+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-19T18:30:10.888+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-19T18:30:10.888+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-19T18:30:10.888+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-19T18:30:10.888+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-19T18:30:10.888+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-19T18:30:10.888+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-19T18:30:10.888+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-19T18:30:10.888+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-19T18:30:10.889+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-19T18:30:10.889+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-19T18:30:10.889+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-19T18:30:10.889+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-19T18:30:10.889+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-19T18:30:10.889+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-19T18:30:10.889+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-19T18:30:10.889+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-19T18:30:10.890+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-19T18:30:10.890+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-19T18:30:10.890+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-19T18:30:10.890+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-19T18:30:10.890+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-19T18:30:10.891+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-19T18:30:10.891+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-19T18:30:10.891+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-19T18:30:10.891+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-19T18:30:10.891+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-19T18:30:10.891+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-19T18:30:10.891+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-19T18:30:10.892+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-19T18:30:10.892+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-19T18:30:10.892+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-19T18:30:10.892+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-19T18:30:10.892+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-19T18:30:10.892+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-19T18:30:10.892+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-19T18:30:10.892+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-19T18:30:10.893+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-19T18:30:10.893+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-19T18:30:10.893+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-19T18:30:10.893+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-19T18:30:10.893+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-19T18:30:10.893+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-19T18:30:10.893+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-19T18:30:10.894+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-19T18:30:10.894+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-19T18:30:10.894+0000] {subprocess.py:93} INFO - 
[2025-07-19T18:30:10.894+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO BaseMetastoreCatalog: Table loaded by catalog: my_catalog.bronze.Feedback_raw
[2025-07-19T18:30:10.894+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO ResolveWriteToStream: Checkpoint root /tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00 resolved to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00.
[2025-07-19T18:30:10.894+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
[2025-07-19T18:30:10.894+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/metadata using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/.metadata.6c49841a-a5c1-41c6-b1d9-5e5bcb78fff0.tmp
[2025-07-19T18:30:10.896+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/.metadata.6c49841a-a5c1-41c6-b1d9-5e5bcb78fff0.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/metadata
[2025-07-19T18:30:10.904+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO MicroBatchExecution: Starting [id = 8f08e6eb-a24d-42b2-b7ec-753236e406e1, runId = 648e1751-6c40-4a55-ad88-6fed441ec877]. Use file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00 to store the query checkpoint.
[2025-07-19T18:30:10.906+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO MicroBatchExecution: Reading table [org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@5e80f70d] from DataSourceV2 named 'kafka' [org.apache.spark.sql.kafka010.KafkaSourceProvider@50470375]
[2025-07-19T18:30:10.907+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO OffsetSeqLog: BatchIds found from listing:
[2025-07-19T18:30:10.907+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO OffsetSeqLog: BatchIds found from listing:
[2025-07-19T18:30:10.907+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO MicroBatchExecution: Starting new streaming query.
[2025-07-19T18:30:10.907+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO MicroBatchExecution: Stream started from {}
[2025-07-19T18:30:10.911+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO AdminClientConfig: AdminClientConfig values:
[2025-07-19T18:30:10.911+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-19T18:30:10.912+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-07-19T18:30:10.912+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-19T18:30:10.912+0000] {subprocess.py:93} INFO - 	client.id =
[2025-07-19T18:30:10.912+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 300000
[2025-07-19T18:30:10.913+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-19T18:30:10.913+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-19T18:30:10.913+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-19T18:30:10.913+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-19T18:30:10.914+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-19T18:30:10.914+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-19T18:30:10.914+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-19T18:30:10.915+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-19T18:30:10.915+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-19T18:30:10.915+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-19T18:30:10.915+0000] {subprocess.py:93} INFO - 	retries = 2147483647
[2025-07-19T18:30:10.915+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-19T18:30:10.915+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-19T18:30:10.915+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-19T18:30:10.916+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-19T18:30:10.916+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-19T18:30:10.916+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-19T18:30:10.916+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-19T18:30:10.916+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-19T18:30:10.916+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-19T18:30:10.917+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-19T18:30:10.917+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-19T18:30:10.917+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-19T18:30:10.917+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-19T18:30:10.917+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-19T18:30:10.917+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-19T18:30:10.917+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-19T18:30:10.917+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-19T18:30:10.917+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-19T18:30:10.918+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-19T18:30:10.918+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-19T18:30:10.918+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-19T18:30:10.918+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-19T18:30:10.918+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-19T18:30:10.918+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-19T18:30:10.918+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-19T18:30:10.918+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-19T18:30:10.918+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-19T18:30:10.918+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-19T18:30:10.919+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-19T18:30:10.919+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-19T18:30:10.919+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-19T18:30:10.919+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-19T18:30:10.919+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-19T18:30:10.919+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-19T18:30:10.919+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-19T18:30:10.919+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-19T18:30:10.919+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-19T18:30:10.920+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-19T18:30:10.920+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-19T18:30:10.920+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-19T18:30:10.920+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-19T18:30:10.920+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-19T18:30:10.920+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-19T18:30:10.920+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-19T18:30:10.920+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-19T18:30:10.920+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-19T18:30:10.921+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-19T18:30:10.921+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-19T18:30:10.921+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-19T18:30:10.922+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-19T18:30:10.922+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-19T18:30:10.922+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-19T18:30:10.922+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-19T18:30:10.922+0000] {subprocess.py:93} INFO - 
[2025-07-19T18:30:10.922+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
[2025-07-19T18:30:10.922+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
[2025-07-19T18:30:10.922+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
[2025-07-19T18:30:10.923+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-19T18:30:10.923+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-19T18:30:10.923+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO AppInfoParser: Kafka startTimeMs: 1752949810911
[2025-07-19T18:30:10.923+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-19T18:30:10.923+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-19T18:30:10.923+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO AppInfoParser: Kafka startTimeMs: 1752949810911
[2025-07-19T18:30:10.923+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-19T18:30:10.923+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-19T18:30:10.923+0000] {subprocess.py:93} INFO - 25/07/19 18:30:10 INFO AppInfoParser: Kafka startTimeMs: 1752949810912
[2025-07-19T18:30:11.063+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/sources/0/0 using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/sources/0/.0.c5e40979-de73-4f17-86ba-a9e9d91e8464.tmp
[2025-07-19T18:30:11.063+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/sources/0/0 using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/sources/0/.0.12cb470c-8ce2-482a-a5c8-f642cbcddb42.tmp
[2025-07-19T18:30:11.064+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/sources/0/0 using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/sources/0/.0.128a9995-6e0c-41f3-853d-e3cbf879d8fa.tmp
[2025-07-19T18:30:11.074+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/sources/0/.0.12cb470c-8ce2-482a-a5c8-f642cbcddb42.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/sources/0/0
[2025-07-19T18:30:11.074+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/sources/0/.0.c5e40979-de73-4f17-86ba-a9e9d91e8464.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/sources/0/0
[2025-07-19T18:30:11.074+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/sources/0/.0.128a9995-6e0c-41f3-853d-e3cbf879d8fa.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/sources/0/0
[2025-07-19T18:30:11.074+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO KafkaMicroBatchStream: Initial offsets: {"feedback":{"0":0}}
[2025-07-19T18:30:11.075+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO KafkaMicroBatchStream: Initial offsets: {"reservations":{"0":0}}
[2025-07-19T18:30:11.075+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO KafkaMicroBatchStream: Initial offsets: {"checkins":{"0":0}}
[2025-07-19T18:30:11.085+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/offsets/0 using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/offsets/.0.a6056bd9-ef11-408c-9d08-f8dcbb9c47ce.tmp
[2025-07-19T18:30:11.085+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/offsets/0 using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/offsets/.0.b780790c-4146-4c3b-a1bf-9b80b5ffdb18.tmp
[2025-07-19T18:30:11.086+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/offsets/0 using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/offsets/.0.019cdd11-19e3-4b75-bf3b-660c1455aa38.tmp
[2025-07-19T18:30:11.103+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/offsets/.0.a6056bd9-ef11-408c-9d08-f8dcbb9c47ce.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/offsets/0
[2025-07-19T18:30:11.103+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO MicroBatchExecution: Committed offsets for batch 0. Metadata OffsetSeqMetadata(0,1752949811078,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.optimizer.pruneFiltersCanPruneStreamingSubplan -> false, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2025-07-19T18:30:11.103+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/offsets/.0.019cdd11-19e3-4b75-bf3b-660c1455aa38.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/offsets/0
[2025-07-19T18:30:11.103+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO MicroBatchExecution: Committed offsets for batch 0. Metadata OffsetSeqMetadata(0,1752949811079,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.optimizer.pruneFiltersCanPruneStreamingSubplan -> false, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2025-07-19T18:30:11.106+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/offsets/.0.b780790c-4146-4c3b-a1bf-9b80b5ffdb18.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/offsets/0
[2025-07-19T18:30:11.106+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO MicroBatchExecution: Committed offsets for batch 0. Metadata OffsetSeqMetadata(0,1752949811079,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.optimizer.pruneFiltersCanPruneStreamingSubplan -> false, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2025-07-19T18:30:11.252+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Feedback_raw
[2025-07-19T18:30:11.252+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Checkins_raw
[2025-07-19T18:30:11.252+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Feedback_raw
[2025-07-19T18:30:11.253+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Reservations_raw
[2025-07-19T18:30:11.253+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Checkins_raw
[2025-07-19T18:30:11.253+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Reservations_raw
[2025-07-19T18:30:11.255+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Feedback_raw
[2025-07-19T18:30:11.255+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Reservations_raw
[2025-07-19T18:30:11.255+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Checkins_raw
[2025-07-19T18:30:11.429+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO CodeGenerator: Code generated in 74.373667 ms
[2025-07-19T18:30:11.441+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T18:30:11.441+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T18:30:11.442+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T18:30:11.471+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T18:30:11.472+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T18:30:11.472+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T18:30:11.506+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Reservations_raw
[2025-07-19T18:30:11.507+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Reservations_raw
[2025-07-19T18:30:11.508+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Reservations_raw
[2025-07-19T18:30:11.509+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Checkins_raw
[2025-07-19T18:30:11.509+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Checkins_raw
[2025-07-19T18:30:11.510+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Checkins_raw
[2025-07-19T18:30:11.510+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T18:30:11.511+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T18:30:11.513+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T18:30:11.517+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T18:30:11.518+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Feedback_raw
[2025-07-19T18:30:11.519+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Feedback_raw
[2025-07-19T18:30:11.520+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Feedback_raw
[2025-07-19T18:30:11.522+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T18:30:11.525+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T18:30:11.550+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Feedback_raw
[2025-07-19T18:30:11.550+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Feedback_raw
[2025-07-19T18:30:11.550+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Feedback_raw
[2025-07-19T18:30:11.551+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Reservations_raw
[2025-07-19T18:30:11.551+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Reservations_raw
[2025-07-19T18:30:11.552+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Reservations_raw
[2025-07-19T18:30:11.552+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Checkins_raw
[2025-07-19T18:30:11.553+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Checkins_raw
[2025-07-19T18:30:11.553+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Checkins_raw
[2025-07-19T18:30:11.555+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T18:30:11.556+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T18:30:11.557+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T18:30:11.557+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T18:30:11.558+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T18:30:11.562+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T18:30:11.663+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO CodeGenerator: Code generated in 45.639167 ms
[2025-07-19T18:30:11.671+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO CodeGenerator: Code generated in 54.296417 ms
[2025-07-19T18:30:11.718+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO CodeGenerator: Code generated in 74.023209 ms
[2025-07-19T18:30:11.897+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 209.0 KiB, free 433.8 MiB)
[2025-07-19T18:30:11.897+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 209.0 KiB, free 433.8 MiB)
[2025-07-19T18:30:11.897+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 209.0 KiB, free 433.8 MiB)
[2025-07-19T18:30:11.939+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.7 MiB)
[2025-07-19T18:30:11.940+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.7 MiB)
[2025-07-19T18:30:11.940+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.7 MiB)
[2025-07-19T18:30:11.940+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 8b44f3d35cfa:40517 (size: 35.4 KiB, free: 434.4 MiB)
[2025-07-19T18:30:11.943+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 8b44f3d35cfa:40517 (size: 35.4 KiB, free: 434.3 MiB)
[2025-07-19T18:30:11.944+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 8b44f3d35cfa:40517 (size: 35.4 KiB, free: 434.3 MiB)
[2025-07-19T18:30:11.944+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO SparkContext: Created broadcast 2 from start at <unknown>:0
[2025-07-19T18:30:11.944+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO SparkContext: Created broadcast 0 from start at <unknown>:0
[2025-07-19T18:30:11.945+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO SparkContext: Created broadcast 1 from start at <unknown>:0
[2025-07-19T18:30:11.963+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 32.0 KiB, free 433.6 MiB)
[2025-07-19T18:30:11.964+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 32.0 KiB, free 433.6 MiB)
[2025-07-19T18:30:11.965+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 32.0 KiB, free 433.6 MiB)
[2025-07-19T18:30:11.976+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 433.6 MiB)
[2025-07-19T18:30:11.977+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 8b44f3d35cfa:40517 (size: 29.6 KiB, free: 434.3 MiB)
[2025-07-19T18:30:11.977+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 433.5 MiB)
[2025-07-19T18:30:11.981+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 8b44f3d35cfa:40517 (size: 29.5 KiB, free: 434.2 MiB)
[2025-07-19T18:30:11.982+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO SparkContext: Created broadcast 3 from start at <unknown>:0
[2025-07-19T18:30:11.983+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 433.5 MiB)
[2025-07-19T18:30:11.983+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO SparkContext: Created broadcast 5 from start at <unknown>:0
[2025-07-19T18:30:11.983+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 8b44f3d35cfa:40517 (size: 29.6 KiB, free: 434.2 MiB)
[2025-07-19T18:30:11.983+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO SparkContext: Created broadcast 4 from start at <unknown>:0
[2025-07-19T18:30:11.984+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO WriteToDataSourceV2Exec: Start processing data source write support: MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Reservations_raw, format=PARQUET)]. The input RDD has 200 partitions.
[2025-07-19T18:30:11.984+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO WriteToDataSourceV2Exec: Start processing data source write support: MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Feedback_raw, format=PARQUET)]. The input RDD has 200 partitions.
[2025-07-19T18:30:11.984+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO WriteToDataSourceV2Exec: Start processing data source write support: MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Checkins_raw, format=PARQUET)]. The input RDD has 200 partitions.
[2025-07-19T18:30:11.994+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO SparkContext: Starting job: start at <unknown>:0
[2025-07-19T18:30:11.995+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO SparkContext: Starting job: start at <unknown>:0
[2025-07-19T18:30:11.995+0000] {subprocess.py:93} INFO - 25/07/19 18:30:11 INFO SparkContext: Starting job: start at <unknown>:0
[2025-07-19T18:30:12.009+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO DAGScheduler: Registering RDD 16 (start at <unknown>:0) as input to shuffle 2
[2025-07-19T18:30:12.015+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO DAGScheduler: Got job 2 (start at <unknown>:0) with 200 output partitions
[2025-07-19T18:30:12.016+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO DAGScheduler: Final stage: ResultStage 1 (start at <unknown>:0)
[2025-07-19T18:30:12.017+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
[2025-07-19T18:30:12.017+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
[2025-07-19T18:30:12.017+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[16] at start at <unknown>:0), which has no missing parents
[2025-07-19T18:30:12.030+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 33.8 KiB, free 433.5 MiB)
[2025-07-19T18:30:12.036+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.7 KiB, free 433.5 MiB)
[2025-07-19T18:30:12.037+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 8b44f3d35cfa:40517 (size: 14.7 KiB, free: 434.2 MiB)
[2025-07-19T18:30:12.044+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1611
[2025-07-19T18:30:12.054+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[16] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-07-19T18:30:12.058+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2025-07-19T18:30:12.069+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO DAGScheduler: Registering RDD 17 (start at <unknown>:0) as input to shuffle 1
[2025-07-19T18:30:12.069+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO DAGScheduler: Got job 0 (start at <unknown>:0) with 200 output partitions
[2025-07-19T18:30:12.069+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO DAGScheduler: Final stage: ResultStage 3 (start at <unknown>:0)
[2025-07-19T18:30:12.069+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
[2025-07-19T18:30:12.069+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
[2025-07-19T18:30:12.070+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[17] at start at <unknown>:0), which has no missing parents
[2025-07-19T18:30:12.072+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 35.8 KiB, free 433.4 MiB)
[2025-07-19T18:30:12.084+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 15.8 KiB, free 433.4 MiB)
[2025-07-19T18:30:12.084+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 8b44f3d35cfa:40517 (size: 15.8 KiB, free: 434.2 MiB)
[2025-07-19T18:30:12.084+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1611
[2025-07-19T18:30:12.085+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[17] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-07-19T18:30:12.085+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
[2025-07-19T18:30:12.086+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 9929 bytes)
[2025-07-19T18:30:12.096+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO DAGScheduler: Registering RDD 15 (start at <unknown>:0) as input to shuffle 0
[2025-07-19T18:30:12.096+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO DAGScheduler: Got job 1 (start at <unknown>:0) with 200 output partitions
[2025-07-19T18:30:12.096+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO DAGScheduler: Final stage: ResultStage 5 (start at <unknown>:0)
[2025-07-19T18:30:12.096+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
[2025-07-19T18:30:12.105+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
[2025-07-19T18:30:12.106+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[15] at start at <unknown>:0), which has no missing parents
[2025-07-19T18:30:12.106+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 32.3 KiB, free 433.4 MiB)
[2025-07-19T18:30:12.107+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 1) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 9925 bytes)
[2025-07-19T18:30:12.107+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.0 KiB, free 433.4 MiB)
[2025-07-19T18:30:12.108+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 8b44f3d35cfa:40517 (size: 14.0 KiB, free: 434.2 MiB)
[2025-07-19T18:30:12.108+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1611
[2025-07-19T18:30:12.109+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[15] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-07-19T18:30:12.109+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
[2025-07-19T18:30:12.109+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
[2025-07-19T18:30:12.110+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 2) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 9924 bytes)
[2025-07-19T18:30:12.110+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO Executor: Running task 0.0 in stage 2.0 (TID 1)
[2025-07-19T18:30:12.111+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO Executor: Running task 0.0 in stage 4.0 (TID 2)
[2025-07-19T18:30:12.208+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO CodeGenerator: Code generated in 14.89575 ms
[2025-07-19T18:30:12.214+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO CodeGenerator: Code generated in 17.664084 ms
[2025-07-19T18:30:12.218+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO CodeGenerator: Code generated in 24.179667 ms
[2025-07-19T18:30:12.232+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO CodeGenerator: Code generated in 12.904666 ms
[2025-07-19T18:30:12.233+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO CodeGenerator: Code generated in 19.49575 ms
[2025-07-19T18:30:12.233+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO CodeGenerator: Code generated in 21.229375 ms
[2025-07-19T18:30:12.241+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO CodeGenerator: Code generated in 5.459875 ms
[2025-07-19T18:30:12.246+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO CodeGenerator: Code generated in 10.64875 ms
[2025-07-19T18:30:12.256+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO CodeGenerator: Code generated in 8.4185 ms
[2025-07-19T18:30:12.257+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO CodeGenerator: Code generated in 7.965917 ms
[2025-07-19T18:30:12.271+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=reservations-0 fromOffset=0 untilOffset=69, for query queryId=2a1d3ae4-6012-45da-96cc-6bbf43f14340 batchId=0 taskId=0 partitionId=0
[2025-07-19T18:30:12.271+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=feedback-0 fromOffset=0 untilOffset=69, for query queryId=8f08e6eb-a24d-42b2-b7ec-753236e406e1 batchId=0 taskId=2 partitionId=0
[2025-07-19T18:30:12.272+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=checkins-0 fromOffset=0 untilOffset=69, for query queryId=987ca175-704b-42a6-8146-d1b15494abbf batchId=0 taskId=1 partitionId=0
[2025-07-19T18:30:12.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO CodeGenerator: Code generated in 11.799834 ms
[2025-07-19T18:30:12.335+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO CodeGenerator: Code generated in 26.191166 ms
[2025-07-19T18:30:12.351+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO ConsumerConfig: ConsumerConfig values:
[2025-07-19T18:30:12.351+0000] {subprocess.py:93} INFO - 	allow.auto.create.topics = true
[2025-07-19T18:30:12.351+0000] {subprocess.py:93} INFO - 	auto.commit.interval.ms = 5000
[2025-07-19T18:30:12.351+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-19T18:30:12.352+0000] {subprocess.py:93} INFO - 	auto.offset.reset = none
[2025-07-19T18:30:12.352+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-07-19T18:30:12.352+0000] {subprocess.py:93} INFO - 	check.crcs = true
[2025-07-19T18:30:12.352+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-19T18:30:12.352+0000] {subprocess.py:93} INFO - 	client.id = consumer-spark-kafka-source-64ca2e3e-791f-4994-9d80-fe05a2f1c757--1203258309-executor-2
[2025-07-19T18:30:12.352+0000] {subprocess.py:93} INFO - 	client.rack =
[2025-07-19T18:30:12.352+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 540000
[2025-07-19T18:30:12.352+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-19T18:30:12.353+0000] {subprocess.py:93} INFO - 	enable.auto.commit = false
[2025-07-19T18:30:12.353+0000] {subprocess.py:93} INFO - 	exclude.internal.topics = true
[2025-07-19T18:30:12.353+0000] {subprocess.py:93} INFO - 	fetch.max.bytes = 52428800
[2025-07-19T18:30:12.353+0000] {subprocess.py:93} INFO - 	fetch.max.wait.ms = 500
[2025-07-19T18:30:12.353+0000] {subprocess.py:93} INFO - 	fetch.min.bytes = 1
[2025-07-19T18:30:12.353+0000] {subprocess.py:93} INFO - 	group.id = spark-kafka-source-64ca2e3e-791f-4994-9d80-fe05a2f1c757--1203258309-executor
[2025-07-19T18:30:12.353+0000] {subprocess.py:93} INFO - 	group.instance.id = null
[2025-07-19T18:30:12.353+0000] {subprocess.py:93} INFO - 	heartbeat.interval.ms = 3000
[2025-07-19T18:30:12.353+0000] {subprocess.py:93} INFO - 	interceptor.classes = []
[2025-07-19T18:30:12.354+0000] {subprocess.py:93} INFO - 	internal.leave.group.on.close = true
[2025-07-19T18:30:12.354+0000] {subprocess.py:93} INFO - 	internal.throw.on.fetch.stable.offset.unsupported = false
[2025-07-19T18:30:12.354+0000] {subprocess.py:93} INFO - 	isolation.level = read_uncommitted
[2025-07-19T18:30:12.354+0000] {subprocess.py:93} INFO - 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-07-19T18:30:12.354+0000] {subprocess.py:93} INFO - 	max.partition.fetch.bytes = 1048576
[2025-07-19T18:30:12.354+0000] {subprocess.py:93} INFO - 	max.poll.interval.ms = 300000
[2025-07-19T18:30:12.355+0000] {subprocess.py:93} INFO - 	max.poll.records = 500
[2025-07-19T18:30:12.355+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-19T18:30:12.355+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-19T18:30:12.355+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-19T18:30:12.355+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-19T18:30:12.355+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-19T18:30:12.355+0000] {subprocess.py:93} INFO - 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
[2025-07-19T18:30:12.355+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-19T18:30:12.356+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-19T18:30:12.356+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-19T18:30:12.356+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-19T18:30:12.356+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-19T18:30:12.356+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-19T18:30:12.356+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-19T18:30:12.356+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-19T18:30:12.357+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-19T18:30:12.357+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-19T18:30:12.357+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-19T18:30:12.357+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-19T18:30:12.357+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-19T18:30:12.357+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-19T18:30:12.357+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-19T18:30:12.358+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-19T18:30:12.358+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-19T18:30:12.358+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-19T18:30:12.359+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-19T18:30:12.359+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-19T18:30:12.359+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-19T18:30:12.360+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-19T18:30:12.360+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-19T18:30:12.360+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-19T18:30:12.360+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-19T18:30:12.360+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-19T18:30:12.361+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-19T18:30:12.361+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-19T18:30:12.361+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-19T18:30:12.362+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-19T18:30:12.362+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-19T18:30:12.362+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-19T18:30:12.363+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-19T18:30:12.364+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-19T18:30:12.365+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-19T18:30:12.365+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-19T18:30:12.366+0000] {subprocess.py:93} INFO - 	session.timeout.ms = 45000
[2025-07-19T18:30:12.366+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-19T18:30:12.366+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-19T18:30:12.366+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-19T18:30:12.367+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-19T18:30:12.367+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-19T18:30:12.367+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-19T18:30:12.367+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-19T18:30:12.367+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-19T18:30:12.368+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-19T18:30:12.368+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-19T18:30:12.368+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-19T18:30:12.368+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-19T18:30:12.368+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-19T18:30:12.368+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-19T18:30:12.368+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-19T18:30:12.368+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-19T18:30:12.369+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-19T18:30:12.369+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-19T18:30:12.369+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-19T18:30:12.369+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-19T18:30:12.369+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-19T18:30:12.369+0000] {subprocess.py:93} INFO - 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-07-19T18:30:12.369+0000] {subprocess.py:93} INFO - 
[2025-07-19T18:30:12.369+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO ConsumerConfig: ConsumerConfig values:
[2025-07-19T18:30:12.369+0000] {subprocess.py:93} INFO - 	allow.auto.create.topics = true
[2025-07-19T18:30:12.369+0000] {subprocess.py:93} INFO - 	auto.commit.interval.ms = 5000
[2025-07-19T18:30:12.370+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-19T18:30:12.370+0000] {subprocess.py:93} INFO - 	auto.offset.reset = none
[2025-07-19T18:30:12.370+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-07-19T18:30:12.370+0000] {subprocess.py:93} INFO - 	check.crcs = true
[2025-07-19T18:30:12.370+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-19T18:30:12.370+0000] {subprocess.py:93} INFO - 	client.id = consumer-spark-kafka-source-6cc9cc98-97fd-4011-b03e-aff31993725d-1566240956-executor-3
[2025-07-19T18:30:12.370+0000] {subprocess.py:93} INFO - 	client.rack =
[2025-07-19T18:30:12.370+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 540000
[2025-07-19T18:30:12.370+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-19T18:30:12.370+0000] {subprocess.py:93} INFO - 	enable.auto.commit = false
[2025-07-19T18:30:12.371+0000] {subprocess.py:93} INFO - 	exclude.internal.topics = true
[2025-07-19T18:30:12.371+0000] {subprocess.py:93} INFO - 	fetch.max.bytes = 52428800
[2025-07-19T18:30:12.371+0000] {subprocess.py:93} INFO - 	fetch.max.wait.ms = 500
[2025-07-19T18:30:12.371+0000] {subprocess.py:93} INFO - 	fetch.min.bytes = 1
[2025-07-19T18:30:12.371+0000] {subprocess.py:93} INFO - 	group.id = spark-kafka-source-6cc9cc98-97fd-4011-b03e-aff31993725d-1566240956-executor
[2025-07-19T18:30:12.371+0000] {subprocess.py:93} INFO - 	group.instance.id = null
[2025-07-19T18:30:12.371+0000] {subprocess.py:93} INFO - 	heartbeat.interval.ms = 3000
[2025-07-19T18:30:12.371+0000] {subprocess.py:93} INFO - 	interceptor.classes = []
[2025-07-19T18:30:12.372+0000] {subprocess.py:93} INFO - 	internal.leave.group.on.close = true
[2025-07-19T18:30:12.372+0000] {subprocess.py:93} INFO - 	internal.throw.on.fetch.stable.offset.unsupported = false
[2025-07-19T18:30:12.372+0000] {subprocess.py:93} INFO - 	isolation.level = read_uncommitted
[2025-07-19T18:30:12.372+0000] {subprocess.py:93} INFO - 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-07-19T18:30:12.372+0000] {subprocess.py:93} INFO - 	max.partition.fetch.bytes = 1048576
[2025-07-19T18:30:12.372+0000] {subprocess.py:93} INFO - 	max.poll.interval.ms = 300000
[2025-07-19T18:30:12.372+0000] {subprocess.py:93} INFO - 	max.poll.records = 500
[2025-07-19T18:30:12.372+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-19T18:30:12.372+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-19T18:30:12.372+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-19T18:30:12.372+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-19T18:30:12.372+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-19T18:30:12.373+0000] {subprocess.py:93} INFO - 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
[2025-07-19T18:30:12.373+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-19T18:30:12.373+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-19T18:30:12.373+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-19T18:30:12.373+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-19T18:30:12.373+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-19T18:30:12.374+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-19T18:30:12.374+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-19T18:30:12.374+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-19T18:30:12.374+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-19T18:30:12.374+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-19T18:30:12.374+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-19T18:30:12.374+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-19T18:30:12.375+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-19T18:30:12.375+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-19T18:30:12.375+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-19T18:30:12.375+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-19T18:30:12.376+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-19T18:30:12.376+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-19T18:30:12.376+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-19T18:30:12.376+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-19T18:30:12.376+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-19T18:30:12.376+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-19T18:30:12.376+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-19T18:30:12.377+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-19T18:30:12.377+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-19T18:30:12.377+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-19T18:30:12.378+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-19T18:30:12.378+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-19T18:30:12.378+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-19T18:30:12.379+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-19T18:30:12.379+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-19T18:30:12.380+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-19T18:30:12.380+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-19T18:30:12.381+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-19T18:30:12.381+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-19T18:30:12.381+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-19T18:30:12.382+0000] {subprocess.py:93} INFO - 	session.timeout.ms = 45000
[2025-07-19T18:30:12.382+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-19T18:30:12.382+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-19T18:30:12.382+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-19T18:30:12.382+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-19T18:30:12.382+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-19T18:30:12.382+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-19T18:30:12.382+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-19T18:30:12.382+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-19T18:30:12.383+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-19T18:30:12.383+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-19T18:30:12.383+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-19T18:30:12.383+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-19T18:30:12.383+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-19T18:30:12.383+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-19T18:30:12.383+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-19T18:30:12.383+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-19T18:30:12.383+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-19T18:30:12.383+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-19T18:30:12.383+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-19T18:30:12.384+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-19T18:30:12.384+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-19T18:30:12.384+0000] {subprocess.py:93} INFO - 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-07-19T18:30:12.384+0000] {subprocess.py:93} INFO - 
[2025-07-19T18:30:12.384+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO ConsumerConfig: ConsumerConfig values:
[2025-07-19T18:30:12.384+0000] {subprocess.py:93} INFO - 	allow.auto.create.topics = true
[2025-07-19T18:30:12.384+0000] {subprocess.py:93} INFO - 	auto.commit.interval.ms = 5000
[2025-07-19T18:30:12.384+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-19T18:30:12.384+0000] {subprocess.py:93} INFO - 	auto.offset.reset = none
[2025-07-19T18:30:12.384+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-07-19T18:30:12.385+0000] {subprocess.py:93} INFO - 	check.crcs = true
[2025-07-19T18:30:12.385+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-19T18:30:12.385+0000] {subprocess.py:93} INFO - 	client.id = consumer-spark-kafka-source-f1e25fe4-84ea-495f-a817-789d74310202--1750756262-executor-1
[2025-07-19T18:30:12.385+0000] {subprocess.py:93} INFO - 	client.rack =
[2025-07-19T18:30:12.385+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 540000
[2025-07-19T18:30:12.385+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-19T18:30:12.385+0000] {subprocess.py:93} INFO - 	enable.auto.commit = false
[2025-07-19T18:30:12.385+0000] {subprocess.py:93} INFO - 	exclude.internal.topics = true
[2025-07-19T18:30:12.385+0000] {subprocess.py:93} INFO - 	fetch.max.bytes = 52428800
[2025-07-19T18:30:12.385+0000] {subprocess.py:93} INFO - 	fetch.max.wait.ms = 500
[2025-07-19T18:30:12.385+0000] {subprocess.py:93} INFO - 	fetch.min.bytes = 1
[2025-07-19T18:30:12.385+0000] {subprocess.py:93} INFO - 	group.id = spark-kafka-source-f1e25fe4-84ea-495f-a817-789d74310202--1750756262-executor
[2025-07-19T18:30:12.386+0000] {subprocess.py:93} INFO - 	group.instance.id = null
[2025-07-19T18:30:12.386+0000] {subprocess.py:93} INFO - 	heartbeat.interval.ms = 3000
[2025-07-19T18:30:12.386+0000] {subprocess.py:93} INFO - 	interceptor.classes = []
[2025-07-19T18:30:12.386+0000] {subprocess.py:93} INFO - 	internal.leave.group.on.close = true
[2025-07-19T18:30:12.386+0000] {subprocess.py:93} INFO - 	internal.throw.on.fetch.stable.offset.unsupported = false
[2025-07-19T18:30:12.386+0000] {subprocess.py:93} INFO - 	isolation.level = read_uncommitted
[2025-07-19T18:30:12.386+0000] {subprocess.py:93} INFO - 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-07-19T18:30:12.386+0000] {subprocess.py:93} INFO - 	max.partition.fetch.bytes = 1048576
[2025-07-19T18:30:12.388+0000] {subprocess.py:93} INFO - 	max.poll.interval.ms = 300000
[2025-07-19T18:30:12.389+0000] {subprocess.py:93} INFO - 	max.poll.records = 500
[2025-07-19T18:30:12.389+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-19T18:30:12.390+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-19T18:30:12.390+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-19T18:30:12.390+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-19T18:30:12.390+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-19T18:30:12.390+0000] {subprocess.py:93} INFO - 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
[2025-07-19T18:30:12.390+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-19T18:30:12.390+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-19T18:30:12.390+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-19T18:30:12.390+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-19T18:30:12.391+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-19T18:30:12.391+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-19T18:30:12.391+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-19T18:30:12.391+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-19T18:30:12.391+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-19T18:30:12.391+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-19T18:30:12.391+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-19T18:30:12.391+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-19T18:30:12.391+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-19T18:30:12.391+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-19T18:30:12.391+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-19T18:30:12.392+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-19T18:30:12.392+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-19T18:30:12.392+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-19T18:30:12.392+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-19T18:30:12.392+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-19T18:30:12.392+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-19T18:30:12.392+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-19T18:30:12.392+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-19T18:30:12.392+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-19T18:30:12.392+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-19T18:30:12.392+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-19T18:30:12.393+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-19T18:30:12.393+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-19T18:30:12.393+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-19T18:30:12.393+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-19T18:30:12.393+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-19T18:30:12.393+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-19T18:30:12.393+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-19T18:30:12.393+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-19T18:30:12.393+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-19T18:30:12.393+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-19T18:30:12.393+0000] {subprocess.py:93} INFO - 	session.timeout.ms = 45000
[2025-07-19T18:30:12.393+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-19T18:30:12.393+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-19T18:30:12.393+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-19T18:30:12.394+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-19T18:30:12.394+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-19T18:30:12.394+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-19T18:30:12.394+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-19T18:30:12.394+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-19T18:30:12.394+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-19T18:30:12.395+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-19T18:30:12.395+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-19T18:30:12.395+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-19T18:30:12.395+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-19T18:30:12.395+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-19T18:30:12.396+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-19T18:30:12.396+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-19T18:30:12.396+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-19T18:30:12.397+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-19T18:30:12.397+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-19T18:30:12.397+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-19T18:30:12.397+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-19T18:30:12.397+0000] {subprocess.py:93} INFO - 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-07-19T18:30:12.397+0000] {subprocess.py:93} INFO - 
[2025-07-19T18:30:12.398+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-19T18:30:12.398+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-19T18:30:12.398+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO AppInfoParser: Kafka startTimeMs: 1752949812387
[2025-07-19T18:30:12.398+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-19T18:30:12.399+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-19T18:30:12.399+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO AppInfoParser: Kafka startTimeMs: 1752949812388
[2025-07-19T18:30:12.399+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-19T18:30:12.399+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-19T18:30:12.399+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO AppInfoParser: Kafka startTimeMs: 1752949812387
[2025-07-19T18:30:12.399+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-f1e25fe4-84ea-495f-a817-789d74310202--1750756262-executor-1, groupId=spark-kafka-source-f1e25fe4-84ea-495f-a817-789d74310202--1750756262-executor] Assigned to partition(s): reservations-0
[2025-07-19T18:30:12.399+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-64ca2e3e-791f-4994-9d80-fe05a2f1c757--1203258309-executor-2, groupId=spark-kafka-source-64ca2e3e-791f-4994-9d80-fe05a2f1c757--1203258309-executor] Assigned to partition(s): checkins-0
[2025-07-19T18:30:12.399+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-6cc9cc98-97fd-4011-b03e-aff31993725d-1566240956-executor-3, groupId=spark-kafka-source-6cc9cc98-97fd-4011-b03e-aff31993725d-1566240956-executor] Assigned to partition(s): feedback-0
[2025-07-19T18:30:12.399+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-6cc9cc98-97fd-4011-b03e-aff31993725d-1566240956-executor-3, groupId=spark-kafka-source-6cc9cc98-97fd-4011-b03e-aff31993725d-1566240956-executor] Seeking to offset 0 for partition feedback-0
[2025-07-19T18:30:12.399+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-64ca2e3e-791f-4994-9d80-fe05a2f1c757--1203258309-executor-2, groupId=spark-kafka-source-64ca2e3e-791f-4994-9d80-fe05a2f1c757--1203258309-executor] Seeking to offset 0 for partition checkins-0
[2025-07-19T18:30:12.399+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-f1e25fe4-84ea-495f-a817-789d74310202--1750756262-executor-1, groupId=spark-kafka-source-f1e25fe4-84ea-495f-a817-789d74310202--1750756262-executor] Seeking to offset 0 for partition reservations-0
[2025-07-19T18:30:12.405+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO Metadata: [Consumer clientId=consumer-spark-kafka-source-f1e25fe4-84ea-495f-a817-789d74310202--1750756262-executor-1, groupId=spark-kafka-source-f1e25fe4-84ea-495f-a817-789d74310202--1750756262-executor] Cluster ID: iIlr_WxeQ6OmNSr-bYGtHA
[2025-07-19T18:30:12.405+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO Metadata: [Consumer clientId=consumer-spark-kafka-source-6cc9cc98-97fd-4011-b03e-aff31993725d-1566240956-executor-3, groupId=spark-kafka-source-6cc9cc98-97fd-4011-b03e-aff31993725d-1566240956-executor] Cluster ID: iIlr_WxeQ6OmNSr-bYGtHA
[2025-07-19T18:30:12.406+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO Metadata: [Consumer clientId=consumer-spark-kafka-source-64ca2e3e-791f-4994-9d80-fe05a2f1c757--1203258309-executor-2, groupId=spark-kafka-source-64ca2e3e-791f-4994-9d80-fe05a2f1c757--1203258309-executor] Cluster ID: iIlr_WxeQ6OmNSr-bYGtHA
[2025-07-19T18:30:12.434+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-f1e25fe4-84ea-495f-a817-789d74310202--1750756262-executor-1, groupId=spark-kafka-source-f1e25fe4-84ea-495f-a817-789d74310202--1750756262-executor] Seeking to earliest offset of partition reservations-0
[2025-07-19T18:30:12.434+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-64ca2e3e-791f-4994-9d80-fe05a2f1c757--1203258309-executor-2, groupId=spark-kafka-source-64ca2e3e-791f-4994-9d80-fe05a2f1c757--1203258309-executor] Seeking to earliest offset of partition checkins-0
[2025-07-19T18:30:12.434+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-6cc9cc98-97fd-4011-b03e-aff31993725d-1566240956-executor-3, groupId=spark-kafka-source-6cc9cc98-97fd-4011-b03e-aff31993725d-1566240956-executor] Seeking to earliest offset of partition feedback-0
[2025-07-19T18:30:12.942+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-6cc9cc98-97fd-4011-b03e-aff31993725d-1566240956-executor-3, groupId=spark-kafka-source-6cc9cc98-97fd-4011-b03e-aff31993725d-1566240956-executor] Resetting offset for partition feedback-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-07-19T18:30:12.943+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-64ca2e3e-791f-4994-9d80-fe05a2f1c757--1203258309-executor-2, groupId=spark-kafka-source-64ca2e3e-791f-4994-9d80-fe05a2f1c757--1203258309-executor] Resetting offset for partition checkins-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-07-19T18:30:12.944+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-f1e25fe4-84ea-495f-a817-789d74310202--1750756262-executor-1, groupId=spark-kafka-source-f1e25fe4-84ea-495f-a817-789d74310202--1750756262-executor] Resetting offset for partition reservations-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-07-19T18:30:12.944+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-64ca2e3e-791f-4994-9d80-fe05a2f1c757--1203258309-executor-2, groupId=spark-kafka-source-64ca2e3e-791f-4994-9d80-fe05a2f1c757--1203258309-executor] Seeking to latest offset of partition checkins-0
[2025-07-19T18:30:12.945+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-6cc9cc98-97fd-4011-b03e-aff31993725d-1566240956-executor-3, groupId=spark-kafka-source-6cc9cc98-97fd-4011-b03e-aff31993725d-1566240956-executor] Seeking to latest offset of partition feedback-0
[2025-07-19T18:30:12.945+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-f1e25fe4-84ea-495f-a817-789d74310202--1750756262-executor-1, groupId=spark-kafka-source-f1e25fe4-84ea-495f-a817-789d74310202--1750756262-executor] Seeking to latest offset of partition reservations-0
[2025-07-19T18:30:12.945+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-64ca2e3e-791f-4994-9d80-fe05a2f1c757--1203258309-executor-2, groupId=spark-kafka-source-64ca2e3e-791f-4994-9d80-fe05a2f1c757--1203258309-executor] Resetting offset for partition checkins-0 to position FetchPosition{offset=69, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-07-19T18:30:12.946+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-6cc9cc98-97fd-4011-b03e-aff31993725d-1566240956-executor-3, groupId=spark-kafka-source-6cc9cc98-97fd-4011-b03e-aff31993725d-1566240956-executor] Resetting offset for partition feedback-0 to position FetchPosition{offset=69, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-07-19T18:30:12.946+0000] {subprocess.py:93} INFO - 25/07/19 18:30:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-f1e25fe4-84ea-495f-a817-789d74310202--1750756262-executor-1, groupId=spark-kafka-source-f1e25fe4-84ea-495f-a817-789d74310202--1750756262-executor] Resetting offset for partition reservations-0 to position FetchPosition{offset=69, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-07-19T18:30:13.092+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO KafkaDataConsumer: From Kafka topicPartition=feedback-0 groupId=spark-kafka-source-6cc9cc98-97fd-4011-b03e-aff31993725d-1566240956-executor read 69 records through 1 polls (polled  out 69 records), taking 549007709 nanos, during time span of 698639667 nanos.
[2025-07-19T18:30:13.094+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO KafkaDataConsumer: From Kafka topicPartition=checkins-0 groupId=spark-kafka-source-64ca2e3e-791f-4994-9d80-fe05a2f1c757--1203258309-executor read 69 records through 1 polls (polled  out 69 records), taking 548858250 nanos, during time span of 698630750 nanos.
[2025-07-19T18:30:13.094+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO KafkaDataConsumer: From Kafka topicPartition=reservations-0 groupId=spark-kafka-source-f1e25fe4-84ea-495f-a817-789d74310202--1750756262-executor read 69 records through 1 polls (polled  out 69 records), taking 548959958 nanos, during time span of 698631417 nanos.
[2025-07-19T18:30:13.107+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO Executor: Finished task 0.0 in stage 4.0 (TID 2). 2642 bytes result sent to driver
[2025-07-19T18:30:13.108+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2642 bytes result sent to driver
[2025-07-19T18:30:13.108+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO Executor: Finished task 0.0 in stage 2.0 (TID 1). 2642 bytes result sent to driver
[2025-07-19T18:30:13.127+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1046 ms on 8b44f3d35cfa (executor driver) (1/1)
[2025-07-19T18:30:13.130+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2025-07-19T18:30:13.131+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 2) in 1023 ms on 8b44f3d35cfa (executor driver) (1/1)
[2025-07-19T18:30:13.131+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool
[2025-07-19T18:30:13.132+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 1) in 1028 ms on 8b44f3d35cfa (executor driver) (1/1)
[2025-07-19T18:30:13.132+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2025-07-19T18:30:13.136+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO DAGScheduler: ShuffleMapStage 0 (start at <unknown>:0) finished in 1.112 s
[2025-07-19T18:30:13.136+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO DAGScheduler: looking for newly runnable stages
[2025-07-19T18:30:13.137+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO DAGScheduler: running: Set(ShuffleMapStage 2, ShuffleMapStage 4)
[2025-07-19T18:30:13.137+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO DAGScheduler: waiting: Set(ResultStage 1, ResultStage 5, ResultStage 3)
[2025-07-19T18:30:13.137+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO DAGScheduler: failed: Set()
[2025-07-19T18:30:13.138+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO DAGScheduler: Submitting ResultStage 1 (StateStoreRDD[23] at start at <unknown>:0), which has no missing parents
[2025-07-19T18:30:13.199+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 39.6 KiB, free 433.3 MiB)
[2025-07-19T18:30:13.209+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 19.6 KiB, free 433.3 MiB)
[2025-07-19T18:30:13.211+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 8b44f3d35cfa:40517 (size: 19.6 KiB, free: 434.1 MiB)
[2025-07-19T18:30:13.212+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1611
[2025-07-19T18:30:13.215+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 1 (StateStoreRDD[23] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-07-19T18:30:13.215+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO TaskSchedulerImpl: Adding task set 1.0 with 200 tasks resource profile 0
[2025-07-19T18:30:13.219+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 3) (8b44f3d35cfa, executor driver, partition 3, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:13.219+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO DAGScheduler: ShuffleMapStage 4 (start at <unknown>:0) finished in 1.112 s
[2025-07-19T18:30:13.220+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO DAGScheduler: looking for newly runnable stages
[2025-07-19T18:30:13.220+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO DAGScheduler: running: Set(ResultStage 1, ShuffleMapStage 2)
[2025-07-19T18:30:13.220+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO DAGScheduler: waiting: Set(ResultStage 5, ResultStage 3)
[2025-07-19T18:30:13.221+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO DAGScheduler: failed: Set()
[2025-07-19T18:30:13.222+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 4) (8b44f3d35cfa, executor driver, partition 5, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:13.233+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO DAGScheduler: Submitting ResultStage 5 (StateStoreRDD[21] at start at <unknown>:0), which has no missing parents
[2025-07-19T18:30:13.233+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO TaskSetManager: Starting task 11.0 in stage 1.0 (TID 5) (8b44f3d35cfa, executor driver, partition 11, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:13.234+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO TaskSetManager: Starting task 12.0 in stage 1.0 (TID 6) (8b44f3d35cfa, executor driver, partition 12, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:13.234+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO TaskSetManager: Starting task 14.0 in stage 1.0 (TID 7) (8b44f3d35cfa, executor driver, partition 14, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:13.234+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO TaskSetManager: Starting task 21.0 in stage 1.0 (TID 8) (8b44f3d35cfa, executor driver, partition 21, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:13.234+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO TaskSetManager: Starting task 24.0 in stage 1.0 (TID 9) (8b44f3d35cfa, executor driver, partition 24, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:13.234+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO TaskSetManager: Starting task 25.0 in stage 1.0 (TID 10) (8b44f3d35cfa, executor driver, partition 25, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:13.234+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO Executor: Running task 3.0 in stage 1.0 (TID 3)
[2025-07-19T18:30:13.235+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO Executor: Running task 11.0 in stage 1.0 (TID 5)
[2025-07-19T18:30:13.235+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO Executor: Running task 5.0 in stage 1.0 (TID 4)
[2025-07-19T18:30:13.235+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO Executor: Running task 12.0 in stage 1.0 (TID 6)
[2025-07-19T18:30:13.235+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO Executor: Running task 14.0 in stage 1.0 (TID 7)
[2025-07-19T18:30:13.245+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO Executor: Running task 21.0 in stage 1.0 (TID 8)
[2025-07-19T18:30:13.258+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO Executor: Running task 24.0 in stage 1.0 (TID 9)
[2025-07-19T18:30:13.258+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO Executor: Running task 25.0 in stage 1.0 (TID 10)
[2025-07-19T18:30:13.297+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 38.8 KiB, free 433.3 MiB)
[2025-07-19T18:30:13.304+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 19.3 KiB, free 433.2 MiB)
[2025-07-19T18:30:13.307+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 8b44f3d35cfa:40517 (size: 19.3 KiB, free: 434.1 MiB)
[2025-07-19T18:30:13.307+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1611
[2025-07-19T18:30:13.307+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 5 (StateStoreRDD[21] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-07-19T18:30:13.309+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO TaskSchedulerImpl: Adding task set 5.0 with 200 tasks resource profile 0
[2025-07-19T18:30:13.309+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:13.309+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:13.309+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:13.309+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:13.309+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:13.309+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:13.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:13.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO DAGScheduler: ShuffleMapStage 2 (start at <unknown>:0) finished in 1.234 s
[2025-07-19T18:30:13.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO DAGScheduler: looking for newly runnable stages
[2025-07-19T18:30:13.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO DAGScheduler: running: Set(ResultStage 1, ResultStage 5)
[2025-07-19T18:30:13.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO DAGScheduler: waiting: Set(ResultStage 3)
[2025-07-19T18:30:13.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO DAGScheduler: failed: Set()
[2025-07-19T18:30:13.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:13.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO DAGScheduler: Submitting ResultStage 3 (StateStoreRDD[22] at start at <unknown>:0), which has no missing parents
[2025-07-19T18:30:13.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
[2025-07-19T18:30:13.312+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms
[2025-07-19T18:30:13.313+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 15 ms
[2025-07-19T18:30:13.313+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
[2025-07-19T18:30:13.313+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
[2025-07-19T18:30:13.314+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 15 ms
[2025-07-19T18:30:13.315+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 15 ms
[2025-07-19T18:30:13.315+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 18 ms
[2025-07-19T18:30:13.316+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO StateStore: State Store maintenance task started
[2025-07-19T18:30:13.331+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 40.1 KiB, free 433.2 MiB)
[2025-07-19T18:30:13.331+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 19.9 KiB, free 433.2 MiB)
[2025-07-19T18:30:13.332+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 8b44f3d35cfa:40517 (size: 19.9 KiB, free: 434.1 MiB)
[2025-07-19T18:30:13.332+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1611
[2025-07-19T18:30:13.332+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 3 (StateStoreRDD[22] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-07-19T18:30:13.332+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO TaskSchedulerImpl: Adding task set 3.0 with 200 tasks resource profile 0
[2025-07-19T18:30:13.334+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@21edd143
[2025-07-19T18:30:13.336+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=24, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:13.341+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=24),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/24] for update
[2025-07-19T18:30:13.348+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1361918e
[2025-07-19T18:30:13.353+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=12, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:13.354+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=12),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/12] for update
[2025-07-19T18:30:13.357+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5cde4709
[2025-07-19T18:30:13.359+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=3, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:13.360+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/3] for update
[2025-07-19T18:30:13.361+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO CodeGenerator: Code generated in 8.482542 ms
[2025-07-19T18:30:13.367+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@bb26617
[2025-07-19T18:30:13.369+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=11, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:13.370+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=11),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/11] for update
[2025-07-19T18:30:13.375+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c6f35b6
[2025-07-19T18:30:13.376+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=25, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:13.378+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=25),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/25] for update
[2025-07-19T18:30:13.379+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO CodeGenerator: Code generated in 5.784583 ms
[2025-07-19T18:30:13.380+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 8b44f3d35cfa:40517 in memory (size: 14.7 KiB, free: 434.1 MiB)
[2025-07-19T18:30:13.383+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68e482b6
[2025-07-19T18:30:13.383+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=5, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:13.384+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/5] for update
[2025-07-19T18:30:13.386+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1f8aff0d
[2025-07-19T18:30:13.391+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=21, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:13.391+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=21),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/21] for update
[2025-07-19T18:30:13.396+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@408e7c6d
[2025-07-19T18:30:13.399+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=14, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:13.399+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=14),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/14] for update
[2025-07-19T18:30:13.428+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:13.432+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:13.432+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:13.437+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:13.437+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:13.441+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:13.441+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:13.443+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:13.479+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 8b44f3d35cfa:40517 in memory (size: 14.0 KiB, free: 434.1 MiB)
[2025-07-19T18:30:13.485+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 8b44f3d35cfa:40517 in memory (size: 15.8 KiB, free: 434.2 MiB)
[2025-07-19T18:30:13.615+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/25/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/25/.1.delta.d94e53e6-70a9-47a0-93df-6fbb56c822e5.TID10.tmp
[2025-07-19T18:30:13.615+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/11/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/11/.1.delta.24295248-fecc-49fa-8167-3edc7dde00c1.TID5.tmp
[2025-07-19T18:30:13.615+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/12/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/12/.1.delta.e9340c2e-e0fc-4798-97a3-13c647a23d5c.TID6.tmp
[2025-07-19T18:30:13.615+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/5/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/5/.1.delta.1e1e33c3-a80d-4a88-9c0e-2bc477bbd24c.TID4.tmp
[2025-07-19T18:30:13.620+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/3/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/3/.1.delta.4cd749c9-a4c1-4500-a045-29fbd71d087a.TID3.tmp
[2025-07-19T18:30:13.621+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/24/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/24/.1.delta.5204bf86-63b0-4214-b658-4c19b5dadfae.TID9.tmp
[2025-07-19T18:30:13.622+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/21/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/21/.1.delta.f50e99a1-727f-466f-9709-6bf54ef16237.TID8.tmp
[2025-07-19T18:30:13.623+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/14/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/14/.1.delta.99cfcecc-98e4-4f4a-8439-4c2f2c66a39b.TID7.tmp
[2025-07-19T18:30:13.624+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO CodeGenerator: Code generated in 5.332458 ms
[2025-07-19T18:30:13.666+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/5/.1.delta.1e1e33c3-a80d-4a88-9c0e-2bc477bbd24c.TID4.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/5/1.delta
[2025-07-19T18:30:13.667+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/5] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/5/1.delta
[2025-07-19T18:30:13.670+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/14/.1.delta.99cfcecc-98e4-4f4a-8439-4c2f2c66a39b.TID7.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/14/1.delta
[2025-07-19T18:30:13.670+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=14),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/14] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/14/1.delta
[2025-07-19T18:30:13.670+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/12/.1.delta.e9340c2e-e0fc-4798-97a3-13c647a23d5c.TID6.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/12/1.delta
[2025-07-19T18:30:13.671+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=12),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/12] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/12/1.delta
[2025-07-19T18:30:13.671+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/11/.1.delta.24295248-fecc-49fa-8167-3edc7dde00c1.TID5.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/11/1.delta
[2025-07-19T18:30:13.672+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=11),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/11] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/11/1.delta
[2025-07-19T18:30:13.672+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/25/.1.delta.d94e53e6-70a9-47a0-93df-6fbb56c822e5.TID10.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/25/1.delta
[2025-07-19T18:30:13.672+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=25),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/25] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/25/1.delta
[2025-07-19T18:30:13.673+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/3/.1.delta.4cd749c9-a4c1-4500-a045-29fbd71d087a.TID3.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/3/1.delta
[2025-07-19T18:30:13.673+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/3] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/3/1.delta
[2025-07-19T18:30:13.676+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO DataWritingSparkTask: Commit authorized for partition 12 (task 6, attempt 0, stage 1.0)
[2025-07-19T18:30:13.676+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/24/.1.delta.5204bf86-63b0-4214-b658-4c19b5dadfae.TID9.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/24/1.delta
[2025-07-19T18:30:13.676+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO DataWritingSparkTask: Commit authorized for partition 11 (task 5, attempt 0, stage 1.0)
[2025-07-19T18:30:13.677+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO DataWritingSparkTask: Commit authorized for partition 25 (task 10, attempt 0, stage 1.0)
[2025-07-19T18:30:13.678+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO DataWritingSparkTask: Commit authorized for partition 3 (task 3, attempt 0, stage 1.0)
[2025-07-19T18:30:13.682+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO DataWritingSparkTask: Commit authorized for partition 14 (task 7, attempt 0, stage 1.0)
[2025-07-19T18:30:13.683+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/21/.1.delta.f50e99a1-727f-466f-9709-6bf54ef16237.TID8.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/21/1.delta
[2025-07-19T18:30:13.684+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO DataWritingSparkTask: Commit authorized for partition 5 (task 4, attempt 0, stage 1.0)
[2025-07-19T18:30:13.684+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=24),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/24] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/24/1.delta
[2025-07-19T18:30:13.685+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=21),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/21] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/21/1.delta
[2025-07-19T18:30:13.685+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO DataWritingSparkTask: Commit authorized for partition 24 (task 9, attempt 0, stage 1.0)
[2025-07-19T18:30:13.686+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO DataWritingSparkTask: Commit authorized for partition 21 (task 8, attempt 0, stage 1.0)
[2025-07-19T18:30:13.916+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO DataWritingSparkTask: Committed partition 5 (task 4, attempt 0, stage 1.0)
[2025-07-19T18:30:13.916+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO DataWritingSparkTask: Committed partition 12 (task 6, attempt 0, stage 1.0)
[2025-07-19T18:30:13.916+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO DataWritingSparkTask: Committed partition 14 (task 7, attempt 0, stage 1.0)
[2025-07-19T18:30:13.917+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO DataWritingSparkTask: Committed partition 24 (task 9, attempt 0, stage 1.0)
[2025-07-19T18:30:13.925+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO DataWritingSparkTask: Committed partition 3 (task 3, attempt 0, stage 1.0)
[2025-07-19T18:30:13.928+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO DataWritingSparkTask: Committed partition 25 (task 10, attempt 0, stage 1.0)
[2025-07-19T18:30:13.930+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO DataWritingSparkTask: Committed partition 11 (task 5, attempt 0, stage 1.0)
[2025-07-19T18:30:13.930+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO DataWritingSparkTask: Committed partition 21 (task 8, attempt 0, stage 1.0)
[2025-07-19T18:30:13.930+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO Executor: Finished task 25.0 in stage 1.0 (TID 10). 9122 bytes result sent to driver
[2025-07-19T18:30:13.931+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO Executor: Finished task 24.0 in stage 1.0 (TID 9). 9113 bytes result sent to driver
[2025-07-19T18:30:13.931+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO Executor: Finished task 5.0 in stage 1.0 (TID 4). 9117 bytes result sent to driver
[2025-07-19T18:30:13.931+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO Executor: Finished task 21.0 in stage 1.0 (TID 8). 9081 bytes result sent to driver
[2025-07-19T18:30:13.931+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO Executor: Finished task 14.0 in stage 1.0 (TID 7). 9121 bytes result sent to driver
[2025-07-19T18:30:13.931+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO Executor: Finished task 11.0 in stage 1.0 (TID 5). 9102 bytes result sent to driver
[2025-07-19T18:30:13.931+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO Executor: Finished task 12.0 in stage 1.0 (TID 6). 9119 bytes result sent to driver
[2025-07-19T18:30:13.931+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO Executor: Finished task 3.0 in stage 1.0 (TID 3). 9119 bytes result sent to driver
[2025-07-19T18:30:13.933+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO TaskSetManager: Starting task 8.0 in stage 3.0 (TID 11) (8b44f3d35cfa, executor driver, partition 8, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:13.934+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO TaskSetManager: Starting task 10.0 in stage 3.0 (TID 12) (8b44f3d35cfa, executor driver, partition 10, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:13.935+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO Executor: Running task 8.0 in stage 3.0 (TID 11)
[2025-07-19T18:30:13.935+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO TaskSetManager: Starting task 16.0 in stage 3.0 (TID 13) (8b44f3d35cfa, executor driver, partition 16, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:13.936+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO Executor: Running task 10.0 in stage 3.0 (TID 12)
[2025-07-19T18:30:13.936+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO Executor: Running task 16.0 in stage 3.0 (TID 13)
[2025-07-19T18:30:13.943+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO TaskSetManager: Starting task 17.0 in stage 3.0 (TID 14) (8b44f3d35cfa, executor driver, partition 17, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:13.945+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:13.947+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:13.948+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO TaskSetManager: Finished task 25.0 in stage 1.0 (TID 10) in 721 ms on 8b44f3d35cfa (executor driver) (1/200)
[2025-07-19T18:30:13.950+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO Executor: Running task 17.0 in stage 3.0 (TID 14)
[2025-07-19T18:30:13.950+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 4) in 728 ms on 8b44f3d35cfa (executor driver) (2/200)
[2025-07-19T18:30:13.951+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO TaskSetManager: Starting task 20.0 in stage 3.0 (TID 15) (8b44f3d35cfa, executor driver, partition 20, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:13.954+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO TaskSetManager: Starting task 30.0 in stage 3.0 (TID 16) (8b44f3d35cfa, executor driver, partition 30, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:13.956+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO TaskSetManager: Starting task 31.0 in stage 3.0 (TID 17) (8b44f3d35cfa, executor driver, partition 31, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:13.959+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO TaskSetManager: Starting task 32.0 in stage 3.0 (TID 18) (8b44f3d35cfa, executor driver, partition 32, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:13.961+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO Executor: Running task 30.0 in stage 3.0 (TID 16)
[2025-07-19T18:30:13.964+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO Executor: Running task 20.0 in stage 3.0 (TID 15)
[2025-07-19T18:30:13.964+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:13.965+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:13.966+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:13.966+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:13.967+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@768bb55d
[2025-07-19T18:30:13.967+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=10, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:13.968+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=10),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/10] for update
[2025-07-19T18:30:13.969+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO TaskSetManager: Finished task 21.0 in stage 1.0 (TID 8) in 736 ms on 8b44f3d35cfa (executor driver) (3/200)
[2025-07-19T18:30:13.970+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:13.970+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:13.971+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO Executor: Running task 32.0 in stage 3.0 (TID 18)
[2025-07-19T18:30:13.972+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO TaskSetManager: Finished task 24.0 in stage 1.0 (TID 9) in 737 ms on 8b44f3d35cfa (executor driver) (4/200)
[2025-07-19T18:30:13.972+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:13.973+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:13.973+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO Executor: Running task 31.0 in stage 3.0 (TID 17)
[2025-07-19T18:30:13.973+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:13.973+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:13.973+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c0b39b0
[2025-07-19T18:30:13.974+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:13.974+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:13.977+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=30, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:13.978+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=30),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/30] for update
[2025-07-19T18:30:13.978+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO TaskSetManager: Finished task 12.0 in stage 1.0 (TID 6) in 750 ms on 8b44f3d35cfa (executor driver) (5/200)
[2025-07-19T18:30:13.979+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO TaskSetManager: Finished task 14.0 in stage 1.0 (TID 7) in 754 ms on 8b44f3d35cfa (executor driver) (6/200)
[2025-07-19T18:30:13.983+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO CodeGenerator: Code generated in 22.166584 ms
[2025-07-19T18:30:13.984+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 3) in 768 ms on 8b44f3d35cfa (executor driver) (7/200)
[2025-07-19T18:30:13.984+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2a5cfb10
[2025-07-19T18:30:13.984+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:13.984+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:13.985+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=17, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:13.985+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=17),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/17] for update
[2025-07-19T18:30:13.993+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO TaskSetManager: Finished task 11.0 in stage 1.0 (TID 5) in 773 ms on 8b44f3d35cfa (executor driver) (8/200)
[2025-07-19T18:30:13.997+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO CodeGenerator: Code generated in 4.48575 ms
[2025-07-19T18:30:13.999+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.000+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.001+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.001+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47a805e1
[2025-07-19T18:30:14.002+0000] {subprocess.py:93} INFO - 25/07/19 18:30:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=16, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.002+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=16),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/16] for update
[2025-07-19T18:30:14.026+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@515ba0fc
[2025-07-19T18:30:14.039+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=31, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.043+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/10/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/10/.1.delta.479b0870-049e-4184-aaf4-817b74304561.TID12.tmp
[2025-07-19T18:30:14.044+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=31),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/31] for update
[2025-07-19T18:30:14.045+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.045+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/30/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/30/.1.delta.838405c2-b04a-4931-86a4-23fd489a72de.TID16.tmp
[2025-07-19T18:30:14.045+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/17/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/17/.1.delta.b6fbc657-4dcc-4f61-8157-a47ee573a03f.TID14.tmp
[2025-07-19T18:30:14.045+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40be0f13
[2025-07-19T18:30:14.045+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=32, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.046+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.046+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=32),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/32] for update
[2025-07-19T18:30:14.046+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.046+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/16/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/16/.1.delta.e3e41bcb-2b41-4da3-b900-d7e8dd2cc4a3.TID13.tmp
[2025-07-19T18:30:14.053+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/31/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/31/.1.delta.270a9747-244a-4381-82d8-c4fd5d2cc6b6.TID17.tmp
[2025-07-19T18:30:14.055+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/32/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/32/.1.delta.dc643fbe-6d72-45d1-8cc3-bcd8797c5fff.TID18.tmp
[2025-07-19T18:30:14.058+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@69718885
[2025-07-19T18:30:14.059+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=8, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.060+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/8] for update
[2025-07-19T18:30:14.066+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.067+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2947b859
[2025-07-19T18:30:14.067+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=20, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.068+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=20),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/20] for update
[2025-07-19T18:30:14.073+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.082+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/30/.1.delta.838405c2-b04a-4931-86a4-23fd489a72de.TID16.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/30/1.delta
[2025-07-19T18:30:14.083+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=30),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/30] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/30/1.delta
[2025-07-19T18:30:14.083+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 30 (task 16, attempt 0, stage 3.0)
[2025-07-19T18:30:14.084+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/8/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/8/.1.delta.3489f6a2-6274-4050-8a45-29699ed25bab.TID11.tmp
[2025-07-19T18:30:14.087+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/10/.1.delta.479b0870-049e-4184-aaf4-817b74304561.TID12.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/10/1.delta
[2025-07-19T18:30:14.089+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=10),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/10] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/10/1.delta
[2025-07-19T18:30:14.090+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 10 (task 12, attempt 0, stage 3.0)
[2025-07-19T18:30:14.095+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/20/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/20/.1.delta.465bfad9-60f2-4114-8c5c-4502159a63a3.TID15.tmp
[2025-07-19T18:30:14.100+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/16/.1.delta.e3e41bcb-2b41-4da3-b900-d7e8dd2cc4a3.TID13.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/16/1.delta
[2025-07-19T18:30:14.101+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=16),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/16] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/16/1.delta
[2025-07-19T18:30:14.102+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 16 (task 13, attempt 0, stage 3.0)
[2025-07-19T18:30:14.103+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/17/.1.delta.b6fbc657-4dcc-4f61-8157-a47ee573a03f.TID14.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/17/1.delta
[2025-07-19T18:30:14.103+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=17),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/17] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/17/1.delta
[2025-07-19T18:30:14.104+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 17 (task 14, attempt 0, stage 3.0)
[2025-07-19T18:30:14.109+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/32/.1.delta.dc643fbe-6d72-45d1-8cc3-bcd8797c5fff.TID18.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/32/1.delta
[2025-07-19T18:30:14.111+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=32),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/32] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/32/1.delta
[2025-07-19T18:30:14.112+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 32 (task 18, attempt 0, stage 3.0)
[2025-07-19T18:30:14.113+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 30 (task 16, attempt 0, stage 3.0)
[2025-07-19T18:30:14.116+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/31/.1.delta.270a9747-244a-4381-82d8-c4fd5d2cc6b6.TID17.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/31/1.delta
[2025-07-19T18:30:14.117+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=31),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/31] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/31/1.delta
[2025-07-19T18:30:14.120+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 30.0 in stage 3.0 (TID 16). 9243 bytes result sent to driver
[2025-07-19T18:30:14.121+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 31 (task 17, attempt 0, stage 3.0)
[2025-07-19T18:30:14.121+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 33.0 in stage 3.0 (TID 19) (8b44f3d35cfa, executor driver, partition 33, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.122+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 33.0 in stage 3.0 (TID 19)
[2025-07-19T18:30:14.123+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 30.0 in stage 3.0 (TID 16) in 175 ms on 8b44f3d35cfa (executor driver) (1/200)
[2025-07-19T18:30:14.123+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 10 (task 12, attempt 0, stage 3.0)
[2025-07-19T18:30:14.125+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 10.0 in stage 3.0 (TID 12). 9245 bytes result sent to driver
[2025-07-19T18:30:14.129+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 40.0 in stage 3.0 (TID 20) (8b44f3d35cfa, executor driver, partition 40, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.132+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 10.0 in stage 3.0 (TID 12) in 196 ms on 8b44f3d35cfa (executor driver) (2/200)
[2025-07-19T18:30:14.135+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.136+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 40.0 in stage 3.0 (TID 20)
[2025-07-19T18:30:14.139+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:14.140+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 32 (task 18, attempt 0, stage 3.0)
[2025-07-19T18:30:14.140+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 16 (task 13, attempt 0, stage 3.0)
[2025-07-19T18:30:14.141+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.141+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:14.144+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 32.0 in stage 3.0 (TID 18). 9249 bytes result sent to driver
[2025-07-19T18:30:14.145+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 16.0 in stage 3.0 (TID 13). 9236 bytes result sent to driver
[2025-07-19T18:30:14.146+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 42.0 in stage 3.0 (TID 21) (8b44f3d35cfa, executor driver, partition 42, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.147+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 42.0 in stage 3.0 (TID 21)
[2025-07-19T18:30:14.147+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1dba973d
[2025-07-19T18:30:14.148+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 47.0 in stage 3.0 (TID 22) (8b44f3d35cfa, executor driver, partition 47, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.149+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 47.0 in stage 3.0 (TID 22)
[2025-07-19T18:30:14.149+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 32.0 in stage 3.0 (TID 18) in 201 ms on 8b44f3d35cfa (executor driver) (3/200)
[2025-07-19T18:30:14.150+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 16.0 in stage 3.0 (TID 13) in 215 ms on 8b44f3d35cfa (executor driver) (4/200)
[2025-07-19T18:30:14.150+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=33, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.151+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=33),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/33] for update
[2025-07-19T18:30:14.152+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.153+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:14.155+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 17 (task 14, attempt 0, stage 3.0)
[2025-07-19T18:30:14.157+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/8/.1.delta.3489f6a2-6274-4050-8a45-29699ed25bab.TID11.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/8/1.delta
[2025-07-19T18:30:14.158+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/8] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/8/1.delta
[2025-07-19T18:30:14.159+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 8 (task 11, attempt 0, stage 3.0)
[2025-07-19T18:30:14.161+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.161+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7643ba41
[2025-07-19T18:30:14.163+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=40, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.164+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=40),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/40] for update
[2025-07-19T18:30:14.164+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.164+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:14.165+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 31 (task 17, attempt 0, stage 3.0)
[2025-07-19T18:30:14.168+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.168+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40aa3605
[2025-07-19T18:30:14.169+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=47, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.170+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=47),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/47] for update
[2025-07-19T18:30:14.171+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 17.0 in stage 3.0 (TID 14). 9251 bytes result sent to driver
[2025-07-19T18:30:14.172+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 31.0 in stage 3.0 (TID 17). 9250 bytes result sent to driver
[2025-07-19T18:30:14.173+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.174+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 48.0 in stage 3.0 (TID 23) (8b44f3d35cfa, executor driver, partition 48, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.176+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 54.0 in stage 3.0 (TID 24) (8b44f3d35cfa, executor driver, partition 54, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.176+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 17.0 in stage 3.0 (TID 14) in 231 ms on 8b44f3d35cfa (executor driver) (5/200)
[2025-07-19T18:30:14.176+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 31.0 in stage 3.0 (TID 17) in 227 ms on 8b44f3d35cfa (executor driver) (6/200)
[2025-07-19T18:30:14.178+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 48.0 in stage 3.0 (TID 23)
[2025-07-19T18:30:14.179+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 54.0 in stage 3.0 (TID 24)
[2025-07-19T18:30:14.179+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/33/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/33/.1.delta.138cce8c-0480-4d5d-affb-bd79e60d775b.TID19.tmp
[2025-07-19T18:30:14.179+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/20/.1.delta.465bfad9-60f2-4114-8c5c-4502159a63a3.TID15.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/20/1.delta
[2025-07-19T18:30:14.180+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=20),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/20] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/20/1.delta
[2025-07-19T18:30:14.180+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 20 (task 15, attempt 0, stage 3.0)
[2025-07-19T18:30:14.180+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3129afbe
[2025-07-19T18:30:14.180+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=42, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.181+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=42),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/42] for update
[2025-07-19T18:30:14.181+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/47/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/47/.1.delta.2a349dde-c9dd-4321-9f0b-547618a50f65.TID22.tmp
[2025-07-19T18:30:14.181+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/40/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/40/.1.delta.a689195a-6fc3-47b6-8e38-714949ac0a81.TID20.tmp
[2025-07-19T18:30:14.182+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.183+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:14.191+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.194+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.194+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:14.195+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 8 (task 11, attempt 0, stage 3.0)
[2025-07-19T18:30:14.195+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59e5163
[2025-07-19T18:30:14.195+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 8.0 in stage 3.0 (TID 11). 9292 bytes result sent to driver
[2025-07-19T18:30:14.196+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 58.0 in stage 3.0 (TID 25) (8b44f3d35cfa, executor driver, partition 58, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.196+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=54, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.197+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=54),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/54] for update
[2025-07-19T18:30:14.199+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 58.0 in stage 3.0 (TID 25)
[2025-07-19T18:30:14.200+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 8.0 in stage 3.0 (TID 11) in 262 ms on 8b44f3d35cfa (executor driver) (7/200)
[2025-07-19T18:30:14.200+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.203+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.203+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:14.204+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54a266ce
[2025-07-19T18:30:14.206+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=48, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.207+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=48),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/48] for update
[2025-07-19T18:30:14.207+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 20 (task 15, attempt 0, stage 3.0)
[2025-07-19T18:30:14.207+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.209+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 20.0 in stage 3.0 (TID 15). 9271 bytes result sent to driver
[2025-07-19T18:30:14.211+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/54/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/54/.1.delta.26cab02f-3c46-4103-88ea-a55ebf050041.TID24.tmp
[2025-07-19T18:30:14.212+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@265dd917
[2025-07-19T18:30:14.212+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/42/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/42/.1.delta.31581e70-4b6d-402b-8d4a-65adf320a9b9.TID21.tmp
[2025-07-19T18:30:14.213+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=58, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.213+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=58),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/58] for update
[2025-07-19T18:30:14.213+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 62.0 in stage 3.0 (TID 26) (8b44f3d35cfa, executor driver, partition 62, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.215+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 62.0 in stage 3.0 (TID 26)
[2025-07-19T18:30:14.222+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 20.0 in stage 3.0 (TID 15) in 276 ms on 8b44f3d35cfa (executor driver) (8/200)
[2025-07-19T18:30:14.223+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.225+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/48/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/48/.1.delta.3cc73de6-bb23-4ee1-87d5-7511e26dba76.TID23.tmp
[2025-07-19T18:30:14.226+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.227+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:14.232+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/58/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/58/.1.delta.1415069c-b378-43d5-a9e8-4c3f6a3af349.TID25.tmp
[2025-07-19T18:30:14.235+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19f2a0b5
[2025-07-19T18:30:14.236+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=62, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.237+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=62),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/62] for update
[2025-07-19T18:30:14.242+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.245+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/40/.1.delta.a689195a-6fc3-47b6-8e38-714949ac0a81.TID20.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/40/1.delta
[2025-07-19T18:30:14.245+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=40),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/40] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/40/1.delta
[2025-07-19T18:30:14.246+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 40 (task 20, attempt 0, stage 3.0)
[2025-07-19T18:30:14.247+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/33/.1.delta.138cce8c-0480-4d5d-affb-bd79e60d775b.TID19.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/33/1.delta
[2025-07-19T18:30:14.247+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=33),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/33] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/33/1.delta
[2025-07-19T18:30:14.250+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 33 (task 19, attempt 0, stage 3.0)
[2025-07-19T18:30:14.257+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/62/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/62/.1.delta.228d6b47-8781-48aa-a8e5-383dea100cbb.TID26.tmp
[2025-07-19T18:30:14.271+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/47/.1.delta.2a349dde-c9dd-4321-9f0b-547618a50f65.TID22.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/47/1.delta
[2025-07-19T18:30:14.272+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=47),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/47] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/47/1.delta
[2025-07-19T18:30:14.273+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 47 (task 22, attempt 0, stage 3.0)
[2025-07-19T18:30:14.275+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/54/.1.delta.26cab02f-3c46-4103-88ea-a55ebf050041.TID24.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/54/1.delta
[2025-07-19T18:30:14.275+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=54),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/54] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/54/1.delta
[2025-07-19T18:30:14.277+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/42/.1.delta.31581e70-4b6d-402b-8d4a-65adf320a9b9.TID21.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/42/1.delta
[2025-07-19T18:30:14.279+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=42),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/42] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/42/1.delta
[2025-07-19T18:30:14.280+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 42 (task 21, attempt 0, stage 3.0)
[2025-07-19T18:30:14.280+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 54 (task 24, attempt 0, stage 3.0)
[2025-07-19T18:30:14.281+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 40 (task 20, attempt 0, stage 3.0)
[2025-07-19T18:30:14.283+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 40.0 in stage 3.0 (TID 20). 9346 bytes result sent to driver
[2025-07-19T18:30:14.289+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/48/.1.delta.3cc73de6-bb23-4ee1-87d5-7511e26dba76.TID23.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/48/1.delta
[2025-07-19T18:30:14.292+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 63.0 in stage 3.0 (TID 27) (8b44f3d35cfa, executor driver, partition 63, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.294+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=48),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/48] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/48/1.delta
[2025-07-19T18:30:14.295+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 48 (task 23, attempt 0, stage 3.0)
[2025-07-19T18:30:14.297+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 40.0 in stage 3.0 (TID 20) in 163 ms on 8b44f3d35cfa (executor driver) (9/200)
[2025-07-19T18:30:14.298+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 63.0 in stage 3.0 (TID 27)
[2025-07-19T18:30:14.299+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/58/.1.delta.1415069c-b378-43d5-a9e8-4c3f6a3af349.TID25.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/58/1.delta
[2025-07-19T18:30:14.299+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 33 (task 19, attempt 0, stage 3.0)
[2025-07-19T18:30:14.300+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=58),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/58] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/58/1.delta
[2025-07-19T18:30:14.301+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 33.0 in stage 3.0 (TID 19). 9288 bytes result sent to driver
[2025-07-19T18:30:14.301+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.301+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:14.303+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 64.0 in stage 3.0 (TID 28) (8b44f3d35cfa, executor driver, partition 64, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.305+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 58 (task 25, attempt 0, stage 3.0)
[2025-07-19T18:30:14.306+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 33.0 in stage 3.0 (TID 19) in 182 ms on 8b44f3d35cfa (executor driver) (10/200)
[2025-07-19T18:30:14.307+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 64.0 in stage 3.0 (TID 28)
[2025-07-19T18:30:14.308+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e1b96c3
[2025-07-19T18:30:14.309+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=63, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=63),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/63] for update
[2025-07-19T18:30:14.311+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/62/.1.delta.228d6b47-8781-48aa-a8e5-383dea100cbb.TID26.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/62/1.delta
[2025-07-19T18:30:14.312+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=62),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/62] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/62/1.delta
[2025-07-19T18:30:14.312+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.312+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 62 (task 26, attempt 0, stage 3.0)
[2025-07-19T18:30:14.312+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 47 (task 22, attempt 0, stage 3.0)
[2025-07-19T18:30:14.313+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 47.0 in stage 3.0 (TID 22). 9318 bytes result sent to driver
[2025-07-19T18:30:14.313+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 66.0 in stage 3.0 (TID 29) (8b44f3d35cfa, executor driver, partition 66, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.314+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 47.0 in stage 3.0 (TID 22) in 170 ms on 8b44f3d35cfa (executor driver) (11/200)
[2025-07-19T18:30:14.318+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 54 (task 24, attempt 0, stage 3.0)
[2025-07-19T18:30:14.319+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 66.0 in stage 3.0 (TID 29)
[2025-07-19T18:30:14.319+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 54.0 in stage 3.0 (TID 24). 9301 bytes result sent to driver
[2025-07-19T18:30:14.319+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 42 (task 21, attempt 0, stage 3.0)
[2025-07-19T18:30:14.320+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 68.0 in stage 3.0 (TID 30) (8b44f3d35cfa, executor driver, partition 68, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.320+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 42.0 in stage 3.0 (TID 21). 9294 bytes result sent to driver
[2025-07-19T18:30:14.321+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.321+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 68.0 in stage 3.0 (TID 30)
[2025-07-19T18:30:14.322+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:14.323+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.323+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:14.323+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.323+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:14.324+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/63/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/63/.1.delta.eae3cec5-2958-49a7-bdd7-ad17dcace676.TID27.tmp
[2025-07-19T18:30:14.324+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 48 (task 23, attempt 0, stage 3.0)
[2025-07-19T18:30:14.324+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 71.0 in stage 3.0 (TID 31) (8b44f3d35cfa, executor driver, partition 71, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.329+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 48.0 in stage 3.0 (TID 23). 9308 bytes result sent to driver
[2025-07-19T18:30:14.330+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 54.0 in stage 3.0 (TID 24) in 154 ms on 8b44f3d35cfa (executor driver) (12/200)
[2025-07-19T18:30:14.330+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 42.0 in stage 3.0 (TID 21) in 184 ms on 8b44f3d35cfa (executor driver) (13/200)
[2025-07-19T18:30:14.331+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 74.0 in stage 3.0 (TID 32) (8b44f3d35cfa, executor driver, partition 74, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.332+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 71.0 in stage 3.0 (TID 31)
[2025-07-19T18:30:14.332+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 48.0 in stage 3.0 (TID 23) in 157 ms on 8b44f3d35cfa (executor driver) (14/200)
[2025-07-19T18:30:14.333+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@38358cea
[2025-07-19T18:30:14.333+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=64, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.334+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=64),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/64] for update
[2025-07-19T18:30:14.334+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 74.0 in stage 3.0 (TID 32)
[2025-07-19T18:30:14.337+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 62 (task 26, attempt 0, stage 3.0)
[2025-07-19T18:30:14.338+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 62.0 in stage 3.0 (TID 26). 9294 bytes result sent to driver
[2025-07-19T18:30:14.339+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 79.0 in stage 3.0 (TID 33) (8b44f3d35cfa, executor driver, partition 79, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.341+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.342+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:14.342+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68ca0a2c
[2025-07-19T18:30:14.343+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=66, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.344+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=66),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/66] for update
[2025-07-19T18:30:14.344+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 62.0 in stage 3.0 (TID 26) in 128 ms on 8b44f3d35cfa (executor driver) (15/200)
[2025-07-19T18:30:14.344+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.344+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.346+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:14.346+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 79.0 in stage 3.0 (TID 33)
[2025-07-19T18:30:14.346+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.347+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 58 (task 25, attempt 0, stage 3.0)
[2025-07-19T18:30:14.348+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.349+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:14.351+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@12431881
[2025-07-19T18:30:14.352+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=68, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.352+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=68),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/68] for update
[2025-07-19T18:30:14.354+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.354+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 58.0 in stage 3.0 (TID 25). 9331 bytes result sent to driver
[2025-07-19T18:30:14.356+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 80.0 in stage 3.0 (TID 34) (8b44f3d35cfa, executor driver, partition 80, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.358+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/64/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/64/.1.delta.964832b3-a46f-4835-9047-5b25b9332548.TID28.tmp
[2025-07-19T18:30:14.359+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 58.0 in stage 3.0 (TID 25) in 161 ms on 8b44f3d35cfa (executor driver) (16/200)
[2025-07-19T18:30:14.359+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 80.0 in stage 3.0 (TID 34)
[2025-07-19T18:30:14.360+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/66/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/66/.1.delta.5989bf90-621b-4684-9deb-3bd3eacd41e8.TID29.tmp
[2025-07-19T18:30:14.361+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@18653456
[2025-07-19T18:30:14.361+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=79, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.362+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=79),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/79] for update
[2025-07-19T18:30:14.362+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.367+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6213b349
[2025-07-19T18:30:14.368+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/68/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/68/.1.delta.eea0b322-60a7-4a06-a857-4131f2f1f704.TID30.tmp
[2025-07-19T18:30:14.368+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T18:30:14.368+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=74, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.369+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.369+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=74),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/74] for update
[2025-07-19T18:30:14.371+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/63/.1.delta.eae3cec5-2958-49a7-bdd7-ad17dcace676.TID27.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/63/1.delta
[2025-07-19T18:30:14.372+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=63),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/63] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/63/1.delta
[2025-07-19T18:30:14.374+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.375+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7dc0dd24
[2025-07-19T18:30:14.376+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=71, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.377+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=71),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/71] for update
[2025-07-19T18:30:14.378+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 63 (task 27, attempt 0, stage 3.0)
[2025-07-19T18:30:14.381+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.382+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/79/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/79/.1.delta.91e780e2-d1e7-4662-8f26-61fc97f40fb5.TID33.tmp
[2025-07-19T18:30:14.390+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/71/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/71/.1.delta.701f182a-c9c0-4cf3-a5de-ca3ed484dd25.TID31.tmp
[2025-07-19T18:30:14.392+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/74/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/74/.1.delta.8ab8190e-8a79-49e2-94cb-54842bd1ad18.TID32.tmp
[2025-07-19T18:30:14.393+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6398fdfa
[2025-07-19T18:30:14.394+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=80, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.395+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=80),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/80] for update
[2025-07-19T18:30:14.398+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.410+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/66/.1.delta.5989bf90-621b-4684-9deb-3bd3eacd41e8.TID29.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/66/1.delta
[2025-07-19T18:30:14.411+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=66),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/66] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/66/1.delta
[2025-07-19T18:30:14.412+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 66 (task 29, attempt 0, stage 3.0)
[2025-07-19T18:30:14.413+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/64/.1.delta.964832b3-a46f-4835-9047-5b25b9332548.TID28.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/64/1.delta
[2025-07-19T18:30:14.415+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=64),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/64] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/64/1.delta
[2025-07-19T18:30:14.416+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 64 (task 28, attempt 0, stage 3.0)
[2025-07-19T18:30:14.416+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 63 (task 27, attempt 0, stage 3.0)
[2025-07-19T18:30:14.421+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 63.0 in stage 3.0 (TID 27). 9247 bytes result sent to driver
[2025-07-19T18:30:14.422+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/68/.1.delta.eea0b322-60a7-4a06-a857-4131f2f1f704.TID30.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/68/1.delta
[2025-07-19T18:30:14.423+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=68),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/68] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/68/1.delta
[2025-07-19T18:30:14.425+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 82.0 in stage 3.0 (TID 35) (8b44f3d35cfa, executor driver, partition 82, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.426+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 82.0 in stage 3.0 (TID 35)
[2025-07-19T18:30:14.426+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 68 (task 30, attempt 0, stage 3.0)
[2025-07-19T18:30:14.427+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 63.0 in stage 3.0 (TID 27) in 139 ms on 8b44f3d35cfa (executor driver) (17/200)
[2025-07-19T18:30:14.430+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/80/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/80/.1.delta.98b10a33-93ed-4cd5-994f-a4e64cf27929.TID34.tmp
[2025-07-19T18:30:14.433+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.435+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T18:30:14.443+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 66 (task 29, attempt 0, stage 3.0)
[2025-07-19T18:30:14.445+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4642c1aa
[2025-07-19T18:30:14.446+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=82, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.446+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=82),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/82] for update
[2025-07-19T18:30:14.446+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 66.0 in stage 3.0 (TID 29). 9243 bytes result sent to driver
[2025-07-19T18:30:14.448+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 83.0 in stage 3.0 (TID 36) (8b44f3d35cfa, executor driver, partition 83, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.449+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 66.0 in stage 3.0 (TID 29) in 135 ms on 8b44f3d35cfa (executor driver) (18/200)
[2025-07-19T18:30:14.450+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.451+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 83.0 in stage 3.0 (TID 36)
[2025-07-19T18:30:14.454+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/79/.1.delta.91e780e2-d1e7-4662-8f26-61fc97f40fb5.TID33.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/79/1.delta
[2025-07-19T18:30:14.456+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=79),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/79] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/79/1.delta
[2025-07-19T18:30:14.457+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 79 (task 33, attempt 0, stage 3.0)
[2025-07-19T18:30:14.460+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.461+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:14.462+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/71/.1.delta.701f182a-c9c0-4cf3-a5de-ca3ed484dd25.TID31.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/71/1.delta
[2025-07-19T18:30:14.463+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=71),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/71] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/71/1.delta
[2025-07-19T18:30:14.464+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/74/.1.delta.8ab8190e-8a79-49e2-94cb-54842bd1ad18.TID32.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/74/1.delta
[2025-07-19T18:30:14.466+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=74),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/74] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/74/1.delta
[2025-07-19T18:30:14.467+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 71 (task 31, attempt 0, stage 3.0)
[2025-07-19T18:30:14.468+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 74 (task 32, attempt 0, stage 3.0)
[2025-07-19T18:30:14.470+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@542a0122
[2025-07-19T18:30:14.475+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=83, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.476+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/82/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/82/.1.delta.def2bc0d-f3bf-42e2-bd37-d7bbb01db0f5.TID35.tmp
[2025-07-19T18:30:14.477+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 64 (task 28, attempt 0, stage 3.0)
[2025-07-19T18:30:14.477+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=83),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/83] for update
[2025-07-19T18:30:14.477+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 68 (task 30, attempt 0, stage 3.0)
[2025-07-19T18:30:14.478+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 68.0 in stage 3.0 (TID 30). 9232 bytes result sent to driver
[2025-07-19T18:30:14.478+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 64.0 in stage 3.0 (TID 28). 9245 bytes result sent to driver
[2025-07-19T18:30:14.486+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/80/.1.delta.98b10a33-93ed-4cd5-994f-a4e64cf27929.TID34.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/80/1.delta
[2025-07-19T18:30:14.488+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=80),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/80] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/80/1.delta
[2025-07-19T18:30:14.489+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 80 (task 34, attempt 0, stage 3.0)
[2025-07-19T18:30:14.490+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 86.0 in stage 3.0 (TID 37) (8b44f3d35cfa, executor driver, partition 86, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.490+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 87.0 in stage 3.0 (TID 38) (8b44f3d35cfa, executor driver, partition 87, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.490+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 68.0 in stage 3.0 (TID 30) in 170 ms on 8b44f3d35cfa (executor driver) (19/200)
[2025-07-19T18:30:14.490+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 86.0 in stage 3.0 (TID 37)
[2025-07-19T18:30:14.490+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 64.0 in stage 3.0 (TID 28) in 188 ms on 8b44f3d35cfa (executor driver) (20/200)
[2025-07-19T18:30:14.490+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 87.0 in stage 3.0 (TID 38)
[2025-07-19T18:30:14.490+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.498+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.499+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T18:30:14.499+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 79 (task 33, attempt 0, stage 3.0)
[2025-07-19T18:30:14.502+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 79.0 in stage 3.0 (TID 33). 9301 bytes result sent to driver
[2025-07-19T18:30:14.502+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.502+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 88.0 in stage 3.0 (TID 39) (8b44f3d35cfa, executor driver, partition 88, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.503+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2025-07-19T18:30:14.503+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 79.0 in stage 3.0 (TID 33) in 164 ms on 8b44f3d35cfa (executor driver) (21/200)
[2025-07-19T18:30:14.503+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 88.0 in stage 3.0 (TID 39)
[2025-07-19T18:30:14.503+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 71 (task 31, attempt 0, stage 3.0)
[2025-07-19T18:30:14.504+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/83/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/83/.1.delta.acbc0a3b-8906-4a9b-8cd5-a918ba4dfb9d.TID36.tmp
[2025-07-19T18:30:14.507+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.508+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:14.508+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5b6bfcd6
[2025-07-19T18:30:14.509+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=86, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.509+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=86),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/86] for update
[2025-07-19T18:30:14.509+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 71.0 in stage 3.0 (TID 31). 9294 bytes result sent to driver
[2025-07-19T18:30:14.510+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.513+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 74 (task 32, attempt 0, stage 3.0)
[2025-07-19T18:30:14.514+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 90.0 in stage 3.0 (TID 40) (8b44f3d35cfa, executor driver, partition 90, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.514+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 90.0 in stage 3.0 (TID 40)
[2025-07-19T18:30:14.516+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 71.0 in stage 3.0 (TID 31) in 193 ms on 8b44f3d35cfa (executor driver) (22/200)
[2025-07-19T18:30:14.517+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 74.0 in stage 3.0 (TID 32). 9307 bytes result sent to driver
[2025-07-19T18:30:14.520+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/82/.1.delta.def2bc0d-f3bf-42e2-bd37-d7bbb01db0f5.TID35.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/82/1.delta
[2025-07-19T18:30:14.521+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 97.0 in stage 3.0 (TID 41) (8b44f3d35cfa, executor driver, partition 97, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.522+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 97.0 in stage 3.0 (TID 41)
[2025-07-19T18:30:14.522+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=82),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/82] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/82/1.delta
[2025-07-19T18:30:14.524+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@60e4ddc
[2025-07-19T18:30:14.524+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 74.0 in stage 3.0 (TID 32) in 195 ms on 8b44f3d35cfa (executor driver) (23/200)
[2025-07-19T18:30:14.525+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/86/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/86/.1.delta.827603a6-4570-48ac-bc99-4b35c2a1c212.TID37.tmp
[2025-07-19T18:30:14.526+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=88, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.526+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=88),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/88] for update
[2025-07-19T18:30:14.527+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 82 (task 35, attempt 0, stage 3.0)
[2025-07-19T18:30:14.527+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.527+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:14.530+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.532+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.532+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T18:30:14.533+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 80 (task 34, attempt 0, stage 3.0)
[2025-07-19T18:30:14.534+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 80.0 in stage 3.0 (TID 34). 9294 bytes result sent to driver
[2025-07-19T18:30:14.536+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 99.0 in stage 3.0 (TID 42) (8b44f3d35cfa, executor driver, partition 99, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.552+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54fc99c4
[2025-07-19T18:30:14.553+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=87, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.553+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=87),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/87] for update
[2025-07-19T18:30:14.553+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 99.0 in stage 3.0 (TID 42)
[2025-07-19T18:30:14.555+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.557+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:14.557+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 80.0 in stage 3.0 (TID 34) in 205 ms on 8b44f3d35cfa (executor driver) (24/200)
[2025-07-19T18:30:14.558+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a5cc06f
[2025-07-19T18:30:14.558+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=90, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.558+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=90),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/90] for update
[2025-07-19T18:30:14.564+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.566+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/88/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/88/.1.delta.a335bb93-6614-48ba-96f6-51b10fee370b.TID39.tmp
[2025-07-19T18:30:14.571+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.572+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5cd7d6
[2025-07-19T18:30:14.574+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=97, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.575+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=97),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/97] for update
[2025-07-19T18:30:14.579+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.583+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/83/.1.delta.acbc0a3b-8906-4a9b-8cd5-a918ba4dfb9d.TID36.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/83/1.delta
[2025-07-19T18:30:14.586+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=83),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/83] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/83/1.delta
[2025-07-19T18:30:14.586+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@cd8e51a
[2025-07-19T18:30:14.587+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/87/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/87/.1.delta.06019824-7898-4b2b-93dc-1287128fafa1.TID38.tmp
[2025-07-19T18:30:14.587+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 83 (task 36, attempt 0, stage 3.0)
[2025-07-19T18:30:14.588+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=99, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.589+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=99),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/99] for update
[2025-07-19T18:30:14.590+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.590+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/90/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/90/.1.delta.bba8c043-7b0a-4246-bffc-bcc53a7c991e.TID40.tmp
[2025-07-19T18:30:14.592+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 82 (task 35, attempt 0, stage 3.0)
[2025-07-19T18:30:14.595+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 82.0 in stage 3.0 (TID 35). 9351 bytes result sent to driver
[2025-07-19T18:30:14.595+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 100.0 in stage 3.0 (TID 43) (8b44f3d35cfa, executor driver, partition 100, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.596+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 100.0 in stage 3.0 (TID 43)
[2025-07-19T18:30:14.596+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 82.0 in stage 3.0 (TID 35) in 177 ms on 8b44f3d35cfa (executor driver) (25/200)
[2025-07-19T18:30:14.604+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.607+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:14.607+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/97/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/97/.1.delta.0861be5a-2238-48ad-b8f8-85ff79b4ab68.TID41.tmp
[2025-07-19T18:30:14.608+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/99/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/99/.1.delta.391808ce-2cff-48e4-bcd5-f1875fee2a33.TID42.tmp
[2025-07-19T18:30:14.610+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/86/.1.delta.827603a6-4570-48ac-bc99-4b35c2a1c212.TID37.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/86/1.delta
[2025-07-19T18:30:14.613+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=86),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/86] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/86/1.delta
[2025-07-19T18:30:14.614+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 86 (task 37, attempt 0, stage 3.0)
[2025-07-19T18:30:14.615+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d973aa7
[2025-07-19T18:30:14.617+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=100, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.617+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=100),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/100] for update
[2025-07-19T18:30:14.617+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.622+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 83 (task 36, attempt 0, stage 3.0)
[2025-07-19T18:30:14.625+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 83.0 in stage 3.0 (TID 36). 9296 bytes result sent to driver
[2025-07-19T18:30:14.626+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 103.0 in stage 3.0 (TID 44) (8b44f3d35cfa, executor driver, partition 103, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.628+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 103.0 in stage 3.0 (TID 44)
[2025-07-19T18:30:14.630+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/100/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/100/.1.delta.4975fe46-de76-4ed5-bc1d-672ad42df6bb.TID43.tmp
[2025-07-19T18:30:14.631+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 83.0 in stage 3.0 (TID 36) in 179 ms on 8b44f3d35cfa (executor driver) (26/200)
[2025-07-19T18:30:14.632+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.632+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:14.632+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/88/.1.delta.a335bb93-6614-48ba-96f6-51b10fee370b.TID39.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/88/1.delta
[2025-07-19T18:30:14.632+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=88),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/88] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/88/1.delta
[2025-07-19T18:30:14.633+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 88 (task 39, attempt 0, stage 3.0)
[2025-07-19T18:30:14.636+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/90/.1.delta.bba8c043-7b0a-4246-bffc-bcc53a7c991e.TID40.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/90/1.delta
[2025-07-19T18:30:14.637+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=90),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/90] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/90/1.delta
[2025-07-19T18:30:14.638+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 90 (task 40, attempt 0, stage 3.0)
[2025-07-19T18:30:14.640+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1691a990
[2025-07-19T18:30:14.641+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=103, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.642+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=103),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/103] for update
[2025-07-19T18:30:14.642+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/87/.1.delta.06019824-7898-4b2b-93dc-1287128fafa1.TID38.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/87/1.delta
[2025-07-19T18:30:14.643+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=87),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/87] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/87/1.delta
[2025-07-19T18:30:14.647+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 87 (task 38, attempt 0, stage 3.0)
[2025-07-19T18:30:14.648+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.653+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/97/.1.delta.0861be5a-2238-48ad-b8f8-85ff79b4ab68.TID41.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/97/1.delta
[2025-07-19T18:30:14.654+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=97),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/97] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/97/1.delta
[2025-07-19T18:30:14.654+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 86 (task 37, attempt 0, stage 3.0)
[2025-07-19T18:30:14.655+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 86.0 in stage 3.0 (TID 37). 9242 bytes result sent to driver
[2025-07-19T18:30:14.656+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 109.0 in stage 3.0 (TID 45) (8b44f3d35cfa, executor driver, partition 109, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.656+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/99/.1.delta.391808ce-2cff-48e4-bcd5-f1875fee2a33.TID42.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/99/1.delta
[2025-07-19T18:30:14.658+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=99),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/99] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/99/1.delta
[2025-07-19T18:30:14.659+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 97 (task 41, attempt 0, stage 3.0)
[2025-07-19T18:30:14.661+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 99 (task 42, attempt 0, stage 3.0)
[2025-07-19T18:30:14.662+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 86.0 in stage 3.0 (TID 37) in 174 ms on 8b44f3d35cfa (executor driver) (27/200)
[2025-07-19T18:30:14.662+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 109.0 in stage 3.0 (TID 45)
[2025-07-19T18:30:14.665+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 90 (task 40, attempt 0, stage 3.0)
[2025-07-19T18:30:14.666+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.667+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:14.667+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 90.0 in stage 3.0 (TID 40). 9241 bytes result sent to driver
[2025-07-19T18:30:14.668+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 110.0 in stage 3.0 (TID 46) (8b44f3d35cfa, executor driver, partition 110, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.668+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 110.0 in stage 3.0 (TID 46)
[2025-07-19T18:30:14.669+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 90.0 in stage 3.0 (TID 40) in 154 ms on 8b44f3d35cfa (executor driver) (28/200)
[2025-07-19T18:30:14.670+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/103/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/103/.1.delta.616fad9c-32e6-44b7-9a32-2dce1a9b31e2.TID44.tmp
[2025-07-19T18:30:14.672+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 88 (task 39, attempt 0, stage 3.0)
[2025-07-19T18:30:14.673+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d2a529
[2025-07-19T18:30:14.674+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 88.0 in stage 3.0 (TID 39). 9261 bytes result sent to driver
[2025-07-19T18:30:14.674+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=109, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.675+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=109),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/109] for update
[2025-07-19T18:30:14.675+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.677+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:14.678+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.679+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 87 (task 38, attempt 0, stage 3.0)
[2025-07-19T18:30:14.680+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 87.0 in stage 3.0 (TID 38). 9267 bytes result sent to driver
[2025-07-19T18:30:14.681+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 111.0 in stage 3.0 (TID 47) (8b44f3d35cfa, executor driver, partition 111, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.682+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 111.0 in stage 3.0 (TID 47)
[2025-07-19T18:30:14.683+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 117.0 in stage 3.0 (TID 48) (8b44f3d35cfa, executor driver, partition 117, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.683+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 87.0 in stage 3.0 (TID 38) in 197 ms on 8b44f3d35cfa (executor driver) (29/200)
[2025-07-19T18:30:14.685+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 88.0 in stage 3.0 (TID 39) in 181 ms on 8b44f3d35cfa (executor driver) (30/200)
[2025-07-19T18:30:14.687+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2c367e00
[2025-07-19T18:30:14.688+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=110, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.689+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=110),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/110] for update
[2025-07-19T18:30:14.692+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/100/.1.delta.4975fe46-de76-4ed5-bc1d-672ad42df6bb.TID43.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/100/1.delta
[2025-07-19T18:30:14.693+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=100),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/100] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/100/1.delta
[2025-07-19T18:30:14.695+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 117.0 in stage 3.0 (TID 48)
[2025-07-19T18:30:14.697+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 100 (task 43, attempt 0, stage 3.0)
[2025-07-19T18:30:14.702+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/109/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/109/.1.delta.44b7ffe4-73ce-4f54-9b83-50bbf07829ed.TID45.tmp
[2025-07-19T18:30:14.703+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.703+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:14.704+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.704+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 99 (task 42, attempt 0, stage 3.0)
[2025-07-19T18:30:14.704+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 99.0 in stage 3.0 (TID 42). 9253 bytes result sent to driver
[2025-07-19T18:30:14.704+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 126.0 in stage 3.0 (TID 49) (8b44f3d35cfa, executor driver, partition 126, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.705+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 97 (task 41, attempt 0, stage 3.0)
[2025-07-19T18:30:14.705+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 97.0 in stage 3.0 (TID 41). 9249 bytes result sent to driver
[2025-07-19T18:30:14.705+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 126.0 in stage 3.0 (TID 49)
[2025-07-19T18:30:14.706+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 130.0 in stage 3.0 (TID 50) (8b44f3d35cfa, executor driver, partition 130, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.706+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 130.0 in stage 3.0 (TID 50)
[2025-07-19T18:30:14.706+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 99.0 in stage 3.0 (TID 42) in 166 ms on 8b44f3d35cfa (executor driver) (31/200)
[2025-07-19T18:30:14.706+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 97.0 in stage 3.0 (TID 41) in 182 ms on 8b44f3d35cfa (executor driver) (32/200)
[2025-07-19T18:30:14.707+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.708+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:14.710+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.711+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:14.711+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/110/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/110/.1.delta.9b99c017-fd17-46d0-a859-f15624f73643.TID46.tmp
[2025-07-19T18:30:14.712+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.713+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a739748
[2025-07-19T18:30:14.713+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:14.714+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=111, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.714+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=111),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/111] for update
[2025-07-19T18:30:14.715+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/103/.1.delta.616fad9c-32e6-44b7-9a32-2dce1a9b31e2.TID44.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/103/1.delta
[2025-07-19T18:30:14.717+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=103),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/103] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/103/1.delta
[2025-07-19T18:30:14.718+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 103 (task 44, attempt 0, stage 3.0)
[2025-07-19T18:30:14.718+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@787bad11
[2025-07-19T18:30:14.719+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=117, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.720+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=117),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/117] for update
[2025-07-19T18:30:14.721+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.723+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.727+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73e9df57
[2025-07-19T18:30:14.728+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=130, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.728+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=130),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/130] for update
[2025-07-19T18:30:14.731+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.735+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/111/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/111/.1.delta.00de8f3b-9a13-4d05-bb81-8ede4b94e3af.TID47.tmp
[2025-07-19T18:30:14.737+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43e16a4f
[2025-07-19T18:30:14.737+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=126, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.737+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/117/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/117/.1.delta.10f48dee-42f7-469b-a944-56543e1bdab2.TID48.tmp
[2025-07-19T18:30:14.740+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=126),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/126] for update
[2025-07-19T18:30:14.742+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 100 (task 43, attempt 0, stage 3.0)
[2025-07-19T18:30:14.743+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 100.0 in stage 3.0 (TID 43). 9292 bytes result sent to driver
[2025-07-19T18:30:14.748+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 137.0 in stage 3.0 (TID 51) (8b44f3d35cfa, executor driver, partition 137, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.749+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/109/.1.delta.44b7ffe4-73ce-4f54-9b83-50bbf07829ed.TID45.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/109/1.delta
[2025-07-19T18:30:14.751+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 137.0 in stage 3.0 (TID 51)
[2025-07-19T18:30:14.751+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=109),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/109] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/109/1.delta
[2025-07-19T18:30:14.752+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 100.0 in stage 3.0 (TID 43) in 149 ms on 8b44f3d35cfa (executor driver) (33/200)
[2025-07-19T18:30:14.752+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 109 (task 45, attempt 0, stage 3.0)
[2025-07-19T18:30:14.754+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.756+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.757+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:14.758+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 103 (task 44, attempt 0, stage 3.0)
[2025-07-19T18:30:14.758+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/130/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/130/.1.delta.f15087fa-d46b-4726-abcc-8c17ae041c17.TID50.tmp
[2025-07-19T18:30:14.760+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/126/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/126/.1.delta.d08ca227-5112-44f5-ada4-af60b256f8e2.TID49.tmp
[2025-07-19T18:30:14.764+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a07a231
[2025-07-19T18:30:14.766+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=137, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.771+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=137),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/137] for update
[2025-07-19T18:30:14.773+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 103.0 in stage 3.0 (TID 44). 9303 bytes result sent to driver
[2025-07-19T18:30:14.774+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 142.0 in stage 3.0 (TID 52) (8b44f3d35cfa, executor driver, partition 142, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.775+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 142.0 in stage 3.0 (TID 52)
[2025-07-19T18:30:14.776+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 103.0 in stage 3.0 (TID 44) in 147 ms on 8b44f3d35cfa (executor driver) (34/200)
[2025-07-19T18:30:14.778+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.779+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.780+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:14.784+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b632d06
[2025-07-19T18:30:14.785+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=142, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.785+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=142),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/142] for update
[2025-07-19T18:30:14.786+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/110/.1.delta.9b99c017-fd17-46d0-a859-f15624f73643.TID46.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/110/1.delta
[2025-07-19T18:30:14.786+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=110),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/110] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/110/1.delta
[2025-07-19T18:30:14.787+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 110 (task 46, attempt 0, stage 3.0)
[2025-07-19T18:30:14.795+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/137/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/137/.1.delta.4fdc9147-a258-40e4-9977-601ff4d1f861.TID51.tmp
[2025-07-19T18:30:14.797+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.800+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 109 (task 45, attempt 0, stage 3.0)
[2025-07-19T18:30:14.803+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 109.0 in stage 3.0 (TID 45). 9290 bytes result sent to driver
[2025-07-19T18:30:14.804+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 144.0 in stage 3.0 (TID 53) (8b44f3d35cfa, executor driver, partition 144, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.806+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 144.0 in stage 3.0 (TID 53)
[2025-07-19T18:30:14.807+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 109.0 in stage 3.0 (TID 45) in 148 ms on 8b44f3d35cfa (executor driver) (35/200)
[2025-07-19T18:30:14.808+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/117/.1.delta.10f48dee-42f7-469b-a944-56543e1bdab2.TID48.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/117/1.delta
[2025-07-19T18:30:14.810+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=117),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/117] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/117/1.delta
[2025-07-19T18:30:14.811+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 117 (task 48, attempt 0, stage 3.0)
[2025-07-19T18:30:14.813+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.813+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T18:30:14.817+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/111/.1.delta.00de8f3b-9a13-4d05-bb81-8ede4b94e3af.TID47.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/111/1.delta
[2025-07-19T18:30:14.819+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=111),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/111] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/111/1.delta
[2025-07-19T18:30:14.820+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/142/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/142/.1.delta.5240480d-c919-429c-8592-c3814496d0e9.TID52.tmp
[2025-07-19T18:30:14.822+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 111 (task 47, attempt 0, stage 3.0)
[2025-07-19T18:30:14.824+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/130/.1.delta.f15087fa-d46b-4726-abcc-8c17ae041c17.TID50.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/130/1.delta
[2025-07-19T18:30:14.825+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=130),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/130] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/130/1.delta
[2025-07-19T18:30:14.826+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/126/.1.delta.d08ca227-5112-44f5-ada4-af60b256f8e2.TID49.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/126/1.delta
[2025-07-19T18:30:14.826+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=126),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/126] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/126/1.delta
[2025-07-19T18:30:14.826+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74923542
[2025-07-19T18:30:14.826+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 126 (task 49, attempt 0, stage 3.0)
[2025-07-19T18:30:14.826+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 130 (task 50, attempt 0, stage 3.0)
[2025-07-19T18:30:14.830+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=144, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.830+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=144),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/144] for update
[2025-07-19T18:30:14.832+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 110 (task 46, attempt 0, stage 3.0)
[2025-07-19T18:30:14.834+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 110.0 in stage 3.0 (TID 46). 9305 bytes result sent to driver
[2025-07-19T18:30:14.834+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 149.0 in stage 3.0 (TID 54) (8b44f3d35cfa, executor driver, partition 149, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.836+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 149.0 in stage 3.0 (TID 54)
[2025-07-19T18:30:14.837+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 110.0 in stage 3.0 (TID 46) in 169 ms on 8b44f3d35cfa (executor driver) (36/200)
[2025-07-19T18:30:14.838+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.840+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/137/.1.delta.4fdc9147-a258-40e4-9977-601ff4d1f861.TID51.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/137/1.delta
[2025-07-19T18:30:14.840+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=137),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/137] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/137/1.delta
[2025-07-19T18:30:14.840+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 137 (task 51, attempt 0, stage 3.0)
[2025-07-19T18:30:14.845+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.846+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:14.846+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 130 (task 50, attempt 0, stage 3.0)
[2025-07-19T18:30:14.847+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 117 (task 48, attempt 0, stage 3.0)
[2025-07-19T18:30:14.848+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 130.0 in stage 3.0 (TID 50). 9290 bytes result sent to driver
[2025-07-19T18:30:14.851+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 117.0 in stage 3.0 (TID 48). 9295 bytes result sent to driver
[2025-07-19T18:30:14.852+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 151.0 in stage 3.0 (TID 55) (8b44f3d35cfa, executor driver, partition 151, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.854+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 130.0 in stage 3.0 (TID 50) in 149 ms on 8b44f3d35cfa (executor driver) (37/200)
[2025-07-19T18:30:14.854+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2099e1b2
[2025-07-19T18:30:14.854+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=149, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.854+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=149),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/149] for update
[2025-07-19T18:30:14.854+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 151.0 in stage 3.0 (TID 55)
[2025-07-19T18:30:14.855+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/144/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/144/.1.delta.356a6f87-5b56-41cf-9871-9574d77bc124.TID53.tmp
[2025-07-19T18:30:14.856+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 152.0 in stage 3.0 (TID 56) (8b44f3d35cfa, executor driver, partition 152, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.857+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 152.0 in stage 3.0 (TID 56)
[2025-07-19T18:30:14.858+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 117.0 in stage 3.0 (TID 48) in 174 ms on 8b44f3d35cfa (executor driver) (38/200)
[2025-07-19T18:30:14.858+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 111 (task 47, attempt 0, stage 3.0)
[2025-07-19T18:30:14.859+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.859+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.859+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:14.860+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 111.0 in stage 3.0 (TID 47). 9296 bytes result sent to driver
[2025-07-19T18:30:14.860+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 162.0 in stage 3.0 (TID 57) (8b44f3d35cfa, executor driver, partition 162, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.861+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 162.0 in stage 3.0 (TID 57)
[2025-07-19T18:30:14.862+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 111.0 in stage 3.0 (TID 47) in 181 ms on 8b44f3d35cfa (executor driver) (39/200)
[2025-07-19T18:30:14.863+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.865+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:14.866+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 126 (task 49, attempt 0, stage 3.0)
[2025-07-19T18:30:14.867+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/142/.1.delta.5240480d-c919-429c-8592-c3814496d0e9.TID52.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/142/1.delta
[2025-07-19T18:30:14.867+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=142),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/142] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/142/1.delta
[2025-07-19T18:30:14.868+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 126.0 in stage 3.0 (TID 49). 9281 bytes result sent to driver
[2025-07-19T18:30:14.868+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.869+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:14.869+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 142 (task 52, attempt 0, stage 3.0)
[2025-07-19T18:30:14.869+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5103bd06
[2025-07-19T18:30:14.870+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 126.0 in stage 3.0 (TID 49) in 170 ms on 8b44f3d35cfa (executor driver) (40/200)
[2025-07-19T18:30:14.870+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=151, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.871+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 166.0 in stage 3.0 (TID 58) (8b44f3d35cfa, executor driver, partition 166, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.871+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=151),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/151] for update
[2025-07-19T18:30:14.871+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 166.0 in stage 3.0 (TID 58)
[2025-07-19T18:30:14.871+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 137 (task 51, attempt 0, stage 3.0)
[2025-07-19T18:30:14.871+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 137.0 in stage 3.0 (TID 51). 9296 bytes result sent to driver
[2025-07-19T18:30:14.872+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 174.0 in stage 3.0 (TID 59) (8b44f3d35cfa, executor driver, partition 174, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.872+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.872+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:14.873+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 137.0 in stage 3.0 (TID 51) in 125 ms on 8b44f3d35cfa (executor driver) (41/200)
[2025-07-19T18:30:14.873+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 174.0 in stage 3.0 (TID 59)
[2025-07-19T18:30:14.874+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/149/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/149/.1.delta.d4e5ef27-703b-499e-9c03-7206ba06976b.TID54.tmp
[2025-07-19T18:30:14.875+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.875+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4146139c
[2025-07-19T18:30:14.876+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=162, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.877+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 142 (task 52, attempt 0, stage 3.0)
[2025-07-19T18:30:14.878+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=162),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/162] for update
[2025-07-19T18:30:14.878+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 142.0 in stage 3.0 (TID 52). 9285 bytes result sent to driver
[2025-07-19T18:30:14.878+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 175.0 in stage 3.0 (TID 60) (8b44f3d35cfa, executor driver, partition 175, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.880+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.880+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.881+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:14.881+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 142.0 in stage 3.0 (TID 52) in 113 ms on 8b44f3d35cfa (executor driver) (42/200)
[2025-07-19T18:30:14.881+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 175.0 in stage 3.0 (TID 60)
[2025-07-19T18:30:14.882+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/151/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/151/.1.delta.a017c5ca-66c3-46aa-854d-c02741ffb8a9.TID55.tmp
[2025-07-19T18:30:14.883+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.883+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:14.885+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3efd3e95
[2025-07-19T18:30:14.885+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=152, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.886+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=152),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/152] for update
[2025-07-19T18:30:14.886+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.888+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/162/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/162/.1.delta.fb245962-71f6-4ae4-8327-7b1cbe4a3d0a.TID57.tmp
[2025-07-19T18:30:14.889+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/144/.1.delta.356a6f87-5b56-41cf-9871-9574d77bc124.TID53.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/144/1.delta
[2025-07-19T18:30:14.890+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=144),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/144] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/144/1.delta
[2025-07-19T18:30:14.892+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 144 (task 53, attempt 0, stage 3.0)
[2025-07-19T18:30:14.893+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ecac121
[2025-07-19T18:30:14.893+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=175, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.893+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=175),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/175] for update
[2025-07-19T18:30:14.894+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/152/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/152/.1.delta.a5340df0-74d7-47ad-b891-f7508cfb9b09.TID56.tmp
[2025-07-19T18:30:14.900+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7ff900fc
[2025-07-19T18:30:14.901+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=174, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.902+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=174),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/174] for update
[2025-07-19T18:30:14.903+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.903+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.908+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@616a8d7b
[2025-07-19T18:30:14.909+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/151/.1.delta.a017c5ca-66c3-46aa-854d-c02741ffb8a9.TID55.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/151/1.delta
[2025-07-19T18:30:14.909+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=151),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/151] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/151/1.delta
[2025-07-19T18:30:14.910+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=166, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.910+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=166),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/166] for update
[2025-07-19T18:30:14.911+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 151 (task 55, attempt 0, stage 3.0)
[2025-07-19T18:30:14.911+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/149/.1.delta.d4e5ef27-703b-499e-9c03-7206ba06976b.TID54.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/149/1.delta
[2025-07-19T18:30:14.911+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=149),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/149] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/149/1.delta
[2025-07-19T18:30:14.912+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 149 (task 54, attempt 0, stage 3.0)
[2025-07-19T18:30:14.915+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.919+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 144 (task 53, attempt 0, stage 3.0)
[2025-07-19T18:30:14.920+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 144.0 in stage 3.0 (TID 53). 9260 bytes result sent to driver
[2025-07-19T18:30:14.921+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/174/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/174/.1.delta.b3db6778-2ec9-4c2c-9bfc-fb7a4b1444e5.TID59.tmp
[2025-07-19T18:30:14.921+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/175/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/175/.1.delta.0d3b1c27-cf8b-4f59-b902-ba4d42f05005.TID60.tmp
[2025-07-19T18:30:14.922+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 176.0 in stage 3.0 (TID 61) (8b44f3d35cfa, executor driver, partition 176, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.927+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/162/.1.delta.fb245962-71f6-4ae4-8327-7b1cbe4a3d0a.TID57.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/162/1.delta
[2025-07-19T18:30:14.928+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=162),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/162] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/162/1.delta
[2025-07-19T18:30:14.928+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 162 (task 57, attempt 0, stage 3.0)
[2025-07-19T18:30:14.929+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 176.0 in stage 3.0 (TID 61)
[2025-07-19T18:30:14.931+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.932+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:14.933+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 144.0 in stage 3.0 (TID 53) in 131 ms on 8b44f3d35cfa (executor driver) (43/200)
[2025-07-19T18:30:14.935+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/166/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/166/.1.delta.0a265ddc-c9d6-4072-92c2-208190ab10ac.TID58.tmp
[2025-07-19T18:30:14.941+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/152/.1.delta.a5340df0-74d7-47ad-b891-f7508cfb9b09.TID56.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/152/1.delta
[2025-07-19T18:30:14.942+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=152),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/152] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/152/1.delta
[2025-07-19T18:30:14.942+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 152 (task 56, attempt 0, stage 3.0)
[2025-07-19T18:30:14.943+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 149 (task 54, attempt 0, stage 3.0)
[2025-07-19T18:30:14.944+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 149.0 in stage 3.0 (TID 54). 9263 bytes result sent to driver
[2025-07-19T18:30:14.945+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 178.0 in stage 3.0 (TID 62) (8b44f3d35cfa, executor driver, partition 178, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.946+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 178.0 in stage 3.0 (TID 62)
[2025-07-19T18:30:14.947+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 149.0 in stage 3.0 (TID 54) in 113 ms on 8b44f3d35cfa (executor driver) (44/200)
[2025-07-19T18:30:14.952+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.953+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:14.953+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 151 (task 55, attempt 0, stage 3.0)
[2025-07-19T18:30:14.954+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6cfca7ad
[2025-07-19T18:30:14.954+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=176, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.954+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 151.0 in stage 3.0 (TID 55). 9258 bytes result sent to driver
[2025-07-19T18:30:14.954+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=176),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/176] for update
[2025-07-19T18:30:14.954+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 183.0 in stage 3.0 (TID 63) (8b44f3d35cfa, executor driver, partition 183, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.956+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 183.0 in stage 3.0 (TID 63)
[2025-07-19T18:30:14.957+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.959+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 151.0 in stage 3.0 (TID 55) in 113 ms on 8b44f3d35cfa (executor driver) (45/200)
[2025-07-19T18:30:14.966+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 162 (task 57, attempt 0, stage 3.0)
[2025-07-19T18:30:14.967+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 162.0 in stage 3.0 (TID 57). 9240 bytes result sent to driver
[2025-07-19T18:30:14.973+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 184.0 in stage 3.0 (TID 64) (8b44f3d35cfa, executor driver, partition 184, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.974+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5b69dbe7
[2025-07-19T18:30:14.974+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 184.0 in stage 3.0 (TID 64)
[2025-07-19T18:30:14.974+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=178, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.976+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=178),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/178] for update
[2025-07-19T18:30:14.977+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/176/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/176/.1.delta.6a76afc7-61e6-4f6d-b287-3afb1d210be6.TID61.tmp
[2025-07-19T18:30:14.977+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 162.0 in stage 3.0 (TID 57) in 114 ms on 8b44f3d35cfa (executor driver) (46/200)
[2025-07-19T18:30:14.977+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.978+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:14.978+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Committed partition 152 (task 56, attempt 0, stage 3.0)
[2025-07-19T18:30:14.978+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Finished task 152.0 in stage 3.0 (TID 56). 9247 bytes result sent to driver
[2025-07-19T18:30:14.979+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.979+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Finished task 152.0 in stage 3.0 (TID 56) in 124 ms on 8b44f3d35cfa (executor driver) (47/200)
[2025-07-19T18:30:14.979+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO TaskSetManager: Starting task 185.0 in stage 3.0 (TID 65) (8b44f3d35cfa, executor driver, partition 185, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:14.979+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.979+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:14.979+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO Executor: Running task 185.0 in stage 3.0 (TID 65)
[2025-07-19T18:30:14.979+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:14.979+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:14.983+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4bfa0d05
[2025-07-19T18:30:14.984+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=184, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.985+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=184),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/184] for update
[2025-07-19T18:30:14.986+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/174/.1.delta.b3db6778-2ec9-4c2c-9bfc-fb7a4b1444e5.TID59.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/174/1.delta
[2025-07-19T18:30:14.987+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=174),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/174] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/174/1.delta
[2025-07-19T18:30:14.988+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 174 (task 59, attempt 0, stage 3.0)
[2025-07-19T18:30:14.988+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.992+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/175/.1.delta.0d3b1c27-cf8b-4f59-b902-ba4d42f05005.TID60.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/175/1.delta
[2025-07-19T18:30:14.994+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=175),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/175] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/175/1.delta
[2025-07-19T18:30:14.994+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ec051bc
[2025-07-19T18:30:14.994+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=185, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:14.995+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=185),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/185] for update
[2025-07-19T18:30:14.995+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 175 (task 60, attempt 0, stage 3.0)
[2025-07-19T18:30:14.995+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:14.997+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/178/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/178/.1.delta.bb6cd553-87a3-45e5-b69d-d713325f5645.TID62.tmp
[2025-07-19T18:30:14.997+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/166/.1.delta.0a265ddc-c9d6-4072-92c2-208190ab10ac.TID58.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/166/1.delta
[2025-07-19T18:30:14.997+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=166),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/166] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/166/1.delta
[2025-07-19T18:30:14.997+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO DataWritingSparkTask: Commit authorized for partition 166 (task 58, attempt 0, stage 3.0)
[2025-07-19T18:30:15.002+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/184/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/184/.1.delta.10d3032f-c10e-4632-83cf-be725869eeb3.TID64.tmp
[2025-07-19T18:30:15.002+0000] {subprocess.py:93} INFO - 25/07/19 18:30:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@753972f4
[2025-07-19T18:30:15.002+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=183, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.003+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=183),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/183] for update
[2025-07-19T18:30:15.006+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/185/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/185/.1.delta.0041da3e-5d34-4934-900d-8a6a57a8b8a9.TID65.tmp
[2025-07-19T18:30:15.007+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.016+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/176/.1.delta.6a76afc7-61e6-4f6d-b287-3afb1d210be6.TID61.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/176/1.delta
[2025-07-19T18:30:15.018+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=176),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/176] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/176/1.delta
[2025-07-19T18:30:15.019+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 176 (task 61, attempt 0, stage 3.0)
[2025-07-19T18:30:15.025+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/183/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/183/.1.delta.effb91b3-4aff-497f-9320-c8f80682a2d9.TID63.tmp
[2025-07-19T18:30:15.028+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 175 (task 60, attempt 0, stage 3.0)
[2025-07-19T18:30:15.029+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 175.0 in stage 3.0 (TID 60). 9243 bytes result sent to driver
[2025-07-19T18:30:15.030+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 187.0 in stage 3.0 (TID 66) (8b44f3d35cfa, executor driver, partition 187, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.030+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 175.0 in stage 3.0 (TID 60) in 150 ms on 8b44f3d35cfa (executor driver) (48/200)
[2025-07-19T18:30:15.031+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 187.0 in stage 3.0 (TID 66)
[2025-07-19T18:30:15.036+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/178/.1.delta.bb6cd553-87a3-45e5-b69d-d713325f5645.TID62.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/178/1.delta
[2025-07-19T18:30:15.036+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=178),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/178] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/178/1.delta
[2025-07-19T18:30:15.036+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 178 (task 62, attempt 0, stage 3.0)
[2025-07-19T18:30:15.041+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 166 (task 58, attempt 0, stage 3.0)
[2025-07-19T18:30:15.042+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 166.0 in stage 3.0 (TID 58). 9246 bytes result sent to driver
[2025-07-19T18:30:15.043+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/184/.1.delta.10d3032f-c10e-4632-83cf-be725869eeb3.TID64.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/184/1.delta
[2025-07-19T18:30:15.044+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=184),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/184] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/184/1.delta
[2025-07-19T18:30:15.044+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 188.0 in stage 3.0 (TID 67) (8b44f3d35cfa, executor driver, partition 188, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.046+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 184 (task 64, attempt 0, stage 3.0)
[2025-07-19T18:30:15.046+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.052+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T18:30:15.053+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 166.0 in stage 3.0 (TID 58) in 184 ms on 8b44f3d35cfa (executor driver) (49/200)
[2025-07-19T18:30:15.053+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 188.0 in stage 3.0 (TID 67)
[2025-07-19T18:30:15.053+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/185/.1.delta.0041da3e-5d34-4934-900d-8a6a57a8b8a9.TID65.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/185/1.delta
[2025-07-19T18:30:15.053+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=185),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/185] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/185/1.delta
[2025-07-19T18:30:15.054+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.054+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.054+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 185 (task 65, attempt 0, stage 3.0)
[2025-07-19T18:30:15.054+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 176 (task 61, attempt 0, stage 3.0)
[2025-07-19T18:30:15.054+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 176.0 in stage 3.0 (TID 61). 9238 bytes result sent to driver
[2025-07-19T18:30:15.055+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 191.0 in stage 3.0 (TID 68) (8b44f3d35cfa, executor driver, partition 191, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.055+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 176.0 in stage 3.0 (TID 61) in 132 ms on 8b44f3d35cfa (executor driver) (50/200)
[2025-07-19T18:30:15.056+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 191.0 in stage 3.0 (TID 68)
[2025-07-19T18:30:15.059+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.060+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.061+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 174 (task 59, attempt 0, stage 3.0)
[2025-07-19T18:30:15.063+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 174.0 in stage 3.0 (TID 59). 9246 bytes result sent to driver
[2025-07-19T18:30:15.066+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/183/.1.delta.effb91b3-4aff-497f-9320-c8f80682a2d9.TID63.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/183/1.delta
[2025-07-19T18:30:15.067+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=183),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/183] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/183/1.delta
[2025-07-19T18:30:15.067+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1813b7ee
[2025-07-19T18:30:15.067+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 183 (task 63, attempt 0, stage 3.0)
[2025-07-19T18:30:15.068+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 199.0 in stage 3.0 (TID 69) (8b44f3d35cfa, executor driver, partition 199, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.068+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=187, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.069+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=187),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/187] for update
[2025-07-19T18:30:15.072+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 174.0 in stage 3.0 (TID 59) in 198 ms on 8b44f3d35cfa (executor driver) (51/200)
[2025-07-19T18:30:15.073+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.073+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 199.0 in stage 3.0 (TID 69)
[2025-07-19T18:30:15.074+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.075+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T18:30:15.075+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/187/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/187/.1.delta.ae13773a-9f80-4c22-a9de-abba0121fa12.TID66.tmp
[2025-07-19T18:30:15.076+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@343a368
[2025-07-19T18:30:15.076+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 184 (task 64, attempt 0, stage 3.0)
[2025-07-19T18:30:15.077+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=191, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.077+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 185 (task 65, attempt 0, stage 3.0)
[2025-07-19T18:30:15.077+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=191),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/191] for update
[2025-07-19T18:30:15.078+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 184.0 in stage 3.0 (TID 64). 9230 bytes result sent to driver
[2025-07-19T18:30:15.086+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 185.0 in stage 3.0 (TID 65). 9234 bytes result sent to driver
[2025-07-19T18:30:15.087+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 70) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.089+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 0.0 in stage 3.0 (TID 70)
[2025-07-19T18:30:15.090+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@69614f5d
[2025-07-19T18:30:15.090+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 178 (task 62, attempt 0, stage 3.0)
[2025-07-19T18:30:15.090+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=188, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.091+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 184.0 in stage 3.0 (TID 64) in 121 ms on 8b44f3d35cfa (executor driver) (52/200)
[2025-07-19T18:30:15.092+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=188),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/188] for update
[2025-07-19T18:30:15.093+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 185.0 in stage 3.0 (TID 65) in 114 ms on 8b44f3d35cfa (executor driver) (53/200)
[2025-07-19T18:30:15.093+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 178.0 in stage 3.0 (TID 62). 9296 bytes result sent to driver
[2025-07-19T18:30:15.093+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.093+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 71) (8b44f3d35cfa, executor driver, partition 1, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.093+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:15.093+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 72) (8b44f3d35cfa, executor driver, partition 2, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.093+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.094+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.105+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 2.0 in stage 3.0 (TID 72)
[2025-07-19T18:30:15.108+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 1.0 in stage 3.0 (TID 71)
[2025-07-19T18:30:15.110+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.111+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.111+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@701b7f63
[2025-07-19T18:30:15.112+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=199, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.113+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=199),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/199] for update
[2025-07-19T18:30:15.113+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 178.0 in stage 3.0 (TID 62) in 165 ms on 8b44f3d35cfa (executor driver) (54/200)
[2025-07-19T18:30:15.113+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 183 (task 63, attempt 0, stage 3.0)
[2025-07-19T18:30:15.115+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.115+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/191/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/191/.1.delta.39de4e80-1884-41d7-ac93-36e50d7f4ad6.TID68.tmp
[2025-07-19T18:30:15.115+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.116+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:15.118+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 183.0 in stage 3.0 (TID 63). 9278 bytes result sent to driver
[2025-07-19T18:30:15.118+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 73) (8b44f3d35cfa, executor driver, partition 3, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.119+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 183.0 in stage 3.0 (TID 63) in 163 ms on 8b44f3d35cfa (executor driver) (55/200)
[2025-07-19T18:30:15.120+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 3.0 in stage 3.0 (TID 73)
[2025-07-19T18:30:15.121+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/188/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/188/.1.delta.391ae2ac-55fc-4e05-a495-495b6f3c4c6b.TID67.tmp
[2025-07-19T18:30:15.122+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1bf96ff5
[2025-07-19T18:30:15.122+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=2, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.123+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/2] for update
[2025-07-19T18:30:15.123+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.125+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.126+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.129+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/199/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/199/.1.delta.789838aa-13b8-44e4-b2db-215df69137ce.TID69.tmp
[2025-07-19T18:30:15.133+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/187/.1.delta.ae13773a-9f80-4c22-a9de-abba0121fa12.TID66.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/187/1.delta
[2025-07-19T18:30:15.135+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=187),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/187] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/187/1.delta
[2025-07-19T18:30:15.137+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 187 (task 66, attempt 0, stage 3.0)
[2025-07-19T18:30:15.141+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/2/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/2/.1.delta.40c4d0c6-f979-4024-8aae-adb8ec921eaa.TID72.tmp
[2025-07-19T18:30:15.152+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/188/.1.delta.391ae2ac-55fc-4e05-a495-495b6f3c4c6b.TID67.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/188/1.delta
[2025-07-19T18:30:15.153+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=188),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/188] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/188/1.delta
[2025-07-19T18:30:15.154+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 188 (task 67, attempt 0, stage 3.0)
[2025-07-19T18:30:15.156+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/0/_metadata/schema using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/0/_metadata/.schema.bfd3b841-07ab-4490-b8f5-53f088222918.TID70.tmp
[2025-07-19T18:30:15.157+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/191/.1.delta.39de4e80-1884-41d7-ac93-36e50d7f4ad6.TID68.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/191/1.delta
[2025-07-19T18:30:15.159+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=191),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/191] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/191/1.delta
[2025-07-19T18:30:15.159+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 191 (task 68, attempt 0, stage 3.0)
[2025-07-19T18:30:15.164+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 187 (task 66, attempt 0, stage 3.0)
[2025-07-19T18:30:15.165+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 187.0 in stage 3.0 (TID 66). 9296 bytes result sent to driver
[2025-07-19T18:30:15.167+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 187.0 in stage 3.0 (TID 66) in 139 ms on 8b44f3d35cfa (executor driver) (56/200)
[2025-07-19T18:30:15.168+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 74) (8b44f3d35cfa, executor driver, partition 4, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.168+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 4.0 in stage 3.0 (TID 74)
[2025-07-19T18:30:15.169+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.170+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.175+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 188 (task 67, attempt 0, stage 3.0)
[2025-07-19T18:30:15.179+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/199/.1.delta.789838aa-13b8-44e4-b2db-215df69137ce.TID69.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/199/1.delta
[2025-07-19T18:30:15.180+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=199),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/199] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/199/1.delta
[2025-07-19T18:30:15.183+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 199 (task 69, attempt 0, stage 3.0)
[2025-07-19T18:30:15.184+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 188.0 in stage 3.0 (TID 67). 9296 bytes result sent to driver
[2025-07-19T18:30:15.184+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 5.0 in stage 3.0 (TID 75) (8b44f3d35cfa, executor driver, partition 5, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.185+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/2/.1.delta.40c4d0c6-f979-4024-8aae-adb8ec921eaa.TID72.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/2/1.delta
[2025-07-19T18:30:15.185+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/2] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/2/1.delta
[2025-07-19T18:30:15.186+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 191 (task 68, attempt 0, stage 3.0)
[2025-07-19T18:30:15.186+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 188.0 in stage 3.0 (TID 67) in 139 ms on 8b44f3d35cfa (executor driver) (57/200)
[2025-07-19T18:30:15.186+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 191.0 in stage 3.0 (TID 68). 9320 bytes result sent to driver
[2025-07-19T18:30:15.186+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 5.0 in stage 3.0 (TID 75)
[2025-07-19T18:30:15.187+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 6.0 in stage 3.0 (TID 76) (8b44f3d35cfa, executor driver, partition 6, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.187+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 6.0 in stage 3.0 (TID 76)
[2025-07-19T18:30:15.188+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 2 (task 72, attempt 0, stage 3.0)
[2025-07-19T18:30:15.189+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 191.0 in stage 3.0 (TID 68) in 130 ms on 8b44f3d35cfa (executor driver) (58/200)
[2025-07-19T18:30:15.189+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.190+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.190+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.190+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.193+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 2 (task 72, attempt 0, stage 3.0)
[2025-07-19T18:30:15.194+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 2.0 in stage 3.0 (TID 72). 6200 bytes result sent to driver
[2025-07-19T18:30:15.194+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 7.0 in stage 3.0 (TID 77) (8b44f3d35cfa, executor driver, partition 7, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.195+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 7.0 in stage 3.0 (TID 77)
[2025-07-19T18:30:15.195+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 72) in 100 ms on 8b44f3d35cfa (executor driver) (59/200)
[2025-07-19T18:30:15.203+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 199 (task 69, attempt 0, stage 3.0)
[2025-07-19T18:30:15.204+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 199.0 in stage 3.0 (TID 69). 9301 bytes result sent to driver
[2025-07-19T18:30:15.205+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.205+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.207+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 9.0 in stage 3.0 (TID 78) (8b44f3d35cfa, executor driver, partition 9, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.207+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 9.0 in stage 3.0 (TID 78)
[2025-07-19T18:30:15.209+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 199.0 in stage 3.0 (TID 69) in 140 ms on 8b44f3d35cfa (executor driver) (60/200)
[2025-07-19T18:30:15.210+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.211+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.213+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/0/_metadata/.schema.bfd3b841-07ab-4490-b8f5-53f088222918.TID70.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/0/_metadata/schema
[2025-07-19T18:30:15.213+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f95bf8c
[2025-07-19T18:30:15.214+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=0, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.214+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/0] for update
[2025-07-19T18:30:15.214+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.220+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@57300a6b
[2025-07-19T18:30:15.221+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=9, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.230+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/9] for update
[2025-07-19T18:30:15.232+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/0/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/0/.1.delta.97b6e34e-e42b-4cd0-9515-0c876c9b354f.TID70.tmp
[2025-07-19T18:30:15.232+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.233+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73e5fc70
[2025-07-19T18:30:15.233+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=7, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.233+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/7] for update
[2025-07-19T18:30:15.234+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.244+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5029457
[2025-07-19T18:30:15.247+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/9/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/9/.1.delta.a879a1f8-e30d-40b8-addf-9131acd72d8c.TID78.tmp
[2025-07-19T18:30:15.247+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=6, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.256+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/6] for update
[2025-07-19T18:30:15.257+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.257+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a9e4496
[2025-07-19T18:30:15.258+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=5, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.259+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/5] for update
[2025-07-19T18:30:15.272+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.276+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/7/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/7/.1.delta.f861bc19-d39a-4717-acd3-83efc02bb317.TID77.tmp
[2025-07-19T18:30:15.277+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/6/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/6/.1.delta.a03d1653-f58a-414c-91af-eb3a076c1e8f.TID76.tmp
[2025-07-19T18:30:15.278+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@88a6f34
[2025-07-19T18:30:15.282+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=4, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.283+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/4] for update
[2025-07-19T18:30:15.283+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/5/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/5/.1.delta.bb39943a-70a0-4958-9365-abaacc58ac19.TID75.tmp
[2025-07-19T18:30:15.284+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.284+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b094e6e
[2025-07-19T18:30:15.284+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=3, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.285+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/3] for update
[2025-07-19T18:30:15.285+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.289+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1f94be9e
[2025-07-19T18:30:15.292+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=1, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.293+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/1] for update
[2025-07-19T18:30:15.295+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/4/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/4/.1.delta.c616543b-7e72-4686-8d8e-2079f5028b8a.TID74.tmp
[2025-07-19T18:30:15.297+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.298+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/0/.1.delta.97b6e34e-e42b-4cd0-9515-0c876c9b354f.TID70.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/0/1.delta
[2025-07-19T18:30:15.300+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/3/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/3/.1.delta.0e3bcb5e-6832-4ffc-b4f2-8097536206fb.TID73.tmp
[2025-07-19T18:30:15.301+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/0] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/0/1.delta
[2025-07-19T18:30:15.301+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 70, attempt 0, stage 3.0)
[2025-07-19T18:30:15.301+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/9/.1.delta.a879a1f8-e30d-40b8-addf-9131acd72d8c.TID78.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/9/1.delta
[2025-07-19T18:30:15.302+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/9] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/9/1.delta
[2025-07-19T18:30:15.303+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 9 (task 78, attempt 0, stage 3.0)
[2025-07-19T18:30:15.306+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/1/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/1/.1.delta.22fa5b9d-69e2-4837-82a5-36215ebcc001.TID71.tmp
[2025-07-19T18:30:15.309+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 0 (task 70, attempt 0, stage 3.0)
[2025-07-19T18:30:15.309+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 9 (task 78, attempt 0, stage 3.0)
[2025-07-19T18:30:15.316+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 0.0 in stage 3.0 (TID 70). 6243 bytes result sent to driver
[2025-07-19T18:30:15.317+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 11.0 in stage 3.0 (TID 79) (8b44f3d35cfa, executor driver, partition 11, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.318+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 11.0 in stage 3.0 (TID 79)
[2025-07-19T18:30:15.321+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/7/.1.delta.f861bc19-d39a-4717-acd3-83efc02bb317.TID77.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/7/1.delta
[2025-07-19T18:30:15.322+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 70) in 232 ms on 8b44f3d35cfa (executor driver) (61/200)
[2025-07-19T18:30:15.323+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/7] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/7/1.delta
[2025-07-19T18:30:15.326+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 9.0 in stage 3.0 (TID 78). 6286 bytes result sent to driver
[2025-07-19T18:30:15.327+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 7 (task 77, attempt 0, stage 3.0)
[2025-07-19T18:30:15.328+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 12.0 in stage 3.0 (TID 80) (8b44f3d35cfa, executor driver, partition 12, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.328+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 12.0 in stage 3.0 (TID 80)
[2025-07-19T18:30:15.328+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 9.0 in stage 3.0 (TID 78) in 118 ms on 8b44f3d35cfa (executor driver) (62/200)
[2025-07-19T18:30:15.328+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/6/.1.delta.a03d1653-f58a-414c-91af-eb3a076c1e8f.TID76.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/6/1.delta
[2025-07-19T18:30:15.330+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/6] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/6/1.delta
[2025-07-19T18:30:15.331+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.332+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:15.335+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 6 (task 76, attempt 0, stage 3.0)
[2025-07-19T18:30:15.335+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/5/.1.delta.bb39943a-70a0-4958-9365-abaacc58ac19.TID75.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/5/1.delta
[2025-07-19T18:30:15.336+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/5] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/5/1.delta
[2025-07-19T18:30:15.337+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.337+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:15.338+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 5 (task 75, attempt 0, stage 3.0)
[2025-07-19T18:30:15.338+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 7 (task 77, attempt 0, stage 3.0)
[2025-07-19T18:30:15.339+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 7.0 in stage 3.0 (TID 77). 6243 bytes result sent to driver
[2025-07-19T18:30:15.339+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c59d253
[2025-07-19T18:30:15.340+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 6 (task 76, attempt 0, stage 3.0)
[2025-07-19T18:30:15.342+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 13.0 in stage 3.0 (TID 81) (8b44f3d35cfa, executor driver, partition 13, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.342+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=11, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.342+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=11),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/11] for update
[2025-07-19T18:30:15.342+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 7.0 in stage 3.0 (TID 77) in 136 ms on 8b44f3d35cfa (executor driver) (63/200)
[2025-07-19T18:30:15.342+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 5 (task 75, attempt 0, stage 3.0)
[2025-07-19T18:30:15.343+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 5.0 in stage 3.0 (TID 75). 6243 bytes result sent to driver
[2025-07-19T18:30:15.343+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 6.0 in stage 3.0 (TID 76). 6243 bytes result sent to driver
[2025-07-19T18:30:15.344+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.344+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 13.0 in stage 3.0 (TID 81)
[2025-07-19T18:30:15.344+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 14.0 in stage 3.0 (TID 82) (8b44f3d35cfa, executor driver, partition 14, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.345+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 15.0 in stage 3.0 (TID 83) (8b44f3d35cfa, executor driver, partition 15, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.345+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@61c66ad6
[2025-07-19T18:30:15.345+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 14.0 in stage 3.0 (TID 82)
[2025-07-19T18:30:15.345+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.345+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.346+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=12, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.346+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=12),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/12] for update
[2025-07-19T18:30:15.346+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 5.0 in stage 3.0 (TID 75) in 157 ms on 8b44f3d35cfa (executor driver) (64/200)
[2025-07-19T18:30:15.346+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/4/.1.delta.c616543b-7e72-4686-8d8e-2079f5028b8a.TID74.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/4/1.delta
[2025-07-19T18:30:15.346+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/4] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/4/1.delta
[2025-07-19T18:30:15.346+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 6.0 in stage 3.0 (TID 76) in 155 ms on 8b44f3d35cfa (executor driver) (65/200)
[2025-07-19T18:30:15.347+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.347+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 15.0 in stage 3.0 (TID 83)
[2025-07-19T18:30:15.347+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/11/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/11/.1.delta.c31802b5-9cb9-4cb9-8991-0aa2516ef540.TID79.tmp
[2025-07-19T18:30:15.347+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 4 (task 74, attempt 0, stage 3.0)
[2025-07-19T18:30:15.350+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.351+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.356+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.356+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.357+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/3/.1.delta.0e3bcb5e-6832-4ffc-b4f2-8097536206fb.TID73.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/3/1.delta
[2025-07-19T18:30:15.358+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4314e9be
[2025-07-19T18:30:15.358+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/3] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/3/1.delta
[2025-07-19T18:30:15.358+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/1/.1.delta.22fa5b9d-69e2-4837-82a5-36215ebcc001.TID71.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/1/1.delta
[2025-07-19T18:30:15.359+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/1] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/1/1.delta
[2025-07-19T18:30:15.359+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=13, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.362+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=13),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/13] for update
[2025-07-19T18:30:15.362+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 4 (task 74, attempt 0, stage 3.0)
[2025-07-19T18:30:15.363+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 1 (task 71, attempt 0, stage 3.0)
[2025-07-19T18:30:15.363+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 3 (task 73, attempt 0, stage 3.0)
[2025-07-19T18:30:15.365+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/12/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/12/.1.delta.18aa6cc9-0344-45f9-9a25-a03f47eb9c23.TID80.tmp
[2025-07-19T18:30:15.368+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.370+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 4.0 in stage 3.0 (TID 74). 6243 bytes result sent to driver
[2025-07-19T18:30:15.370+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 18.0 in stage 3.0 (TID 84) (8b44f3d35cfa, executor driver, partition 18, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.370+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@976e89d
[2025-07-19T18:30:15.371+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 74) in 199 ms on 8b44f3d35cfa (executor driver) (66/200)
[2025-07-19T18:30:15.372+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 18.0 in stage 3.0 (TID 84)
[2025-07-19T18:30:15.373+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=14, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.373+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 3 (task 73, attempt 0, stage 3.0)
[2025-07-19T18:30:15.373+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 3.0 in stage 3.0 (TID 73). 6243 bytes result sent to driver
[2025-07-19T18:30:15.373+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 1 (task 71, attempt 0, stage 3.0)
[2025-07-19T18:30:15.373+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 1.0 in stage 3.0 (TID 71). 6243 bytes result sent to driver
[2025-07-19T18:30:15.373+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 19.0 in stage 3.0 (TID 85) (8b44f3d35cfa, executor driver, partition 19, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.373+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=14),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/14] for update
[2025-07-19T18:30:15.374+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.374+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.374+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 21.0 in stage 3.0 (TID 86) (8b44f3d35cfa, executor driver, partition 21, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.374+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 71) in 282 ms on 8b44f3d35cfa (executor driver) (67/200)
[2025-07-19T18:30:15.374+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 73) in 254 ms on 8b44f3d35cfa (executor driver) (68/200)
[2025-07-19T18:30:15.374+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 19.0 in stage 3.0 (TID 85)
[2025-07-19T18:30:15.374+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.374+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 21.0 in stage 3.0 (TID 86)
[2025-07-19T18:30:15.374+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/13/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/13/.1.delta.37e2e33c-08a3-4d3d-9bf7-d88c2d82c8a8.TID81.tmp
[2025-07-19T18:30:15.377+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.378+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.379+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@77e72ec9
[2025-07-19T18:30:15.379+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=15, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.379+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=15),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/15] for update
[2025-07-19T18:30:15.380+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.380+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.380+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.386+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@481c2f5f
[2025-07-19T18:30:15.387+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=19, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.388+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=19),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/19] for update
[2025-07-19T18:30:15.394+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@336ee8ba
[2025-07-19T18:30:15.394+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/15/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/15/.1.delta.e9e415d1-5671-4920-8170-f1f3f837d989.TID83.tmp
[2025-07-19T18:30:15.395+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/14/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/14/.1.delta.926832f1-c2c5-47df-ad4d-e2dcb4710dd9.TID82.tmp
[2025-07-19T18:30:15.395+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.395+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=21, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.395+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=21),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/21] for update
[2025-07-19T18:30:15.397+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/12/.1.delta.18aa6cc9-0344-45f9-9a25-a03f47eb9c23.TID80.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/12/1.delta
[2025-07-19T18:30:15.397+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=12),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/12] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/12/1.delta
[2025-07-19T18:30:15.397+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 12 (task 80, attempt 0, stage 3.0)
[2025-07-19T18:30:15.398+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/11/.1.delta.c31802b5-9cb9-4cb9-8991-0aa2516ef540.TID79.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/11/1.delta
[2025-07-19T18:30:15.398+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=11),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/11] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/11/1.delta
[2025-07-19T18:30:15.399+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 11 (task 79, attempt 0, stage 3.0)
[2025-07-19T18:30:15.399+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ccaaa68
[2025-07-19T18:30:15.403+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.404+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=18, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.406+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=18),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/18] for update
[2025-07-19T18:30:15.409+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.410+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 12 (task 80, attempt 0, stage 3.0)
[2025-07-19T18:30:15.410+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 12.0 in stage 3.0 (TID 80). 6243 bytes result sent to driver
[2025-07-19T18:30:15.410+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 11 (task 79, attempt 0, stage 3.0)
[2025-07-19T18:30:15.410+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 22.0 in stage 3.0 (TID 87) (8b44f3d35cfa, executor driver, partition 22, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.410+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 12.0 in stage 3.0 (TID 80) in 90 ms on 8b44f3d35cfa (executor driver) (69/200)
[2025-07-19T18:30:15.411+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 22.0 in stage 3.0 (TID 87)
[2025-07-19T18:30:15.411+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 11.0 in stage 3.0 (TID 79). 6243 bytes result sent to driver
[2025-07-19T18:30:15.411+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.411+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.411+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 23.0 in stage 3.0 (TID 88) (8b44f3d35cfa, executor driver, partition 23, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.413+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 11.0 in stage 3.0 (TID 79) in 97 ms on 8b44f3d35cfa (executor driver) (70/200)
[2025-07-19T18:30:15.413+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/19/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/19/.1.delta.0495d8b3-1dab-44b2-85e5-63c40357a8f7.TID85.tmp
[2025-07-19T18:30:15.413+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 23.0 in stage 3.0 (TID 88)
[2025-07-19T18:30:15.415+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/13/.1.delta.37e2e33c-08a3-4d3d-9bf7-d88c2d82c8a8.TID81.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/13/1.delta
[2025-07-19T18:30:15.416+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=13),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/13] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/13/1.delta
[2025-07-19T18:30:15.416+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.417+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:15.418+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/21/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/21/.1.delta.9669b1d1-5038-4269-86b7-9f26240b52ff.TID86.tmp
[2025-07-19T18:30:15.418+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/18/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/18/.1.delta.c61ede8a-d38d-4a15-ad5c-67ab3b5acdc0.TID84.tmp
[2025-07-19T18:30:15.418+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 13 (task 81, attempt 0, stage 3.0)
[2025-07-19T18:30:15.419+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c30a2ed
[2025-07-19T18:30:15.419+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=22, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.421+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=22),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/22] for update
[2025-07-19T18:30:15.428+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.429+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@44969bb6
[2025-07-19T18:30:15.429+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=23, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.429+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=23),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/23] for update
[2025-07-19T18:30:15.430+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.438+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 13 (task 81, attempt 0, stage 3.0)
[2025-07-19T18:30:15.440+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 13.0 in stage 3.0 (TID 81). 6243 bytes result sent to driver
[2025-07-19T18:30:15.442+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 24.0 in stage 3.0 (TID 89) (8b44f3d35cfa, executor driver, partition 24, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.443+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/15/.1.delta.e9e415d1-5671-4920-8170-f1f3f837d989.TID83.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/15/1.delta
[2025-07-19T18:30:15.443+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 24.0 in stage 3.0 (TID 89)
[2025-07-19T18:30:15.443+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 13.0 in stage 3.0 (TID 81) in 112 ms on 8b44f3d35cfa (executor driver) (71/200)
[2025-07-19T18:30:15.443+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=15),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/15] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/15/1.delta
[2025-07-19T18:30:15.443+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 15 (task 83, attempt 0, stage 3.0)
[2025-07-19T18:30:15.443+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.443+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.447+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/22/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/22/.1.delta.1af23867-3455-4a51-996d-6b3ef64c5ef8.TID87.tmp
[2025-07-19T18:30:15.448+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68563ec8
[2025-07-19T18:30:15.448+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=24, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.448+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=24),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/24] for update
[2025-07-19T18:30:15.449+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 15 (task 83, attempt 0, stage 3.0)
[2025-07-19T18:30:15.450+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 15.0 in stage 3.0 (TID 83). 6243 bytes result sent to driver
[2025-07-19T18:30:15.451+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 15.0 in stage 3.0 (TID 83) in 116 ms on 8b44f3d35cfa (executor driver) (72/200)
[2025-07-19T18:30:15.452+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.455+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 25.0 in stage 3.0 (TID 90) (8b44f3d35cfa, executor driver, partition 25, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.457+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/14/.1.delta.926832f1-c2c5-47df-ad4d-e2dcb4710dd9.TID82.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/14/1.delta
[2025-07-19T18:30:15.457+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=14),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/14] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/14/1.delta
[2025-07-19T18:30:15.458+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 25.0 in stage 3.0 (TID 90)
[2025-07-19T18:30:15.459+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 14 (task 82, attempt 0, stage 3.0)
[2025-07-19T18:30:15.459+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/23/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/23/.1.delta.bdefd61f-2382-4465-8084-be71cf218bf2.TID88.tmp
[2025-07-19T18:30:15.462+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/19/.1.delta.0495d8b3-1dab-44b2-85e5-63c40357a8f7.TID85.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/19/1.delta
[2025-07-19T18:30:15.464+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=19),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/19] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/19/1.delta
[2025-07-19T18:30:15.465+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 19 (task 85, attempt 0, stage 3.0)
[2025-07-19T18:30:15.466+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/18/.1.delta.c61ede8a-d38d-4a15-ad5c-67ab3b5acdc0.TID84.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/18/1.delta
[2025-07-19T18:30:15.466+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=18),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/18] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/18/1.delta
[2025-07-19T18:30:15.467+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 18 (task 84, attempt 0, stage 3.0)
[2025-07-19T18:30:15.469+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.470+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:15.471+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 14 (task 82, attempt 0, stage 3.0)
[2025-07-19T18:30:15.471+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 19 (task 85, attempt 0, stage 3.0)
[2025-07-19T18:30:15.471+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 19.0 in stage 3.0 (TID 85). 6243 bytes result sent to driver
[2025-07-19T18:30:15.471+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 26.0 in stage 3.0 (TID 91) (8b44f3d35cfa, executor driver, partition 26, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.471+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 14.0 in stage 3.0 (TID 82). 6243 bytes result sent to driver
[2025-07-19T18:30:15.471+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 19.0 in stage 3.0 (TID 85) in 101 ms on 8b44f3d35cfa (executor driver) (73/200)
[2025-07-19T18:30:15.471+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 18 (task 84, attempt 0, stage 3.0)
[2025-07-19T18:30:15.471+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 26.0 in stage 3.0 (TID 91)
[2025-07-19T18:30:15.471+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 27.0 in stage 3.0 (TID 92) (8b44f3d35cfa, executor driver, partition 27, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.471+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 18.0 in stage 3.0 (TID 84). 6243 bytes result sent to driver
[2025-07-19T18:30:15.472+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 27.0 in stage 3.0 (TID 92)
[2025-07-19T18:30:15.472+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 14.0 in stage 3.0 (TID 82) in 140 ms on 8b44f3d35cfa (executor driver) (74/200)
[2025-07-19T18:30:15.476+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/24/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/24/.1.delta.a78e9d69-4d70-4ea1-83eb-92db5ff83c98.TID89.tmp
[2025-07-19T18:30:15.477+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c69ac51
[2025-07-19T18:30:15.478+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=25, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.480+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=25),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/25] for update
[2025-07-19T18:30:15.480+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.483+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.484+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 28.0 in stage 3.0 (TID 93) (8b44f3d35cfa, executor driver, partition 28, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.484+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/21/.1.delta.9669b1d1-5038-4269-86b7-9f26240b52ff.TID86.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/21/1.delta
[2025-07-19T18:30:15.484+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=21),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/21] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/21/1.delta
[2025-07-19T18:30:15.484+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 18.0 in stage 3.0 (TID 84) in 113 ms on 8b44f3d35cfa (executor driver) (75/200)
[2025-07-19T18:30:15.484+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.484+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 28.0 in stage 3.0 (TID 93)
[2025-07-19T18:30:15.484+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 21 (task 86, attempt 0, stage 3.0)
[2025-07-19T18:30:15.484+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.484+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.485+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@83c85a3
[2025-07-19T18:30:15.485+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=26, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.485+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=26),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/26] for update
[2025-07-19T18:30:15.485+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.485+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.485+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.487+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 21 (task 86, attempt 0, stage 3.0)
[2025-07-19T18:30:15.488+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 21.0 in stage 3.0 (TID 86). 6243 bytes result sent to driver
[2025-07-19T18:30:15.489+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 29.0 in stage 3.0 (TID 94) (8b44f3d35cfa, executor driver, partition 29, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.489+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 29.0 in stage 3.0 (TID 94)
[2025-07-19T18:30:15.490+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 21.0 in stage 3.0 (TID 86) in 119 ms on 8b44f3d35cfa (executor driver) (76/200)
[2025-07-19T18:30:15.491+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/25/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/25/.1.delta.05cf1905-9351-4b99-92fd-eee66d38cce3.TID90.tmp
[2025-07-19T18:30:15.494+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3a6413dd
[2025-07-19T18:30:15.494+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.495+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=27, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.495+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=27),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/27] for update
[2025-07-19T18:30:15.496+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:15.498+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/26/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/26/.1.delta.5e715990-79ed-468a-bfbe-60560b495d5f.TID91.tmp
[2025-07-19T18:30:15.499+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.501+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/22/.1.delta.1af23867-3455-4a51-996d-6b3ef64c5ef8.TID87.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/22/1.delta
[2025-07-19T18:30:15.501+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=22),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/22] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/22/1.delta
[2025-07-19T18:30:15.503+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 22 (task 87, attempt 0, stage 3.0)
[2025-07-19T18:30:15.504+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ff0fe88
[2025-07-19T18:30:15.505+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=28, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.505+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=28),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/28] for update
[2025-07-19T18:30:15.506+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.511+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 22 (task 87, attempt 0, stage 3.0)
[2025-07-19T18:30:15.512+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 22.0 in stage 3.0 (TID 87). 6243 bytes result sent to driver
[2025-07-19T18:30:15.514+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/27/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/27/.1.delta.5f7867db-baf6-4edc-b215-ec65a79b1a0b.TID92.tmp
[2025-07-19T18:30:15.518+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 34.0 in stage 3.0 (TID 95) (8b44f3d35cfa, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.518+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d8bf3eb
[2025-07-19T18:30:15.519+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 34.0 in stage 3.0 (TID 95)
[2025-07-19T18:30:15.519+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 22.0 in stage 3.0 (TID 87) in 105 ms on 8b44f3d35cfa (executor driver) (77/200)
[2025-07-19T18:30:15.519+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=29, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.519+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=29),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/29] for update
[2025-07-19T18:30:15.519+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.519+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.519+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.520+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/23/.1.delta.bdefd61f-2382-4465-8084-be71cf218bf2.TID88.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/23/1.delta
[2025-07-19T18:30:15.520+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=23),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/23] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/23/1.delta
[2025-07-19T18:30:15.520+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 23 (task 88, attempt 0, stage 3.0)
[2025-07-19T18:30:15.522+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 23 (task 88, attempt 0, stage 3.0)
[2025-07-19T18:30:15.524+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/28/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/28/.1.delta.114cf8d6-3343-464a-a2a4-a058abe0b5b9.TID93.tmp
[2025-07-19T18:30:15.524+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/24/.1.delta.a78e9d69-4d70-4ea1-83eb-92db5ff83c98.TID89.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/24/1.delta
[2025-07-19T18:30:15.525+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f071081
[2025-07-19T18:30:15.525+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=24),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/24] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/24/1.delta
[2025-07-19T18:30:15.526+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=34, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.527+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=34),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/34] for update
[2025-07-19T18:30:15.528+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 23.0 in stage 3.0 (TID 88). 6286 bytes result sent to driver
[2025-07-19T18:30:15.528+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 24 (task 89, attempt 0, stage 3.0)
[2025-07-19T18:30:15.528+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/29/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/29/.1.delta.cda77975-f5c5-4dbd-8311-a1a7d3bd0320.TID94.tmp
[2025-07-19T18:30:15.528+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.535+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 35.0 in stage 3.0 (TID 96) (8b44f3d35cfa, executor driver, partition 35, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.536+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 23.0 in stage 3.0 (TID 88) in 124 ms on 8b44f3d35cfa (executor driver) (78/200)
[2025-07-19T18:30:15.538+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 35.0 in stage 3.0 (TID 96)
[2025-07-19T18:30:15.538+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/26/.1.delta.5e715990-79ed-468a-bfbe-60560b495d5f.TID91.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/26/1.delta
[2025-07-19T18:30:15.539+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=26),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/26] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/26/1.delta
[2025-07-19T18:30:15.539+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 26 (task 91, attempt 0, stage 3.0)
[2025-07-19T18:30:15.539+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 24 (task 89, attempt 0, stage 3.0)
[2025-07-19T18:30:15.540+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 24.0 in stage 3.0 (TID 89). 6243 bytes result sent to driver
[2025-07-19T18:30:15.542+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.544+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T18:30:15.545+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/25/.1.delta.05cf1905-9351-4b99-92fd-eee66d38cce3.TID90.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/25/1.delta
[2025-07-19T18:30:15.548+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=25),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/25] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/25/1.delta
[2025-07-19T18:30:15.548+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 25 (task 90, attempt 0, stage 3.0)
[2025-07-19T18:30:15.549+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 26 (task 91, attempt 0, stage 3.0)
[2025-07-19T18:30:15.550+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/34/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/34/.1.delta.b2244812-55cf-4c75-8940-5aa6b18779d8.TID95.tmp
[2025-07-19T18:30:15.551+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 36.0 in stage 3.0 (TID 97) (8b44f3d35cfa, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.551+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 36.0 in stage 3.0 (TID 97)
[2025-07-19T18:30:15.552+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 26.0 in stage 3.0 (TID 91). 6243 bytes result sent to driver
[2025-07-19T18:30:15.553+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 37.0 in stage 3.0 (TID 98) (8b44f3d35cfa, executor driver, partition 37, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.555+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 24.0 in stage 3.0 (TID 89) in 109 ms on 8b44f3d35cfa (executor driver) (79/200)
[2025-07-19T18:30:15.557+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.558+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.559+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/27/.1.delta.5f7867db-baf6-4edc-b215-ec65a79b1a0b.TID92.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/27/1.delta
[2025-07-19T18:30:15.559+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=27),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/27] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/27/1.delta
[2025-07-19T18:30:15.560+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 26.0 in stage 3.0 (TID 91) in 81 ms on 8b44f3d35cfa (executor driver) (80/200)
[2025-07-19T18:30:15.560+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 37.0 in stage 3.0 (TID 98)
[2025-07-19T18:30:15.561+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 27 (task 92, attempt 0, stage 3.0)
[2025-07-19T18:30:15.562+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 25 (task 90, attempt 0, stage 3.0)
[2025-07-19T18:30:15.563+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 25.0 in stage 3.0 (TID 90). 6243 bytes result sent to driver
[2025-07-19T18:30:15.564+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@773f78c4
[2025-07-19T18:30:15.564+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=35, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.565+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 38.0 in stage 3.0 (TID 99) (8b44f3d35cfa, executor driver, partition 38, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.567+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=35),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/35] for update
[2025-07-19T18:30:15.568+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 38.0 in stage 3.0 (TID 99)
[2025-07-19T18:30:15.568+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 25.0 in stage 3.0 (TID 90) in 102 ms on 8b44f3d35cfa (executor driver) (81/200)
[2025-07-19T18:30:15.569+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.569+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.570+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.570+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/28/.1.delta.114cf8d6-3343-464a-a2a4-a058abe0b5b9.TID93.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/28/1.delta
[2025-07-19T18:30:15.570+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=28),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/28] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/28/1.delta
[2025-07-19T18:30:15.570+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 28 (task 93, attempt 0, stage 3.0)
[2025-07-19T18:30:15.574+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 27 (task 92, attempt 0, stage 3.0)
[2025-07-19T18:30:15.575+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.576+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.577+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4aa73d9f
[2025-07-19T18:30:15.578+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 27.0 in stage 3.0 (TID 92). 6243 bytes result sent to driver
[2025-07-19T18:30:15.579+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=36, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.580+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=36),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/36] for update
[2025-07-19T18:30:15.580+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 27.0 in stage 3.0 (TID 92) in 96 ms on 8b44f3d35cfa (executor driver) (82/200)
[2025-07-19T18:30:15.581+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 28 (task 93, attempt 0, stage 3.0)
[2025-07-19T18:30:15.581+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 28.0 in stage 3.0 (TID 93). 6243 bytes result sent to driver
[2025-07-19T18:30:15.582+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 39.0 in stage 3.0 (TID 100) (8b44f3d35cfa, executor driver, partition 39, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.582+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/35/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/35/.1.delta.fa70c5c2-6d83-4bc7-991e-d67f793b3437.TID96.tmp
[2025-07-19T18:30:15.583+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a450c39
[2025-07-19T18:30:15.583+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 41.0 in stage 3.0 (TID 101) (8b44f3d35cfa, executor driver, partition 41, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.584+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 28.0 in stage 3.0 (TID 93) in 98 ms on 8b44f3d35cfa (executor driver) (83/200)
[2025-07-19T18:30:15.586+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=38, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.587+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=38),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/38] for update
[2025-07-19T18:30:15.590+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 41.0 in stage 3.0 (TID 101)
[2025-07-19T18:30:15.591+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 39.0 in stage 3.0 (TID 100)
[2025-07-19T18:30:15.592+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/29/.1.delta.cda77975-f5c5-4dbd-8311-a1a7d3bd0320.TID94.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/29/1.delta
[2025-07-19T18:30:15.592+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.593+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.593+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.593+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.593+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=29),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/29] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/29/1.delta
[2025-07-19T18:30:15.593+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.594+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 29 (task 94, attempt 0, stage 3.0)
[2025-07-19T18:30:15.594+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6523c86b
[2025-07-19T18:30:15.594+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=37, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.594+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=37),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/37] for update
[2025-07-19T18:30:15.594+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.596+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.597+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7fa88697
[2025-07-19T18:30:15.597+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=39, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.598+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=39),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/39] for update
[2025-07-19T18:30:15.598+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 29 (task 94, attempt 0, stage 3.0)
[2025-07-19T18:30:15.599+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 29.0 in stage 3.0 (TID 94). 6243 bytes result sent to driver
[2025-07-19T18:30:15.600+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.600+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/34/.1.delta.b2244812-55cf-4c75-8940-5aa6b18779d8.TID95.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/34/1.delta
[2025-07-19T18:30:15.600+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=34),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/34] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/34/1.delta
[2025-07-19T18:30:15.601+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 43.0 in stage 3.0 (TID 102) (8b44f3d35cfa, executor driver, partition 43, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.601+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/38/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/38/.1.delta.923e19be-1938-49c1-9b28-811ea123cfc3.TID99.tmp
[2025-07-19T18:30:15.601+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 43.0 in stage 3.0 (TID 102)
[2025-07-19T18:30:15.601+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 29.0 in stage 3.0 (TID 94) in 100 ms on 8b44f3d35cfa (executor driver) (84/200)
[2025-07-19T18:30:15.602+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 34 (task 95, attempt 0, stage 3.0)
[2025-07-19T18:30:15.602+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/36/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/36/.1.delta.dafefb23-f25a-45e3-b559-12825d1d5816.TID97.tmp
[2025-07-19T18:30:15.603+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.603+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.604+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6312b830
[2025-07-19T18:30:15.605+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=41, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.605+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=41),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/41] for update
[2025-07-19T18:30:15.606+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 34 (task 95, attempt 0, stage 3.0)
[2025-07-19T18:30:15.606+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.606+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/37/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/37/.1.delta.672890e7-09de-44f7-918e-7fa49aaf4334.TID98.tmp
[2025-07-19T18:30:15.606+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/39/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/39/.1.delta.d6302be5-5166-4a51-98e4-9387edd3aa02.TID100.tmp
[2025-07-19T18:30:15.606+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 34.0 in stage 3.0 (TID 95). 6243 bytes result sent to driver
[2025-07-19T18:30:15.607+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b4a3505
[2025-07-19T18:30:15.607+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=43, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.608+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=43),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/43] for update
[2025-07-19T18:30:15.609+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 44.0 in stage 3.0 (TID 103) (8b44f3d35cfa, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.610+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.611+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 34.0 in stage 3.0 (TID 95) in 98 ms on 8b44f3d35cfa (executor driver) (85/200)
[2025-07-19T18:30:15.613+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/35/.1.delta.fa70c5c2-6d83-4bc7-991e-d67f793b3437.TID96.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/35/1.delta
[2025-07-19T18:30:15.614+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=35),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/35] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/35/1.delta
[2025-07-19T18:30:15.615+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 35 (task 96, attempt 0, stage 3.0)
[2025-07-19T18:30:15.617+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 44.0 in stage 3.0 (TID 103)
[2025-07-19T18:30:15.617+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/41/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/41/.1.delta.ada3d162-2fa2-48a0-873e-2d936ad5daf2.TID101.tmp
[2025-07-19T18:30:15.618+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 35 (task 96, attempt 0, stage 3.0)
[2025-07-19T18:30:15.619+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 35.0 in stage 3.0 (TID 96). 6243 bytes result sent to driver
[2025-07-19T18:30:15.620+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 45.0 in stage 3.0 (TID 104) (8b44f3d35cfa, executor driver, partition 45, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.620+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 35.0 in stage 3.0 (TID 96) in 93 ms on 8b44f3d35cfa (executor driver) (86/200)
[2025-07-19T18:30:15.621+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.621+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.621+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/43/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/43/.1.delta.51c04e37-1b91-44a0-9653-bdd2d721d0f3.TID102.tmp
[2025-07-19T18:30:15.622+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 45.0 in stage 3.0 (TID 104)
[2025-07-19T18:30:15.624+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.625+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.630+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/36/.1.delta.dafefb23-f25a-45e3-b559-12825d1d5816.TID97.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/36/1.delta
[2025-07-19T18:30:15.631+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=36),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/36] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/36/1.delta
[2025-07-19T18:30:15.632+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 36 (task 97, attempt 0, stage 3.0)
[2025-07-19T18:30:15.635+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/38/.1.delta.923e19be-1938-49c1-9b28-811ea123cfc3.TID99.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/38/1.delta
[2025-07-19T18:30:15.635+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=38),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/38] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/38/1.delta
[2025-07-19T18:30:15.636+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@397606ea
[2025-07-19T18:30:15.636+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=44, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.636+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 38 (task 99, attempt 0, stage 3.0)
[2025-07-19T18:30:15.637+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=44),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/44] for update
[2025-07-19T18:30:15.638+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.640+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 36 (task 97, attempt 0, stage 3.0)
[2025-07-19T18:30:15.641+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/37/.1.delta.672890e7-09de-44f7-918e-7fa49aaf4334.TID98.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/37/1.delta
[2025-07-19T18:30:15.641+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 38 (task 99, attempt 0, stage 3.0)
[2025-07-19T18:30:15.641+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=37),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/37] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/37/1.delta
[2025-07-19T18:30:15.642+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 36.0 in stage 3.0 (TID 97). 6243 bytes result sent to driver
[2025-07-19T18:30:15.642+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 38.0 in stage 3.0 (TID 99). 6243 bytes result sent to driver
[2025-07-19T18:30:15.643+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/39/.1.delta.d6302be5-5166-4a51-98e4-9387edd3aa02.TID100.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/39/1.delta
[2025-07-19T18:30:15.644+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 46.0 in stage 3.0 (TID 105) (8b44f3d35cfa, executor driver, partition 46, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.644+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=39),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/39] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/39/1.delta
[2025-07-19T18:30:15.644+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 49.0 in stage 3.0 (TID 106) (8b44f3d35cfa, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.645+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 37 (task 98, attempt 0, stage 3.0)
[2025-07-19T18:30:15.645+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 46.0 in stage 3.0 (TID 105)
[2025-07-19T18:30:15.646+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 39 (task 100, attempt 0, stage 3.0)
[2025-07-19T18:30:15.646+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 49.0 in stage 3.0 (TID 106)
[2025-07-19T18:30:15.647+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 36.0 in stage 3.0 (TID 97) in 103 ms on 8b44f3d35cfa (executor driver) (87/200)
[2025-07-19T18:30:15.647+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2addcb8d
[2025-07-19T18:30:15.649+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=45, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.649+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=45),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/45] for update
[2025-07-19T18:30:15.651+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 38.0 in stage 3.0 (TID 99) in 91 ms on 8b44f3d35cfa (executor driver) (88/200)
[2025-07-19T18:30:15.652+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.653+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.655+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/41/.1.delta.ada3d162-2fa2-48a0-873e-2d936ad5daf2.TID101.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/41/1.delta
[2025-07-19T18:30:15.657+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=41),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/41] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/41/1.delta
[2025-07-19T18:30:15.658+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 41 (task 101, attempt 0, stage 3.0)
[2025-07-19T18:30:15.659+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.660+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@162f2222
[2025-07-19T18:30:15.661+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=49, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.661+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=49),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/49] for update
[2025-07-19T18:30:15.662+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.662+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 37 (task 98, attempt 0, stage 3.0)
[2025-07-19T18:30:15.663+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.663+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/44/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/44/.1.delta.e8e31150-41a1-4ea7-b822-bea112bdb766.TID103.tmp
[2025-07-19T18:30:15.664+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.664+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 37.0 in stage 3.0 (TID 98). 6243 bytes result sent to driver
[2025-07-19T18:30:15.664+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/43/.1.delta.51c04e37-1b91-44a0-9653-bdd2d721d0f3.TID102.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/43/1.delta
[2025-07-19T18:30:15.665+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=43),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/43] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/43/1.delta
[2025-07-19T18:30:15.665+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/45/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/45/.1.delta.8a1a0f97-cca9-4353-b3c3-2f695ba42533.TID104.tmp
[2025-07-19T18:30:15.666+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 50.0 in stage 3.0 (TID 107) (8b44f3d35cfa, executor driver, partition 50, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.666+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 50.0 in stage 3.0 (TID 107)
[2025-07-19T18:30:15.666+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 39 (task 100, attempt 0, stage 3.0)
[2025-07-19T18:30:15.666+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.666+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.667+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 39.0 in stage 3.0 (TID 100). 6243 bytes result sent to driver
[2025-07-19T18:30:15.667+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 37.0 in stage 3.0 (TID 98) in 110 ms on 8b44f3d35cfa (executor driver) (89/200)
[2025-07-19T18:30:15.667+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 51.0 in stage 3.0 (TID 108) (8b44f3d35cfa, executor driver, partition 51, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.667+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 43 (task 102, attempt 0, stage 3.0)
[2025-07-19T18:30:15.667+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6f77c088
[2025-07-19T18:30:15.668+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 41 (task 101, attempt 0, stage 3.0)
[2025-07-19T18:30:15.669+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=46, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.670+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 41.0 in stage 3.0 (TID 101). 6286 bytes result sent to driver
[2025-07-19T18:30:15.672+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 43 (task 102, attempt 0, stage 3.0)
[2025-07-19T18:30:15.672+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 51.0 in stage 3.0 (TID 108)
[2025-07-19T18:30:15.672+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=46),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/46] for update
[2025-07-19T18:30:15.675+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/49/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/49/.1.delta.828337ea-3cf8-41bf-a019-619e23774788.TID106.tmp
[2025-07-19T18:30:15.678+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 39.0 in stage 3.0 (TID 100) in 102 ms on 8b44f3d35cfa (executor driver) (90/200)
[2025-07-19T18:30:15.679+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 41.0 in stage 3.0 (TID 101) in 104 ms on 8b44f3d35cfa (executor driver) (91/200)
[2025-07-19T18:30:15.680+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 43.0 in stage 3.0 (TID 102). 6286 bytes result sent to driver
[2025-07-19T18:30:15.680+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 52.0 in stage 3.0 (TID 109) (8b44f3d35cfa, executor driver, partition 52, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.681+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 53.0 in stage 3.0 (TID 110) (8b44f3d35cfa, executor driver, partition 53, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.681+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 43.0 in stage 3.0 (TID 102) in 90 ms on 8b44f3d35cfa (executor driver) (92/200)
[2025-07-19T18:30:15.682+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 52.0 in stage 3.0 (TID 109)
[2025-07-19T18:30:15.682+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 53.0 in stage 3.0 (TID 110)
[2025-07-19T18:30:15.682+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.683+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.683+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.684+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.684+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.684+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.685+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.685+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d6facef
[2025-07-19T18:30:15.686+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=50, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.686+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=50),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/50] for update
[2025-07-19T18:30:15.687+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.689+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/46/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/46/.1.delta.066b6fdc-5248-4fe5-b424-710599cf42a0.TID105.tmp
[2025-07-19T18:30:15.693+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/44/.1.delta.e8e31150-41a1-4ea7-b822-bea112bdb766.TID103.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/44/1.delta
[2025-07-19T18:30:15.695+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=44),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/44] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/44/1.delta
[2025-07-19T18:30:15.697+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 44 (task 103, attempt 0, stage 3.0)
[2025-07-19T18:30:15.698+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/45/.1.delta.8a1a0f97-cca9-4353-b3c3-2f695ba42533.TID104.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/45/1.delta
[2025-07-19T18:30:15.699+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=45),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/45] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/45/1.delta
[2025-07-19T18:30:15.700+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ce747b3
[2025-07-19T18:30:15.700+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 45 (task 104, attempt 0, stage 3.0)
[2025-07-19T18:30:15.702+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=52, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.704+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=52),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/52] for update
[2025-07-19T18:30:15.707+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 44 (task 103, attempt 0, stage 3.0)
[2025-07-19T18:30:15.707+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 44.0 in stage 3.0 (TID 103). 6243 bytes result sent to driver
[2025-07-19T18:30:15.708+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 55.0 in stage 3.0 (TID 111) (8b44f3d35cfa, executor driver, partition 55, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.708+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 44.0 in stage 3.0 (TID 103) in 94 ms on 8b44f3d35cfa (executor driver) (93/200)
[2025-07-19T18:30:15.708+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 55.0 in stage 3.0 (TID 111)
[2025-07-19T18:30:15.708+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/50/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/50/.1.delta.5fedf113-feed-4769-967e-fa97565dd4b7.TID107.tmp
[2025-07-19T18:30:15.709+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 45 (task 104, attempt 0, stage 3.0)
[2025-07-19T18:30:15.710+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5bddcdb5
[2025-07-19T18:30:15.711+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=51, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.712+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=51),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/51] for update
[2025-07-19T18:30:15.712+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 45.0 in stage 3.0 (TID 104). 6243 bytes result sent to driver
[2025-07-19T18:30:15.713+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.713+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 56.0 in stage 3.0 (TID 112) (8b44f3d35cfa, executor driver, partition 56, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.713+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 45.0 in stage 3.0 (TID 104) in 85 ms on 8b44f3d35cfa (executor driver) (94/200)
[2025-07-19T18:30:15.714+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 56.0 in stage 3.0 (TID 112)
[2025-07-19T18:30:15.715+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.716+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.716+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.716+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.717+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:15.718+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/49/.1.delta.828337ea-3cf8-41bf-a019-619e23774788.TID106.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/49/1.delta
[2025-07-19T18:30:15.719+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=49),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/49] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/49/1.delta
[2025-07-19T18:30:15.719+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 49 (task 106, attempt 0, stage 3.0)
[2025-07-19T18:30:15.720+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5689b95a
[2025-07-19T18:30:15.720+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=55, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.721+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=55),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/55] for update
[2025-07-19T18:30:15.721+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.721+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/51/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/51/.1.delta.143d663f-e82c-4cac-bde1-e9966cda727d.TID108.tmp
[2025-07-19T18:30:15.722+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/52/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/52/.1.delta.cbea2993-3e7e-4b09-9a27-44328ba7102c.TID109.tmp
[2025-07-19T18:30:15.722+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2cda8abf
[2025-07-19T18:30:15.723+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=53, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.724+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=53),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/53] for update
[2025-07-19T18:30:15.725+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 49 (task 106, attempt 0, stage 3.0)
[2025-07-19T18:30:15.725+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 49.0 in stage 3.0 (TID 106). 6243 bytes result sent to driver
[2025-07-19T18:30:15.726+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 57.0 in stage 3.0 (TID 113) (8b44f3d35cfa, executor driver, partition 57, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.727+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.730+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/55/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/55/.1.delta.4682322f-0ed6-4f88-8823-256137dd0c53.TID111.tmp
[2025-07-19T18:30:15.730+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/46/.1.delta.066b6fdc-5248-4fe5-b424-710599cf42a0.TID105.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/46/1.delta
[2025-07-19T18:30:15.731+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=46),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/46] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/46/1.delta
[2025-07-19T18:30:15.731+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 46 (task 105, attempt 0, stage 3.0)
[2025-07-19T18:30:15.731+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 49.0 in stage 3.0 (TID 106) in 87 ms on 8b44f3d35cfa (executor driver) (95/200)
[2025-07-19T18:30:15.732+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7fb05d7
[2025-07-19T18:30:15.733+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 57.0 in stage 3.0 (TID 113)
[2025-07-19T18:30:15.734+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=56, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.734+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=56),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/56] for update
[2025-07-19T18:30:15.735+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.735+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.738+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.742+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/53/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/53/.1.delta.ad4e176b-4507-476a-8df8-ee7a6e1f1d81.TID110.tmp
[2025-07-19T18:30:15.744+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/50/.1.delta.5fedf113-feed-4769-967e-fa97565dd4b7.TID107.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/50/1.delta
[2025-07-19T18:30:15.747+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=50),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/50] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/50/1.delta
[2025-07-19T18:30:15.749+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 50 (task 107, attempt 0, stage 3.0)
[2025-07-19T18:30:15.749+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52e79031
[2025-07-19T18:30:15.750+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=57, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.754+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=57),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/57] for update
[2025-07-19T18:30:15.755+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 46 (task 105, attempt 0, stage 3.0)
[2025-07-19T18:30:15.756+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 46.0 in stage 3.0 (TID 105). 6243 bytes result sent to driver
[2025-07-19T18:30:15.757+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 50 (task 107, attempt 0, stage 3.0)
[2025-07-19T18:30:15.758+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.759+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 59.0 in stage 3.0 (TID 114) (8b44f3d35cfa, executor driver, partition 59, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.760+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 50.0 in stage 3.0 (TID 107). 6243 bytes result sent to driver
[2025-07-19T18:30:15.761+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 60.0 in stage 3.0 (TID 115) (8b44f3d35cfa, executor driver, partition 60, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.762+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 60.0 in stage 3.0 (TID 115)
[2025-07-19T18:30:15.762+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 46.0 in stage 3.0 (TID 105) in 109 ms on 8b44f3d35cfa (executor driver) (96/200)
[2025-07-19T18:30:15.763+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 59.0 in stage 3.0 (TID 114)
[2025-07-19T18:30:15.764+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/52/.1.delta.cbea2993-3e7e-4b09-9a27-44328ba7102c.TID109.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/52/1.delta
[2025-07-19T18:30:15.765+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=52),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/52] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/52/1.delta
[2025-07-19T18:30:15.767+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/51/.1.delta.143d663f-e82c-4cac-bde1-e9966cda727d.TID108.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/51/1.delta
[2025-07-19T18:30:15.768+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=51),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/51] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/51/1.delta
[2025-07-19T18:30:15.769+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 50.0 in stage 3.0 (TID 107) in 98 ms on 8b44f3d35cfa (executor driver) (97/200)
[2025-07-19T18:30:15.769+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 52 (task 109, attempt 0, stage 3.0)
[2025-07-19T18:30:15.769+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 51 (task 108, attempt 0, stage 3.0)
[2025-07-19T18:30:15.770+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.770+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.771+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.771+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.772+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/56/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/56/.1.delta.b0bbc5a8-ee73-4652-9f29-43953fef03ba.TID112.tmp
[2025-07-19T18:30:15.772+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 52 (task 109, attempt 0, stage 3.0)
[2025-07-19T18:30:15.772+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 52.0 in stage 3.0 (TID 109). 6200 bytes result sent to driver
[2025-07-19T18:30:15.773+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3432651e
[2025-07-19T18:30:15.773+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 61.0 in stage 3.0 (TID 116) (8b44f3d35cfa, executor driver, partition 61, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.773+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 61.0 in stage 3.0 (TID 116)
[2025-07-19T18:30:15.773+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 51 (task 108, attempt 0, stage 3.0)
[2025-07-19T18:30:15.774+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 52.0 in stage 3.0 (TID 109) in 93 ms on 8b44f3d35cfa (executor driver) (98/200)
[2025-07-19T18:30:15.774+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=59, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.774+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 51.0 in stage 3.0 (TID 108). 6200 bytes result sent to driver
[2025-07-19T18:30:15.774+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=59),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/59] for update
[2025-07-19T18:30:15.775+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/57/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/57/.1.delta.dfc0f9a0-44b8-4d2a-b904-61f197b3db2b.TID113.tmp
[2025-07-19T18:30:15.775+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 65.0 in stage 3.0 (TID 117) (8b44f3d35cfa, executor driver, partition 65, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.776+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 65.0 in stage 3.0 (TID 117)
[2025-07-19T18:30:15.777+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 51.0 in stage 3.0 (TID 108) in 111 ms on 8b44f3d35cfa (executor driver) (99/200)
[2025-07-19T18:30:15.778+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/55/.1.delta.4682322f-0ed6-4f88-8823-256137dd0c53.TID111.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/55/1.delta
[2025-07-19T18:30:15.779+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=55),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/55] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/55/1.delta
[2025-07-19T18:30:15.779+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.780+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.780+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@11f70aff
[2025-07-19T18:30:15.781+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 55 (task 111, attempt 0, stage 3.0)
[2025-07-19T18:30:15.782+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=60, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.782+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=60),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/60] for update
[2025-07-19T18:30:15.783+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.784+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.785+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.785+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.786+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/53/.1.delta.ad4e176b-4507-476a-8df8-ee7a6e1f1d81.TID110.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/53/1.delta
[2025-07-19T18:30:15.787+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=53),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/53] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/53/1.delta
[2025-07-19T18:30:15.787+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 55 (task 111, attempt 0, stage 3.0)
[2025-07-19T18:30:15.787+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 53 (task 110, attempt 0, stage 3.0)
[2025-07-19T18:30:15.793+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23c5527d
[2025-07-19T18:30:15.795+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/59/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/59/.1.delta.2a2b90e4-4a5d-4e7d-acb6-b900b9de43f7.TID114.tmp
[2025-07-19T18:30:15.796+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 55.0 in stage 3.0 (TID 111). 6286 bytes result sent to driver
[2025-07-19T18:30:15.797+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=61, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.798+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=61),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/61] for update
[2025-07-19T18:30:15.799+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 67.0 in stage 3.0 (TID 118) (8b44f3d35cfa, executor driver, partition 67, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.800+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 67.0 in stage 3.0 (TID 118)
[2025-07-19T18:30:15.801+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 55.0 in stage 3.0 (TID 111) in 95 ms on 8b44f3d35cfa (executor driver) (100/200)
[2025-07-19T18:30:15.802+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.802+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.803+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 53 (task 110, attempt 0, stage 3.0)
[2025-07-19T18:30:15.803+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@70d0e397
[2025-07-19T18:30:15.804+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=65, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.804+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 53.0 in stage 3.0 (TID 110). 6200 bytes result sent to driver
[2025-07-19T18:30:15.804+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=65),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/65] for update
[2025-07-19T18:30:15.805+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 53.0 in stage 3.0 (TID 110) in 126 ms on 8b44f3d35cfa (executor driver) (101/200)
[2025-07-19T18:30:15.805+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.805+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/60/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/60/.1.delta.1f274fd3-ce00-4f06-8da1-cf32dd283764.TID115.tmp
[2025-07-19T18:30:15.806+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/56/.1.delta.b0bbc5a8-ee73-4652-9f29-43953fef03ba.TID112.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/56/1.delta
[2025-07-19T18:30:15.806+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=56),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/56] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/56/1.delta
[2025-07-19T18:30:15.806+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1aa8a574
[2025-07-19T18:30:15.807+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=67, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.808+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.809+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=67),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/67] for update
[2025-07-19T18:30:15.809+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.812+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 56 (task 112, attempt 0, stage 3.0)
[2025-07-19T18:30:15.815+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/61/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/61/.1.delta.ad9f076d-22ee-4f53-900f-266842868ccc.TID116.tmp
[2025-07-19T18:30:15.816+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 69.0 in stage 3.0 (TID 119) (8b44f3d35cfa, executor driver, partition 69, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.818+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/57/.1.delta.dfc0f9a0-44b8-4d2a-b904-61f197b3db2b.TID113.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/57/1.delta
[2025-07-19T18:30:15.820+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 69.0 in stage 3.0 (TID 119)
[2025-07-19T18:30:15.825+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=57),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/57] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/57/1.delta
[2025-07-19T18:30:15.826+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 57 (task 113, attempt 0, stage 3.0)
[2025-07-19T18:30:15.827+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.827+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:15.828+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 56 (task 112, attempt 0, stage 3.0)
[2025-07-19T18:30:15.829+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/67/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/67/.1.delta.2c6530f2-dc67-4cd5-8070-cf864b194522.TID118.tmp
[2025-07-19T18:30:15.829+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 57 (task 113, attempt 0, stage 3.0)
[2025-07-19T18:30:15.829+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 56.0 in stage 3.0 (TID 112). 6243 bytes result sent to driver
[2025-07-19T18:30:15.830+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 57.0 in stage 3.0 (TID 113). 6243 bytes result sent to driver
[2025-07-19T18:30:15.830+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/65/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/65/.1.delta.46739af2-b0aa-4c23-a348-5eb9f287114b.TID117.tmp
[2025-07-19T18:30:15.830+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 70.0 in stage 3.0 (TID 120) (8b44f3d35cfa, executor driver, partition 70, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.830+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 70.0 in stage 3.0 (TID 120)
[2025-07-19T18:30:15.830+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 72.0 in stage 3.0 (TID 121) (8b44f3d35cfa, executor driver, partition 72, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.831+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 57.0 in stage 3.0 (TID 113) in 105 ms on 8b44f3d35cfa (executor driver) (102/200)
[2025-07-19T18:30:15.831+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 72.0 in stage 3.0 (TID 121)
[2025-07-19T18:30:15.831+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 56.0 in stage 3.0 (TID 112) in 126 ms on 8b44f3d35cfa (executor driver) (103/200)
[2025-07-19T18:30:15.831+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.835+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@658af748
[2025-07-19T18:30:15.836+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T18:30:15.837+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.837+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=69, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.838+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=69),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/69] for update
[2025-07-19T18:30:15.839+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T18:30:15.840+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.842+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/59/.1.delta.2a2b90e4-4a5d-4e7d-acb6-b900b9de43f7.TID114.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/59/1.delta
[2025-07-19T18:30:15.843+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=59),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/59] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/59/1.delta
[2025-07-19T18:30:15.844+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 59 (task 114, attempt 0, stage 3.0)
[2025-07-19T18:30:15.844+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b3ebde4
[2025-07-19T18:30:15.845+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=72, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.845+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=72),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/72] for update
[2025-07-19T18:30:15.852+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/60/.1.delta.1f274fd3-ce00-4f06-8da1-cf32dd283764.TID115.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/60/1.delta
[2025-07-19T18:30:15.853+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=60),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/60] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/60/1.delta
[2025-07-19T18:30:15.855+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/61/.1.delta.ad9f076d-22ee-4f53-900f-266842868ccc.TID116.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/61/1.delta
[2025-07-19T18:30:15.856+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=61),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/61] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/61/1.delta
[2025-07-19T18:30:15.857+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 61 (task 116, attempt 0, stage 3.0)
[2025-07-19T18:30:15.858+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@109a17c4
[2025-07-19T18:30:15.860+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=70, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.861+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=70),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/70] for update
[2025-07-19T18:30:15.862+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.863+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 59 (task 114, attempt 0, stage 3.0)
[2025-07-19T18:30:15.863+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 59.0 in stage 3.0 (TID 114). 6243 bytes result sent to driver
[2025-07-19T18:30:15.863+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.865+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 60 (task 115, attempt 0, stage 3.0)
[2025-07-19T18:30:15.866+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 59.0 in stage 3.0 (TID 114) in 108 ms on 8b44f3d35cfa (executor driver) (104/200)
[2025-07-19T18:30:15.870+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 73.0 in stage 3.0 (TID 122) (8b44f3d35cfa, executor driver, partition 73, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.870+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 73.0 in stage 3.0 (TID 122)
[2025-07-19T18:30:15.870+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/69/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/69/.1.delta.deac7086-c765-43d5-b223-a0678e81f97d.TID119.tmp
[2025-07-19T18:30:15.872+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.872+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.872+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 60 (task 115, attempt 0, stage 3.0)
[2025-07-19T18:30:15.872+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 61 (task 116, attempt 0, stage 3.0)
[2025-07-19T18:30:15.872+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 61.0 in stage 3.0 (TID 116). 6243 bytes result sent to driver
[2025-07-19T18:30:15.873+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 60.0 in stage 3.0 (TID 115). 6243 bytes result sent to driver
[2025-07-19T18:30:15.873+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 75.0 in stage 3.0 (TID 123) (8b44f3d35cfa, executor driver, partition 75, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.873+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 61.0 in stage 3.0 (TID 116) in 103 ms on 8b44f3d35cfa (executor driver) (105/200)
[2025-07-19T18:30:15.873+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 75.0 in stage 3.0 (TID 123)
[2025-07-19T18:30:15.873+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 76.0 in stage 3.0 (TID 124) (8b44f3d35cfa, executor driver, partition 76, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.874+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 60.0 in stage 3.0 (TID 115) in 120 ms on 8b44f3d35cfa (executor driver) (106/200)
[2025-07-19T18:30:15.874+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 76.0 in stage 3.0 (TID 124)
[2025-07-19T18:30:15.874+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.874+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:15.875+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.875+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.876+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/70/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/70/.1.delta.b9d2e3e9-7c35-44ad-8c66-1949ddac8a6f.TID120.tmp
[2025-07-19T18:30:15.876+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73695f94
[2025-07-19T18:30:15.876+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=73, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.877+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=73),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/73] for update
[2025-07-19T18:30:15.879+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.879+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/67/.1.delta.2c6530f2-dc67-4cd5-8070-cf864b194522.TID118.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/67/1.delta
[2025-07-19T18:30:15.879+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/72/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/72/.1.delta.223ada09-2d1b-42e7-99ee-c74b2b4bbd04.TID121.tmp
[2025-07-19T18:30:15.879+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=67),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/67] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/67/1.delta
[2025-07-19T18:30:15.880+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/65/.1.delta.46739af2-b0aa-4c23-a348-5eb9f287114b.TID117.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/65/1.delta
[2025-07-19T18:30:15.880+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=65),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/65] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/65/1.delta
[2025-07-19T18:30:15.882+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 67 (task 118, attempt 0, stage 3.0)
[2025-07-19T18:30:15.891+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 65 (task 117, attempt 0, stage 3.0)
[2025-07-19T18:30:15.891+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/69/.1.delta.deac7086-c765-43d5-b223-a0678e81f97d.TID119.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/69/1.delta
[2025-07-19T18:30:15.891+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=69),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/69] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/69/1.delta
[2025-07-19T18:30:15.892+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 69 (task 119, attempt 0, stage 3.0)
[2025-07-19T18:30:15.892+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@26303d3d
[2025-07-19T18:30:15.892+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=76, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.892+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=76),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/76] for update
[2025-07-19T18:30:15.892+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 69 (task 119, attempt 0, stage 3.0)
[2025-07-19T18:30:15.893+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 67 (task 118, attempt 0, stage 3.0)
[2025-07-19T18:30:15.893+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 69.0 in stage 3.0 (TID 119). 6200 bytes result sent to driver
[2025-07-19T18:30:15.893+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 67.0 in stage 3.0 (TID 118). 6200 bytes result sent to driver
[2025-07-19T18:30:15.893+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.902+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 77.0 in stage 3.0 (TID 125) (8b44f3d35cfa, executor driver, partition 77, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.906+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 77.0 in stage 3.0 (TID 125)
[2025-07-19T18:30:15.907+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/73/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/73/.1.delta.ae2d84c8-9234-400a-86e5-8cbea630793e.TID122.tmp
[2025-07-19T18:30:15.907+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 78.0 in stage 3.0 (TID 126) (8b44f3d35cfa, executor driver, partition 78, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.908+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 69.0 in stage 3.0 (TID 119) in 93 ms on 8b44f3d35cfa (executor driver) (107/200)
[2025-07-19T18:30:15.908+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 65 (task 117, attempt 0, stage 3.0)
[2025-07-19T18:30:15.908+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.908+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.909+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 65.0 in stage 3.0 (TID 117). 6243 bytes result sent to driver
[2025-07-19T18:30:15.909+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 81.0 in stage 3.0 (TID 127) (8b44f3d35cfa, executor driver, partition 81, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.910+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 67.0 in stage 3.0 (TID 118) in 107 ms on 8b44f3d35cfa (executor driver) (108/200)
[2025-07-19T18:30:15.911+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 81.0 in stage 3.0 (TID 127)
[2025-07-19T18:30:15.911+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 65.0 in stage 3.0 (TID 117) in 133 ms on 8b44f3d35cfa (executor driver) (109/200)
[2025-07-19T18:30:15.911+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5aa96aee
[2025-07-19T18:30:15.912+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=75, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.912+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=75),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/75] for update
[2025-07-19T18:30:15.912+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 78.0 in stage 3.0 (TID 126)
[2025-07-19T18:30:15.913+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.913+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.913+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.913+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.913+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.913+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/70/.1.delta.b9d2e3e9-7c35-44ad-8c66-1949ddac8a6f.TID120.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/70/1.delta
[2025-07-19T18:30:15.913+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=70),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/70] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/70/1.delta
[2025-07-19T18:30:15.913+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 70 (task 120, attempt 0, stage 3.0)
[2025-07-19T18:30:15.913+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ff2827f
[2025-07-19T18:30:15.914+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/76/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/76/.1.delta.05a7e786-87b2-45a4-8a3e-c4ca4ebc9845.TID124.tmp
[2025-07-19T18:30:15.914+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=77, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.914+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=77),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/77] for update
[2025-07-19T18:30:15.916+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/72/.1.delta.223ada09-2d1b-42e7-99ee-c74b2b4bbd04.TID121.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/72/1.delta
[2025-07-19T18:30:15.917+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=72),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/72] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/72/1.delta
[2025-07-19T18:30:15.917+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 72 (task 121, attempt 0, stage 3.0)
[2025-07-19T18:30:15.917+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.917+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/75/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/75/.1.delta.67bacaa9-c497-4643-94f4-202fbb875cc7.TID123.tmp
[2025-07-19T18:30:15.917+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2603ff50
[2025-07-19T18:30:15.917+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=78, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.918+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=78),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/78] for update
[2025-07-19T18:30:15.920+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.923+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 70 (task 120, attempt 0, stage 3.0)
[2025-07-19T18:30:15.924+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 70.0 in stage 3.0 (TID 120). 6243 bytes result sent to driver
[2025-07-19T18:30:15.925+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 84.0 in stage 3.0 (TID 128) (8b44f3d35cfa, executor driver, partition 84, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.925+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 84.0 in stage 3.0 (TID 128)
[2025-07-19T18:30:15.927+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/77/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/77/.1.delta.cdb41e3d-1d78-4045-a7bb-b34672aec692.TID125.tmp
[2025-07-19T18:30:15.927+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 70.0 in stage 3.0 (TID 120) in 99 ms on 8b44f3d35cfa (executor driver) (110/200)
[2025-07-19T18:30:15.927+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 72 (task 121, attempt 0, stage 3.0)
[2025-07-19T18:30:15.929+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 72.0 in stage 3.0 (TID 121). 6243 bytes result sent to driver
[2025-07-19T18:30:15.931+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.932+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T18:30:15.934+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 85.0 in stage 3.0 (TID 129) (8b44f3d35cfa, executor driver, partition 85, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.934+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1f982354
[2025-07-19T18:30:15.934+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=81, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.934+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=81),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/81] for update
[2025-07-19T18:30:15.934+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/78/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/78/.1.delta.8672c40a-a233-4ae6-96dd-339dfd72c102.TID126.tmp
[2025-07-19T18:30:15.934+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 72.0 in stage 3.0 (TID 121) in 105 ms on 8b44f3d35cfa (executor driver) (111/200)
[2025-07-19T18:30:15.938+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.941+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 85.0 in stage 3.0 (TID 129)
[2025-07-19T18:30:15.944+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3474397
[2025-07-19T18:30:15.945+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=84, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.945+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=84),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/84] for update
[2025-07-19T18:30:15.947+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.952+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/81/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/81/.1.delta.97a0d109-6230-46e3-91fa-0c109b815dec.TID127.tmp
[2025-07-19T18:30:15.954+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/73/.1.delta.ae2d84c8-9234-400a-86e5-8cbea630793e.TID122.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/73/1.delta
[2025-07-19T18:30:15.954+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.954+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T18:30:15.954+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=73),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/73] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/73/1.delta
[2025-07-19T18:30:15.954+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 73 (task 122, attempt 0, stage 3.0)
[2025-07-19T18:30:15.961+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/76/.1.delta.05a7e786-87b2-45a4-8a3e-c4ca4ebc9845.TID124.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/76/1.delta
[2025-07-19T18:30:15.963+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=76),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/76] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/76/1.delta
[2025-07-19T18:30:15.963+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/75/.1.delta.67bacaa9-c497-4643-94f4-202fbb875cc7.TID123.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/75/1.delta
[2025-07-19T18:30:15.963+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=75),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/75] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/75/1.delta
[2025-07-19T18:30:15.963+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 76 (task 124, attempt 0, stage 3.0)
[2025-07-19T18:30:15.963+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7cbe1984
[2025-07-19T18:30:15.968+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 75 (task 123, attempt 0, stage 3.0)
[2025-07-19T18:30:15.969+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=85, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:15.969+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=85),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/85] for update
[2025-07-19T18:30:15.969+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/77/.1.delta.cdb41e3d-1d78-4045-a7bb-b34672aec692.TID125.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/77/1.delta
[2025-07-19T18:30:15.969+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 76 (task 124, attempt 0, stage 3.0)
[2025-07-19T18:30:15.969+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=77),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/77] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/77/1.delta
[2025-07-19T18:30:15.969+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 77 (task 125, attempt 0, stage 3.0)
[2025-07-19T18:30:15.969+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 76.0 in stage 3.0 (TID 124). 6243 bytes result sent to driver
[2025-07-19T18:30:15.970+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:15.970+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 75 (task 123, attempt 0, stage 3.0)
[2025-07-19T18:30:15.970+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 89.0 in stage 3.0 (TID 130) (8b44f3d35cfa, executor driver, partition 89, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.970+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 89.0 in stage 3.0 (TID 130)
[2025-07-19T18:30:15.970+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 75.0 in stage 3.0 (TID 123). 6243 bytes result sent to driver
[2025-07-19T18:30:15.970+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 91.0 in stage 3.0 (TID 131) (8b44f3d35cfa, executor driver, partition 91, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.970+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 91.0 in stage 3.0 (TID 131)
[2025-07-19T18:30:15.973+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.975+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 76.0 in stage 3.0 (TID 124) in 101 ms on 8b44f3d35cfa (executor driver) (112/200)
[2025-07-19T18:30:15.975+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 75.0 in stage 3.0 (TID 123) in 105 ms on 8b44f3d35cfa (executor driver) (113/200)
[2025-07-19T18:30:15.975+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:15.975+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.975+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.975+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 73 (task 122, attempt 0, stage 3.0)
[2025-07-19T18:30:15.975+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 73.0 in stage 3.0 (TID 122). 6243 bytes result sent to driver
[2025-07-19T18:30:15.975+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 92.0 in stage 3.0 (TID 132) (8b44f3d35cfa, executor driver, partition 92, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.976+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Committed partition 77 (task 125, attempt 0, stage 3.0)
[2025-07-19T18:30:15.976+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 92.0 in stage 3.0 (TID 132)
[2025-07-19T18:30:15.982+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Finished task 77.0 in stage 3.0 (TID 125). 6286 bytes result sent to driver
[2025-07-19T18:30:15.983+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:15.985+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:15.985+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 73.0 in stage 3.0 (TID 122) in 123 ms on 8b44f3d35cfa (executor driver) (114/200)
[2025-07-19T18:30:15.986+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Starting task 93.0 in stage 3.0 (TID 133) (8b44f3d35cfa, executor driver, partition 93, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:15.986+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO TaskSetManager: Finished task 77.0 in stage 3.0 (TID 125) in 95 ms on 8b44f3d35cfa (executor driver) (115/200)
[2025-07-19T18:30:15.989+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/84/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/84/.1.delta.98e9269e-bf02-4fcf-ab98-3de8f7f5d2ea.TID128.tmp
[2025-07-19T18:30:15.989+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/85/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/85/.1.delta.67f5445a-8a38-4c61-b1ff-4613b3285c1a.TID129.tmp
[2025-07-19T18:30:15.992+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/81/.1.delta.97a0d109-6230-46e3-91fa-0c109b815dec.TID127.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/81/1.delta
[2025-07-19T18:30:15.993+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=81),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/81] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/81/1.delta
[2025-07-19T18:30:15.993+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/78/.1.delta.8672c40a-a233-4ae6-96dd-339dfd72c102.TID126.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/78/1.delta
[2025-07-19T18:30:16.001+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO DataWritingSparkTask: Commit authorized for partition 81 (task 127, attempt 0, stage 3.0)
[2025-07-19T18:30:16.002+0000] {subprocess.py:93} INFO - 25/07/19 18:30:15 INFO Executor: Running task 93.0 in stage 3.0 (TID 133)
[2025-07-19T18:30:16.002+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/84/.1.delta.98e9269e-bf02-4fcf-ab98-3de8f7f5d2ea.TID128.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/84/1.delta
[2025-07-19T18:30:16.003+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=84),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/84] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/84/1.delta
[2025-07-19T18:30:16.003+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 84 (task 128, attempt 0, stage 3.0)
[2025-07-19T18:30:16.004+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.005+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.006+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@60f3b373
[2025-07-19T18:30:16.006+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=78),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/78] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/78/1.delta
[2025-07-19T18:30:16.008+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=91, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.010+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=91),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/91] for update
[2025-07-19T18:30:16.012+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 81 (task 127, attempt 0, stage 3.0)
[2025-07-19T18:30:16.013+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 78 (task 126, attempt 0, stage 3.0)
[2025-07-19T18:30:16.013+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 81.0 in stage 3.0 (TID 127). 6286 bytes result sent to driver
[2025-07-19T18:30:16.014+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.014+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 84 (task 128, attempt 0, stage 3.0)
[2025-07-19T18:30:16.015+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 94.0 in stage 3.0 (TID 134) (8b44f3d35cfa, executor driver, partition 94, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.016+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 84.0 in stage 3.0 (TID 128). 6243 bytes result sent to driver
[2025-07-19T18:30:16.016+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 78 (task 126, attempt 0, stage 3.0)
[2025-07-19T18:30:16.017+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 94.0 in stage 3.0 (TID 134)
[2025-07-19T18:30:16.019+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 81.0 in stage 3.0 (TID 127) in 109 ms on 8b44f3d35cfa (executor driver) (116/200)
[2025-07-19T18:30:16.019+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 78.0 in stage 3.0 (TID 126). 6243 bytes result sent to driver
[2025-07-19T18:30:16.019+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.020+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.021+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 95.0 in stage 3.0 (TID 135) (8b44f3d35cfa, executor driver, partition 95, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.021+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 84.0 in stage 3.0 (TID 128) in 91 ms on 8b44f3d35cfa (executor driver) (117/200)
[2025-07-19T18:30:16.022+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 95.0 in stage 3.0 (TID 135)
[2025-07-19T18:30:16.023+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 96.0 in stage 3.0 (TID 136) (8b44f3d35cfa, executor driver, partition 96, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.023+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 78.0 in stage 3.0 (TID 126) in 118 ms on 8b44f3d35cfa (executor driver) (118/200)
[2025-07-19T18:30:16.023+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2622c063
[2025-07-19T18:30:16.024+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 96.0 in stage 3.0 (TID 136)
[2025-07-19T18:30:16.024+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.025+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.025+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=93, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.026+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=93),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/93] for update
[2025-07-19T18:30:16.026+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/91/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/91/.1.delta.aea877ad-504d-4d33-b047-a44b9eede075.TID131.tmp
[2025-07-19T18:30:16.027+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.027+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.027+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.028+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/85/.1.delta.67f5445a-8a38-4c61-b1ff-4613b3285c1a.TID129.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/85/1.delta
[2025-07-19T18:30:16.028+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=85),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/85] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/85/1.delta
[2025-07-19T18:30:16.028+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 85 (task 129, attempt 0, stage 3.0)
[2025-07-19T18:30:16.028+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@996acf0
[2025-07-19T18:30:16.028+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=92, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.028+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=92),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/92] for update
[2025-07-19T18:30:16.028+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.029+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 85 (task 129, attempt 0, stage 3.0)
[2025-07-19T18:30:16.029+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 85.0 in stage 3.0 (TID 129). 6243 bytes result sent to driver
[2025-07-19T18:30:16.029+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 98.0 in stage 3.0 (TID 137) (8b44f3d35cfa, executor driver, partition 98, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.031+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 98.0 in stage 3.0 (TID 137)
[2025-07-19T18:30:16.032+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 85.0 in stage 3.0 (TID 129) in 100 ms on 8b44f3d35cfa (executor driver) (119/200)
[2025-07-19T18:30:16.032+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.032+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.033+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/93/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/93/.1.delta.853f8936-11c4-48cb-9c28-bf54f5151993.TID133.tmp
[2025-07-19T18:30:16.034+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a1f0c03
[2025-07-19T18:30:16.035+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/92/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/92/.1.delta.3bad628e-5821-4b9d-ab58-7d5561c8600f.TID132.tmp
[2025-07-19T18:30:16.035+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=89, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.036+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=89),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/89] for update
[2025-07-19T18:30:16.040+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.050+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@61293c61
[2025-07-19T18:30:16.051+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=98, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.051+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=98),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/98] for update
[2025-07-19T18:30:16.052+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.053+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/91/.1.delta.aea877ad-504d-4d33-b047-a44b9eede075.TID131.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/91/1.delta
[2025-07-19T18:30:16.053+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=91),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/91] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/91/1.delta
[2025-07-19T18:30:16.054+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 91 (task 131, attempt 0, stage 3.0)
[2025-07-19T18:30:16.055+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47753b02
[2025-07-19T18:30:16.055+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=96, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.057+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=96),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/96] for update
[2025-07-19T18:30:16.058+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/89/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/89/.1.delta.cf3ffb84-706c-40a9-8f00-21b604716451.TID130.tmp
[2025-07-19T18:30:16.060+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/98/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/98/.1.delta.55ad9e12-fc28-425e-9afe-d52936adbbb3.TID137.tmp
[2025-07-19T18:30:16.063+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/93/.1.delta.853f8936-11c4-48cb-9c28-bf54f5151993.TID133.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/93/1.delta
[2025-07-19T18:30:16.065+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=93),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/93] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/93/1.delta
[2025-07-19T18:30:16.065+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 93 (task 133, attempt 0, stage 3.0)
[2025-07-19T18:30:16.065+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.065+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/92/.1.delta.3bad628e-5821-4b9d-ab58-7d5561c8600f.TID132.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/92/1.delta
[2025-07-19T18:30:16.067+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=92),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/92] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/92/1.delta
[2025-07-19T18:30:16.067+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 91 (task 131, attempt 0, stage 3.0)
[2025-07-19T18:30:16.068+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 92 (task 132, attempt 0, stage 3.0)
[2025-07-19T18:30:16.069+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3b1a3f9f
[2025-07-19T18:30:16.070+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=95, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.070+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=95),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/95] for update
[2025-07-19T18:30:16.071+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 91.0 in stage 3.0 (TID 131). 6286 bytes result sent to driver
[2025-07-19T18:30:16.073+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 101.0 in stage 3.0 (TID 138) (8b44f3d35cfa, executor driver, partition 101, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.074+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 91.0 in stage 3.0 (TID 131) in 103 ms on 8b44f3d35cfa (executor driver) (120/200)
[2025-07-19T18:30:16.076+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.076+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 101.0 in stage 3.0 (TID 138)
[2025-07-19T18:30:16.076+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 92 (task 132, attempt 0, stage 3.0)
[2025-07-19T18:30:16.076+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 92.0 in stage 3.0 (TID 132). 6243 bytes result sent to driver
[2025-07-19T18:30:16.077+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 102.0 in stage 3.0 (TID 139) (8b44f3d35cfa, executor driver, partition 102, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.078+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.079+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.080+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/96/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/96/.1.delta.e69401ea-a0ec-46be-a2cf-a8ee8c246576.TID136.tmp
[2025-07-19T18:30:16.081+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 92.0 in stage 3.0 (TID 132) in 102 ms on 8b44f3d35cfa (executor driver) (121/200)
[2025-07-19T18:30:16.082+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 93 (task 133, attempt 0, stage 3.0)
[2025-07-19T18:30:16.083+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ef8835a
[2025-07-19T18:30:16.083+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 93.0 in stage 3.0 (TID 133). 6243 bytes result sent to driver
[2025-07-19T18:30:16.085+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/95/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/95/.1.delta.1919fff8-63ba-466d-806f-6af6e7314ba7.TID135.tmp
[2025-07-19T18:30:16.085+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 102.0 in stage 3.0 (TID 139)
[2025-07-19T18:30:16.086+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=94, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.087+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 104.0 in stage 3.0 (TID 140) (8b44f3d35cfa, executor driver, partition 104, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.087+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=94),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/94] for update
[2025-07-19T18:30:16.087+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 104.0 in stage 3.0 (TID 140)
[2025-07-19T18:30:16.087+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 93.0 in stage 3.0 (TID 133) in 99 ms on 8b44f3d35cfa (executor driver) (122/200)
[2025-07-19T18:30:16.088+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.088+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.089+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.090+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b67aa18
[2025-07-19T18:30:16.091+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.091+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=101, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.092+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=101),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/101] for update
[2025-07-19T18:30:16.093+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.094+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T18:30:16.099+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d5458c
[2025-07-19T18:30:16.099+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=104, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.099+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=104),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/104] for update
[2025-07-19T18:30:16.102+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/89/.1.delta.cf3ffb84-706c-40a9-8f00-21b604716451.TID130.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/89/1.delta
[2025-07-19T18:30:16.102+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=89),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/89] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/89/1.delta
[2025-07-19T18:30:16.103+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.103+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 89 (task 130, attempt 0, stage 3.0)
[2025-07-19T18:30:16.103+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/94/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/94/.1.delta.735e42f5-8e63-4d87-8eaa-b4b9e5bce2b3.TID134.tmp
[2025-07-19T18:30:16.106+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/98/.1.delta.55ad9e12-fc28-425e-9afe-d52936adbbb3.TID137.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/98/1.delta
[2025-07-19T18:30:16.107+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=98),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/98] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/98/1.delta
[2025-07-19T18:30:16.108+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 98 (task 137, attempt 0, stage 3.0)
[2025-07-19T18:30:16.108+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2cff52d3
[2025-07-19T18:30:16.108+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=102, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.109+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=102),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/102] for update
[2025-07-19T18:30:16.109+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/101/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/101/.1.delta.4e45dc60-a706-44fb-91fe-df2eb74321ea.TID138.tmp
[2025-07-19T18:30:16.110+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.112+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 98 (task 137, attempt 0, stage 3.0)
[2025-07-19T18:30:16.115+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 98.0 in stage 3.0 (TID 137). 6243 bytes result sent to driver
[2025-07-19T18:30:16.115+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/104/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/104/.1.delta.870d774c-24b1-4dc7-9db3-2919e4349c69.TID140.tmp
[2025-07-19T18:30:16.117+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 105.0 in stage 3.0 (TID 141) (8b44f3d35cfa, executor driver, partition 105, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.118+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 89 (task 130, attempt 0, stage 3.0)
[2025-07-19T18:30:16.119+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 105.0 in stage 3.0 (TID 141)
[2025-07-19T18:30:16.119+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 98.0 in stage 3.0 (TID 137) in 87 ms on 8b44f3d35cfa (executor driver) (123/200)
[2025-07-19T18:30:16.120+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 89.0 in stage 3.0 (TID 130). 6243 bytes result sent to driver
[2025-07-19T18:30:16.121+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 106.0 in stage 3.0 (TID 142) (8b44f3d35cfa, executor driver, partition 106, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.122+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 106.0 in stage 3.0 (TID 142)
[2025-07-19T18:30:16.122+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.124+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.125+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 89.0 in stage 3.0 (TID 130) in 150 ms on 8b44f3d35cfa (executor driver) (124/200)
[2025-07-19T18:30:16.126+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.127+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.127+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/102/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/102/.1.delta.66c57349-111d-4475-b048-b6aa50d9c48e.TID139.tmp
[2025-07-19T18:30:16.128+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65ba4a47
[2025-07-19T18:30:16.129+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=105, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.130+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=105),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/105] for update
[2025-07-19T18:30:16.131+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/96/.1.delta.e69401ea-a0ec-46be-a2cf-a8ee8c246576.TID136.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/96/1.delta
[2025-07-19T18:30:16.131+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=96),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/96] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/96/1.delta
[2025-07-19T18:30:16.131+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 96 (task 136, attempt 0, stage 3.0)
[2025-07-19T18:30:16.131+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/95/.1.delta.1919fff8-63ba-466d-806f-6af6e7314ba7.TID135.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/95/1.delta
[2025-07-19T18:30:16.131+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=95),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/95] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/95/1.delta
[2025-07-19T18:30:16.131+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 95 (task 135, attempt 0, stage 3.0)
[2025-07-19T18:30:16.131+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.132+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 96 (task 136, attempt 0, stage 3.0)
[2025-07-19T18:30:16.132+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 95 (task 135, attempt 0, stage 3.0)
[2025-07-19T18:30:16.132+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 96.0 in stage 3.0 (TID 136). 6243 bytes result sent to driver
[2025-07-19T18:30:16.132+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 95.0 in stage 3.0 (TID 135). 6243 bytes result sent to driver
[2025-07-19T18:30:16.133+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f7b0fec
[2025-07-19T18:30:16.134+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 107.0 in stage 3.0 (TID 143) (8b44f3d35cfa, executor driver, partition 107, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.134+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 108.0 in stage 3.0 (TID 144) (8b44f3d35cfa, executor driver, partition 108, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.135+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 95.0 in stage 3.0 (TID 135) in 120 ms on 8b44f3d35cfa (executor driver) (125/200)
[2025-07-19T18:30:16.135+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 96.0 in stage 3.0 (TID 136) in 119 ms on 8b44f3d35cfa (executor driver) (126/200)
[2025-07-19T18:30:16.136+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 107.0 in stage 3.0 (TID 143)
[2025-07-19T18:30:16.139+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.140+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.140+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=106, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.140+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=106),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/106] for update
[2025-07-19T18:30:16.140+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 108.0 in stage 3.0 (TID 144)
[2025-07-19T18:30:16.141+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.143+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/101/.1.delta.4e45dc60-a706-44fb-91fe-df2eb74321ea.TID138.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/101/1.delta
[2025-07-19T18:30:16.144+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/105/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/105/.1.delta.2f87c69a-1047-4385-866e-bbe7025894d4.TID141.tmp
[2025-07-19T18:30:16.144+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=101),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/101] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/101/1.delta
[2025-07-19T18:30:16.144+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 101 (task 138, attempt 0, stage 3.0)
[2025-07-19T18:30:16.148+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/94/.1.delta.735e42f5-8e63-4d87-8eaa-b4b9e5bce2b3.TID134.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/94/1.delta
[2025-07-19T18:30:16.149+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=94),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/94] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/94/1.delta
[2025-07-19T18:30:16.149+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 94 (task 134, attempt 0, stage 3.0)
[2025-07-19T18:30:16.149+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 101 (task 138, attempt 0, stage 3.0)
[2025-07-19T18:30:16.154+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.154+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 101.0 in stage 3.0 (TID 138). 6286 bytes result sent to driver
[2025-07-19T18:30:16.155+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.155+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 112.0 in stage 3.0 (TID 145) (8b44f3d35cfa, executor driver, partition 112, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.155+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 112.0 in stage 3.0 (TID 145)
[2025-07-19T18:30:16.157+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@38fdba87
[2025-07-19T18:30:16.157+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 101.0 in stage 3.0 (TID 138) in 84 ms on 8b44f3d35cfa (executor driver) (127/200)
[2025-07-19T18:30:16.159+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.162+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.162+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=107, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.163+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 94 (task 134, attempt 0, stage 3.0)
[2025-07-19T18:30:16.163+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 94.0 in stage 3.0 (TID 134). 6243 bytes result sent to driver
[2025-07-19T18:30:16.163+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 113.0 in stage 3.0 (TID 146) (8b44f3d35cfa, executor driver, partition 113, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.163+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 113.0 in stage 3.0 (TID 146)
[2025-07-19T18:30:16.164+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=107),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/107] for update
[2025-07-19T18:30:16.165+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 94.0 in stage 3.0 (TID 134) in 156 ms on 8b44f3d35cfa (executor driver) (128/200)
[2025-07-19T18:30:16.166+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.166+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.167+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.168+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/102/.1.delta.66c57349-111d-4475-b048-b6aa50d9c48e.TID139.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/102/1.delta
[2025-07-19T18:30:16.168+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=102),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/102] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/102/1.delta
[2025-07-19T18:30:16.169+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 102 (task 139, attempt 0, stage 3.0)
[2025-07-19T18:30:16.170+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/104/.1.delta.870d774c-24b1-4dc7-9db3-2919e4349c69.TID140.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/104/1.delta
[2025-07-19T18:30:16.171+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=104),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/104] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/104/1.delta
[2025-07-19T18:30:16.172+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 104 (task 140, attempt 0, stage 3.0)
[2025-07-19T18:30:16.172+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/106/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/106/.1.delta.8c12d4a9-00be-4ac1-94d7-eeab8ce9e642.TID142.tmp
[2025-07-19T18:30:16.175+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@766e8d6f
[2025-07-19T18:30:16.176+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=112, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.177+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=112),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/112] for update
[2025-07-19T18:30:16.177+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 104 (task 140, attempt 0, stage 3.0)
[2025-07-19T18:30:16.177+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 102 (task 139, attempt 0, stage 3.0)
[2025-07-19T18:30:16.178+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 104.0 in stage 3.0 (TID 140). 6243 bytes result sent to driver
[2025-07-19T18:30:16.178+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/107/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/107/.1.delta.8fb72a93-b401-4782-a35b-02736d83f06e.TID143.tmp
[2025-07-19T18:30:16.179+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 102.0 in stage 3.0 (TID 139). 6243 bytes result sent to driver
[2025-07-19T18:30:16.179+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 114.0 in stage 3.0 (TID 147) (8b44f3d35cfa, executor driver, partition 114, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.180+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.180+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 114.0 in stage 3.0 (TID 147)
[2025-07-19T18:30:16.181+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58a43d0d
[2025-07-19T18:30:16.184+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=108, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.185+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 115.0 in stage 3.0 (TID 148) (8b44f3d35cfa, executor driver, partition 115, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.186+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=108),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/108] for update
[2025-07-19T18:30:16.186+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 104.0 in stage 3.0 (TID 140) in 100 ms on 8b44f3d35cfa (executor driver) (129/200)
[2025-07-19T18:30:16.187+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 115.0 in stage 3.0 (TID 148)
[2025-07-19T18:30:16.187+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 102.0 in stage 3.0 (TID 139) in 108 ms on 8b44f3d35cfa (executor driver) (130/200)
[2025-07-19T18:30:16.188+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.188+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.189+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.189+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.189+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.191+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b0dd0da
[2025-07-19T18:30:16.191+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=113, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.191+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=113),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/113] for update
[2025-07-19T18:30:16.192+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/105/.1.delta.2f87c69a-1047-4385-866e-bbe7025894d4.TID141.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/105/1.delta
[2025-07-19T18:30:16.192+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=105),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/105] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/105/1.delta
[2025-07-19T18:30:16.192+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 105 (task 141, attempt 0, stage 3.0)
[2025-07-19T18:30:16.192+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.195+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/108/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/108/.1.delta.acf7ad43-c068-4679-878e-e1079bcdd970.TID144.tmp
[2025-07-19T18:30:16.196+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 105 (task 141, attempt 0, stage 3.0)
[2025-07-19T18:30:16.197+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@57209d6f
[2025-07-19T18:30:16.198+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 105.0 in stage 3.0 (TID 141). 6243 bytes result sent to driver
[2025-07-19T18:30:16.199+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=114, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.199+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 105.0 in stage 3.0 (TID 141) in 83 ms on 8b44f3d35cfa (executor driver) (131/200)
[2025-07-19T18:30:16.199+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 116.0 in stage 3.0 (TID 149) (8b44f3d35cfa, executor driver, partition 116, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.201+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=114),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/114] for update
[2025-07-19T18:30:16.202+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 116.0 in stage 3.0 (TID 149)
[2025-07-19T18:30:16.202+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/112/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/112/.1.delta.388ee90a-9394-4aad-9d68-0581add59694.TID145.tmp
[2025-07-19T18:30:16.203+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.204+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/113/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/113/.1.delta.451d7360-d190-45dd-b7bc-0e6e2ed2fa87.TID146.tmp
[2025-07-19T18:30:16.206+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.206+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.207+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b65fad5
[2025-07-19T18:30:16.208+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=115, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.208+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=115),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/115] for update
[2025-07-19T18:30:16.211+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.215+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/114/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/114/.1.delta.cece0899-2f40-4288-9ef2-7c3265294b04.TID147.tmp
[2025-07-19T18:30:16.215+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/107/.1.delta.8fb72a93-b401-4782-a35b-02736d83f06e.TID143.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/107/1.delta
[2025-07-19T18:30:16.215+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=107),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/107] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/107/1.delta
[2025-07-19T18:30:16.216+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 107 (task 143, attempt 0, stage 3.0)
[2025-07-19T18:30:16.219+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@126cdf64
[2025-07-19T18:30:16.220+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=116, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.220+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=116),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/116] for update
[2025-07-19T18:30:16.221+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 107 (task 143, attempt 0, stage 3.0)
[2025-07-19T18:30:16.221+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 107.0 in stage 3.0 (TID 143). 6243 bytes result sent to driver
[2025-07-19T18:30:16.222+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.222+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 118.0 in stage 3.0 (TID 150) (8b44f3d35cfa, executor driver, partition 118, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.224+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 118.0 in stage 3.0 (TID 150)
[2025-07-19T18:30:16.225+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/115/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/115/.1.delta.d769dc56-22b2-439d-b775-2315296dd6e6.TID148.tmp
[2025-07-19T18:30:16.225+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 107.0 in stage 3.0 (TID 143) in 93 ms on 8b44f3d35cfa (executor driver) (132/200)
[2025-07-19T18:30:16.228+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/106/.1.delta.8c12d4a9-00be-4ac1-94d7-eeab8ce9e642.TID142.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/106/1.delta
[2025-07-19T18:30:16.228+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=106),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/106] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/106/1.delta
[2025-07-19T18:30:16.229+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.229+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.231+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 106 (task 142, attempt 0, stage 3.0)
[2025-07-19T18:30:16.232+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/116/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/116/.1.delta.c8803c2b-1216-4fac-a14c-0ea77ddf9cb1.TID149.tmp
[2025-07-19T18:30:16.233+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 106 (task 142, attempt 0, stage 3.0)
[2025-07-19T18:30:16.234+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 106.0 in stage 3.0 (TID 142). 6243 bytes result sent to driver
[2025-07-19T18:30:16.238+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 119.0 in stage 3.0 (TID 151) (8b44f3d35cfa, executor driver, partition 119, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.240+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@687075ee
[2025-07-19T18:30:16.240+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=118, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.242+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=118),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/118] for update
[2025-07-19T18:30:16.243+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 106.0 in stage 3.0 (TID 142) in 123 ms on 8b44f3d35cfa (executor driver) (133/200)
[2025-07-19T18:30:16.244+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.244+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/112/.1.delta.388ee90a-9394-4aad-9d68-0581add59694.TID145.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/112/1.delta
[2025-07-19T18:30:16.245+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=112),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/112] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/112/1.delta
[2025-07-19T18:30:16.246+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 119.0 in stage 3.0 (TID 151)
[2025-07-19T18:30:16.247+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 112 (task 145, attempt 0, stage 3.0)
[2025-07-19T18:30:16.247+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/108/.1.delta.acf7ad43-c068-4679-878e-e1079bcdd970.TID144.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/108/1.delta
[2025-07-19T18:30:16.249+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=108),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/108] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/108/1.delta
[2025-07-19T18:30:16.249+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 108 (task 144, attempt 0, stage 3.0)
[2025-07-19T18:30:16.251+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.251+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.252+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/114/.1.delta.cece0899-2f40-4288-9ef2-7c3265294b04.TID147.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/114/1.delta
[2025-07-19T18:30:16.252+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=114),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/114] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/114/1.delta
[2025-07-19T18:30:16.253+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 114 (task 147, attempt 0, stage 3.0)
[2025-07-19T18:30:16.254+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 108 (task 144, attempt 0, stage 3.0)
[2025-07-19T18:30:16.263+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 108.0 in stage 3.0 (TID 144). 6286 bytes result sent to driver
[2025-07-19T18:30:16.264+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/115/.1.delta.d769dc56-22b2-439d-b775-2315296dd6e6.TID148.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/115/1.delta
[2025-07-19T18:30:16.265+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@36ebd768
[2025-07-19T18:30:16.266+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=115),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/115] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/115/1.delta
[2025-07-19T18:30:16.266+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=119, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.267+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 112 (task 145, attempt 0, stage 3.0)
[2025-07-19T18:30:16.267+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 120.0 in stage 3.0 (TID 152) (8b44f3d35cfa, executor driver, partition 120, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.268+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=119),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/119] for update
[2025-07-19T18:30:16.269+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 112.0 in stage 3.0 (TID 145). 6243 bytes result sent to driver
[2025-07-19T18:30:16.270+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 115 (task 148, attempt 0, stage 3.0)
[2025-07-19T18:30:16.270+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.271+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 121.0 in stage 3.0 (TID 153) (8b44f3d35cfa, executor driver, partition 121, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.272+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 114 (task 147, attempt 0, stage 3.0)
[2025-07-19T18:30:16.273+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 120.0 in stage 3.0 (TID 152)
[2025-07-19T18:30:16.273+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 108.0 in stage 3.0 (TID 144) in 132 ms on 8b44f3d35cfa (executor driver) (134/200)
[2025-07-19T18:30:16.273+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 121.0 in stage 3.0 (TID 153)
[2025-07-19T18:30:16.273+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 112.0 in stage 3.0 (TID 145) in 110 ms on 8b44f3d35cfa (executor driver) (135/200)
[2025-07-19T18:30:16.274+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 114.0 in stage 3.0 (TID 147). 6286 bytes result sent to driver
[2025-07-19T18:30:16.274+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/113/.1.delta.451d7360-d190-45dd-b7bc-0e6e2ed2fa87.TID146.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/113/1.delta
[2025-07-19T18:30:16.275+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=113),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/113] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/113/1.delta
[2025-07-19T18:30:16.276+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 122.0 in stage 3.0 (TID 154) (8b44f3d35cfa, executor driver, partition 122, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.277+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 122.0 in stage 3.0 (TID 154)
[2025-07-19T18:30:16.278+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 114.0 in stage 3.0 (TID 147) in 91 ms on 8b44f3d35cfa (executor driver) (136/200)
[2025-07-19T18:30:16.278+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 113 (task 146, attempt 0, stage 3.0)
[2025-07-19T18:30:16.278+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.279+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.279+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/118/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/118/.1.delta.1a229d8f-9539-4b9a-859b-413e431cf230.TID150.tmp
[2025-07-19T18:30:16.279+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 115 (task 148, attempt 0, stage 3.0)
[2025-07-19T18:30:16.280+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.281+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 113 (task 146, attempt 0, stage 3.0)
[2025-07-19T18:30:16.281+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.282+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 113.0 in stage 3.0 (TID 146). 6243 bytes result sent to driver
[2025-07-19T18:30:16.282+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 123.0 in stage 3.0 (TID 155) (8b44f3d35cfa, executor driver, partition 123, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.282+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 115.0 in stage 3.0 (TID 148). 6243 bytes result sent to driver
[2025-07-19T18:30:16.282+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.283+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:16.283+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 123.0 in stage 3.0 (TID 155)
[2025-07-19T18:30:16.284+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 113.0 in stage 3.0 (TID 146) in 112 ms on 8b44f3d35cfa (executor driver) (137/200)
[2025-07-19T18:30:16.285+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 124.0 in stage 3.0 (TID 156) (8b44f3d35cfa, executor driver, partition 124, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.285+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@629e2976
[2025-07-19T18:30:16.286+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 115.0 in stage 3.0 (TID 148) in 100 ms on 8b44f3d35cfa (executor driver) (138/200)
[2025-07-19T18:30:16.287+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=121, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.288+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 124.0 in stage 3.0 (TID 156)
[2025-07-19T18:30:16.290+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=121),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/121] for update
[2025-07-19T18:30:16.291+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.291+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T18:30:16.291+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.291+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/119/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/119/.1.delta.0df9b4ba-3eca-4485-a39c-8cd234dff56c.TID151.tmp
[2025-07-19T18:30:16.291+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.291+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.292+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ec3e19a
[2025-07-19T18:30:16.293+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=120, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.294+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=120),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/120] for update
[2025-07-19T18:30:16.295+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/121/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/121/.1.delta.93206632-9bcb-4be9-8b97-6fec98143e5f.TID153.tmp
[2025-07-19T18:30:16.296+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/116/.1.delta.c8803c2b-1216-4fac-a14c-0ea77ddf9cb1.TID149.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/116/1.delta
[2025-07-19T18:30:16.296+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=116),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/116] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/116/1.delta
[2025-07-19T18:30:16.296+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 116 (task 149, attempt 0, stage 3.0)
[2025-07-19T18:30:16.299+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@b8728a9
[2025-07-19T18:30:16.301+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.301+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=122, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.302+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=122),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/122] for update
[2025-07-19T18:30:16.305+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 116 (task 149, attempt 0, stage 3.0)
[2025-07-19T18:30:16.307+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 116.0 in stage 3.0 (TID 149). 6243 bytes result sent to driver
[2025-07-19T18:30:16.308+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 125.0 in stage 3.0 (TID 157) (8b44f3d35cfa, executor driver, partition 125, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.309+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7020b25d
[2025-07-19T18:30:16.309+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 116.0 in stage 3.0 (TID 149) in 109 ms on 8b44f3d35cfa (executor driver) (139/200)
[2025-07-19T18:30:16.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 125.0 in stage 3.0 (TID 157)
[2025-07-19T18:30:16.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=124, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.312+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=124),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/124] for update
[2025-07-19T18:30:16.312+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.313+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.313+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.313+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.315+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/120/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/120/.1.delta.561faa9f-2f92-4f9d-b3f3-623db840fda3.TID152.tmp
[2025-07-19T18:30:16.316+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@fde454b
[2025-07-19T18:30:16.318+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=123, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.319+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=123),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/123] for update
[2025-07-19T18:30:16.319+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/122/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/122/.1.delta.f410ef63-3356-437a-bbe7-a9c7972e1fa1.TID154.tmp
[2025-07-19T18:30:16.320+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.323+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28ef3c61
[2025-07-19T18:30:16.323+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=125, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.324+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=125),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/125] for update
[2025-07-19T18:30:16.325+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.326+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/124/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/124/.1.delta.f388c76f-c537-45fb-989d-f84f630f011f.TID156.tmp
[2025-07-19T18:30:16.327+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/118/.1.delta.1a229d8f-9539-4b9a-859b-413e431cf230.TID150.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/118/1.delta
[2025-07-19T18:30:16.328+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=118),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/118] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/118/1.delta
[2025-07-19T18:30:16.329+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 118 (task 150, attempt 0, stage 3.0)
[2025-07-19T18:30:16.331+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/119/.1.delta.0df9b4ba-3eca-4485-a39c-8cd234dff56c.TID151.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/119/1.delta
[2025-07-19T18:30:16.331+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=119),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/119] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/119/1.delta
[2025-07-19T18:30:16.332+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 119 (task 151, attempt 0, stage 3.0)
[2025-07-19T18:30:16.332+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/123/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/123/.1.delta.7471370c-c7df-474d-9656-225f76d4e1d8.TID155.tmp
[2025-07-19T18:30:16.336+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 118 (task 150, attempt 0, stage 3.0)
[2025-07-19T18:30:16.337+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/125/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/125/.1.delta.311f6a29-d924-4173-ae52-0892b42dcd06.TID157.tmp
[2025-07-19T18:30:16.338+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 118.0 in stage 3.0 (TID 150). 6243 bytes result sent to driver
[2025-07-19T18:30:16.338+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 127.0 in stage 3.0 (TID 158) (8b44f3d35cfa, executor driver, partition 127, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.338+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 118.0 in stage 3.0 (TID 150) in 116 ms on 8b44f3d35cfa (executor driver) (140/200)
[2025-07-19T18:30:16.339+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/121/.1.delta.93206632-9bcb-4be9-8b97-6fec98143e5f.TID153.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/121/1.delta
[2025-07-19T18:30:16.339+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=121),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/121] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/121/1.delta
[2025-07-19T18:30:16.341+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 121 (task 153, attempt 0, stage 3.0)
[2025-07-19T18:30:16.344+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 119 (task 151, attempt 0, stage 3.0)
[2025-07-19T18:30:16.345+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 121 (task 153, attempt 0, stage 3.0)
[2025-07-19T18:30:16.345+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 127.0 in stage 3.0 (TID 158)
[2025-07-19T18:30:16.346+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 119.0 in stage 3.0 (TID 151). 6243 bytes result sent to driver
[2025-07-19T18:30:16.349+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 121.0 in stage 3.0 (TID 153). 6286 bytes result sent to driver
[2025-07-19T18:30:16.351+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 128.0 in stage 3.0 (TID 159) (8b44f3d35cfa, executor driver, partition 128, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.352+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/120/.1.delta.561faa9f-2f92-4f9d-b3f3-623db840fda3.TID152.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/120/1.delta
[2025-07-19T18:30:16.352+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=120),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/120] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/120/1.delta
[2025-07-19T18:30:16.353+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 129.0 in stage 3.0 (TID 160) (8b44f3d35cfa, executor driver, partition 129, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.354+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 119.0 in stage 3.0 (TID 151) in 112 ms on 8b44f3d35cfa (executor driver) (141/200)
[2025-07-19T18:30:16.354+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 121.0 in stage 3.0 (TID 153) in 87 ms on 8b44f3d35cfa (executor driver) (142/200)
[2025-07-19T18:30:16.354+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.355+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.356+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 128.0 in stage 3.0 (TID 159)
[2025-07-19T18:30:16.356+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 129.0 in stage 3.0 (TID 160)
[2025-07-19T18:30:16.357+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.358+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 120 (task 152, attempt 0, stage 3.0)
[2025-07-19T18:30:16.359+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.359+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.360+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.360+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@fd1315e
[2025-07-19T18:30:16.361+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=127, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.362+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=127),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/127] for update
[2025-07-19T18:30:16.364+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/122/.1.delta.f410ef63-3356-437a-bbe7-a9c7972e1fa1.TID154.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/122/1.delta
[2025-07-19T18:30:16.364+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/124/.1.delta.f388c76f-c537-45fb-989d-f84f630f011f.TID156.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/124/1.delta
[2025-07-19T18:30:16.365+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=122),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/122] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/122/1.delta
[2025-07-19T18:30:16.367+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 120 (task 152, attempt 0, stage 3.0)
[2025-07-19T18:30:16.367+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 120.0 in stage 3.0 (TID 152). 6243 bytes result sent to driver
[2025-07-19T18:30:16.368+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.368+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=124),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/124] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/124/1.delta
[2025-07-19T18:30:16.368+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 122 (task 154, attempt 0, stage 3.0)
[2025-07-19T18:30:16.368+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 124 (task 156, attempt 0, stage 3.0)
[2025-07-19T18:30:16.369+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 131.0 in stage 3.0 (TID 161) (8b44f3d35cfa, executor driver, partition 131, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.369+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 120.0 in stage 3.0 (TID 152) in 103 ms on 8b44f3d35cfa (executor driver) (143/200)
[2025-07-19T18:30:16.370+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 131.0 in stage 3.0 (TID 161)
[2025-07-19T18:30:16.371+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 122 (task 154, attempt 0, stage 3.0)
[2025-07-19T18:30:16.372+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 122.0 in stage 3.0 (TID 154). 6243 bytes result sent to driver
[2025-07-19T18:30:16.374+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 132.0 in stage 3.0 (TID 162) (8b44f3d35cfa, executor driver, partition 132, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.375+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 124 (task 156, attempt 0, stage 3.0)
[2025-07-19T18:30:16.375+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/123/.1.delta.7471370c-c7df-474d-9656-225f76d4e1d8.TID155.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/123/1.delta
[2025-07-19T18:30:16.375+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=123),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/123] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/123/1.delta
[2025-07-19T18:30:16.375+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 123 (task 155, attempt 0, stage 3.0)
[2025-07-19T18:30:16.376+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 122.0 in stage 3.0 (TID 154) in 104 ms on 8b44f3d35cfa (executor driver) (144/200)
[2025-07-19T18:30:16.376+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 132.0 in stage 3.0 (TID 162)
[2025-07-19T18:30:16.376+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@46aab01c
[2025-07-19T18:30:16.376+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=128, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.378+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=128),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/128] for update
[2025-07-19T18:30:16.379+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 124.0 in stage 3.0 (TID 156). 6243 bytes result sent to driver
[2025-07-19T18:30:16.379+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.379+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.379+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 133.0 in stage 3.0 (TID 163) (8b44f3d35cfa, executor driver, partition 133, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.379+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 123 (task 155, attempt 0, stage 3.0)
[2025-07-19T18:30:16.380+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 123.0 in stage 3.0 (TID 155). 6243 bytes result sent to driver
[2025-07-19T18:30:16.380+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 124.0 in stage 3.0 (TID 156) in 99 ms on 8b44f3d35cfa (executor driver) (145/200)
[2025-07-19T18:30:16.381+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 123.0 in stage 3.0 (TID 155) in 102 ms on 8b44f3d35cfa (executor driver) (146/200)
[2025-07-19T18:30:16.381+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 133.0 in stage 3.0 (TID 163)
[2025-07-19T18:30:16.381+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 134.0 in stage 3.0 (TID 164) (8b44f3d35cfa, executor driver, partition 134, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.381+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/127/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/127/.1.delta.4bef82aa-2edd-43c8-954a-f29d6e28e71f.TID158.tmp
[2025-07-19T18:30:16.381+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.381+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T18:30:16.381+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.381+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.382+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@283d7841
[2025-07-19T18:30:16.382+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=129, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.382+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=129),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/129] for update
[2025-07-19T18:30:16.382+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.384+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 134.0 in stage 3.0 (TID 164)
[2025-07-19T18:30:16.385+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.386+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.386+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.386+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/125/.1.delta.311f6a29-d924-4173-ae52-0892b42dcd06.TID157.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/125/1.delta
[2025-07-19T18:30:16.388+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=125),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/125] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/125/1.delta
[2025-07-19T18:30:16.389+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 125 (task 157, attempt 0, stage 3.0)
[2025-07-19T18:30:16.391+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/128/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/128/.1.delta.f64a4b64-153b-4d16-ade8-eb90530078a7.TID159.tmp
[2025-07-19T18:30:16.394+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 125 (task 157, attempt 0, stage 3.0)
[2025-07-19T18:30:16.394+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 125.0 in stage 3.0 (TID 157). 6243 bytes result sent to driver
[2025-07-19T18:30:16.395+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 135.0 in stage 3.0 (TID 165) (8b44f3d35cfa, executor driver, partition 135, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.397+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 125.0 in stage 3.0 (TID 157) in 88 ms on 8b44f3d35cfa (executor driver) (147/200)
[2025-07-19T18:30:16.398+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/129/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/129/.1.delta.764f8b62-70d8-4b8d-aac0-f6028fb1a582.TID160.tmp
[2025-07-19T18:30:16.398+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2bd12d44
[2025-07-19T18:30:16.399+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 135.0 in stage 3.0 (TID 165)
[2025-07-19T18:30:16.401+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=134, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.402+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=134),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/134] for update
[2025-07-19T18:30:16.402+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.402+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.403+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.403+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ea995ed
[2025-07-19T18:30:16.403+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=133, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.403+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=133),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/133] for update
[2025-07-19T18:30:16.406+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/134/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/134/.1.delta.dcbde976-40f6-4971-b5b9-0668cb75f6ed.TID164.tmp
[2025-07-19T18:30:16.407+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@510954ba
[2025-07-19T18:30:16.408+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.408+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=132, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.409+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=132),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/132] for update
[2025-07-19T18:30:16.412+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.417+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2753834
[2025-07-19T18:30:16.418+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=131, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.419+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=131),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/131] for update
[2025-07-19T18:30:16.420+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.420+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/128/.1.delta.f64a4b64-153b-4d16-ade8-eb90530078a7.TID159.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/128/1.delta
[2025-07-19T18:30:16.421+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=128),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/128] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/128/1.delta
[2025-07-19T18:30:16.422+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 128 (task 159, attempt 0, stage 3.0)
[2025-07-19T18:30:16.423+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5857d4df
[2025-07-19T18:30:16.423+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=135, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.424+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=135),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/135] for update
[2025-07-19T18:30:16.425+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/133/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/133/.1.delta.4d6862cc-62d2-4ad5-b934-d6fc80cd94e4.TID163.tmp
[2025-07-19T18:30:16.427+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/127/.1.delta.4bef82aa-2edd-43c8-954a-f29d6e28e71f.TID158.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/127/1.delta
[2025-07-19T18:30:16.427+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=127),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/127] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/127/1.delta
[2025-07-19T18:30:16.427+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 127 (task 158, attempt 0, stage 3.0)
[2025-07-19T18:30:16.428+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/132/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/132/.1.delta.8938f44c-04ff-4881-92fa-f79cc6c49f73.TID162.tmp
[2025-07-19T18:30:16.428+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.428+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 128 (task 159, attempt 0, stage 3.0)
[2025-07-19T18:30:16.430+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 127 (task 158, attempt 0, stage 3.0)
[2025-07-19T18:30:16.431+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 128.0 in stage 3.0 (TID 159). 6200 bytes result sent to driver
[2025-07-19T18:30:16.432+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/131/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/131/.1.delta.17c4b4f5-99d5-4dab-9e79-3b70e98f4284.TID161.tmp
[2025-07-19T18:30:16.432+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 136.0 in stage 3.0 (TID 166) (8b44f3d35cfa, executor driver, partition 136, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.432+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 127.0 in stage 3.0 (TID 158). 6243 bytes result sent to driver
[2025-07-19T18:30:16.433+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 136.0 in stage 3.0 (TID 166)
[2025-07-19T18:30:16.434+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 128.0 in stage 3.0 (TID 159) in 81 ms on 8b44f3d35cfa (executor driver) (148/200)
[2025-07-19T18:30:16.434+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 127.0 in stage 3.0 (TID 158) in 96 ms on 8b44f3d35cfa (executor driver) (149/200)
[2025-07-19T18:30:16.435+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 138.0 in stage 3.0 (TID 167) (8b44f3d35cfa, executor driver, partition 138, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.436+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 138.0 in stage 3.0 (TID 167)
[2025-07-19T18:30:16.437+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/129/.1.delta.764f8b62-70d8-4b8d-aac0-f6028fb1a582.TID160.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/129/1.delta
[2025-07-19T18:30:16.438+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=129),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/129] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/129/1.delta
[2025-07-19T18:30:16.439+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 129 (task 160, attempt 0, stage 3.0)
[2025-07-19T18:30:16.440+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.440+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.441+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.441+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.442+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 129 (task 160, attempt 0, stage 3.0)
[2025-07-19T18:30:16.443+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 129.0 in stage 3.0 (TID 160). 6200 bytes result sent to driver
[2025-07-19T18:30:16.443+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 139.0 in stage 3.0 (TID 168) (8b44f3d35cfa, executor driver, partition 139, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.444+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 129.0 in stage 3.0 (TID 160) in 92 ms on 8b44f3d35cfa (executor driver) (150/200)
[2025-07-19T18:30:16.445+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 139.0 in stage 3.0 (TID 168)
[2025-07-19T18:30:16.445+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/135/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/135/.1.delta.f8c6aa4f-81fa-4cb4-880a-3200ca69e059.TID165.tmp
[2025-07-19T18:30:16.445+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5adf9290
[2025-07-19T18:30:16.446+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.447+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.447+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=136, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.447+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=136),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/136] for update
[2025-07-19T18:30:16.449+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.459+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3caf6cc0
[2025-07-19T18:30:16.460+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=139, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.460+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/134/.1.delta.dcbde976-40f6-4971-b5b9-0668cb75f6ed.TID164.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/134/1.delta
[2025-07-19T18:30:16.461+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=139),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/139] for update
[2025-07-19T18:30:16.461+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=134),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/134] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/134/1.delta
[2025-07-19T18:30:16.462+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.462+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 134 (task 164, attempt 0, stage 3.0)
[2025-07-19T18:30:16.466+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/133/.1.delta.4d6862cc-62d2-4ad5-b934-d6fc80cd94e4.TID163.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/133/1.delta
[2025-07-19T18:30:16.467+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=133),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/133] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/133/1.delta
[2025-07-19T18:30:16.469+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 133 (task 163, attempt 0, stage 3.0)
[2025-07-19T18:30:16.470+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/136/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/136/.1.delta.a027d1fe-1483-4093-a06f-0628efc6b5e1.TID166.tmp
[2025-07-19T18:30:16.471+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@497a5c05
[2025-07-19T18:30:16.471+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=138, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.472+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=138),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/138] for update
[2025-07-19T18:30:16.472+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 134 (task 164, attempt 0, stage 3.0)
[2025-07-19T18:30:16.472+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/139/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/139/.1.delta.37d90da9-8004-4674-89cd-43ff516e64cf.TID168.tmp
[2025-07-19T18:30:16.473+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.473+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 133 (task 163, attempt 0, stage 3.0)
[2025-07-19T18:30:16.474+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 133.0 in stage 3.0 (TID 163). 6243 bytes result sent to driver
[2025-07-19T18:30:16.475+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 140.0 in stage 3.0 (TID 169) (8b44f3d35cfa, executor driver, partition 140, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.476+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 140.0 in stage 3.0 (TID 169)
[2025-07-19T18:30:16.479+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 133.0 in stage 3.0 (TID 163) in 96 ms on 8b44f3d35cfa (executor driver) (151/200)
[2025-07-19T18:30:16.480+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 134.0 in stage 3.0 (TID 164). 6243 bytes result sent to driver
[2025-07-19T18:30:16.481+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.482+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.483+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 141.0 in stage 3.0 (TID 170) (8b44f3d35cfa, executor driver, partition 141, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.484+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 141.0 in stage 3.0 (TID 170)
[2025-07-19T18:30:16.485+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/131/.1.delta.17c4b4f5-99d5-4dab-9e79-3b70e98f4284.TID161.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/131/1.delta
[2025-07-19T18:30:16.486+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=131),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/131] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/131/1.delta
[2025-07-19T18:30:16.487+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 131 (task 161, attempt 0, stage 3.0)
[2025-07-19T18:30:16.488+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 134.0 in stage 3.0 (TID 164) in 103 ms on 8b44f3d35cfa (executor driver) (152/200)
[2025-07-19T18:30:16.488+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/132/.1.delta.8938f44c-04ff-4881-92fa-f79cc6c49f73.TID162.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/132/1.delta
[2025-07-19T18:30:16.488+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=132),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/132] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/132/1.delta
[2025-07-19T18:30:16.488+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 132 (task 162, attempt 0, stage 3.0)
[2025-07-19T18:30:16.489+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.489+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.489+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47ef94e0
[2025-07-19T18:30:16.490+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 131 (task 161, attempt 0, stage 3.0)
[2025-07-19T18:30:16.490+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=140, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.491+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=140),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/140] for update
[2025-07-19T18:30:16.491+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 132 (task 162, attempt 0, stage 3.0)
[2025-07-19T18:30:16.494+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 132.0 in stage 3.0 (TID 162). 6243 bytes result sent to driver
[2025-07-19T18:30:16.495+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 131.0 in stage 3.0 (TID 161). 6243 bytes result sent to driver
[2025-07-19T18:30:16.496+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/138/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/138/.1.delta.b062a39d-f03e-440d-93fb-5e95603f685f.TID167.tmp
[2025-07-19T18:30:16.496+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 143.0 in stage 3.0 (TID 171) (8b44f3d35cfa, executor driver, partition 143, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.497+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 143.0 in stage 3.0 (TID 171)
[2025-07-19T18:30:16.498+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 145.0 in stage 3.0 (TID 172) (8b44f3d35cfa, executor driver, partition 145, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.499+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 132.0 in stage 3.0 (TID 162) in 120 ms on 8b44f3d35cfa (executor driver) (153/200)
[2025-07-19T18:30:16.500+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 145.0 in stage 3.0 (TID 172)
[2025-07-19T18:30:16.500+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 131.0 in stage 3.0 (TID 161) in 129 ms on 8b44f3d35cfa (executor driver) (154/200)
[2025-07-19T18:30:16.503+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.504+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43a8081e
[2025-07-19T18:30:16.504+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.505+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.506+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.506+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=141, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.507+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.512+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=141),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/141] for update
[2025-07-19T18:30:16.513+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.514+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/135/.1.delta.f8c6aa4f-81fa-4cb4-880a-3200ca69e059.TID165.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/135/1.delta
[2025-07-19T18:30:16.515+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=135),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/135] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/135/1.delta
[2025-07-19T18:30:16.515+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 135 (task 165, attempt 0, stage 3.0)
[2025-07-19T18:30:16.516+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@27ac8546
[2025-07-19T18:30:16.518+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=143, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.519+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=143),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/143] for update
[2025-07-19T18:30:16.520+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/140/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/140/.1.delta.5c305602-d9f2-448e-82d3-7590e7eba48f.TID169.tmp
[2025-07-19T18:30:16.521+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.521+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/141/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/141/.1.delta.97f7fb7f-952d-4a75-ae3f-fee6a136bab0.TID170.tmp
[2025-07-19T18:30:16.522+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 135 (task 165, attempt 0, stage 3.0)
[2025-07-19T18:30:16.522+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 135.0 in stage 3.0 (TID 165). 6286 bytes result sent to driver
[2025-07-19T18:30:16.523+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 146.0 in stage 3.0 (TID 173) (8b44f3d35cfa, executor driver, partition 146, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.523+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 135.0 in stage 3.0 (TID 165) in 124 ms on 8b44f3d35cfa (executor driver) (155/200)
[2025-07-19T18:30:16.524+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 146.0 in stage 3.0 (TID 173)
[2025-07-19T18:30:16.526+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35109594
[2025-07-19T18:30:16.527+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.527+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.527+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/136/.1.delta.a027d1fe-1483-4093-a06f-0628efc6b5e1.TID166.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/136/1.delta
[2025-07-19T18:30:16.528+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=136),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/136] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/136/1.delta
[2025-07-19T18:30:16.528+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 136 (task 166, attempt 0, stage 3.0)
[2025-07-19T18:30:16.529+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=145, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.529+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=145),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/145] for update
[2025-07-19T18:30:16.529+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/139/.1.delta.37d90da9-8004-4674-89cd-43ff516e64cf.TID168.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/139/1.delta
[2025-07-19T18:30:16.531+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=139),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/139] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/139/1.delta
[2025-07-19T18:30:16.532+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 139 (task 168, attempt 0, stage 3.0)
[2025-07-19T18:30:16.533+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/143/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/143/.1.delta.9901b347-3b67-4761-991e-20626c2fd136.TID171.tmp
[2025-07-19T18:30:16.534+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 136 (task 166, attempt 0, stage 3.0)
[2025-07-19T18:30:16.535+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a0138a3
[2025-07-19T18:30:16.535+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=146, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.536+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=146),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/146] for update
[2025-07-19T18:30:16.536+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.536+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 139 (task 168, attempt 0, stage 3.0)
[2025-07-19T18:30:16.537+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 139.0 in stage 3.0 (TID 168). 6243 bytes result sent to driver
[2025-07-19T18:30:16.538+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 136.0 in stage 3.0 (TID 166). 6286 bytes result sent to driver
[2025-07-19T18:30:16.539+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 139.0 in stage 3.0 (TID 168) in 95 ms on 8b44f3d35cfa (executor driver) (156/200)
[2025-07-19T18:30:16.540+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 147.0 in stage 3.0 (TID 174) (8b44f3d35cfa, executor driver, partition 147, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.541+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 136.0 in stage 3.0 (TID 166) in 108 ms on 8b44f3d35cfa (executor driver) (157/200)
[2025-07-19T18:30:16.541+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 147.0 in stage 3.0 (TID 174)
[2025-07-19T18:30:16.541+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 148.0 in stage 3.0 (TID 175) (8b44f3d35cfa, executor driver, partition 148, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.542+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 148.0 in stage 3.0 (TID 175)
[2025-07-19T18:30:16.543+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.544+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.545+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.545+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.546+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.546+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/145/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/145/.1.delta.7dd0ca99-6841-482d-b5e2-435a198294ef.TID172.tmp
[2025-07-19T18:30:16.547+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/138/.1.delta.b062a39d-f03e-440d-93fb-5e95603f685f.TID167.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/138/1.delta
[2025-07-19T18:30:16.547+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=138),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/138] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/138/1.delta
[2025-07-19T18:30:16.548+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 138 (task 167, attempt 0, stage 3.0)
[2025-07-19T18:30:16.550+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 138 (task 167, attempt 0, stage 3.0)
[2025-07-19T18:30:16.552+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73cdcbb5
[2025-07-19T18:30:16.553+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=148, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.553+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=148),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/148] for update
[2025-07-19T18:30:16.559+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/140/.1.delta.5c305602-d9f2-448e-82d3-7590e7eba48f.TID169.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/140/1.delta
[2025-07-19T18:30:16.560+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=140),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/140] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/140/1.delta
[2025-07-19T18:30:16.562+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/146/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/146/.1.delta.060418cc-8b7a-460c-ae9a-02085382535c.TID173.tmp
[2025-07-19T18:30:16.562+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.562+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 138.0 in stage 3.0 (TID 167). 6286 bytes result sent to driver
[2025-07-19T18:30:16.562+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 140 (task 169, attempt 0, stage 3.0)
[2025-07-19T18:30:16.563+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 150.0 in stage 3.0 (TID 176) (8b44f3d35cfa, executor driver, partition 150, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.564+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e1c7a5b
[2025-07-19T18:30:16.566+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 138.0 in stage 3.0 (TID 167) in 133 ms on 8b44f3d35cfa (executor driver) (158/200)
[2025-07-19T18:30:16.566+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=147, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.568+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=147),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/147] for update
[2025-07-19T18:30:16.569+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 150.0 in stage 3.0 (TID 176)
[2025-07-19T18:30:16.570+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/141/.1.delta.97f7fb7f-952d-4a75-ae3f-fee6a136bab0.TID170.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/141/1.delta
[2025-07-19T18:30:16.571+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=141),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/141] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/141/1.delta
[2025-07-19T18:30:16.572+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.573+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 141 (task 170, attempt 0, stage 3.0)
[2025-07-19T18:30:16.573+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.573+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.574+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 140 (task 169, attempt 0, stage 3.0)
[2025-07-19T18:30:16.574+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/148/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/148/.1.delta.0a7a2bdd-a929-40df-a6ad-215e3f162834.TID175.tmp
[2025-07-19T18:30:16.576+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 140.0 in stage 3.0 (TID 169). 6243 bytes result sent to driver
[2025-07-19T18:30:16.578+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 153.0 in stage 3.0 (TID 177) (8b44f3d35cfa, executor driver, partition 153, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.579+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 140.0 in stage 3.0 (TID 169) in 105 ms on 8b44f3d35cfa (executor driver) (159/200)
[2025-07-19T18:30:16.579+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 153.0 in stage 3.0 (TID 177)
[2025-07-19T18:30:16.580+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 141 (task 170, attempt 0, stage 3.0)
[2025-07-19T18:30:16.580+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@411f0d4e
[2025-07-19T18:30:16.581+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 141.0 in stage 3.0 (TID 170). 6243 bytes result sent to driver
[2025-07-19T18:30:16.581+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.582+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.582+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 154.0 in stage 3.0 (TID 178) (8b44f3d35cfa, executor driver, partition 154, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.583+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=150, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.583+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 141.0 in stage 3.0 (TID 170) in 105 ms on 8b44f3d35cfa (executor driver) (160/200)
[2025-07-19T18:30:16.583+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=150),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/150] for update
[2025-07-19T18:30:16.583+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 154.0 in stage 3.0 (TID 178)
[2025-07-19T18:30:16.583+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.584+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/143/.1.delta.9901b347-3b67-4761-991e-20626c2fd136.TID171.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/143/1.delta
[2025-07-19T18:30:16.584+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=143),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/143] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/143/1.delta
[2025-07-19T18:30:16.584+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 143 (task 171, attempt 0, stage 3.0)
[2025-07-19T18:30:16.585+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/147/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/147/.1.delta.b2e8445c-a2d0-478d-9a89-43ac1eb789db.TID174.tmp
[2025-07-19T18:30:16.589+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.591+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.592+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d327823
[2025-07-19T18:30:16.594+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=153, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.595+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=153),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/153] for update
[2025-07-19T18:30:16.597+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 143 (task 171, attempt 0, stage 3.0)
[2025-07-19T18:30:16.597+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 143.0 in stage 3.0 (TID 171). 6243 bytes result sent to driver
[2025-07-19T18:30:16.598+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/150/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/150/.1.delta.c5bcdaee-3033-488c-872a-efc0f2d52711.TID176.tmp
[2025-07-19T18:30:16.603+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.605+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68da7266
[2025-07-19T18:30:16.606+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/145/.1.delta.7dd0ca99-6841-482d-b5e2-435a198294ef.TID172.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/145/1.delta
[2025-07-19T18:30:16.606+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=154, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.607+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=154),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/154] for update
[2025-07-19T18:30:16.608+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=145),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/145] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/145/1.delta
[2025-07-19T18:30:16.608+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 145 (task 172, attempt 0, stage 3.0)
[2025-07-19T18:30:16.609+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 155.0 in stage 3.0 (TID 179) (8b44f3d35cfa, executor driver, partition 155, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.610+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.610+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 143.0 in stage 3.0 (TID 171) in 113 ms on 8b44f3d35cfa (executor driver) (161/200)
[2025-07-19T18:30:16.611+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 145 (task 172, attempt 0, stage 3.0)
[2025-07-19T18:30:16.612+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 145.0 in stage 3.0 (TID 172). 6243 bytes result sent to driver
[2025-07-19T18:30:16.614+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 155.0 in stage 3.0 (TID 179)
[2025-07-19T18:30:16.615+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 156.0 in stage 3.0 (TID 180) (8b44f3d35cfa, executor driver, partition 156, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.615+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 145.0 in stage 3.0 (TID 172) in 114 ms on 8b44f3d35cfa (executor driver) (162/200)
[2025-07-19T18:30:16.615+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 156.0 in stage 3.0 (TID 180)
[2025-07-19T18:30:16.616+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.616+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.617+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.617+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.617+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/153/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/153/.1.delta.454feb79-6857-49cc-bf10-72b414acbc6b.TID177.tmp
[2025-07-19T18:30:16.618+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/146/.1.delta.060418cc-8b7a-460c-ae9a-02085382535c.TID173.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/146/1.delta
[2025-07-19T18:30:16.618+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=146),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/146] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/146/1.delta
[2025-07-19T18:30:16.619+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 146 (task 173, attempt 0, stage 3.0)
[2025-07-19T18:30:16.619+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35a9bfe6
[2025-07-19T18:30:16.619+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=155, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.620+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=155),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/155] for update
[2025-07-19T18:30:16.620+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/154/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/154/.1.delta.cd90d329-6224-4c80-82e9-8418def5283c.TID178.tmp
[2025-07-19T18:30:16.620+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.622+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 146 (task 173, attempt 0, stage 3.0)
[2025-07-19T18:30:16.624+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 146.0 in stage 3.0 (TID 173). 6243 bytes result sent to driver
[2025-07-19T18:30:16.624+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 157.0 in stage 3.0 (TID 181) (8b44f3d35cfa, executor driver, partition 157, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.625+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 157.0 in stage 3.0 (TID 181)
[2025-07-19T18:30:16.625+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 146.0 in stage 3.0 (TID 173) in 109 ms on 8b44f3d35cfa (executor driver) (163/200)
[2025-07-19T18:30:16.626+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.627+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/148/.1.delta.0a7a2bdd-a929-40df-a6ad-215e3f162834.TID175.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/148/1.delta
[2025-07-19T18:30:16.627+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=148),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/148] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/148/1.delta
[2025-07-19T18:30:16.629+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T18:30:16.630+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d6b9901
[2025-07-19T18:30:16.632+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 148 (task 175, attempt 0, stage 3.0)
[2025-07-19T18:30:16.632+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=156, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.633+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=156),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/156] for update
[2025-07-19T18:30:16.634+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/155/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/155/.1.delta.edb8c606-4f7e-4be3-8cd6-d101ef4d3e75.TID179.tmp
[2025-07-19T18:30:16.635+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.636+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/147/.1.delta.b2e8445c-a2d0-478d-9a89-43ac1eb789db.TID174.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/147/1.delta
[2025-07-19T18:30:16.637+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=147),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/147] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/147/1.delta
[2025-07-19T18:30:16.637+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 148 (task 175, attempt 0, stage 3.0)
[2025-07-19T18:30:16.637+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 147 (task 174, attempt 0, stage 3.0)
[2025-07-19T18:30:16.637+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ff9d3b3
[2025-07-19T18:30:16.637+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=157, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.637+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=157),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/157] for update
[2025-07-19T18:30:16.643+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 148.0 in stage 3.0 (TID 175). 6286 bytes result sent to driver
[2025-07-19T18:30:16.644+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 158.0 in stage 3.0 (TID 182) (8b44f3d35cfa, executor driver, partition 158, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.645+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 148.0 in stage 3.0 (TID 175) in 106 ms on 8b44f3d35cfa (executor driver) (164/200)
[2025-07-19T18:30:16.646+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.647+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/150/.1.delta.c5bcdaee-3033-488c-872a-efc0f2d52711.TID176.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/150/1.delta
[2025-07-19T18:30:16.647+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=150),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/150] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/150/1.delta
[2025-07-19T18:30:16.648+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 147 (task 174, attempt 0, stage 3.0)
[2025-07-19T18:30:16.648+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 150 (task 176, attempt 0, stage 3.0)
[2025-07-19T18:30:16.648+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 158.0 in stage 3.0 (TID 182)
[2025-07-19T18:30:16.650+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/153/.1.delta.454feb79-6857-49cc-bf10-72b414acbc6b.TID177.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/153/1.delta
[2025-07-19T18:30:16.651+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=153),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/153] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/153/1.delta
[2025-07-19T18:30:16.652+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/157/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/157/.1.delta.c7ce05b3-8f21-4a8e-819d-9c23c4325e69.TID181.tmp
[2025-07-19T18:30:16.652+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 153 (task 177, attempt 0, stage 3.0)
[2025-07-19T18:30:16.652+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 147.0 in stage 3.0 (TID 174). 6243 bytes result sent to driver
[2025-07-19T18:30:16.653+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 159.0 in stage 3.0 (TID 183) (8b44f3d35cfa, executor driver, partition 159, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.654+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 147.0 in stage 3.0 (TID 174) in 116 ms on 8b44f3d35cfa (executor driver) (165/200)
[2025-07-19T18:30:16.656+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 159.0 in stage 3.0 (TID 183)
[2025-07-19T18:30:16.656+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 150 (task 176, attempt 0, stage 3.0)
[2025-07-19T18:30:16.656+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 153 (task 177, attempt 0, stage 3.0)
[2025-07-19T18:30:16.657+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 153.0 in stage 3.0 (TID 177). 6243 bytes result sent to driver
[2025-07-19T18:30:16.657+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 160.0 in stage 3.0 (TID 184) (8b44f3d35cfa, executor driver, partition 160, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.658+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 150.0 in stage 3.0 (TID 176). 6243 bytes result sent to driver
[2025-07-19T18:30:16.659+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 160.0 in stage 3.0 (TID 184)
[2025-07-19T18:30:16.660+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 153.0 in stage 3.0 (TID 177) in 81 ms on 8b44f3d35cfa (executor driver) (166/200)
[2025-07-19T18:30:16.661+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.661+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:16.661+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 161.0 in stage 3.0 (TID 185) (8b44f3d35cfa, executor driver, partition 161, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.661+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 161.0 in stage 3.0 (TID 185)
[2025-07-19T18:30:16.661+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.662+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.662+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/156/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/156/.1.delta.6cba11bb-2bf8-4666-92a9-21870db478d7.TID180.tmp
[2025-07-19T18:30:16.662+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 150.0 in stage 3.0 (TID 176) in 97 ms on 8b44f3d35cfa (executor driver) (167/200)
[2025-07-19T18:30:16.663+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.663+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.663+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.664+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.664+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d27bc2c
[2025-07-19T18:30:16.664+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/154/.1.delta.cd90d329-6224-4c80-82e9-8418def5283c.TID178.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/154/1.delta
[2025-07-19T18:30:16.665+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=154),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/154] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/154/1.delta
[2025-07-19T18:30:16.665+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=158, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.666+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=158),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/158] for update
[2025-07-19T18:30:16.666+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 154 (task 178, attempt 0, stage 3.0)
[2025-07-19T18:30:16.667+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1afffd60
[2025-07-19T18:30:16.667+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=159, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.667+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.667+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=159),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/159] for update
[2025-07-19T18:30:16.668+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.670+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 154 (task 178, attempt 0, stage 3.0)
[2025-07-19T18:30:16.671+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 154.0 in stage 3.0 (TID 178). 6243 bytes result sent to driver
[2025-07-19T18:30:16.672+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 163.0 in stage 3.0 (TID 186) (8b44f3d35cfa, executor driver, partition 163, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.673+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 154.0 in stage 3.0 (TID 178) in 93 ms on 8b44f3d35cfa (executor driver) (168/200)
[2025-07-19T18:30:16.674+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 163.0 in stage 3.0 (TID 186)
[2025-07-19T18:30:16.677+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@542eb501
[2025-07-19T18:30:16.677+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=161, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.679+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=161),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/161] for update
[2025-07-19T18:30:16.679+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/155/.1.delta.edb8c606-4f7e-4be3-8cd6-d101ef4d3e75.TID179.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/155/1.delta
[2025-07-19T18:30:16.680+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=155),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/155] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/155/1.delta
[2025-07-19T18:30:16.680+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 155 (task 179, attempt 0, stage 3.0)
[2025-07-19T18:30:16.681+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.682+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.682+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.684+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3809757c
[2025-07-19T18:30:16.685+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=160, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.687+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=160),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/160] for update
[2025-07-19T18:30:16.688+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.689+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/158/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/158/.1.delta.01eae087-f14e-4392-a4e9-9238a292bc8d.TID182.tmp
[2025-07-19T18:30:16.690+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25dd284a
[2025-07-19T18:30:16.692+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=163, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.693+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=163),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/163] for update
[2025-07-19T18:30:16.693+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.694+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/159/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/159/.1.delta.dc5d20a3-cfcb-4f43-93fc-0c2032b68a48.TID183.tmp
[2025-07-19T18:30:16.694+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 155 (task 179, attempt 0, stage 3.0)
[2025-07-19T18:30:16.695+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 155.0 in stage 3.0 (TID 179). 6243 bytes result sent to driver
[2025-07-19T18:30:16.695+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 164.0 in stage 3.0 (TID 187) (8b44f3d35cfa, executor driver, partition 164, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.696+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 164.0 in stage 3.0 (TID 187)
[2025-07-19T18:30:16.696+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 155.0 in stage 3.0 (TID 179) in 96 ms on 8b44f3d35cfa (executor driver) (169/200)
[2025-07-19T18:30:16.696+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.697+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.700+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/160/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/160/.1.delta.68d50033-f8f9-4931-beb5-5ac4c306fa44.TID184.tmp
[2025-07-19T18:30:16.701+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/157/.1.delta.c7ce05b3-8f21-4a8e-819d-9c23c4325e69.TID181.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/157/1.delta
[2025-07-19T18:30:16.702+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=157),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/157] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/157/1.delta
[2025-07-19T18:30:16.702+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@13cf422c
[2025-07-19T18:30:16.702+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/161/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/161/.1.delta.b35c863d-d4a4-41d1-a5c3-da5b85ecea09.TID185.tmp
[2025-07-19T18:30:16.702+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=164, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.702+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=164),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/164] for update
[2025-07-19T18:30:16.702+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 157 (task 181, attempt 0, stage 3.0)
[2025-07-19T18:30:16.703+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.703+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/163/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/163/.1.delta.541d0e79-5631-4ef7-be69-33d3ad154877.TID186.tmp
[2025-07-19T18:30:16.711+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 157 (task 181, attempt 0, stage 3.0)
[2025-07-19T18:30:16.712+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 157.0 in stage 3.0 (TID 181). 6243 bytes result sent to driver
[2025-07-19T18:30:16.712+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 165.0 in stage 3.0 (TID 188) (8b44f3d35cfa, executor driver, partition 165, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.713+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 157.0 in stage 3.0 (TID 181) in 88 ms on 8b44f3d35cfa (executor driver) (170/200)
[2025-07-19T18:30:16.713+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 165.0 in stage 3.0 (TID 188)
[2025-07-19T18:30:16.714+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/164/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/164/.1.delta.2fb02348-7c2b-4dee-b350-8657520ac6d8.TID187.tmp
[2025-07-19T18:30:16.718+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.719+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.721+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/156/.1.delta.6cba11bb-2bf8-4666-92a9-21870db478d7.TID180.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/156/1.delta
[2025-07-19T18:30:16.721+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=156),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/156] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/156/1.delta
[2025-07-19T18:30:16.721+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/159/.1.delta.dc5d20a3-cfcb-4f43-93fc-0c2032b68a48.TID183.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/159/1.delta
[2025-07-19T18:30:16.722+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=159),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/159] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/159/1.delta
[2025-07-19T18:30:16.722+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 156 (task 180, attempt 0, stage 3.0)
[2025-07-19T18:30:16.722+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/158/.1.delta.01eae087-f14e-4392-a4e9-9238a292bc8d.TID182.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/158/1.delta
[2025-07-19T18:30:16.723+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=158),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/158] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/158/1.delta
[2025-07-19T18:30:16.724+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 158 (task 182, attempt 0, stage 3.0)
[2025-07-19T18:30:16.725+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 159 (task 183, attempt 0, stage 3.0)
[2025-07-19T18:30:16.725+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/161/.1.delta.b35c863d-d4a4-41d1-a5c3-da5b85ecea09.TID185.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/161/1.delta
[2025-07-19T18:30:16.725+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=161),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/161] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/161/1.delta
[2025-07-19T18:30:16.726+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 161 (task 185, attempt 0, stage 3.0)
[2025-07-19T18:30:16.726+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58e3a73b
[2025-07-19T18:30:16.727+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=165, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.727+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=165),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/165] for update
[2025-07-19T18:30:16.730+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 156 (task 180, attempt 0, stage 3.0)
[2025-07-19T18:30:16.731+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 158 (task 182, attempt 0, stage 3.0)
[2025-07-19T18:30:16.731+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 156.0 in stage 3.0 (TID 180). 6243 bytes result sent to driver
[2025-07-19T18:30:16.731+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 158.0 in stage 3.0 (TID 182). 6200 bytes result sent to driver
[2025-07-19T18:30:16.732+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.732+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/160/.1.delta.68d50033-f8f9-4931-beb5-5ac4c306fa44.TID184.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/160/1.delta
[2025-07-19T18:30:16.732+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=160),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/160] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/160/1.delta
[2025-07-19T18:30:16.732+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 161 (task 185, attempt 0, stage 3.0)
[2025-07-19T18:30:16.740+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 161.0 in stage 3.0 (TID 185). 6286 bytes result sent to driver
[2025-07-19T18:30:16.741+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 160 (task 184, attempt 0, stage 3.0)
[2025-07-19T18:30:16.741+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 167.0 in stage 3.0 (TID 189) (8b44f3d35cfa, executor driver, partition 167, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.741+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 159 (task 183, attempt 0, stage 3.0)
[2025-07-19T18:30:16.742+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 167.0 in stage 3.0 (TID 189)
[2025-07-19T18:30:16.742+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 159.0 in stage 3.0 (TID 183). 6243 bytes result sent to driver
[2025-07-19T18:30:16.743+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 168.0 in stage 3.0 (TID 190) (8b44f3d35cfa, executor driver, partition 168, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.744+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/163/.1.delta.541d0e79-5631-4ef7-be69-33d3ad154877.TID186.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/163/1.delta
[2025-07-19T18:30:16.744+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=163),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/163] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/163/1.delta
[2025-07-19T18:30:16.745+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 168.0 in stage 3.0 (TID 190)
[2025-07-19T18:30:16.746+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 163 (task 186, attempt 0, stage 3.0)
[2025-07-19T18:30:16.747+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.748+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.749+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.749+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/165/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/165/.1.delta.b2d3616f-7fa9-4d8d-a4f3-d82ac12ae893.TID188.tmp
[2025-07-19T18:30:16.750+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.751+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 169.0 in stage 3.0 (TID 191) (8b44f3d35cfa, executor driver, partition 169, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.751+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 170.0 in stage 3.0 (TID 192) (8b44f3d35cfa, executor driver, partition 170, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.752+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 170.0 in stage 3.0 (TID 192)
[2025-07-19T18:30:16.752+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 169.0 in stage 3.0 (TID 191)
[2025-07-19T18:30:16.752+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 163 (task 186, attempt 0, stage 3.0)
[2025-07-19T18:30:16.752+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.753+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 156.0 in stage 3.0 (TID 180) in 146 ms on 8b44f3d35cfa (executor driver) (171/200)
[2025-07-19T18:30:16.753+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 161.0 in stage 3.0 (TID 185) in 92 ms on 8b44f3d35cfa (executor driver) (172/200)
[2025-07-19T18:30:16.753+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 159.0 in stage 3.0 (TID 183) in 96 ms on 8b44f3d35cfa (executor driver) (173/200)
[2025-07-19T18:30:16.753+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.753+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 163.0 in stage 3.0 (TID 186). 6243 bytes result sent to driver
[2025-07-19T18:30:16.753+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 158.0 in stage 3.0 (TID 182) in 107 ms on 8b44f3d35cfa (executor driver) (174/200)
[2025-07-19T18:30:16.753+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 171.0 in stage 3.0 (TID 193) (8b44f3d35cfa, executor driver, partition 171, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.753+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 171.0 in stage 3.0 (TID 193)
[2025-07-19T18:30:16.754+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/164/.1.delta.2fb02348-7c2b-4dee-b350-8657520ac6d8.TID187.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/164/1.delta
[2025-07-19T18:30:16.754+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=164),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/164] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/164/1.delta
[2025-07-19T18:30:16.755+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 164 (task 187, attempt 0, stage 3.0)
[2025-07-19T18:30:16.755+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.755+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.755+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@716c7551
[2025-07-19T18:30:16.757+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 163.0 in stage 3.0 (TID 186) in 83 ms on 8b44f3d35cfa (executor driver) (175/200)
[2025-07-19T18:30:16.758+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=168, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.759+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=168),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/168] for update
[2025-07-19T18:30:16.759+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.759+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.760+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
[2025-07-19T18:30:16.760+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 164 (task 187, attempt 0, stage 3.0)
[2025-07-19T18:30:16.760+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 160 (task 184, attempt 0, stage 3.0)
[2025-07-19T18:30:16.760+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 164.0 in stage 3.0 (TID 187). 6243 bytes result sent to driver
[2025-07-19T18:30:16.760+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 160.0 in stage 3.0 (TID 184). 6243 bytes result sent to driver
[2025-07-19T18:30:16.761+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@684715ca
[2025-07-19T18:30:16.764+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 172.0 in stage 3.0 (TID 194) (8b44f3d35cfa, executor driver, partition 172, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.765+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=171, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.765+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=171),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/171] for update
[2025-07-19T18:30:16.766+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 164.0 in stage 3.0 (TID 187) in 71 ms on 8b44f3d35cfa (executor driver) (176/200)
[2025-07-19T18:30:16.766+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 160.0 in stage 3.0 (TID 184) in 108 ms on 8b44f3d35cfa (executor driver) (177/200)
[2025-07-19T18:30:16.767+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 172.0 in stage 3.0 (TID 194)
[2025-07-19T18:30:16.767+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.767+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 173.0 in stage 3.0 (TID 195) (8b44f3d35cfa, executor driver, partition 173, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.768+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.768+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.768+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 173.0 in stage 3.0 (TID 195)
[2025-07-19T18:30:16.769+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.769+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.771+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/168/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/168/.1.delta.38f87ba2-9390-4b6d-9a31-1c92146ddce2.TID190.tmp
[2025-07-19T18:30:16.773+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@46233931
[2025-07-19T18:30:16.773+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=169, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.774+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=169),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/169] for update
[2025-07-19T18:30:16.777+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.781+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/171/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/171/.1.delta.5c4e4e8f-6941-4112-a274-9e0fe76c9e57.TID193.tmp
[2025-07-19T18:30:16.782+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@502d901
[2025-07-19T18:30:16.782+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=167, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.783+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=167),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/167] for update
[2025-07-19T18:30:16.786+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/165/.1.delta.b2d3616f-7fa9-4d8d-a4f3-d82ac12ae893.TID188.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/165/1.delta
[2025-07-19T18:30:16.787+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=165),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/165] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/165/1.delta
[2025-07-19T18:30:16.789+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 165 (task 188, attempt 0, stage 3.0)
[2025-07-19T18:30:16.790+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.791+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/169/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/169/.1.delta.5efd963f-a498-454f-885e-7967e16f691a.TID191.tmp
[2025-07-19T18:30:16.792+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@655c96b8
[2025-07-19T18:30:16.793+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=173, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.793+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=173),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/173] for update
[2025-07-19T18:30:16.793+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.796+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 165 (task 188, attempt 0, stage 3.0)
[2025-07-19T18:30:16.799+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 165.0 in stage 3.0 (TID 188). 6243 bytes result sent to driver
[2025-07-19T18:30:16.800+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 177.0 in stage 3.0 (TID 196) (8b44f3d35cfa, executor driver, partition 177, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.802+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 177.0 in stage 3.0 (TID 196)
[2025-07-19T18:30:16.804+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6591845
[2025-07-19T18:30:16.804+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 165.0 in stage 3.0 (TID 188) in 87 ms on 8b44f3d35cfa (executor driver) (178/200)
[2025-07-19T18:30:16.806+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=172, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.806+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=172),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/172] for update
[2025-07-19T18:30:16.807+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.808+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.809+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.809+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/167/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/167/.1.delta.b75b6fa9-854a-453d-9e14-33dff066896c.TID189.tmp
[2025-07-19T18:30:16.810+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a07615
[2025-07-19T18:30:16.810+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=170, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.811+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/173/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/173/.1.delta.ba30bf05-53fc-407c-8dd4-50dbd8100e59.TID195.tmp
[2025-07-19T18:30:16.811+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=170),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/170] for update
[2025-07-19T18:30:16.813+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/168/.1.delta.38f87ba2-9390-4b6d-9a31-1c92146ddce2.TID190.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/168/1.delta
[2025-07-19T18:30:16.813+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=168),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/168] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/168/1.delta
[2025-07-19T18:30:16.814+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.814+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 168 (task 190, attempt 0, stage 3.0)
[2025-07-19T18:30:16.815+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/172/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/172/.1.delta.81d5917d-3f17-4298-b0fe-becb3d58d55b.TID194.tmp
[2025-07-19T18:30:16.821+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6005dff9
[2025-07-19T18:30:16.821+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=177, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.821+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=177),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/177] for update
[2025-07-19T18:30:16.822+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 168 (task 190, attempt 0, stage 3.0)
[2025-07-19T18:30:16.826+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 168.0 in stage 3.0 (TID 190). 6286 bytes result sent to driver
[2025-07-19T18:30:16.827+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 179.0 in stage 3.0 (TID 197) (8b44f3d35cfa, executor driver, partition 179, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.829+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.829+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 168.0 in stage 3.0 (TID 190) in 89 ms on 8b44f3d35cfa (executor driver) (179/200)
[2025-07-19T18:30:16.831+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 179.0 in stage 3.0 (TID 197)
[2025-07-19T18:30:16.831+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/170/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/170/.1.delta.dec9bfb5-83eb-4668-9c30-8c4d12a2baa9.TID192.tmp
[2025-07-19T18:30:16.836+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.836+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.838+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/171/.1.delta.5c4e4e8f-6941-4112-a274-9e0fe76c9e57.TID193.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/171/1.delta
[2025-07-19T18:30:16.838+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=171),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/171] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/171/1.delta
[2025-07-19T18:30:16.839+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 171 (task 193, attempt 0, stage 3.0)
[2025-07-19T18:30:16.842+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/169/.1.delta.5efd963f-a498-454f-885e-7967e16f691a.TID191.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/169/1.delta
[2025-07-19T18:30:16.844+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=169),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/169] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/169/1.delta
[2025-07-19T18:30:16.844+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/177/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/177/.1.delta.2d36c93a-c8f1-4b4d-83d8-be6a02dba323.TID196.tmp
[2025-07-19T18:30:16.845+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 169 (task 191, attempt 0, stage 3.0)
[2025-07-19T18:30:16.845+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@135206bb
[2025-07-19T18:30:16.845+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=179, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.846+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=179),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/179] for update
[2025-07-19T18:30:16.846+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.846+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 171 (task 193, attempt 0, stage 3.0)
[2025-07-19T18:30:16.846+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 171.0 in stage 3.0 (TID 193). 6243 bytes result sent to driver
[2025-07-19T18:30:16.850+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 169 (task 191, attempt 0, stage 3.0)
[2025-07-19T18:30:16.851+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 180.0 in stage 3.0 (TID 198) (8b44f3d35cfa, executor driver, partition 180, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.851+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 171.0 in stage 3.0 (TID 193) in 100 ms on 8b44f3d35cfa (executor driver) (180/200)
[2025-07-19T18:30:16.852+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 180.0 in stage 3.0 (TID 198)
[2025-07-19T18:30:16.853+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/172/.1.delta.81d5917d-3f17-4298-b0fe-becb3d58d55b.TID194.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/172/1.delta
[2025-07-19T18:30:16.853+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=172),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/172] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/172/1.delta
[2025-07-19T18:30:16.854+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/167/.1.delta.b75b6fa9-854a-453d-9e14-33dff066896c.TID189.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/167/1.delta
[2025-07-19T18:30:16.855+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=167),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/167] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/167/1.delta
[2025-07-19T18:30:16.856+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 169.0 in stage 3.0 (TID 191). 6243 bytes result sent to driver
[2025-07-19T18:30:16.856+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 181.0 in stage 3.0 (TID 199) (8b44f3d35cfa, executor driver, partition 181, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.857+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 167 (task 189, attempt 0, stage 3.0)
[2025-07-19T18:30:16.857+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 172 (task 194, attempt 0, stage 3.0)
[2025-07-19T18:30:16.857+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.858+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.858+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 169.0 in stage 3.0 (TID 191) in 107 ms on 8b44f3d35cfa (executor driver) (181/200)
[2025-07-19T18:30:16.859+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/173/.1.delta.ba30bf05-53fc-407c-8dd4-50dbd8100e59.TID195.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/173/1.delta
[2025-07-19T18:30:16.861+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=173),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/173] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/173/1.delta
[2025-07-19T18:30:16.863+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/179/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/179/.1.delta.df4585e9-1008-4898-a220-e3a18d75d011.TID197.tmp
[2025-07-19T18:30:16.864+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 181.0 in stage 3.0 (TID 199)
[2025-07-19T18:30:16.865+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 173 (task 195, attempt 0, stage 3.0)
[2025-07-19T18:30:16.866+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7ab41a72
[2025-07-19T18:30:16.866+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=180, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.866+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=180),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/180] for update
[2025-07-19T18:30:16.866+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 167 (task 189, attempt 0, stage 3.0)
[2025-07-19T18:30:16.866+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.866+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.867+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.868+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 173 (task 195, attempt 0, stage 3.0)
[2025-07-19T18:30:16.869+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 167.0 in stage 3.0 (TID 189). 6243 bytes result sent to driver
[2025-07-19T18:30:16.869+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 173.0 in stage 3.0 (TID 195). 6243 bytes result sent to driver
[2025-07-19T18:30:16.869+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 172 (task 194, attempt 0, stage 3.0)
[2025-07-19T18:30:16.869+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 172.0 in stage 3.0 (TID 194). 6243 bytes result sent to driver
[2025-07-19T18:30:16.869+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 182.0 in stage 3.0 (TID 200) (8b44f3d35cfa, executor driver, partition 182, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.869+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 186.0 in stage 3.0 (TID 201) (8b44f3d35cfa, executor driver, partition 186, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.869+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 189.0 in stage 3.0 (TID 202) (8b44f3d35cfa, executor driver, partition 189, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.869+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 189.0 in stage 3.0 (TID 202)
[2025-07-19T18:30:16.869+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 186.0 in stage 3.0 (TID 201)
[2025-07-19T18:30:16.870+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 182.0 in stage 3.0 (TID 200)
[2025-07-19T18:30:16.873+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.874+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T18:30:16.875+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/180/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/180/.1.delta.bbb2f0f5-9a09-4782-adb6-746cc6a19d31.TID198.tmp
[2025-07-19T18:30:16.875+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.875+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.875+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.876+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:16.876+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 167.0 in stage 3.0 (TID 189) in 133 ms on 8b44f3d35cfa (executor driver) (182/200)
[2025-07-19T18:30:16.877+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 173.0 in stage 3.0 (TID 195) in 108 ms on 8b44f3d35cfa (executor driver) (183/200)
[2025-07-19T18:30:16.877+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 172.0 in stage 3.0 (TID 194) in 111 ms on 8b44f3d35cfa (executor driver) (184/200)
[2025-07-19T18:30:16.877+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c87a0f3
[2025-07-19T18:30:16.877+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=181, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.878+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=181),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/181] for update
[2025-07-19T18:30:16.878+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.879+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31f85a70
[2025-07-19T18:30:16.880+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=186, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.880+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=186),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/186] for update
[2025-07-19T18:30:16.880+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.882+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/170/.1.delta.dec9bfb5-83eb-4668-9c30-8c4d12a2baa9.TID192.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/170/1.delta
[2025-07-19T18:30:16.883+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=170),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/170] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/170/1.delta
[2025-07-19T18:30:16.883+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 170 (task 192, attempt 0, stage 3.0)
[2025-07-19T18:30:16.884+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7e848a80
[2025-07-19T18:30:16.885+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=182, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.886+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=182),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/182] for update
[2025-07-19T18:30:16.888+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4134655b
[2025-07-19T18:30:16.889+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=189, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.889+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=189),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/189] for update
[2025-07-19T18:30:16.889+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/179/.1.delta.df4585e9-1008-4898-a220-e3a18d75d011.TID197.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/179/1.delta
[2025-07-19T18:30:16.889+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=179),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/179] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/179/1.delta
[2025-07-19T18:30:16.889+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 179 (task 197, attempt 0, stage 3.0)
[2025-07-19T18:30:16.890+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 170 (task 192, attempt 0, stage 3.0)
[2025-07-19T18:30:16.893+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 170.0 in stage 3.0 (TID 192). 6243 bytes result sent to driver
[2025-07-19T18:30:16.895+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 179 (task 197, attempt 0, stage 3.0)
[2025-07-19T18:30:16.896+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 170.0 in stage 3.0 (TID 192) in 145 ms on 8b44f3d35cfa (executor driver) (185/200)
[2025-07-19T18:30:16.896+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.897+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 179.0 in stage 3.0 (TID 197). 6200 bytes result sent to driver
[2025-07-19T18:30:16.897+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 190.0 in stage 3.0 (TID 203) (8b44f3d35cfa, executor driver, partition 190, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.897+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 192.0 in stage 3.0 (TID 204) (8b44f3d35cfa, executor driver, partition 192, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.898+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 192.0 in stage 3.0 (TID 204)
[2025-07-19T18:30:16.898+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 179.0 in stage 3.0 (TID 197) in 67 ms on 8b44f3d35cfa (executor driver) (186/200)
[2025-07-19T18:30:16.898+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 190.0 in stage 3.0 (TID 203)
[2025-07-19T18:30:16.899+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.900+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/177/.1.delta.2d36c93a-c8f1-4b4d-83d8-be6a02dba323.TID196.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/177/1.delta
[2025-07-19T18:30:16.901+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=177),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/177] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/177/1.delta
[2025-07-19T18:30:16.902+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 177 (task 196, attempt 0, stage 3.0)
[2025-07-19T18:30:16.902+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.902+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.902+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.902+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.902+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/186/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/186/.1.delta.c94218ed-7150-4882-a8bc-929b2f4feedd.TID201.tmp
[2025-07-19T18:30:16.902+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/181/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/181/.1.delta.2dcbf053-e5ec-4818-a9c3-fcc2a36e20bd.TID199.tmp
[2025-07-19T18:30:16.902+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 177 (task 196, attempt 0, stage 3.0)
[2025-07-19T18:30:16.903+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 177.0 in stage 3.0 (TID 196). 6243 bytes result sent to driver
[2025-07-19T18:30:16.903+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/182/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/182/.1.delta.6135c0bc-4787-4318-b0d5-aa50bd69c158.TID200.tmp
[2025-07-19T18:30:16.904+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 193.0 in stage 3.0 (TID 205) (8b44f3d35cfa, executor driver, partition 193, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.904+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 177.0 in stage 3.0 (TID 196) in 106 ms on 8b44f3d35cfa (executor driver) (187/200)
[2025-07-19T18:30:16.904+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 193.0 in stage 3.0 (TID 205)
[2025-07-19T18:30:16.907+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7161c754
[2025-07-19T18:30:16.909+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=192, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.909+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=192),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/192] for update
[2025-07-19T18:30:16.909+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/180/.1.delta.bbb2f0f5-9a09-4782-adb6-746cc6a19d31.TID198.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/180/1.delta
[2025-07-19T18:30:16.910+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=180),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/180] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/180/1.delta
[2025-07-19T18:30:16.910+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 180 (task 198, attempt 0, stage 3.0)
[2025-07-19T18:30:16.911+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.913+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@773cc163
[2025-07-19T18:30:16.914+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=190, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.914+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=190),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/190] for update
[2025-07-19T18:30:16.914+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/189/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/189/.1.delta.ef8b41d1-27ca-406a-ac02-2aa6a0ef593c.TID202.tmp
[2025-07-19T18:30:16.915+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.915+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.915+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 180 (task 198, attempt 0, stage 3.0)
[2025-07-19T18:30:16.915+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.922+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 180.0 in stage 3.0 (TID 198). 6286 bytes result sent to driver
[2025-07-19T18:30:16.926+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 194.0 in stage 3.0 (TID 206) (8b44f3d35cfa, executor driver, partition 194, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.926+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 180.0 in stage 3.0 (TID 198) in 77 ms on 8b44f3d35cfa (executor driver) (188/200)
[2025-07-19T18:30:16.927+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 194.0 in stage 3.0 (TID 206)
[2025-07-19T18:30:16.927+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/192/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/192/.1.delta.1be004c0-84b8-4b80-9824-35eb17d43b03.TID204.tmp
[2025-07-19T18:30:16.927+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2900d5a0
[2025-07-19T18:30:16.928+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=193, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.928+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=193),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/193] for update
[2025-07-19T18:30:16.929+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.929+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.929+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.935+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2238c745
[2025-07-19T18:30:16.937+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=194, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.938+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/190/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/190/.1.delta.453f0eee-8740-4549-aad9-eda8e57fdc32.TID203.tmp
[2025-07-19T18:30:16.938+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=194),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/194] for update
[2025-07-19T18:30:16.939+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.947+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/186/.1.delta.c94218ed-7150-4882-a8bc-929b2f4feedd.TID201.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/186/1.delta
[2025-07-19T18:30:16.947+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=186),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/186] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/186/1.delta
[2025-07-19T18:30:16.947+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 186 (task 201, attempt 0, stage 3.0)
[2025-07-19T18:30:16.949+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/181/.1.delta.2dcbf053-e5ec-4818-a9c3-fcc2a36e20bd.TID199.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/181/1.delta
[2025-07-19T18:30:16.950+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/189/.1.delta.ef8b41d1-27ca-406a-ac02-2aa6a0ef593c.TID202.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/189/1.delta
[2025-07-19T18:30:16.951+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=189),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/189] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/189/1.delta
[2025-07-19T18:30:16.952+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/193/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/193/.1.delta.1075eab6-ffe6-4519-9229-3b0d277f07d9.TID205.tmp
[2025-07-19T18:30:16.953+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=181),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/181] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/181/1.delta
[2025-07-19T18:30:16.953+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/182/.1.delta.6135c0bc-4787-4318-b0d5-aa50bd69c158.TID200.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/182/1.delta
[2025-07-19T18:30:16.954+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=182),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/182] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/182/1.delta
[2025-07-19T18:30:16.954+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 189 (task 202, attempt 0, stage 3.0)
[2025-07-19T18:30:16.954+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 182 (task 200, attempt 0, stage 3.0)
[2025-07-19T18:30:16.955+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 181 (task 199, attempt 0, stage 3.0)
[2025-07-19T18:30:16.955+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 186 (task 201, attempt 0, stage 3.0)
[2025-07-19T18:30:16.955+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 186.0 in stage 3.0 (TID 201). 6243 bytes result sent to driver
[2025-07-19T18:30:16.957+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 189 (task 202, attempt 0, stage 3.0)
[2025-07-19T18:30:16.958+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 189.0 in stage 3.0 (TID 202). 6243 bytes result sent to driver
[2025-07-19T18:30:16.958+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 195.0 in stage 3.0 (TID 207) (8b44f3d35cfa, executor driver, partition 195, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.959+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 196.0 in stage 3.0 (TID 208) (8b44f3d35cfa, executor driver, partition 196, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.960+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 189.0 in stage 3.0 (TID 202) in 91 ms on 8b44f3d35cfa (executor driver) (189/200)
[2025-07-19T18:30:16.961+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 186.0 in stage 3.0 (TID 201) in 91 ms on 8b44f3d35cfa (executor driver) (190/200)
[2025-07-19T18:30:16.961+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 196.0 in stage 3.0 (TID 208)
[2025-07-19T18:30:16.962+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 182 (task 200, attempt 0, stage 3.0)
[2025-07-19T18:30:16.963+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 195.0 in stage 3.0 (TID 207)
[2025-07-19T18:30:16.963+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 182.0 in stage 3.0 (TID 200). 6243 bytes result sent to driver
[2025-07-19T18:30:16.963+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 181 (task 199, attempt 0, stage 3.0)
[2025-07-19T18:30:16.964+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.965+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.966+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.967+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.967+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 182.0 in stage 3.0 (TID 200) in 95 ms on 8b44f3d35cfa (executor driver) (191/200)
[2025-07-19T18:30:16.967+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 197.0 in stage 3.0 (TID 209) (8b44f3d35cfa, executor driver, partition 197, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.968+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/194/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/194/.1.delta.e1f222d3-1734-4f84-8121-985707d3aca6.TID206.tmp
[2025-07-19T18:30:16.969+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 197.0 in stage 3.0 (TID 209)
[2025-07-19T18:30:16.971+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 181.0 in stage 3.0 (TID 199). 6243 bytes result sent to driver
[2025-07-19T18:30:16.971+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.972+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.972+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 198.0 in stage 3.0 (TID 210) (8b44f3d35cfa, executor driver, partition 198, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:16.972+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f5dcdbf
[2025-07-19T18:30:16.972+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 181.0 in stage 3.0 (TID 199) in 114 ms on 8b44f3d35cfa (executor driver) (192/200)
[2025-07-19T18:30:16.972+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=195, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:16.973+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=195),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/195] for update
[2025-07-19T18:30:16.973+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:16.973+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 198.0 in stage 3.0 (TID 210)
[2025-07-19T18:30:16.974+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:16.974+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:16.975+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/192/.1.delta.1be004c0-84b8-4b80-9824-35eb17d43b03.TID204.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/192/1.delta
[2025-07-19T18:30:16.976+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=192),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/192] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/192/1.delta
[2025-07-19T18:30:16.976+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 192 (task 204, attempt 0, stage 3.0)
[2025-07-19T18:30:16.981+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/193/.1.delta.1075eab6-ffe6-4519-9229-3b0d277f07d9.TID205.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/193/1.delta
[2025-07-19T18:30:16.982+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=193),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/193] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/193/1.delta
[2025-07-19T18:30:16.983+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/190/.1.delta.453f0eee-8740-4549-aad9-eda8e57fdc32.TID203.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/190/1.delta
[2025-07-19T18:30:16.983+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=190),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/190] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/190/1.delta
[2025-07-19T18:30:16.984+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 190 (task 203, attempt 0, stage 3.0)
[2025-07-19T18:30:16.985+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 193 (task 205, attempt 0, stage 3.0)
[2025-07-19T18:30:16.987+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 193 (task 205, attempt 0, stage 3.0)
[2025-07-19T18:30:16.987+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d641d5c
[2025-07-19T18:30:16.991+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 192 (task 204, attempt 0, stage 3.0)
[2025-07-19T18:30:16.993+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/195/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/195/.1.delta.0c35d969-ce1a-40a6-af80-052de43c6995.TID207.tmp
[2025-07-19T18:30:16.995+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 192.0 in stage 3.0 (TID 204). 6243 bytes result sent to driver
[2025-07-19T18:30:16.997+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Committed partition 190 (task 203, attempt 0, stage 3.0)
[2025-07-19T18:30:16.998+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/194/.1.delta.e1f222d3-1734-4f84-8121-985707d3aca6.TID206.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/194/1.delta
[2025-07-19T18:30:16.998+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=194),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/194] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/194/1.delta
[2025-07-19T18:30:16.999+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 193.0 in stage 3.0 (TID 205). 6243 bytes result sent to driver
[2025-07-19T18:30:16.999+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Finished task 190.0 in stage 3.0 (TID 203). 6243 bytes result sent to driver
[2025-07-19T18:30:17.001+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 211) (8b44f3d35cfa, executor driver, partition 0, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.002+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 0.0 in stage 5.0 (TID 211)
[2025-07-19T18:30:17.003+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 212) (8b44f3d35cfa, executor driver, partition 1, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.003+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 213) (8b44f3d35cfa, executor driver, partition 2, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.004+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 2.0 in stage 5.0 (TID 213)
[2025-07-19T18:30:17.004+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 192.0 in stage 3.0 (TID 204) in 101 ms on 8b44f3d35cfa (executor driver) (193/200)
[2025-07-19T18:30:17.004+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 193.0 in stage 3.0 (TID 205) in 91 ms on 8b44f3d35cfa (executor driver) (194/200)
[2025-07-19T18:30:17.004+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO Executor: Running task 1.0 in stage 5.0 (TID 212)
[2025-07-19T18:30:17.004+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO TaskSetManager: Finished task 190.0 in stage 3.0 (TID 203) in 102 ms on 8b44f3d35cfa (executor driver) (195/200)
[2025-07-19T18:30:17.004+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO DataWritingSparkTask: Commit authorized for partition 194 (task 206, attempt 0, stage 3.0)
[2025-07-19T18:30:17.004+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.005+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.008+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=196, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:17.008+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=196),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/196] for update
[2025-07-19T18:30:17.008+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.008+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.008+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T18:30:17.008+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T18:30:17.009+0000] {subprocess.py:93} INFO - 25/07/19 18:30:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.010+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 194 (task 206, attempt 0, stage 3.0)
[2025-07-19T18:30:17.012+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 194.0 in stage 3.0 (TID 206). 6243 bytes result sent to driver
[2025-07-19T18:30:17.012+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 214) (8b44f3d35cfa, executor driver, partition 3, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.013+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 194.0 in stage 3.0 (TID 206) in 80 ms on 8b44f3d35cfa (executor driver) (196/200)
[2025-07-19T18:30:17.013+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 3.0 in stage 5.0 (TID 214)
[2025-07-19T18:30:17.014+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ce09e7f
[2025-07-19T18:30:17.015+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=197, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:17.015+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=197),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/197] for update
[2025-07-19T18:30:17.016+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.016+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.018+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.020+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/195/.1.delta.0c35d969-ce1a-40a6-af80-052de43c6995.TID207.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/195/1.delta
[2025-07-19T18:30:17.020+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=195),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/195] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/195/1.delta
[2025-07-19T18:30:17.021+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 195 (task 207, attempt 0, stage 3.0)
[2025-07-19T18:30:17.021+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/197/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/197/.1.delta.716eb3b7-47de-4426-b195-eb2448edbe32.TID209.tmp
[2025-07-19T18:30:17.022+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/196/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/196/.1.delta.35524b2f-75c7-449e-ad5f-b8c9edf99759.TID208.tmp
[2025-07-19T18:30:17.024+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 195 (task 207, attempt 0, stage 3.0)
[2025-07-19T18:30:17.025+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 195.0 in stage 3.0 (TID 207). 6200 bytes result sent to driver
[2025-07-19T18:30:17.031+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/0/_metadata/schema using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/0/_metadata/.schema.07165041-9bcc-4113-9626-46850ffb25cd.TID211.tmp
[2025-07-19T18:30:17.032+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 215) (8b44f3d35cfa, executor driver, partition 4, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.032+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 4.0 in stage 5.0 (TID 215)
[2025-07-19T18:30:17.033+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 195.0 in stage 3.0 (TID 207) in 75 ms on 8b44f3d35cfa (executor driver) (197/200)
[2025-07-19T18:30:17.033+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.033+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.037+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/196/.1.delta.35524b2f-75c7-449e-ad5f-b8c9edf99759.TID208.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/196/1.delta
[2025-07-19T18:30:17.037+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=196),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/196] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/196/1.delta
[2025-07-19T18:30:17.038+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/197/.1.delta.716eb3b7-47de-4426-b195-eb2448edbe32.TID209.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/197/1.delta
[2025-07-19T18:30:17.038+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=197),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/197] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/197/1.delta
[2025-07-19T18:30:17.047+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 196 (task 208, attempt 0, stage 3.0)
[2025-07-19T18:30:17.048+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 197 (task 209, attempt 0, stage 3.0)
[2025-07-19T18:30:17.048+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 196 (task 208, attempt 0, stage 3.0)
[2025-07-19T18:30:17.048+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 196.0 in stage 3.0 (TID 208). 6200 bytes result sent to driver
[2025-07-19T18:30:17.049+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 9.0 in stage 5.0 (TID 216) (8b44f3d35cfa, executor driver, partition 9, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.049+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 197 (task 209, attempt 0, stage 3.0)
[2025-07-19T18:30:17.050+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 9.0 in stage 5.0 (TID 216)
[2025-07-19T18:30:17.050+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 197.0 in stage 3.0 (TID 209). 6200 bytes result sent to driver
[2025-07-19T18:30:17.050+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.050+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.052+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 11.0 in stage 5.0 (TID 217) (8b44f3d35cfa, executor driver, partition 11, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.052+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 196.0 in stage 3.0 (TID 208) in 94 ms on 8b44f3d35cfa (executor driver) (198/200)
[2025-07-19T18:30:17.052+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 197.0 in stage 3.0 (TID 209) in 91 ms on 8b44f3d35cfa (executor driver) (199/200)
[2025-07-19T18:30:17.053+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 11.0 in stage 5.0 (TID 217)
[2025-07-19T18:30:17.055+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.056+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.062+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/0/_metadata/.schema.07165041-9bcc-4113-9626-46850ffb25cd.TID211.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/0/_metadata/schema
[2025-07-19T18:30:17.062+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47a66459
[2025-07-19T18:30:17.062+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=0, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.062+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/0] for update
[2025-07-19T18:30:17.065+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.066+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4eaff012
[2025-07-19T18:30:17.066+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=2, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.067+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/2] for update
[2025-07-19T18:30:17.070+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.070+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/0/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/0/.1.delta.3138ff45-7609-495b-a1b0-e58ddabf1fab.TID211.tmp
[2025-07-19T18:30:17.071+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59cfa8de
[2025-07-19T18:30:17.071+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=1, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.071+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/1] for update
[2025-07-19T18:30:17.072+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.074+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/2/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/2/.1.delta.a3ec95df-6c39-4132-a1ff-13f3c9d4bae9.TID213.tmp
[2025-07-19T18:30:17.077+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@670e5fce
[2025-07-19T18:30:17.079+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=198, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:17.079+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=198),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/198] for update
[2025-07-19T18:30:17.081+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.082+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/1/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/1/.1.delta.b4d7fe65-92dc-440c-83db-d8bbf3a79dde.TID212.tmp
[2025-07-19T18:30:17.083+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c63dc44
[2025-07-19T18:30:17.084+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=11, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.084+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=11),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/11] for update
[2025-07-19T18:30:17.085+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/198/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/198/.1.delta.0dcc3af6-240a-408d-9ce7-a581e3403873.TID210.tmp
[2025-07-19T18:30:17.087+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.094+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/11/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/11/.1.delta.d3385556-e403-43c8-b35d-62424e31bab5.TID217.tmp
[2025-07-19T18:30:17.095+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ae889a8
[2025-07-19T18:30:17.096+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=9, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.096+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/9] for update
[2025-07-19T18:30:17.097+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/0/.1.delta.3138ff45-7609-495b-a1b0-e58ddabf1fab.TID211.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/0/1.delta
[2025-07-19T18:30:17.098+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.099+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/0] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/0/1.delta
[2025-07-19T18:30:17.099+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 211, attempt 0, stage 5.0)
[2025-07-19T18:30:17.103+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b5e1285
[2025-07-19T18:30:17.104+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=4, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.105+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/4] for update
[2025-07-19T18:30:17.105+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/9/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/9/.1.delta.52880ced-6ae3-4566-b9b3-76d6f40c8017.TID216.tmp
[2025-07-19T18:30:17.107+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.111+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@216603e7
[2025-07-19T18:30:17.112+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=3, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.113+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/2/.1.delta.a3ec95df-6c39-4132-a1ff-13f3c9d4bae9.TID213.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/2/1.delta
[2025-07-19T18:30:17.114+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/2] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/2/1.delta
[2025-07-19T18:30:17.114+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/3] for update
[2025-07-19T18:30:17.114+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.115+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 2 (task 213, attempt 0, stage 5.0)
[2025-07-19T18:30:17.115+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/1/.1.delta.b4d7fe65-92dc-440c-83db-d8bbf3a79dde.TID212.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/1/1.delta
[2025-07-19T18:30:17.116+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/1] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/1/1.delta
[2025-07-19T18:30:17.120+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 1 (task 212, attempt 0, stage 5.0)
[2025-07-19T18:30:17.122+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/4/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/4/.1.delta.54cf19ba-fa71-48ef-b1b1-cf59bb95bc1f.TID215.tmp
[2025-07-19T18:30:17.124+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/198/.1.delta.0dcc3af6-240a-408d-9ce7-a581e3403873.TID210.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/198/1.delta
[2025-07-19T18:30:17.124+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=198),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/198] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/198/1.delta
[2025-07-19T18:30:17.125+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 198 (task 210, attempt 0, stage 3.0)
[2025-07-19T18:30:17.126+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 0 (task 211, attempt 0, stage 5.0)
[2025-07-19T18:30:17.126+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/3/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/3/.1.delta.3dfb8c98-49f0-4ce7-a369-f5a45be76b53.TID214.tmp
[2025-07-19T18:30:17.128+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 0.0 in stage 5.0 (TID 211). 9113 bytes result sent to driver
[2025-07-19T18:30:17.132+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 12.0 in stage 5.0 (TID 218) (8b44f3d35cfa, executor driver, partition 12, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.133+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 12.0 in stage 5.0 (TID 218)
[2025-07-19T18:30:17.135+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/11/.1.delta.d3385556-e403-43c8-b35d-62424e31bab5.TID217.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/11/1.delta
[2025-07-19T18:30:17.135+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=11),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/11] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/11/1.delta
[2025-07-19T18:30:17.136+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 11 (task 217, attempt 0, stage 5.0)
[2025-07-19T18:30:17.136+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 211) in 138 ms on 8b44f3d35cfa (executor driver) (1/200)
[2025-07-19T18:30:17.136+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.137+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.140+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 198 (task 210, attempt 0, stage 3.0)
[2025-07-19T18:30:17.141+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 198.0 in stage 3.0 (TID 210). 6200 bytes result sent to driver
[2025-07-19T18:30:17.142+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 1 (task 212, attempt 0, stage 5.0)
[2025-07-19T18:30:17.142+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 1.0 in stage 5.0 (TID 212). 9064 bytes result sent to driver
[2025-07-19T18:30:17.142+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@61617ff4
[2025-07-19T18:30:17.142+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 13.0 in stage 5.0 (TID 219) (8b44f3d35cfa, executor driver, partition 13, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.142+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=12, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.142+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=12),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/12] for update
[2025-07-19T18:30:17.143+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 198.0 in stage 3.0 (TID 210) in 175 ms on 8b44f3d35cfa (executor driver) (200/200)
[2025-07-19T18:30:17.143+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
[2025-07-19T18:30:17.144+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.144+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 13.0 in stage 5.0 (TID 219)
[2025-07-19T18:30:17.145+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DAGScheduler: ResultStage 3 (start at <unknown>:0) finished in 3.817 s
[2025-07-19T18:30:17.147+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 15.0 in stage 5.0 (TID 220) (8b44f3d35cfa, executor driver, partition 15, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.147+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 15.0 in stage 5.0 (TID 220)
[2025-07-19T18:30:17.148+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 212) in 153 ms on 8b44f3d35cfa (executor driver) (2/200)
[2025-07-19T18:30:17.148+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.148+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.149+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.150+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.152+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-19T18:30:17.153+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
[2025-07-19T18:30:17.154+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54f0caf6
[2025-07-19T18:30:17.155+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=13, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.156+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=13),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/13] for update
[2025-07-19T18:30:17.156+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DAGScheduler: Job 0 finished: start at <unknown>:0, took 5.160532 s
[2025-07-19T18:30:17.156+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/12/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/12/.1.delta.fcb5ae4a-9c23-4b80-b557-6fc198eeece2.TID218.tmp
[2025-07-19T18:30:17.156+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.156+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 11 (task 217, attempt 0, stage 5.0)
[2025-07-19T18:30:17.156+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 11.0 in stage 5.0 (TID 217). 9106 bytes result sent to driver
[2025-07-19T18:30:17.157+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 16.0 in stage 5.0 (TID 221) (8b44f3d35cfa, executor driver, partition 16, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.158+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 16.0 in stage 5.0 (TID 221)
[2025-07-19T18:30:17.160+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Checkins_raw, format=PARQUET)] is committing.
[2025-07-19T18:30:17.161+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO SparkWrite: Committing epoch 0 for query 987ca175-704b-42a6-8146-d1b15494abbf in append mode
[2025-07-19T18:30:17.161+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.163+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.164+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/4/.1.delta.54cf19ba-fa71-48ef-b1b1-cf59bb95bc1f.TID215.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/4/1.delta
[2025-07-19T18:30:17.164+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/4] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/4/1.delta
[2025-07-19T18:30:17.164+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 4 (task 215, attempt 0, stage 5.0)
[2025-07-19T18:30:17.165+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/9/.1.delta.52880ced-6ae3-4566-b9b3-76d6f40c8017.TID216.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/9/1.delta
[2025-07-19T18:30:17.165+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/9] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/9/1.delta
[2025-07-19T18:30:17.166+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 2 (task 213, attempt 0, stage 5.0)
[2025-07-19T18:30:17.166+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 9 (task 216, attempt 0, stage 5.0)
[2025-07-19T18:30:17.166+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 2.0 in stage 5.0 (TID 213). 9113 bytes result sent to driver
[2025-07-19T18:30:17.167+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 11.0 in stage 5.0 (TID 217) in 112 ms on 8b44f3d35cfa (executor driver) (3/200)
[2025-07-19T18:30:17.167+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 23.0 in stage 5.0 (TID 222) (8b44f3d35cfa, executor driver, partition 23, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.170+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 23.0 in stage 5.0 (TID 222)
[2025-07-19T18:30:17.174+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/3/.1.delta.3dfb8c98-49f0-4ce7-a369-f5a45be76b53.TID214.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/3/1.delta
[2025-07-19T18:30:17.177+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/3] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/3/1.delta
[2025-07-19T18:30:17.178+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.180+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T18:30:17.180+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 3 (task 214, attempt 0, stage 5.0)
[2025-07-19T18:30:17.180+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/13/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/13/.1.delta.d8452adb-4bba-472c-a54e-6f12a758808d.TID219.tmp
[2025-07-19T18:30:17.181+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ce83b07
[2025-07-19T18:30:17.181+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 213) in 177 ms on 8b44f3d35cfa (executor driver) (4/200)
[2025-07-19T18:30:17.182+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=16, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.183+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=16),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/16] for update
[2025-07-19T18:30:17.189+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 4 (task 215, attempt 0, stage 5.0)
[2025-07-19T18:30:17.190+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.194+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 4.0 in stage 5.0 (TID 215). 9115 bytes result sent to driver
[2025-07-19T18:30:17.194+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 26.0 in stage 5.0 (TID 223) (8b44f3d35cfa, executor driver, partition 26, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.194+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d1133c5
[2025-07-19T18:30:17.195+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 215) in 161 ms on 8b44f3d35cfa (executor driver) (5/200)
[2025-07-19T18:30:17.196+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 26.0 in stage 5.0 (TID 223)
[2025-07-19T18:30:17.196+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=15, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.198+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=15),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/15] for update
[2025-07-19T18:30:17.198+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 9 (task 216, attempt 0, stage 5.0)
[2025-07-19T18:30:17.199+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/12/.1.delta.fcb5ae4a-9c23-4b80-b557-6fc198eeece2.TID218.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/12/1.delta
[2025-07-19T18:30:17.202+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=12),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/12] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/12/1.delta
[2025-07-19T18:30:17.202+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 9.0 in stage 5.0 (TID 216). 9111 bytes result sent to driver
[2025-07-19T18:30:17.203+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.204+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.205+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 28.0 in stage 5.0 (TID 224) (8b44f3d35cfa, executor driver, partition 28, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.205+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T18:30:17.205+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 12 (task 218, attempt 0, stage 5.0)
[2025-07-19T18:30:17.205+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 9.0 in stage 5.0 (TID 216) in 151 ms on 8b44f3d35cfa (executor driver) (6/200)
[2025-07-19T18:30:17.205+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 28.0 in stage 5.0 (TID 224)
[2025-07-19T18:30:17.206+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5b6905a6
[2025-07-19T18:30:17.206+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=23, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.206+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=23),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/23] for update
[2025-07-19T18:30:17.207+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.207+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/16/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/16/.1.delta.ab7c78ce-e67f-494b-924a-b66fb2f6e97c.TID221.tmp
[2025-07-19T18:30:17.207+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.207+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 3 (task 214, attempt 0, stage 5.0)
[2025-07-19T18:30:17.207+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T18:30:17.209+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 3.0 in stage 5.0 (TID 214). 9109 bytes result sent to driver
[2025-07-19T18:30:17.211+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 214) in 209 ms on 8b44f3d35cfa (executor driver) (7/200)
[2025-07-19T18:30:17.212+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 30.0 in stage 5.0 (TID 225) (8b44f3d35cfa, executor driver, partition 30, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.213+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 30.0 in stage 5.0 (TID 225)
[2025-07-19T18:30:17.216+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/15/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/15/.1.delta.f7a20f5d-e940-4a8f-afb2-3705ff54dc6a.TID220.tmp
[2025-07-19T18:30:17.218+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d39c874
[2025-07-19T18:30:17.220+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=26, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.221+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=26),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/26] for update
[2025-07-19T18:30:17.221+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.221+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 12 (task 218, attempt 0, stage 5.0)
[2025-07-19T18:30:17.222+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/23/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/23/.1.delta.8f1c38e3-5a00-4194-ae1b-a869f0d85673.TID222.tmp
[2025-07-19T18:30:17.222+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.223+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.223+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 12.0 in stage 5.0 (TID 218). 9127 bytes result sent to driver
[2025-07-19T18:30:17.224+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 39.0 in stage 5.0 (TID 226) (8b44f3d35cfa, executor driver, partition 39, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.224+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 12.0 in stage 5.0 (TID 218) in 94 ms on 8b44f3d35cfa (executor driver) (8/200)
[2025-07-19T18:30:17.225+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@15608847
[2025-07-19T18:30:17.226+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 39.0 in stage 5.0 (TID 226)
[2025-07-19T18:30:17.227+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=28, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.228+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=28),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/28] for update
[2025-07-19T18:30:17.228+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/26/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/26/.1.delta.7531a958-a2a7-4771-aae3-4d75ceb1fa0d.TID223.tmp
[2025-07-19T18:30:17.229+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.233+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.233+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.240+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/28/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/28/.1.delta.958a764d-6f1e-40de-9919-df44a48ad490.TID224.tmp
[2025-07-19T18:30:17.241+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d411a08
[2025-07-19T18:30:17.242+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=30, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.242+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=30),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/30] for update
[2025-07-19T18:30:17.243+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/16/.1.delta.ab7c78ce-e67f-494b-924a-b66fb2f6e97c.TID221.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/16/1.delta
[2025-07-19T18:30:17.243+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=16),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/16] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/16/1.delta
[2025-07-19T18:30:17.243+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/13/.1.delta.d8452adb-4bba-472c-a54e-6f12a758808d.TID219.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/13/1.delta
[2025-07-19T18:30:17.244+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=13),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/13] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/13/1.delta
[2025-07-19T18:30:17.244+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 13 (task 219, attempt 0, stage 5.0)
[2025-07-19T18:30:17.245+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 16 (task 221, attempt 0, stage 5.0)
[2025-07-19T18:30:17.245+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO SparkWrite: Committing streaming append with 59 new data files to table my_catalog.bronze.Checkins_raw
[2025-07-19T18:30:17.251+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/15/.1.delta.f7a20f5d-e940-4a8f-afb2-3705ff54dc6a.TID220.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/15/1.delta
[2025-07-19T18:30:17.251+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=15),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/15] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/15/1.delta
[2025-07-19T18:30:17.252+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.258+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/23/.1.delta.8f1c38e3-5a00-4194-ae1b-a869f0d85673.TID222.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/23/1.delta
[2025-07-19T18:30:17.260+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=23),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/23] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/23/1.delta
[2025-07-19T18:30:17.261+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 15 (task 220, attempt 0, stage 5.0)
[2025-07-19T18:30:17.262+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 23 (task 222, attempt 0, stage 5.0)
[2025-07-19T18:30:17.262+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e4e5b24
[2025-07-19T18:30:17.263+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=39, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.263+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=39),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/39] for update
[2025-07-19T18:30:17.264+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 16 (task 221, attempt 0, stage 5.0)
[2025-07-19T18:30:17.265+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 16.0 in stage 5.0 (TID 221). 9115 bytes result sent to driver
[2025-07-19T18:30:17.267+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 41.0 in stage 5.0 (TID 227) (8b44f3d35cfa, executor driver, partition 41, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.268+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 41.0 in stage 5.0 (TID 227)
[2025-07-19T18:30:17.268+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 16.0 in stage 5.0 (TID 221) in 102 ms on 8b44f3d35cfa (executor driver) (9/200)
[2025-07-19T18:30:17.268+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.268+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.269+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.269+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/30/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/30/.1.delta.5e5907db-4725-4c07-a71f-cd4503429048.TID225.tmp
[2025-07-19T18:30:17.269+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/26/.1.delta.7531a958-a2a7-4771-aae3-4d75ceb1fa0d.TID223.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/26/1.delta
[2025-07-19T18:30:17.269+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=26),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/26] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/26/1.delta
[2025-07-19T18:30:17.269+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 26 (task 223, attempt 0, stage 5.0)
[2025-07-19T18:30:17.271+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5cb373bf
[2025-07-19T18:30:17.272+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/39/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/39/.1.delta.cf079bd6-72da-4bbe-9d45-c41126490208.TID226.tmp
[2025-07-19T18:30:17.272+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=41, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.272+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=41),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/41] for update
[2025-07-19T18:30:17.273+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/28/.1.delta.958a764d-6f1e-40de-9919-df44a48ad490.TID224.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/28/1.delta
[2025-07-19T18:30:17.273+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=28),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/28] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/28/1.delta
[2025-07-19T18:30:17.273+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.273+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 28 (task 224, attempt 0, stage 5.0)
[2025-07-19T18:30:17.277+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 15 (task 220, attempt 0, stage 5.0)
[2025-07-19T18:30:17.278+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 15.0 in stage 5.0 (TID 220). 9107 bytes result sent to driver
[2025-07-19T18:30:17.282+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 60.0 in stage 5.0 (TID 228) (8b44f3d35cfa, executor driver, partition 60, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.282+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 13 (task 219, attempt 0, stage 5.0)
[2025-07-19T18:30:17.283+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 15.0 in stage 5.0 (TID 220) in 136 ms on 8b44f3d35cfa (executor driver) (10/200)
[2025-07-19T18:30:17.283+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 60.0 in stage 5.0 (TID 228)
[2025-07-19T18:30:17.284+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.285+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T18:30:17.287+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/41/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/41/.1.delta.5a1db5c7-3a0e-42a0-9714-91f07072e597.TID227.tmp
[2025-07-19T18:30:17.295+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 13.0 in stage 5.0 (TID 219). 9150 bytes result sent to driver
[2025-07-19T18:30:17.296+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 66.0 in stage 5.0 (TID 229) (8b44f3d35cfa, executor driver, partition 66, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.296+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c10a85d
[2025-07-19T18:30:17.297+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=60, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.297+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=60),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/60] for update
[2025-07-19T18:30:17.297+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 23 (task 222, attempt 0, stage 5.0)
[2025-07-19T18:30:17.297+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 13.0 in stage 5.0 (TID 219) in 156 ms on 8b44f3d35cfa (executor driver) (11/200)
[2025-07-19T18:30:17.299+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.299+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 23.0 in stage 5.0 (TID 222). 9162 bytes result sent to driver
[2025-07-19T18:30:17.301+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 67.0 in stage 5.0 (TID 230) (8b44f3d35cfa, executor driver, partition 67, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.302+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 66.0 in stage 5.0 (TID 229)
[2025-07-19T18:30:17.302+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 23.0 in stage 5.0 (TID 222) in 134 ms on 8b44f3d35cfa (executor driver) (12/200)
[2025-07-19T18:30:17.303+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 67.0 in stage 5.0 (TID 230)
[2025-07-19T18:30:17.304+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.304+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.305+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.305+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:17.308+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/39/.1.delta.cf079bd6-72da-4bbe-9d45-c41126490208.TID226.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/39/1.delta
[2025-07-19T18:30:17.309+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=39),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/39] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/39/1.delta
[2025-07-19T18:30:17.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/30/.1.delta.5e5907db-4725-4c07-a71f-cd4503429048.TID225.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/30/1.delta
[2025-07-19T18:30:17.311+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=30),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/30] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/30/1.delta
[2025-07-19T18:30:17.312+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/60/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/60/.1.delta.2745c771-d7cd-4a6c-9240-917e0d16ce41.TID228.tmp
[2025-07-19T18:30:17.312+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2af677ee
[2025-07-19T18:30:17.313+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=66, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.314+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=66),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/66] for update
[2025-07-19T18:30:17.315+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 30 (task 225, attempt 0, stage 5.0)
[2025-07-19T18:30:17.316+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 39 (task 226, attempt 0, stage 5.0)
[2025-07-19T18:30:17.316+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 26 (task 223, attempt 0, stage 5.0)
[2025-07-19T18:30:17.316+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.316+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/41/.1.delta.5a1db5c7-3a0e-42a0-9714-91f07072e597.TID227.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/41/1.delta
[2025-07-19T18:30:17.316+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=41),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/41] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/41/1.delta
[2025-07-19T18:30:17.316+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 26.0 in stage 5.0 (TID 223). 9117 bytes result sent to driver
[2025-07-19T18:30:17.318+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 41 (task 227, attempt 0, stage 5.0)
[2025-07-19T18:30:17.318+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 76.0 in stage 5.0 (TID 231) (8b44f3d35cfa, executor driver, partition 76, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.319+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 26.0 in stage 5.0 (TID 223) in 126 ms on 8b44f3d35cfa (executor driver) (13/200)
[2025-07-19T18:30:17.319+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 76.0 in stage 5.0 (TID 231)
[2025-07-19T18:30:17.319+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.319+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.321+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5cb35763
[2025-07-19T18:30:17.325+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=67, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.326+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=67),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/67] for update
[2025-07-19T18:30:17.326+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 28 (task 224, attempt 0, stage 5.0)
[2025-07-19T18:30:17.326+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 28.0 in stage 5.0 (TID 224). 9111 bytes result sent to driver
[2025-07-19T18:30:17.326+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.329+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 82.0 in stage 5.0 (TID 232) (8b44f3d35cfa, executor driver, partition 82, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.331+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 28.0 in stage 5.0 (TID 224) in 132 ms on 8b44f3d35cfa (executor driver) (14/200)
[2025-07-19T18:30:17.332+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/67/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/67/.1.delta.f2d265fc-b5f5-4b4a-89f3-8db48657db87.TID230.tmp
[2025-07-19T18:30:17.332+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@70665a83
[2025-07-19T18:30:17.333+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=76, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.333+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=76),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/76] for update
[2025-07-19T18:30:17.334+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.334+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 82.0 in stage 5.0 (TID 232)
[2025-07-19T18:30:17.340+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/66/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/66/.1.delta.fe3b1503-0c05-4c69-a2b9-5ab265bf3e6c.TID229.tmp
[2025-07-19T18:30:17.344+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/76/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/76/.1.delta.a853ff3a-e0a2-426b-a0c9-5c8f811a23a1.TID231.tmp
[2025-07-19T18:30:17.345+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/60/.1.delta.2745c771-d7cd-4a6c-9240-917e0d16ce41.TID228.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/60/1.delta
[2025-07-19T18:30:17.346+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=60),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/60] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/60/1.delta
[2025-07-19T18:30:17.346+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 39 (task 226, attempt 0, stage 5.0)
[2025-07-19T18:30:17.347+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 60 (task 228, attempt 0, stage 5.0)
[2025-07-19T18:30:17.348+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 39.0 in stage 5.0 (TID 226). 9146 bytes result sent to driver
[2025-07-19T18:30:17.348+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 83.0 in stage 5.0 (TID 233) (8b44f3d35cfa, executor driver, partition 83, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.348+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 39.0 in stage 5.0 (TID 226) in 126 ms on 8b44f3d35cfa (executor driver) (15/200)
[2025-07-19T18:30:17.349+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 83.0 in stage 5.0 (TID 233)
[2025-07-19T18:30:17.349+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.349+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.349+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.349+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.354+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 30 (task 225, attempt 0, stage 5.0)
[2025-07-19T18:30:17.354+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 30.0 in stage 5.0 (TID 225). 9109 bytes result sent to driver
[2025-07-19T18:30:17.355+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 103.0 in stage 5.0 (TID 234) (8b44f3d35cfa, executor driver, partition 103, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.355+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 30.0 in stage 5.0 (TID 225) in 141 ms on 8b44f3d35cfa (executor driver) (16/200)
[2025-07-19T18:30:17.355+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 103.0 in stage 5.0 (TID 234)
[2025-07-19T18:30:17.356+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 41 (task 227, attempt 0, stage 5.0)
[2025-07-19T18:30:17.356+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 41.0 in stage 5.0 (TID 227). 9115 bytes result sent to driver
[2025-07-19T18:30:17.357+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.357+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.358+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 104.0 in stage 5.0 (TID 235) (8b44f3d35cfa, executor driver, partition 104, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.358+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 41.0 in stage 5.0 (TID 227) in 99 ms on 8b44f3d35cfa (executor driver) (17/200)
[2025-07-19T18:30:17.359+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 104.0 in stage 5.0 (TID 235)
[2025-07-19T18:30:17.363+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@173908d2
[2025-07-19T18:30:17.365+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.365+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.366+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=82, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.366+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=82),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/82] for update
[2025-07-19T18:30:17.366+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 60 (task 228, attempt 0, stage 5.0)
[2025-07-19T18:30:17.367+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 60.0 in stage 5.0 (TID 228). 9120 bytes result sent to driver
[2025-07-19T18:30:17.370+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 111.0 in stage 5.0 (TID 236) (8b44f3d35cfa, executor driver, partition 111, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.371+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 60.0 in stage 5.0 (TID 228) in 86 ms on 8b44f3d35cfa (executor driver) (18/200)
[2025-07-19T18:30:17.371+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.371+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 111.0 in stage 5.0 (TID 236)
[2025-07-19T18:30:17.371+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.371+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.372+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@66849f89
[2025-07-19T18:30:17.372+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=104, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.372+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=104),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/104] for update
[2025-07-19T18:30:17.372+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.376+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@164075b1
[2025-07-19T18:30:17.376+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=103, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.377+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=103),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/103] for update
[2025-07-19T18:30:17.377+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/67/.1.delta.f2d265fc-b5f5-4b4a-89f3-8db48657db87.TID230.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/67/1.delta
[2025-07-19T18:30:17.377+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=67),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/67] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/67/1.delta
[2025-07-19T18:30:17.377+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 67 (task 230, attempt 0, stage 5.0)
[2025-07-19T18:30:17.378+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/82/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/82/.1.delta.db6c51e2-0e6b-456b-b00e-0d2738880fa3.TID232.tmp
[2025-07-19T18:30:17.379+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.383+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@225a104f
[2025-07-19T18:30:17.385+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=83, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.386+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=83),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/83] for update
[2025-07-19T18:30:17.387+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/104/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/104/.1.delta.b6c68f06-43a2-49b7-8978-39af04a083e2.TID235.tmp
[2025-07-19T18:30:17.392+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/76/.1.delta.a853ff3a-e0a2-426b-a0c9-5c8f811a23a1.TID231.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/76/1.delta
[2025-07-19T18:30:17.392+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=76),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/76] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/76/1.delta
[2025-07-19T18:30:17.392+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 76 (task 231, attempt 0, stage 5.0)
[2025-07-19T18:30:17.392+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.400+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/66/.1.delta.fe3b1503-0c05-4c69-a2b9-5ab265bf3e6c.TID229.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/66/1.delta
[2025-07-19T18:30:17.402+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=66),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/66] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/66/1.delta
[2025-07-19T18:30:17.402+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 66 (task 229, attempt 0, stage 5.0)
[2025-07-19T18:30:17.403+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@266a747e
[2025-07-19T18:30:17.403+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/103/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/103/.1.delta.4cd02a5d-18b4-4015-8c37-2d0b4be92110.TID234.tmp
[2025-07-19T18:30:17.406+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=111, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.407+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=111),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/111] for update
[2025-07-19T18:30:17.408+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.411+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/83/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/83/.1.delta.9f84d600-cf00-4eba-a83b-ab97db308b26.TID233.tmp
[2025-07-19T18:30:17.411+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 67 (task 230, attempt 0, stage 5.0)
[2025-07-19T18:30:17.411+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 67.0 in stage 5.0 (TID 230). 9160 bytes result sent to driver
[2025-07-19T18:30:17.416+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 76 (task 231, attempt 0, stage 5.0)
[2025-07-19T18:30:17.417+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 76.0 in stage 5.0 (TID 231). 9152 bytes result sent to driver
[2025-07-19T18:30:17.418+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 112.0 in stage 5.0 (TID 237) (8b44f3d35cfa, executor driver, partition 112, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.421+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 112.0 in stage 5.0 (TID 237)
[2025-07-19T18:30:17.424+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/111/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/111/.1.delta.b6a17e46-e53d-4ba3-81db-b9b9f83c0af3.TID236.tmp
[2025-07-19T18:30:17.425+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.427+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 114.0 in stage 5.0 (TID 238) (8b44f3d35cfa, executor driver, partition 114, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.427+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 76.0 in stage 5.0 (TID 231) in 106 ms on 8b44f3d35cfa (executor driver) (19/200)
[2025-07-19T18:30:17.427+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 67.0 in stage 5.0 (TID 230) in 122 ms on 8b44f3d35cfa (executor driver) (20/200)
[2025-07-19T18:30:17.427+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 114.0 in stage 5.0 (TID 238)
[2025-07-19T18:30:17.427+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.428+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T18:30:17.428+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.428+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/104/.1.delta.b6c68f06-43a2-49b7-8978-39af04a083e2.TID235.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/104/1.delta
[2025-07-19T18:30:17.428+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=104),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/104] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/104/1.delta
[2025-07-19T18:30:17.428+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 104 (task 235, attempt 0, stage 5.0)
[2025-07-19T18:30:17.428+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/82/.1.delta.db6c51e2-0e6b-456b-b00e-0d2738880fa3.TID232.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/82/1.delta
[2025-07-19T18:30:17.428+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=82),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/82] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/82/1.delta
[2025-07-19T18:30:17.428+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 66 (task 229, attempt 0, stage 5.0)
[2025-07-19T18:30:17.429+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 82 (task 232, attempt 0, stage 5.0)
[2025-07-19T18:30:17.431+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@9db8dbc
[2025-07-19T18:30:17.433+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=114, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.433+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=114),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/114] for update
[2025-07-19T18:30:17.434+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 66.0 in stage 5.0 (TID 229). 9140 bytes result sent to driver
[2025-07-19T18:30:17.434+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 115.0 in stage 5.0 (TID 239) (8b44f3d35cfa, executor driver, partition 115, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.434+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 115.0 in stage 5.0 (TID 239)
[2025-07-19T18:30:17.435+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.436+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.438+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.439+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/114/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/114/.1.delta.a4940b8a-b434-4936-921b-dc79c83f6ce8.TID238.tmp
[2025-07-19T18:30:17.446+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7ac583bb
[2025-07-19T18:30:17.447+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=112, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.447+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=112),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/112] for update
[2025-07-19T18:30:17.455+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 104 (task 235, attempt 0, stage 5.0)
[2025-07-19T18:30:17.456+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 66.0 in stage 5.0 (TID 229) in 160 ms on 8b44f3d35cfa (executor driver) (21/200)
[2025-07-19T18:30:17.456+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 104.0 in stage 5.0 (TID 235). 9154 bytes result sent to driver
[2025-07-19T18:30:17.457+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/83/.1.delta.9f84d600-cf00-4eba-a83b-ab97db308b26.TID233.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/83/1.delta
[2025-07-19T18:30:17.458+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=83),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/83] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/83/1.delta
[2025-07-19T18:30:17.458+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 117.0 in stage 5.0 (TID 240) (8b44f3d35cfa, executor driver, partition 117, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.458+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 83 (task 233, attempt 0, stage 5.0)
[2025-07-19T18:30:17.458+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 104.0 in stage 5.0 (TID 235) in 96 ms on 8b44f3d35cfa (executor driver) (22/200)
[2025-07-19T18:30:17.458+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 117.0 in stage 5.0 (TID 240)
[2025-07-19T18:30:17.458+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.458+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.459+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.467+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@422bd2fa
[2025-07-19T18:30:17.468+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/103/.1.delta.4cd02a5d-18b4-4015-8c37-2d0b4be92110.TID234.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/103/1.delta
[2025-07-19T18:30:17.468+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=103),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/103] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/103/1.delta
[2025-07-19T18:30:17.469+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=115, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.469+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/112/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/112/.1.delta.8acfd655-caf5-4431-b674-73ecc50cb909.TID237.tmp
[2025-07-19T18:30:17.469+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=115),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/115] for update
[2025-07-19T18:30:17.469+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 103 (task 234, attempt 0, stage 5.0)
[2025-07-19T18:30:17.469+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.471+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 82 (task 232, attempt 0, stage 5.0)
[2025-07-19T18:30:17.472+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 82.0 in stage 5.0 (TID 232). 9148 bytes result sent to driver
[2025-07-19T18:30:17.472+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 118.0 in stage 5.0 (TID 241) (8b44f3d35cfa, executor driver, partition 118, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.473+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 82.0 in stage 5.0 (TID 232) in 143 ms on 8b44f3d35cfa (executor driver) (23/200)
[2025-07-19T18:30:17.477+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52d939a9
[2025-07-19T18:30:17.478+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=117, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.479+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=117),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/117] for update
[2025-07-19T18:30:17.479+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 118.0 in stage 5.0 (TID 241)
[2025-07-19T18:30:17.479+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.480+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.480+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.481+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/111/.1.delta.b6a17e46-e53d-4ba3-81db-b9b9f83c0af3.TID236.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/111/1.delta
[2025-07-19T18:30:17.482+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=111),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/111] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/111/1.delta
[2025-07-19T18:30:17.482+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 111 (task 236, attempt 0, stage 5.0)
[2025-07-19T18:30:17.482+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 83 (task 233, attempt 0, stage 5.0)
[2025-07-19T18:30:17.483+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 83.0 in stage 5.0 (TID 233). 9156 bytes result sent to driver
[2025-07-19T18:30:17.483+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 120.0 in stage 5.0 (TID 242) (8b44f3d35cfa, executor driver, partition 120, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.483+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 83.0 in stage 5.0 (TID 233) in 135 ms on 8b44f3d35cfa (executor driver) (24/200)
[2025-07-19T18:30:17.483+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 120.0 in stage 5.0 (TID 242)
[2025-07-19T18:30:17.484+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.484+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.489+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/115/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/115/.1.delta.038bc4ca-3b7e-41ad-899b-2778f7234bda.TID239.tmp
[2025-07-19T18:30:17.490+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@316a8953
[2025-07-19T18:30:17.492+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=118, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.493+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=118),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/118] for update
[2025-07-19T18:30:17.493+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/117/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/117/.1.delta.ec808c75-c3d7-428e-badd-5a54b1a4ca65.TID240.tmp
[2025-07-19T18:30:17.494+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/114/.1.delta.a4940b8a-b434-4936-921b-dc79c83f6ce8.TID238.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/114/1.delta
[2025-07-19T18:30:17.495+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=114),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/114] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/114/1.delta
[2025-07-19T18:30:17.495+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 114 (task 238, attempt 0, stage 5.0)
[2025-07-19T18:30:17.496+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.497+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 103 (task 234, attempt 0, stage 5.0)
[2025-07-19T18:30:17.498+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 103.0 in stage 5.0 (TID 234). 9148 bytes result sent to driver
[2025-07-19T18:30:17.499+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 103.0 in stage 5.0 (TID 234) in 147 ms on 8b44f3d35cfa (executor driver) (25/200)
[2025-07-19T18:30:17.500+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25e1dae3
[2025-07-19T18:30:17.501+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 125.0 in stage 5.0 (TID 243) (8b44f3d35cfa, executor driver, partition 125, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.501+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=120, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.501+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=120),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/120] for update
[2025-07-19T18:30:17.502+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 125.0 in stage 5.0 (TID 243)
[2025-07-19T18:30:17.502+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.505+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.510+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.514+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/118/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/118/.1.delta.099c79ba-9743-402d-8d36-c81c3e1fe89a.TID241.tmp
[2025-07-19T18:30:17.515+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6fc1d711
[2025-07-19T18:30:17.516+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=125, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.516+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=125),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/125] for update
[2025-07-19T18:30:17.517+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 114 (task 238, attempt 0, stage 5.0)
[2025-07-19T18:30:17.518+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 114.0 in stage 5.0 (TID 238). 9156 bytes result sent to driver
[2025-07-19T18:30:17.519+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/120/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/120/.1.delta.ed7ab8ae-4eff-472d-8d29-ef8da865bfb8.TID242.tmp
[2025-07-19T18:30:17.519+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.519+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 130.0 in stage 5.0 (TID 244) (8b44f3d35cfa, executor driver, partition 130, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.519+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 111 (task 236, attempt 0, stage 5.0)
[2025-07-19T18:30:17.520+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 114.0 in stage 5.0 (TID 238) in 92 ms on 8b44f3d35cfa (executor driver) (26/200)
[2025-07-19T18:30:17.520+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 111.0 in stage 5.0 (TID 236). 9160 bytes result sent to driver
[2025-07-19T18:30:17.520+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 130.0 in stage 5.0 (TID 244)
[2025-07-19T18:30:17.520+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 133.0 in stage 5.0 (TID 245) (8b44f3d35cfa, executor driver, partition 133, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.520+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 133.0 in stage 5.0 (TID 245)
[2025-07-19T18:30:17.520+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 111.0 in stage 5.0 (TID 236) in 150 ms on 8b44f3d35cfa (executor driver) (27/200)
[2025-07-19T18:30:17.520+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.520+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.520+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.521+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T18:30:17.522+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/125/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/125/.1.delta.88ead078-3f06-4286-ac78-8a45d7469a40.TID243.tmp
[2025-07-19T18:30:17.523+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/112/.1.delta.8acfd655-caf5-4431-b674-73ecc50cb909.TID237.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/112/1.delta
[2025-07-19T18:30:17.523+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=112),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/112] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/112/1.delta
[2025-07-19T18:30:17.523+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 112 (task 237, attempt 0, stage 5.0)
[2025-07-19T18:30:17.527+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2765f2f5
[2025-07-19T18:30:17.528+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=133, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.530+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=133),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/133] for update
[2025-07-19T18:30:17.531+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.533+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5fc74c53
[2025-07-19T18:30:17.534+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=130, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.535+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=130),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/130] for update
[2025-07-19T18:30:17.536+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.543+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/115/.1.delta.038bc4ca-3b7e-41ad-899b-2778f7234bda.TID239.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/115/1.delta
[2025-07-19T18:30:17.544+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=115),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/115] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/115/1.delta
[2025-07-19T18:30:17.548+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 115 (task 239, attempt 0, stage 5.0)
[2025-07-19T18:30:17.548+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/133/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/133/.1.delta.884ef8e5-1b22-4889-beab-c466d8f32ce5.TID245.tmp
[2025-07-19T18:30:17.551+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 112 (task 237, attempt 0, stage 5.0)
[2025-07-19T18:30:17.556+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/130/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/130/.1.delta.abb17356-8047-49a5-956c-aacb3b24f764.TID244.tmp
[2025-07-19T18:30:17.558+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 112.0 in stage 5.0 (TID 237). 9163 bytes result sent to driver
[2025-07-19T18:30:17.559+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/117/.1.delta.ec808c75-c3d7-428e-badd-5a54b1a4ca65.TID240.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/117/1.delta
[2025-07-19T18:30:17.560+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=117),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/117] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/117/1.delta
[2025-07-19T18:30:17.561+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 134.0 in stage 5.0 (TID 246) (8b44f3d35cfa, executor driver, partition 134, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.562+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 134.0 in stage 5.0 (TID 246)
[2025-07-19T18:30:17.562+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 112.0 in stage 5.0 (TID 237) in 142 ms on 8b44f3d35cfa (executor driver) (28/200)
[2025-07-19T18:30:17.563+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 117 (task 240, attempt 0, stage 5.0)
[2025-07-19T18:30:17.563+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.567+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.570+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/118/.1.delta.099c79ba-9743-402d-8d36-c81c3e1fe89a.TID241.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/118/1.delta
[2025-07-19T18:30:17.570+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=118),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/118] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/118/1.delta
[2025-07-19T18:30:17.571+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 118 (task 241, attempt 0, stage 5.0)
[2025-07-19T18:30:17.571+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@12662c29
[2025-07-19T18:30:17.572+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=134, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.572+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=134),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/134] for update
[2025-07-19T18:30:17.572+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 115 (task 239, attempt 0, stage 5.0)
[2025-07-19T18:30:17.573+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.573+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 115.0 in stage 5.0 (TID 239). 9142 bytes result sent to driver
[2025-07-19T18:30:17.574+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 135.0 in stage 5.0 (TID 247) (8b44f3d35cfa, executor driver, partition 135, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.575+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 135.0 in stage 5.0 (TID 247)
[2025-07-19T18:30:17.576+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 115.0 in stage 5.0 (TID 239) in 141 ms on 8b44f3d35cfa (executor driver) (29/200)
[2025-07-19T18:30:17.577+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/120/.1.delta.ed7ab8ae-4eff-472d-8d29-ef8da865bfb8.TID242.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/120/1.delta
[2025-07-19T18:30:17.578+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=120),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/120] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/120/1.delta
[2025-07-19T18:30:17.578+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 120 (task 242, attempt 0, stage 5.0)
[2025-07-19T18:30:17.580+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.580+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.580+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/134/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/134/.1.delta.100936ea-fdf9-42d6-8d75-dc84a3e4b884.TID246.tmp
[2025-07-19T18:30:17.580+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/125/.1.delta.88ead078-3f06-4286-ac78-8a45d7469a40.TID243.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/125/1.delta
[2025-07-19T18:30:17.581+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=125),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/125] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/125/1.delta
[2025-07-19T18:30:17.581+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 125 (task 243, attempt 0, stage 5.0)
[2025-07-19T18:30:17.586+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@508a25f5
[2025-07-19T18:30:17.587+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 118 (task 241, attempt 0, stage 5.0)
[2025-07-19T18:30:17.592+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=135, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.593+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=135),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/135] for update
[2025-07-19T18:30:17.595+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 118.0 in stage 5.0 (TID 241). 9113 bytes result sent to driver
[2025-07-19T18:30:17.596+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 117 (task 240, attempt 0, stage 5.0)
[2025-07-19T18:30:17.596+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 117.0 in stage 5.0 (TID 240). 9119 bytes result sent to driver
[2025-07-19T18:30:17.597+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.599+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 139.0 in stage 5.0 (TID 248) (8b44f3d35cfa, executor driver, partition 139, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.599+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 142.0 in stage 5.0 (TID 249) (8b44f3d35cfa, executor driver, partition 142, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.599+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 139.0 in stage 5.0 (TID 248)
[2025-07-19T18:30:17.599+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 118.0 in stage 5.0 (TID 241) in 123 ms on 8b44f3d35cfa (executor driver) (30/200)
[2025-07-19T18:30:17.599+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 142.0 in stage 5.0 (TID 249)
[2025-07-19T18:30:17.600+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 117.0 in stage 5.0 (TID 240) in 141 ms on 8b44f3d35cfa (executor driver) (31/200)
[2025-07-19T18:30:17.600+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/133/.1.delta.884ef8e5-1b22-4889-beab-c466d8f32ce5.TID245.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/133/1.delta
[2025-07-19T18:30:17.600+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=133),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/133] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/133/1.delta
[2025-07-19T18:30:17.600+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.600+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.600+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 120 (task 242, attempt 0, stage 5.0)
[2025-07-19T18:30:17.600+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 120.0 in stage 5.0 (TID 242). 9125 bytes result sent to driver
[2025-07-19T18:30:17.600+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/130/.1.delta.abb17356-8047-49a5-956c-aacb3b24f764.TID244.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/130/1.delta
[2025-07-19T18:30:17.600+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=130),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/130] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/130/1.delta
[2025-07-19T18:30:17.602+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 133 (task 245, attempt 0, stage 5.0)
[2025-07-19T18:30:17.603+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.603+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T18:30:17.604+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 130 (task 244, attempt 0, stage 5.0)
[2025-07-19T18:30:17.606+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 143.0 in stage 5.0 (TID 250) (8b44f3d35cfa, executor driver, partition 143, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.607+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 143.0 in stage 5.0 (TID 250)
[2025-07-19T18:30:17.607+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 120.0 in stage 5.0 (TID 242) in 122 ms on 8b44f3d35cfa (executor driver) (32/200)
[2025-07-19T18:30:17.608+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.609+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.610+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/135/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/135/.1.delta.3002a8b8-b9db-48ed-b4e0-7e020f3a2560.TID247.tmp
[2025-07-19T18:30:17.611+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a1429f8
[2025-07-19T18:30:17.613+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=139, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.614+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=139),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/139] for update
[2025-07-19T18:30:17.619+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ea81f33
[2025-07-19T18:30:17.620+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=143, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.620+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.621+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=143),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/143] for update
[2025-07-19T18:30:17.623+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 125 (task 243, attempt 0, stage 5.0)
[2025-07-19T18:30:17.623+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 133 (task 245, attempt 0, stage 5.0)
[2025-07-19T18:30:17.626+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/134/.1.delta.100936ea-fdf9-42d6-8d75-dc84a3e4b884.TID246.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/134/1.delta
[2025-07-19T18:30:17.627+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=134),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/134] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/134/1.delta
[2025-07-19T18:30:17.628+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 125.0 in stage 5.0 (TID 243). 9158 bytes result sent to driver
[2025-07-19T18:30:17.628+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 134 (task 246, attempt 0, stage 5.0)
[2025-07-19T18:30:17.629+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 133.0 in stage 5.0 (TID 245). 9154 bytes result sent to driver
[2025-07-19T18:30:17.632+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6f5be2c9
[2025-07-19T18:30:17.633+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.633+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 144.0 in stage 5.0 (TID 251) (8b44f3d35cfa, executor driver, partition 144, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.633+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=142, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.634+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 147.0 in stage 5.0 (TID 252) (8b44f3d35cfa, executor driver, partition 147, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.634+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 144.0 in stage 5.0 (TID 251)
[2025-07-19T18:30:17.634+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=142),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/142] for update
[2025-07-19T18:30:17.634+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 147.0 in stage 5.0 (TID 252)
[2025-07-19T18:30:17.635+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 125.0 in stage 5.0 (TID 243) in 134 ms on 8b44f3d35cfa (executor driver) (33/200)
[2025-07-19T18:30:17.635+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 133.0 in stage 5.0 (TID 245) in 121 ms on 8b44f3d35cfa (executor driver) (34/200)
[2025-07-19T18:30:17.637+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.638+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.638+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.638+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.639+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.643+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/139/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/139/.1.delta.760003d4-aee4-42ba-bf8b-be9f73b827db.TID248.tmp
[2025-07-19T18:30:17.644+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 130 (task 244, attempt 0, stage 5.0)
[2025-07-19T18:30:17.647+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 130.0 in stage 5.0 (TID 244). 9131 bytes result sent to driver
[2025-07-19T18:30:17.649+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 134 (task 246, attempt 0, stage 5.0)
[2025-07-19T18:30:17.651+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 149.0 in stage 5.0 (TID 253) (8b44f3d35cfa, executor driver, partition 149, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.654+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 149.0 in stage 5.0 (TID 253)
[2025-07-19T18:30:17.654+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 130.0 in stage 5.0 (TID 244) in 137 ms on 8b44f3d35cfa (executor driver) (35/200)
[2025-07-19T18:30:17.655+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 134.0 in stage 5.0 (TID 246). 9119 bytes result sent to driver
[2025-07-19T18:30:17.656+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/143/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/143/.1.delta.172f157d-231f-4c5b-947d-11f4c61c171e.TID250.tmp
[2025-07-19T18:30:17.657+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 151.0 in stage 5.0 (TID 254) (8b44f3d35cfa, executor driver, partition 151, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.658+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.658+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.658+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 134.0 in stage 5.0 (TID 246) in 96 ms on 8b44f3d35cfa (executor driver) (36/200)
[2025-07-19T18:30:17.658+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 151.0 in stage 5.0 (TID 254)
[2025-07-19T18:30:17.659+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d8d2c16
[2025-07-19T18:30:17.660+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=144, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.661+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=144),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/144] for update
[2025-07-19T18:30:17.661+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.661+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.661+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/142/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/142/.1.delta.e851b6da-cc72-4dfe-b906-94b0e25ee058.TID249.tmp
[2025-07-19T18:30:17.661+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.663+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5309cc70
[2025-07-19T18:30:17.664+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=151, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.665+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=151),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/151] for update
[2025-07-19T18:30:17.667+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.668+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/135/.1.delta.3002a8b8-b9db-48ed-b4e0-7e020f3a2560.TID247.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/135/1.delta
[2025-07-19T18:30:17.669+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=135),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/135] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/135/1.delta
[2025-07-19T18:30:17.670+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 135 (task 247, attempt 0, stage 5.0)
[2025-07-19T18:30:17.672+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/144/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/144/.1.delta.61524db1-e8a5-4a8e-a379-925ac605e013.TID251.tmp
[2025-07-19T18:30:17.677+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@27f754de
[2025-07-19T18:30:17.678+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=149, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.678+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=149),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/149] for update
[2025-07-19T18:30:17.680+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.683+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/151/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/151/.1.delta.8fbbe805-55d2-448e-8645-2bb0307daafa.TID254.tmp
[2025-07-19T18:30:17.684+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d3fa08d
[2025-07-19T18:30:17.685+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=147, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.687+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=147),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/147] for update
[2025-07-19T18:30:17.688+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 135 (task 247, attempt 0, stage 5.0)
[2025-07-19T18:30:17.689+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 135.0 in stage 5.0 (TID 247). 9113 bytes result sent to driver
[2025-07-19T18:30:17.690+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/149/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/149/.1.delta.99326add-dbf5-45ff-a60f-3ff66f9b54b3.TID253.tmp
[2025-07-19T18:30:17.692+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 153.0 in stage 5.0 (TID 255) (8b44f3d35cfa, executor driver, partition 153, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.692+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.693+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 153.0 in stage 5.0 (TID 255)
[2025-07-19T18:30:17.694+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 135.0 in stage 5.0 (TID 247) in 124 ms on 8b44f3d35cfa (executor driver) (37/200)
[2025-07-19T18:30:17.705+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/139/.1.delta.760003d4-aee4-42ba-bf8b-be9f73b827db.TID248.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/139/1.delta
[2025-07-19T18:30:17.705+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=139),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/139] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/139/1.delta
[2025-07-19T18:30:17.712+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.713+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T18:30:17.714+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 139 (task 248, attempt 0, stage 5.0)
[2025-07-19T18:30:17.714+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ece1c14
[2025-07-19T18:30:17.715+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=153, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.715+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/147/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/147/.1.delta.07a1f4ea-f4f2-4056-937d-48a0ef573063.TID252.tmp
[2025-07-19T18:30:17.718+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=153),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/153] for update
[2025-07-19T18:30:17.719+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/143/.1.delta.172f157d-231f-4c5b-947d-11f4c61c171e.TID250.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/143/1.delta
[2025-07-19T18:30:17.719+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=143),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/143] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/143/1.delta
[2025-07-19T18:30:17.719+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 143 (task 250, attempt 0, stage 5.0)
[2025-07-19T18:30:17.720+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.729+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/142/.1.delta.e851b6da-cc72-4dfe-b906-94b0e25ee058.TID249.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/142/1.delta
[2025-07-19T18:30:17.729+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=142),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/142] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/142/1.delta
[2025-07-19T18:30:17.729+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 142 (task 249, attempt 0, stage 5.0)
[2025-07-19T18:30:17.737+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/144/.1.delta.61524db1-e8a5-4a8e-a379-925ac605e013.TID251.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/144/1.delta
[2025-07-19T18:30:17.738+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=144),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/144] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/144/1.delta
[2025-07-19T18:30:17.739+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 144 (task 251, attempt 0, stage 5.0)
[2025-07-19T18:30:17.740+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/153/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/153/.1.delta.9bdc38f7-c4ed-4296-a9bc-0f18135a213b.TID255.tmp
[2025-07-19T18:30:17.744+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 142 (task 249, attempt 0, stage 5.0)
[2025-07-19T18:30:17.748+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/151/.1.delta.8fbbe805-55d2-448e-8645-2bb0307daafa.TID254.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/151/1.delta
[2025-07-19T18:30:17.749+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=151),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/151] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/151/1.delta
[2025-07-19T18:30:17.750+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 142.0 in stage 5.0 (TID 249). 9197 bytes result sent to driver
[2025-07-19T18:30:17.754+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 151 (task 254, attempt 0, stage 5.0)
[2025-07-19T18:30:17.755+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 154.0 in stage 5.0 (TID 256) (8b44f3d35cfa, executor driver, partition 154, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.755+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 154.0 in stage 5.0 (TID 256)
[2025-07-19T18:30:17.756+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 142.0 in stage 5.0 (TID 249) in 158 ms on 8b44f3d35cfa (executor driver) (38/200)
[2025-07-19T18:30:17.757+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/149/.1.delta.99326add-dbf5-45ff-a60f-3ff66f9b54b3.TID253.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/149/1.delta
[2025-07-19T18:30:17.757+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=149),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/149] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/149/1.delta
[2025-07-19T18:30:17.758+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 149 (task 253, attempt 0, stage 5.0)
[2025-07-19T18:30:17.758+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.758+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.759+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 139 (task 248, attempt 0, stage 5.0)
[2025-07-19T18:30:17.759+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 139.0 in stage 5.0 (TID 248). 9158 bytes result sent to driver
[2025-07-19T18:30:17.760+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 158.0 in stage 5.0 (TID 257) (8b44f3d35cfa, executor driver, partition 158, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.760+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 139.0 in stage 5.0 (TID 248) in 164 ms on 8b44f3d35cfa (executor driver) (39/200)
[2025-07-19T18:30:17.761+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 158.0 in stage 5.0 (TID 257)
[2025-07-19T18:30:17.761+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 144 (task 251, attempt 0, stage 5.0)
[2025-07-19T18:30:17.761+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.761+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.762+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/147/.1.delta.07a1f4ea-f4f2-4056-937d-48a0ef573063.TID252.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/147/1.delta
[2025-07-19T18:30:17.762+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=147),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/147] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/147/1.delta
[2025-07-19T18:30:17.770+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 144.0 in stage 5.0 (TID 251). 9180 bytes result sent to driver
[2025-07-19T18:30:17.771+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 143 (task 250, attempt 0, stage 5.0)
[2025-07-19T18:30:17.771+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 147 (task 252, attempt 0, stage 5.0)
[2025-07-19T18:30:17.771+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 143.0 in stage 5.0 (TID 250). 9152 bytes result sent to driver
[2025-07-19T18:30:17.772+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 159.0 in stage 5.0 (TID 258) (8b44f3d35cfa, executor driver, partition 159, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.772+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 167.0 in stage 5.0 (TID 259) (8b44f3d35cfa, executor driver, partition 167, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.773+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 167.0 in stage 5.0 (TID 259)
[2025-07-19T18:30:17.773+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 143.0 in stage 5.0 (TID 250) in 163 ms on 8b44f3d35cfa (executor driver) (40/200)
[2025-07-19T18:30:17.773+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 144.0 in stage 5.0 (TID 251) in 137 ms on 8b44f3d35cfa (executor driver) (41/200)
[2025-07-19T18:30:17.773+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 159.0 in stage 5.0 (TID 258)
[2025-07-19T18:30:17.774+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ce818bf
[2025-07-19T18:30:17.774+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=154, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.774+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=154),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/154] for update
[2025-07-19T18:30:17.776+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 151 (task 254, attempt 0, stage 5.0)
[2025-07-19T18:30:17.777+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 151.0 in stage 5.0 (TID 254). 9148 bytes result sent to driver
[2025-07-19T18:30:17.778+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 170.0 in stage 5.0 (TID 260) (8b44f3d35cfa, executor driver, partition 170, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.778+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 170.0 in stage 5.0 (TID 260)
[2025-07-19T18:30:17.778+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 151.0 in stage 5.0 (TID 254) in 126 ms on 8b44f3d35cfa (executor driver) (42/200)
[2025-07-19T18:30:17.778+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.779+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.779+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.779+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.780+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.780+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.780+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.787+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1edc8c6b
[2025-07-19T18:30:17.791+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 8b44f3d35cfa:40517 in memory (size: 19.9 KiB, free: 434.2 MiB)
[2025-07-19T18:30:17.792+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 149 (task 253, attempt 0, stage 5.0)
[2025-07-19T18:30:17.792+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=158, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.792+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=158),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/158] for update
[2025-07-19T18:30:17.792+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 149.0 in stage 5.0 (TID 253). 9154 bytes result sent to driver
[2025-07-19T18:30:17.793+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.796+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@30bad27c
[2025-07-19T18:30:17.799+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 171.0 in stage 5.0 (TID 261) (8b44f3d35cfa, executor driver, partition 171, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.800+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=167, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.804+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=167),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/167] for update
[2025-07-19T18:30:17.805+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 149.0 in stage 5.0 (TID 253) in 150 ms on 8b44f3d35cfa (executor driver) (43/200)
[2025-07-19T18:30:17.806+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 171.0 in stage 5.0 (TID 261)
[2025-07-19T18:30:17.806+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.806+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.807+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.807+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/153/.1.delta.9bdc38f7-c4ed-4296-a9bc-0f18135a213b.TID255.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/153/1.delta
[2025-07-19T18:30:17.807+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=153),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/153] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/153/1.delta
[2025-07-19T18:30:17.808+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7924f602
[2025-07-19T18:30:17.808+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=159, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.809+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=159),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/159] for update
[2025-07-19T18:30:17.810+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 153 (task 255, attempt 0, stage 5.0)
[2025-07-19T18:30:17.811+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.812+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/154/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/154/.1.delta.5eceab19-8f34-4bff-9ba1-870484d3ba55.TID256.tmp
[2025-07-19T18:30:17.812+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@183b4863
[2025-07-19T18:30:17.813+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 147 (task 252, attempt 0, stage 5.0)
[2025-07-19T18:30:17.814+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 147.0 in stage 5.0 (TID 252). 9154 bytes result sent to driver
[2025-07-19T18:30:17.815+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/158/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/158/.1.delta.60248184-5b51-4d09-bf02-bffa4a36f9f8.TID257.tmp
[2025-07-19T18:30:17.815+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=170, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.817+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=170),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/170] for update
[2025-07-19T18:30:17.817+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 183.0 in stage 5.0 (TID 262) (8b44f3d35cfa, executor driver, partition 183, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.817+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 183.0 in stage 5.0 (TID 262)
[2025-07-19T18:30:17.818+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/167/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/167/.1.delta.5d7a653b-48c9-435a-9cb2-40d330997e5d.TID259.tmp
[2025-07-19T18:30:17.818+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 147.0 in stage 5.0 (TID 252) in 184 ms on 8b44f3d35cfa (executor driver) (44/200)
[2025-07-19T18:30:17.818+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.819+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.820+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.820+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@18feca9f
[2025-07-19T18:30:17.820+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=171, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.821+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=171),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/171] for update
[2025-07-19T18:30:17.822+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/159/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/159/.1.delta.5017b90a-44ae-4a4b-8590-f94f87d6cb45.TID258.tmp
[2025-07-19T18:30:17.822+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.825+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HadoopTableOperations: Committed a new metadata file s3a://warehouse/bronze/Checkins_raw/metadata/v18.metadata.json
[2025-07-19T18:30:17.827+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/171/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/171/.1.delta.4afbc377-df7a-41aa-96ee-f0f53b8fa0ac.TID261.tmp
[2025-07-19T18:30:17.828+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1daa102e
[2025-07-19T18:30:17.830+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=183, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.830+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=183),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/183] for update
[2025-07-19T18:30:17.831+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 153 (task 255, attempt 0, stage 5.0)
[2025-07-19T18:30:17.832+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/170/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/170/.1.delta.bc9245b0-cf14-4846-b8b2-d73c0865470b.TID260.tmp
[2025-07-19T18:30:17.833+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.833+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 153.0 in stage 5.0 (TID 255). 9154 bytes result sent to driver
[2025-07-19T18:30:17.834+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 184.0 in stage 5.0 (TID 263) (8b44f3d35cfa, executor driver, partition 184, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.834+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 184.0 in stage 5.0 (TID 263)
[2025-07-19T18:30:17.834+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 153.0 in stage 5.0 (TID 255) in 143 ms on 8b44f3d35cfa (executor driver) (45/200)
[2025-07-19T18:30:17.839+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.839+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.843+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/183/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/183/.1.delta.98bb9811-bb7f-41dd-a4ef-a3caf72da4c8.TID262.tmp
[2025-07-19T18:30:17.850+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@49425849
[2025-07-19T18:30:17.851+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=184, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.851+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=184),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/184] for update
[2025-07-19T18:30:17.852+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/154/.1.delta.5eceab19-8f34-4bff-9ba1-870484d3ba55.TID256.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/154/1.delta
[2025-07-19T18:30:17.853+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=154),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/154] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/154/1.delta
[2025-07-19T18:30:17.853+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.853+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 154 (task 256, attempt 0, stage 5.0)
[2025-07-19T18:30:17.854+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/167/.1.delta.5d7a653b-48c9-435a-9cb2-40d330997e5d.TID259.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/167/1.delta
[2025-07-19T18:30:17.854+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=167),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/167] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/167/1.delta
[2025-07-19T18:30:17.857+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 167 (task 259, attempt 0, stage 5.0)
[2025-07-19T18:30:17.858+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/158/.1.delta.60248184-5b51-4d09-bf02-bffa4a36f9f8.TID257.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/158/1.delta
[2025-07-19T18:30:17.858+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=158),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/158] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/158/1.delta
[2025-07-19T18:30:17.858+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 158 (task 257, attempt 0, stage 5.0)
[2025-07-19T18:30:17.862+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/171/.1.delta.4afbc377-df7a-41aa-96ee-f0f53b8fa0ac.TID261.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/171/1.delta
[2025-07-19T18:30:17.863+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=171),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/171] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/171/1.delta
[2025-07-19T18:30:17.863+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 171 (task 261, attempt 0, stage 5.0)
[2025-07-19T18:30:17.864+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/159/.1.delta.5017b90a-44ae-4a4b-8590-f94f87d6cb45.TID258.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/159/1.delta
[2025-07-19T18:30:17.865+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=159),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/159] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/159/1.delta
[2025-07-19T18:30:17.865+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 159 (task 258, attempt 0, stage 5.0)
[2025-07-19T18:30:17.865+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/184/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/184/.1.delta.55f741b3-7bf8-46aa-a7a6-30fa6dcdde04.TID263.tmp
[2025-07-19T18:30:17.866+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/170/.1.delta.bc9245b0-cf14-4846-b8b2-d73c0865470b.TID260.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/170/1.delta
[2025-07-19T18:30:17.867+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=170),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/170] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/170/1.delta
[2025-07-19T18:30:17.868+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 170 (task 260, attempt 0, stage 5.0)
[2025-07-19T18:30:17.874+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 154 (task 256, attempt 0, stage 5.0)
[2025-07-19T18:30:17.876+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 154.0 in stage 5.0 (TID 256). 9107 bytes result sent to driver
[2025-07-19T18:30:17.876+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 158 (task 257, attempt 0, stage 5.0)
[2025-07-19T18:30:17.877+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 167 (task 259, attempt 0, stage 5.0)
[2025-07-19T18:30:17.877+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 187.0 in stage 5.0 (TID 264) (8b44f3d35cfa, executor driver, partition 187, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.878+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 158.0 in stage 5.0 (TID 257). 9165 bytes result sent to driver
[2025-07-19T18:30:17.879+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 167.0 in stage 5.0 (TID 259). 9121 bytes result sent to driver
[2025-07-19T18:30:17.879+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 187.0 in stage 5.0 (TID 264)
[2025-07-19T18:30:17.880+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO SnapshotProducer: Committed snapshot 1114749360720794235 (FastAppend)
[2025-07-19T18:30:17.881+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 189.0 in stage 5.0 (TID 265) (8b44f3d35cfa, executor driver, partition 189, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.881+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 189.0 in stage 5.0 (TID 265)
[2025-07-19T18:30:17.882+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 192.0 in stage 5.0 (TID 266) (8b44f3d35cfa, executor driver, partition 192, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.884+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 154.0 in stage 5.0 (TID 256) in 130 ms on 8b44f3d35cfa (executor driver) (46/200)
[2025-07-19T18:30:17.885+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 167.0 in stage 5.0 (TID 259) in 115 ms on 8b44f3d35cfa (executor driver) (47/200)
[2025-07-19T18:30:17.885+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 158.0 in stage 5.0 (TID 257) in 125 ms on 8b44f3d35cfa (executor driver) (48/200)
[2025-07-19T18:30:17.886+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.886+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.887+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 192.0 in stage 5.0 (TID 266)
[2025-07-19T18:30:17.887+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.889+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.891+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.891+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.891+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 171 (task 261, attempt 0, stage 5.0)
[2025-07-19T18:30:17.892+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 170 (task 260, attempt 0, stage 5.0)
[2025-07-19T18:30:17.893+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 170.0 in stage 5.0 (TID 260). 9111 bytes result sent to driver
[2025-07-19T18:30:17.894+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 171.0 in stage 5.0 (TID 261). 9109 bytes result sent to driver
[2025-07-19T18:30:17.894+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 194.0 in stage 5.0 (TID 267) (8b44f3d35cfa, executor driver, partition 194, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.895+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 197.0 in stage 5.0 (TID 268) (8b44f3d35cfa, executor driver, partition 197, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.895+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 171.0 in stage 5.0 (TID 261) in 97 ms on 8b44f3d35cfa (executor driver) (49/200)
[2025-07-19T18:30:17.895+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 170.0 in stage 5.0 (TID 260) in 115 ms on 8b44f3d35cfa (executor driver) (50/200)
[2025-07-19T18:30:17.896+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 197.0 in stage 5.0 (TID 268)
[2025-07-19T18:30:17.896+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.896+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.896+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 159 (task 258, attempt 0, stage 5.0)
[2025-07-19T18:30:17.897+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 159.0 in stage 5.0 (TID 258). 9113 bytes result sent to driver
[2025-07-19T18:30:17.897+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 194.0 in stage 5.0 (TID 267)
[2025-07-19T18:30:17.899+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.900+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/183/.1.delta.98bb9811-bb7f-41dd-a4ef-a3caf72da4c8.TID262.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/183/1.delta
[2025-07-19T18:30:17.900+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=183),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/183] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/183/1.delta
[2025-07-19T18:30:17.900+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 5.0 in stage 5.0 (TID 269) (8b44f3d35cfa, executor driver, partition 5, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.901+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 5.0 in stage 5.0 (TID 269)
[2025-07-19T18:30:17.901+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 159.0 in stage 5.0 (TID 258) in 135 ms on 8b44f3d35cfa (executor driver) (51/200)
[2025-07-19T18:30:17.902+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 183 (task 262, attempt 0, stage 5.0)
[2025-07-19T18:30:17.903+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T18:30:17.904+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/184/.1.delta.55f741b3-7bf8-46aa-a7a6-30fa6dcdde04.TID263.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/184/1.delta
[2025-07-19T18:30:17.904+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=184),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/184] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/184/1.delta
[2025-07-19T18:30:17.904+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 184 (task 263, attempt 0, stage 5.0)
[2025-07-19T18:30:17.906+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d069b45
[2025-07-19T18:30:17.907+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.909+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.911+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=189, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.911+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=189),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/189] for update
[2025-07-19T18:30:17.912+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.912+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33c8f38
[2025-07-19T18:30:17.914+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=5, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.915+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/5] for update
[2025-07-19T18:30:17.915+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.916+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 184 (task 263, attempt 0, stage 5.0)
[2025-07-19T18:30:17.919+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5cd7a2f2
[2025-07-19T18:30:17.924+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=194, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.925+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=194),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/194] for update
[2025-07-19T18:30:17.926+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 184.0 in stage 5.0 (TID 263). 9150 bytes result sent to driver
[2025-07-19T18:30:17.927+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 183 (task 262, attempt 0, stage 5.0)
[2025-07-19T18:30:17.927+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.928+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 183.0 in stage 5.0 (TID 262). 9115 bytes result sent to driver
[2025-07-19T18:30:17.928+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 6.0 in stage 5.0 (TID 270) (8b44f3d35cfa, executor driver, partition 6, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.929+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 184.0 in stage 5.0 (TID 263) in 92 ms on 8b44f3d35cfa (executor driver) (52/200)
[2025-07-19T18:30:17.929+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 6.0 in stage 5.0 (TID 270)
[2025-07-19T18:30:17.930+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 183.0 in stage 5.0 (TID 262) in 111 ms on 8b44f3d35cfa (executor driver) (53/200)
[2025-07-19T18:30:17.930+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/189/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/189/.1.delta.bd507f95-212e-47f3-b51c-d0e4d105d1b8.TID265.tmp
[2025-07-19T18:30:17.931+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 7.0 in stage 5.0 (TID 271) (8b44f3d35cfa, executor driver, partition 7, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.932+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 7.0 in stage 5.0 (TID 271)
[2025-07-19T18:30:17.932+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.933+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.933+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/5/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/5/.1.delta.7bd1f4bc-80e2-4f56-992e-6ae2a1227d85.TID269.tmp
[2025-07-19T18:30:17.933+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.934+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:17.934+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f2e9182
[2025-07-19T18:30:17.935+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=197, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.935+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=197),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/197] for update
[2025-07-19T18:30:17.935+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/194/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/194/.1.delta.da541127-f30e-401f-b27f-489716b58557.TID267.tmp
[2025-07-19T18:30:17.936+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.937+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7616be1b
[2025-07-19T18:30:17.937+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=192, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.938+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=192),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/192] for update
[2025-07-19T18:30:17.940+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.942+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@11b838fe
[2025-07-19T18:30:17.942+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=187, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.943+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=187),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/187] for update
[2025-07-19T18:30:17.944+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.946+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/192/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/192/.1.delta.929add7c-93b0-45ab-8cd9-b0372b9f7c39.TID266.tmp
[2025-07-19T18:30:17.947+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/197/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/197/.1.delta.a36332ce-a70e-4d59-96c4-bb5e553aac8b.TID268.tmp
[2025-07-19T18:30:17.948+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO LoggingMetricsReporter: Received metrics report: CommitReport{tableName=my_catalog.bronze.Checkins_raw, snapshotId=1114749360720794235, sequenceNumber=17, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.682900626S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=CounterResult{unit=COUNT, value=59}, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=463}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=CounterResult{unit=COUNT, value=69}, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=513}, addedFilesSizeInBytes=CounterResult{unit=BYTES, value=190213}, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=1490806}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}}, metadata={engine-version=3.5.6, app-id=local-1752949808869, engine-name=spark, iceberg-version=Apache Iceberg 1.4.0 (commit 10367c380098c2e06a49521a33681ac7f6c64b2c)}}
[2025-07-19T18:30:17.948+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO SparkWrite: Committed in 703 ms
[2025-07-19T18:30:17.949+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Checkins_raw, format=PARQUET)] committed.
[2025-07-19T18:30:17.953+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/187/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/187/.1.delta.96505b6f-3653-451d-a088-4fbb2d504277.TID264.tmp
[2025-07-19T18:30:17.953+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@29691771
[2025-07-19T18:30:17.957+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=7, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.958+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/7] for update
[2025-07-19T18:30:17.959+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO WatermarkTracker: Updating event-time watermark from 0 to 1752775980000 ms
[2025-07-19T18:30:17.961+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.962+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/5/.1.delta.7bd1f4bc-80e2-4f56-992e-6ae2a1227d85.TID269.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/5/1.delta
[2025-07-19T18:30:17.963+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/5] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/5/1.delta
[2025-07-19T18:30:17.963+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 5 (task 269, attempt 0, stage 5.0)
[2025-07-19T18:30:17.965+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@186beae2
[2025-07-19T18:30:17.967+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=6, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.968+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/6] for update
[2025-07-19T18:30:17.972+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.973+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/commits/0 using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/commits/.0.1d9a9d67-9227-41e4-a3bd-e342ed45557f.tmp
[2025-07-19T18:30:17.974+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/189/.1.delta.bd507f95-212e-47f3-b51c-d0e4d105d1b8.TID265.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/189/1.delta
[2025-07-19T18:30:17.975+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=189),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/189] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/189/1.delta
[2025-07-19T18:30:17.975+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 189 (task 265, attempt 0, stage 5.0)
[2025-07-19T18:30:17.975+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 5 (task 269, attempt 0, stage 5.0)
[2025-07-19T18:30:17.976+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 5.0 in stage 5.0 (TID 269). 6200 bytes result sent to driver
[2025-07-19T18:30:17.976+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 8.0 in stage 5.0 (TID 272) (8b44f3d35cfa, executor driver, partition 8, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.976+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 5.0 in stage 5.0 (TID 269) in 77 ms on 8b44f3d35cfa (executor driver) (54/200)
[2025-07-19T18:30:17.976+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 8.0 in stage 5.0 (TID 272)
[2025-07-19T18:30:17.979+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/7/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/7/.1.delta.41903b34-89e2-4ccc-a30f-b10fa8f0963f.TID271.tmp
[2025-07-19T18:30:17.985+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:17.985+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T18:30:17.988+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/6/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/6/.1.delta.29fab7fd-f4c5-4c53-9909-1a38cc74ba21.TID270.tmp
[2025-07-19T18:30:17.988+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Committed partition 189 (task 265, attempt 0, stage 5.0)
[2025-07-19T18:30:17.989+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/194/.1.delta.da541127-f30e-401f-b27f-489716b58557.TID267.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/194/1.delta
[2025-07-19T18:30:17.990+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=194),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/194] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/194/1.delta
[2025-07-19T18:30:17.990+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 194 (task 267, attempt 0, stage 5.0)
[2025-07-19T18:30:17.991+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Finished task 189.0 in stage 5.0 (TID 265). 9115 bytes result sent to driver
[2025-07-19T18:30:17.993+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Starting task 10.0 in stage 5.0 (TID 273) (8b44f3d35cfa, executor driver, partition 10, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:17.993+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO Executor: Running task 10.0 in stage 5.0 (TID 273)
[2025-07-19T18:30:17.994+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@356f9b2
[2025-07-19T18:30:17.994+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=8, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:17.994+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/8] for update
[2025-07-19T18:30:17.995+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO TaskSetManager: Finished task 189.0 in stage 5.0 (TID 265) in 117 ms on 8b44f3d35cfa (executor driver) (55/200)
[2025-07-19T18:30:17.995+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:17.998+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/192/.1.delta.929add7c-93b0-45ab-8cd9-b0372b9f7c39.TID266.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/192/1.delta
[2025-07-19T18:30:17.999+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=192),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/192] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/192/1.delta
[2025-07-19T18:30:18.002+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO DataWritingSparkTask: Commit authorized for partition 192 (task 266, attempt 0, stage 5.0)
[2025-07-19T18:30:18.003+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.003+0000] {subprocess.py:93} INFO - 25/07/19 18:30:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.005+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/197/.1.delta.a36332ce-a70e-4d59-96c4-bb5e553aac8b.TID268.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/197/1.delta
[2025-07-19T18:30:18.005+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=197),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/197] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/197/1.delta
[2025-07-19T18:30:18.008+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 197 (task 268, attempt 0, stage 5.0)
[2025-07-19T18:30:18.010+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7351db72
[2025-07-19T18:30:18.011+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=10, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.011+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=10),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/10] for update
[2025-07-19T18:30:18.012+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/8/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/8/.1.delta.ccf4da50-94ab-4416-b51a-36ed152850b4.TID272.tmp
[2025-07-19T18:30:18.015+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/187/.1.delta.96505b6f-3653-451d-a088-4fbb2d504277.TID264.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/187/1.delta
[2025-07-19T18:30:18.016+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=187),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/187] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/187/1.delta
[2025-07-19T18:30:18.016+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 187 (task 264, attempt 0, stage 5.0)
[2025-07-19T18:30:18.019+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.021+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/commits/.0.1d9a9d67-9227-41e4-a3bd-e342ed45557f.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/commits/0
[2025-07-19T18:30:18.024+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 192 (task 266, attempt 0, stage 5.0)
[2025-07-19T18:30:18.025+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 192.0 in stage 5.0 (TID 266). 9107 bytes result sent to driver
[2025-07-19T18:30:18.025+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 14.0 in stage 5.0 (TID 274) (8b44f3d35cfa, executor driver, partition 14, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.026+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 14.0 in stage 5.0 (TID 274)
[2025-07-19T18:30:18.027+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.027+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.029+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 192.0 in stage 5.0 (TID 266) in 150 ms on 8b44f3d35cfa (executor driver) (56/200)
[2025-07-19T18:30:18.030+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 194 (task 267, attempt 0, stage 5.0)
[2025-07-19T18:30:18.030+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/10/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/10/.1.delta.b9bb0f2c-fdce-4546-80f1-c8f1d6ea3244.TID273.tmp
[2025-07-19T18:30:18.031+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 194.0 in stage 5.0 (TID 267). 9101 bytes result sent to driver
[2025-07-19T18:30:18.033+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 17.0 in stage 5.0 (TID 275) (8b44f3d35cfa, executor driver, partition 17, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.035+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1bd553d7
[2025-07-19T18:30:18.036+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=14, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.037+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=14),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/14] for update
[2025-07-19T18:30:18.037+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/6/.1.delta.29fab7fd-f4c5-4c53-9909-1a38cc74ba21.TID270.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/6/1.delta
[2025-07-19T18:30:18.038+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/6] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/6/1.delta
[2025-07-19T18:30:18.038+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 6 (task 270, attempt 0, stage 5.0)
[2025-07-19T18:30:18.040+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 194.0 in stage 5.0 (TID 267) in 146 ms on 8b44f3d35cfa (executor driver) (57/200)
[2025-07-19T18:30:18.040+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.041+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/7/.1.delta.41903b34-89e2-4ccc-a30f-b10fa8f0963f.TID271.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/7/1.delta
[2025-07-19T18:30:18.041+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/7] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/7/1.delta
[2025-07-19T18:30:18.042+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 7 (task 271, attempt 0, stage 5.0)
[2025-07-19T18:30:18.042+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 187 (task 264, attempt 0, stage 5.0)
[2025-07-19T18:30:18.044+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 17.0 in stage 5.0 (TID 275)
[2025-07-19T18:30:18.046+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 6 (task 270, attempt 0, stage 5.0)
[2025-07-19T18:30:18.048+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 6.0 in stage 5.0 (TID 270). 6200 bytes result sent to driver
[2025-07-19T18:30:18.048+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 197 (task 268, attempt 0, stage 5.0)
[2025-07-19T18:30:18.049+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 187.0 in stage 5.0 (TID 264). 9128 bytes result sent to driver
[2025-07-19T18:30:18.050+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 197.0 in stage 5.0 (TID 268). 9113 bytes result sent to driver
[2025-07-19T18:30:18.050+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 18.0 in stage 5.0 (TID 276) (8b44f3d35cfa, executor driver, partition 18, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.050+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 19.0 in stage 5.0 (TID 277) (8b44f3d35cfa, executor driver, partition 19, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.051+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 20.0 in stage 5.0 (TID 278) (8b44f3d35cfa, executor driver, partition 20, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.051+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 20.0 in stage 5.0 (TID 278)
[2025-07-19T18:30:18.051+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.051+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.051+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.051+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T18:30:18.052+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 6.0 in stage 5.0 (TID 270) in 119 ms on 8b44f3d35cfa (executor driver) (58/200)
[2025-07-19T18:30:18.052+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 19.0 in stage 5.0 (TID 277)
[2025-07-19T18:30:18.052+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 187.0 in stage 5.0 (TID 264) in 170 ms on 8b44f3d35cfa (executor driver) (59/200)
[2025-07-19T18:30:18.052+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 197.0 in stage 5.0 (TID 268) in 155 ms on 8b44f3d35cfa (executor driver) (60/200)
[2025-07-19T18:30:18.052+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 18.0 in stage 5.0 (TID 276)
[2025-07-19T18:30:18.052+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1dd7239e
[2025-07-19T18:30:18.052+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.052+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.052+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=20, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.052+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=20),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/20] for update
[2025-07-19T18:30:18.054+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.054+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/14/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/14/.1.delta.199df5ac-0e14-4e75-a10f-3e57021f4777.TID274.tmp
[2025-07-19T18:30:18.055+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.055+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 7 (task 271, attempt 0, stage 5.0)
[2025-07-19T18:30:18.055+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 7.0 in stage 5.0 (TID 271). 6200 bytes result sent to driver
[2025-07-19T18:30:18.057+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.057+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/8/.1.delta.ccf4da50-94ab-4416-b51a-36ed152850b4.TID272.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/8/1.delta
[2025-07-19T18:30:18.057+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/8] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/8/1.delta
[2025-07-19T18:30:18.060+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 21.0 in stage 5.0 (TID 279) (8b44f3d35cfa, executor driver, partition 21, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.061+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1128f3c3
[2025-07-19T18:30:18.062+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 21.0 in stage 5.0 (TID 279)
[2025-07-19T18:30:18.062+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 8 (task 272, attempt 0, stage 5.0)
[2025-07-19T18:30:18.062+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=19, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.063+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=19),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/19] for update
[2025-07-19T18:30:18.063+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 7.0 in stage 5.0 (TID 271) in 132 ms on 8b44f3d35cfa (executor driver) (61/200)
[2025-07-19T18:30:18.064+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.064+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.065+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/20/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/20/.1.delta.44cb8d76-ca73-4f8b-b339-211d6e5615a5.TID278.tmp
[2025-07-19T18:30:18.065+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 8 (task 272, attempt 0, stage 5.0)
[2025-07-19T18:30:18.066+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 8.0 in stage 5.0 (TID 272). 6200 bytes result sent to driver
[2025-07-19T18:30:18.066+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 22.0 in stage 5.0 (TID 280) (8b44f3d35cfa, executor driver, partition 22, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.066+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 22.0 in stage 5.0 (TID 280)
[2025-07-19T18:30:18.067+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.067+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 8.0 in stage 5.0 (TID 272) in 91 ms on 8b44f3d35cfa (executor driver) (62/200)
[2025-07-19T18:30:18.068+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.068+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.068+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@8cb680d
[2025-07-19T18:30:18.069+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=17, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.069+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/10/.1.delta.b9bb0f2c-fdce-4546-80f1-c8f1d6ea3244.TID273.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/10/1.delta
[2025-07-19T18:30:18.069+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=10),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/10] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/10/1.delta
[2025-07-19T18:30:18.070+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=17),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/17] for update
[2025-07-19T18:30:18.070+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 10 (task 273, attempt 0, stage 5.0)
[2025-07-19T18:30:18.071+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.074+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 10 (task 273, attempt 0, stage 5.0)
[2025-07-19T18:30:18.075+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/19/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/19/.1.delta.75584227-8bc4-4006-b0f1-c58135dc0943.TID277.tmp
[2025-07-19T18:30:18.075+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 10.0 in stage 5.0 (TID 273). 6200 bytes result sent to driver
[2025-07-19T18:30:18.081+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/17/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/17/.1.delta.e0a7ce2e-3c88-416b-95dc-d1416c25c4d8.TID275.tmp
[2025-07-19T18:30:18.081+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2352743a
[2025-07-19T18:30:18.081+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 24.0 in stage 5.0 (TID 281) (8b44f3d35cfa, executor driver, partition 24, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.081+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 10.0 in stage 5.0 (TID 273) in 86 ms on 8b44f3d35cfa (executor driver) (63/200)
[2025-07-19T18:30:18.081+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=22, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.082+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 24.0 in stage 5.0 (TID 281)
[2025-07-19T18:30:18.082+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=22),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/22] for update
[2025-07-19T18:30:18.082+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.082+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.082+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.082+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a141743
[2025-07-19T18:30:18.084+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=21, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.084+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=21),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/21] for update
[2025-07-19T18:30:18.085+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/14/.1.delta.199df5ac-0e14-4e75-a10f-3e57021f4777.TID274.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/14/1.delta
[2025-07-19T18:30:18.088+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=14),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/14] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/14/1.delta
[2025-07-19T18:30:18.088+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 14 (task 274, attempt 0, stage 5.0)
[2025-07-19T18:30:18.088+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/22/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/22/.1.delta.c9325484-01d3-4cfd-902f-8269ef7aa474.TID280.tmp
[2025-07-19T18:30:18.092+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.093+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO MicroBatchExecution: Streaming query made progress: {
[2025-07-19T18:30:18.094+0000] {subprocess.py:93} INFO -   "id" : "987ca175-704b-42a6-8146-d1b15494abbf",
[2025-07-19T18:30:18.095+0000] {subprocess.py:93} INFO -   "runId" : "e7c2576d-5139-486e-a3a4-0d60a8d676b4",
[2025-07-19T18:30:18.096+0000] {subprocess.py:93} INFO -   "name" : null,
[2025-07-19T18:30:18.097+0000] {subprocess.py:93} INFO -   "timestamp" : "2025-07-19T18:30:10.773Z",
[2025-07-19T18:30:18.098+0000] {subprocess.py:93} INFO -   "batchId" : 0,
[2025-07-19T18:30:18.098+0000] {subprocess.py:93} INFO -   "numInputRows" : 69,
[2025-07-19T18:30:18.099+0000] {subprocess.py:93} INFO -   "inputRowsPerSecond" : 0.0,
[2025-07-19T18:30:18.099+0000] {subprocess.py:93} INFO -   "processedRowsPerSecond" : 9.518554283349427,
[2025-07-19T18:30:18.099+0000] {subprocess.py:93} INFO -   "durationMs" : {
[2025-07-19T18:30:18.099+0000] {subprocess.py:93} INFO -     "addBatch" : 6459,
[2025-07-19T18:30:18.099+0000] {subprocess.py:93} INFO -     "commitOffsets" : 61,
[2025-07-19T18:30:18.099+0000] {subprocess.py:93} INFO -     "getBatch" : 8,
[2025-07-19T18:30:18.099+0000] {subprocess.py:93} INFO -     "latestOffset" : 304,
[2025-07-19T18:30:18.099+0000] {subprocess.py:93} INFO -     "queryPlanning" : 378,
[2025-07-19T18:30:18.099+0000] {subprocess.py:93} INFO -     "triggerExecution" : 7249,
[2025-07-19T18:30:18.099+0000] {subprocess.py:93} INFO -     "walCommit" : 23
[2025-07-19T18:30:18.100+0000] {subprocess.py:93} INFO -   },
[2025-07-19T18:30:18.100+0000] {subprocess.py:93} INFO -   "eventTime" : {
[2025-07-19T18:30:18.100+0000] {subprocess.py:93} INFO -     "avg" : "2025-07-19T17:11:23.478Z",
[2025-07-19T18:30:18.100+0000] {subprocess.py:93} INFO -     "max" : "2025-07-19T18:13:00.000Z",
[2025-07-19T18:30:18.100+0000] {subprocess.py:93} INFO -     "min" : "2025-07-19T16:04:00.000Z",
[2025-07-19T18:30:18.100+0000] {subprocess.py:93} INFO -     "watermark" : "1970-01-01T00:00:00.000Z"
[2025-07-19T18:30:18.100+0000] {subprocess.py:93} INFO -   },
[2025-07-19T18:30:18.100+0000] {subprocess.py:93} INFO -   "stateOperators" : [ {
[2025-07-19T18:30:18.100+0000] {subprocess.py:93} INFO -     "operatorName" : "dedupe",
[2025-07-19T18:30:18.100+0000] {subprocess.py:93} INFO -     "numRowsTotal" : 69,
[2025-07-19T18:30:18.100+0000] {subprocess.py:93} INFO -     "numRowsUpdated" : 69,
[2025-07-19T18:30:18.101+0000] {subprocess.py:93} INFO -     "allUpdatesTimeMs" : 1439,
[2025-07-19T18:30:18.101+0000] {subprocess.py:93} INFO -     "numRowsRemoved" : 0,
[2025-07-19T18:30:18.101+0000] {subprocess.py:93} INFO -     "allRemovalsTimeMs" : 207,
[2025-07-19T18:30:18.101+0000] {subprocess.py:93} INFO -     "commitTimeMs" : 11295,
[2025-07-19T18:30:18.101+0000] {subprocess.py:93} INFO -     "memoryUsedBytes" : 65416,
[2025-07-19T18:30:18.101+0000] {subprocess.py:93} INFO -     "numRowsDroppedByWatermark" : 0,
[2025-07-19T18:30:18.101+0000] {subprocess.py:93} INFO -     "numShufflePartitions" : 200,
[2025-07-19T18:30:18.101+0000] {subprocess.py:93} INFO -     "numStateStoreInstances" : 200,
[2025-07-19T18:30:18.101+0000] {subprocess.py:93} INFO -     "customMetrics" : {
[2025-07-19T18:30:18.101+0000] {subprocess.py:93} INFO -       "loadedMapCacheHitCount" : 0,
[2025-07-19T18:30:18.101+0000] {subprocess.py:93} INFO -       "loadedMapCacheMissCount" : 0,
[2025-07-19T18:30:18.102+0000] {subprocess.py:93} INFO -       "numDroppedDuplicateRows" : 0,
[2025-07-19T18:30:18.102+0000] {subprocess.py:93} INFO -       "stateOnCurrentVersionSizeBytes" : 36616
[2025-07-19T18:30:18.102+0000] {subprocess.py:93} INFO -     }
[2025-07-19T18:30:18.102+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T18:30:18.102+0000] {subprocess.py:93} INFO -   "sources" : [ {
[2025-07-19T18:30:18.102+0000] {subprocess.py:93} INFO -     "description" : "KafkaV2[Subscribe[checkins]]",
[2025-07-19T18:30:18.102+0000] {subprocess.py:93} INFO -     "startOffset" : null,
[2025-07-19T18:30:18.103+0000] {subprocess.py:93} INFO -     "endOffset" : {
[2025-07-19T18:30:18.103+0000] {subprocess.py:93} INFO -       "checkins" : {
[2025-07-19T18:30:18.106+0000] {subprocess.py:93} INFO -         "0" : 69
[2025-07-19T18:30:18.106+0000] {subprocess.py:93} INFO -       }
[2025-07-19T18:30:18.107+0000] {subprocess.py:93} INFO -     },
[2025-07-19T18:30:18.107+0000] {subprocess.py:93} INFO -     "latestOffset" : {
[2025-07-19T18:30:18.108+0000] {subprocess.py:93} INFO -       "checkins" : {
[2025-07-19T18:30:18.109+0000] {subprocess.py:93} INFO -         "0" : 69
[2025-07-19T18:30:18.109+0000] {subprocess.py:93} INFO -       }
[2025-07-19T18:30:18.110+0000] {subprocess.py:93} INFO -     },
[2025-07-19T18:30:18.110+0000] {subprocess.py:93} INFO -     "numInputRows" : 69,
[2025-07-19T18:30:18.110+0000] {subprocess.py:93} INFO -     "inputRowsPerSecond" : 0.0,
[2025-07-19T18:30:18.111+0000] {subprocess.py:93} INFO -     "processedRowsPerSecond" : 9.518554283349427,
[2025-07-19T18:30:18.111+0000] {subprocess.py:93} INFO -     "metrics" : {
[2025-07-19T18:30:18.111+0000] {subprocess.py:93} INFO -       "avgOffsetsBehindLatest" : "0.0",
[2025-07-19T18:30:18.111+0000] {subprocess.py:93} INFO -       "maxOffsetsBehindLatest" : "0",
[2025-07-19T18:30:18.112+0000] {subprocess.py:93} INFO -       "minOffsetsBehindLatest" : "0"
[2025-07-19T18:30:18.112+0000] {subprocess.py:93} INFO -     }
[2025-07-19T18:30:18.112+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T18:30:18.113+0000] {subprocess.py:93} INFO -   "sink" : {
[2025-07-19T18:30:18.113+0000] {subprocess.py:93} INFO -     "description" : "my_catalog.bronze.Checkins_raw",
[2025-07-19T18:30:18.113+0000] {subprocess.py:93} INFO -     "numOutputRows" : 69
[2025-07-19T18:30:18.113+0000] {subprocess.py:93} INFO -   }
[2025-07-19T18:30:18.114+0000] {subprocess.py:93} INFO - }
[2025-07-19T18:30:18.114+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b286952
[2025-07-19T18:30:18.114+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 14 (task 274, attempt 0, stage 5.0)
[2025-07-19T18:30:18.115+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=18, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.116+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=18),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/18] for update
[2025-07-19T18:30:18.116+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 14.0 in stage 5.0 (TID 274). 6200 bytes result sent to driver
[2025-07-19T18:30:18.116+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 25.0 in stage 5.0 (TID 282) (8b44f3d35cfa, executor driver, partition 25, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.117+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/20/.1.delta.44cb8d76-ca73-4f8b-b339-211d6e5615a5.TID278.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/20/1.delta
[2025-07-19T18:30:18.119+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.119+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 25.0 in stage 5.0 (TID 282)
[2025-07-19T18:30:18.120+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=20),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/20] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/20/1.delta
[2025-07-19T18:30:18.120+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 20 (task 278, attempt 0, stage 5.0)
[2025-07-19T18:30:18.120+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 14.0 in stage 5.0 (TID 274) in 71 ms on 8b44f3d35cfa (executor driver) (64/200)
[2025-07-19T18:30:18.121+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.121+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.121+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e880b59
[2025-07-19T18:30:18.122+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 20 (task 278, attempt 0, stage 5.0)
[2025-07-19T18:30:18.122+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=24, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.123+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=24),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/24] for update
[2025-07-19T18:30:18.123+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 20.0 in stage 5.0 (TID 278). 6200 bytes result sent to driver
[2025-07-19T18:30:18.124+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 27.0 in stage 5.0 (TID 283) (8b44f3d35cfa, executor driver, partition 27, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.124+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 20.0 in stage 5.0 (TID 278) in 64 ms on 8b44f3d35cfa (executor driver) (65/200)
[2025-07-19T18:30:18.124+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 27.0 in stage 5.0 (TID 283)
[2025-07-19T18:30:18.125+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/21/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/21/.1.delta.417dbabd-d015-4e8c-8a30-e0b669e6df6b.TID279.tmp
[2025-07-19T18:30:18.126+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.127+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.128+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.130+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19b35399
[2025-07-19T18:30:18.130+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=25, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.133+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=25),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/25] for update
[2025-07-19T18:30:18.133+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.133+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/18/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/18/.1.delta.2c066717-560e-46c6-8cd6-5fd9c1edc042.TID276.tmp
[2025-07-19T18:30:18.133+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/offsets/1 using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/offsets/.1.c7136364-a5ae-4edc-89d6-2b2cb99d1a6b.tmp
[2025-07-19T18:30:18.134+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/19/.1.delta.75584227-8bc4-4006-b0f1-c58135dc0943.TID277.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/19/1.delta
[2025-07-19T18:30:18.134+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=19),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/19] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/19/1.delta
[2025-07-19T18:30:18.135+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/17/.1.delta.e0a7ce2e-3c88-416b-95dc-d1416c25c4d8.TID275.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/17/1.delta
[2025-07-19T18:30:18.136+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=17),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/17] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/17/1.delta
[2025-07-19T18:30:18.136+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 19 (task 277, attempt 0, stage 5.0)
[2025-07-19T18:30:18.137+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 17 (task 275, attempt 0, stage 5.0)
[2025-07-19T18:30:18.138+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5cdce521
[2025-07-19T18:30:18.139+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=27, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.139+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=27),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/27] for update
[2025-07-19T18:30:18.140+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.141+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 19 (task 277, attempt 0, stage 5.0)
[2025-07-19T18:30:18.143+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 19.0 in stage 5.0 (TID 277). 6200 bytes result sent to driver
[2025-07-19T18:30:18.143+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/22/.1.delta.c9325484-01d3-4cfd-902f-8269ef7aa474.TID280.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/22/1.delta
[2025-07-19T18:30:18.144+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=22),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/22] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/22/1.delta
[2025-07-19T18:30:18.144+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 22 (task 280, attempt 0, stage 5.0)
[2025-07-19T18:30:18.146+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 17 (task 275, attempt 0, stage 5.0)
[2025-07-19T18:30:18.146+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 29.0 in stage 5.0 (TID 284) (8b44f3d35cfa, executor driver, partition 29, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.147+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/25/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/25/.1.delta.311148ec-95b4-456a-be05-2a15b79bd29b.TID282.tmp
[2025-07-19T18:30:18.147+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 17.0 in stage 5.0 (TID 275). 6200 bytes result sent to driver
[2025-07-19T18:30:18.148+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/24/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/24/.1.delta.55bbc27c-4fc8-4a8e-b59d-e20802bc5910.TID281.tmp
[2025-07-19T18:30:18.148+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 29.0 in stage 5.0 (TID 284)
[2025-07-19T18:30:18.149+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 31.0 in stage 5.0 (TID 285) (8b44f3d35cfa, executor driver, partition 31, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.151+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.151+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.153+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 19.0 in stage 5.0 (TID 277) in 96 ms on 8b44f3d35cfa (executor driver) (66/200)
[2025-07-19T18:30:18.153+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 17.0 in stage 5.0 (TID 275) in 105 ms on 8b44f3d35cfa (executor driver) (67/200)
[2025-07-19T18:30:18.153+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 31.0 in stage 5.0 (TID 285)
[2025-07-19T18:30:18.154+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.154+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.154+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 22 (task 280, attempt 0, stage 5.0)
[2025-07-19T18:30:18.154+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/27/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/27/.1.delta.6ae827e9-5464-4fed-9f85-bf4be01104f9.TID283.tmp
[2025-07-19T18:30:18.155+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 22.0 in stage 5.0 (TID 280). 6200 bytes result sent to driver
[2025-07-19T18:30:18.155+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@16544d71
[2025-07-19T18:30:18.155+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 32.0 in stage 5.0 (TID 286) (8b44f3d35cfa, executor driver, partition 32, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.155+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 22.0 in stage 5.0 (TID 280) in 78 ms on 8b44f3d35cfa (executor driver) (68/200)
[2025-07-19T18:30:18.156+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 32.0 in stage 5.0 (TID 286)
[2025-07-19T18:30:18.157+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=29, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.157+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=29),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/29] for update
[2025-07-19T18:30:18.157+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.159+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f8a4e73
[2025-07-19T18:30:18.160+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=31, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.162+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=31),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/31] for update
[2025-07-19T18:30:18.163+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.163+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.167+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.167+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/offsets/.1.c7136364-a5ae-4edc-89d6-2b2cb99d1a6b.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/offsets/1
[2025-07-19T18:30:18.167+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO MicroBatchExecution: Committed offsets for batch 1. Metadata OffsetSeqMetadata(1752775980000,1752949818100,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.optimizer.pruneFiltersCanPruneStreamingSubplan -> false, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2025-07-19T18:30:18.167+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/18/.1.delta.2c066717-560e-46c6-8cd6-5fd9c1edc042.TID276.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/18/1.delta
[2025-07-19T18:30:18.167+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=18),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/18] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/18/1.delta
[2025-07-19T18:30:18.167+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 18 (task 276, attempt 0, stage 5.0)
[2025-07-19T18:30:18.168+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5b5f64d5
[2025-07-19T18:30:18.168+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=32, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.168+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=32),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/32] for update
[2025-07-19T18:30:18.168+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/29/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/29/.1.delta.22155ac3-1f84-4b98-a09b-c98ddcac6028.TID284.tmp
[2025-07-19T18:30:18.169+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/31/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/31/.1.delta.6dc53968-56d2-4c5e-adee-4ae46e127832.TID285.tmp
[2025-07-19T18:30:18.169+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 18 (task 276, attempt 0, stage 5.0)
[2025-07-19T18:30:18.169+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.181+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 18.0 in stage 5.0 (TID 276). 6200 bytes result sent to driver
[2025-07-19T18:30:18.181+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 33.0 in stage 5.0 (TID 287) (8b44f3d35cfa, executor driver, partition 33, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.181+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 33.0 in stage 5.0 (TID 287)
[2025-07-19T18:30:18.182+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 18.0 in stage 5.0 (TID 276) in 133 ms on 8b44f3d35cfa (executor driver) (69/200)
[2025-07-19T18:30:18.182+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/21/.1.delta.417dbabd-d015-4e8c-8a30-e0b669e6df6b.TID279.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/21/1.delta
[2025-07-19T18:30:18.182+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=21),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/21] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/21/1.delta
[2025-07-19T18:30:18.182+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.182+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.183+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 21 (task 279, attempt 0, stage 5.0)
[2025-07-19T18:30:18.186+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 21 (task 279, attempt 0, stage 5.0)
[2025-07-19T18:30:18.188+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/24/.1.delta.55bbc27c-4fc8-4a8e-b59d-e20802bc5910.TID281.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/24/1.delta
[2025-07-19T18:30:18.190+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=24),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/24] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/24/1.delta
[2025-07-19T18:30:18.191+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 21.0 in stage 5.0 (TID 279). 6243 bytes result sent to driver
[2025-07-19T18:30:18.192+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28743361
[2025-07-19T18:30:18.193+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=33, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.193+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 24 (task 281, attempt 0, stage 5.0)
[2025-07-19T18:30:18.194+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=33),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/33] for update
[2025-07-19T18:30:18.195+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.196+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 34.0 in stage 5.0 (TID 288) (8b44f3d35cfa, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.197+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 21.0 in stage 5.0 (TID 279) in 134 ms on 8b44f3d35cfa (executor driver) (70/200)
[2025-07-19T18:30:18.198+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 34.0 in stage 5.0 (TID 288)
[2025-07-19T18:30:18.199+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/25/.1.delta.311148ec-95b4-456a-be05-2a15b79bd29b.TID282.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/25/1.delta
[2025-07-19T18:30:18.200+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=25),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/25] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/25/1.delta
[2025-07-19T18:30:18.201+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 25 (task 282, attempt 0, stage 5.0)
[2025-07-19T18:30:18.202+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/32/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/32/.1.delta.165fc3b0-184a-43c6-82b8-ad921348e111.TID286.tmp
[2025-07-19T18:30:18.204+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/27/.1.delta.6ae827e9-5464-4fed-9f85-bf4be01104f9.TID283.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/27/1.delta
[2025-07-19T18:30:18.205+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=27),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/27] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/27/1.delta
[2025-07-19T18:30:18.206+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.206+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.207+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 24 (task 281, attempt 0, stage 5.0)
[2025-07-19T18:30:18.209+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 27 (task 283, attempt 0, stage 5.0)
[2025-07-19T18:30:18.210+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 24.0 in stage 5.0 (TID 281). 6243 bytes result sent to driver
[2025-07-19T18:30:18.211+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 35.0 in stage 5.0 (TID 289) (8b44f3d35cfa, executor driver, partition 35, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.212+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 25 (task 282, attempt 0, stage 5.0)
[2025-07-19T18:30:18.213+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@720e9395
[2025-07-19T18:30:18.214+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 24.0 in stage 5.0 (TID 281) in 125 ms on 8b44f3d35cfa (executor driver) (71/200)
[2025-07-19T18:30:18.215+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=34, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.216+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=34),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/34] for update
[2025-07-19T18:30:18.217+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 25.0 in stage 5.0 (TID 282). 6243 bytes result sent to driver
[2025-07-19T18:30:18.217+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 36.0 in stage 5.0 (TID 290) (8b44f3d35cfa, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.218+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 25.0 in stage 5.0 (TID 282) in 111 ms on 8b44f3d35cfa (executor driver) (72/200)
[2025-07-19T18:30:18.219+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 35.0 in stage 5.0 (TID 289)
[2025-07-19T18:30:18.221+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 36.0 in stage 5.0 (TID 290)
[2025-07-19T18:30:18.221+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.221+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 27 (task 283, attempt 0, stage 5.0)
[2025-07-19T18:30:18.221+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 27.0 in stage 5.0 (TID 283). 6243 bytes result sent to driver
[2025-07-19T18:30:18.221+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/33/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/33/.1.delta.c9fdf440-17f3-4aed-8ef5-efbe6991cabc.TID287.tmp
[2025-07-19T18:30:18.221+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.222+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:18.222+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.222+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.222+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 37.0 in stage 5.0 (TID 291) (8b44f3d35cfa, executor driver, partition 37, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.222+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Checkins_raw
[2025-07-19T18:30:18.222+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Checkins_raw
[2025-07-19T18:30:18.222+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Checkins_raw
[2025-07-19T18:30:18.222+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 27.0 in stage 5.0 (TID 283) in 107 ms on 8b44f3d35cfa (executor driver) (73/200)
[2025-07-19T18:30:18.223+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 37.0 in stage 5.0 (TID 291)
[2025-07-19T18:30:18.223+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.223+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.224+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/34/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/34/.1.delta.590c5972-d8b6-47b0-bd9b-25d801224dbe.TID288.tmp
[2025-07-19T18:30:18.225+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6846fc5b
[2025-07-19T18:30:18.226+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=36, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.228+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=36),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/36] for update
[2025-07-19T18:30:18.229+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.230+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/31/.1.delta.6dc53968-56d2-4c5e-adee-4ae46e127832.TID285.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/31/1.delta
[2025-07-19T18:30:18.230+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=31),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/31] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/31/1.delta
[2025-07-19T18:30:18.231+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 31 (task 285, attempt 0, stage 5.0)
[2025-07-19T18:30:18.232+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/29/.1.delta.22155ac3-1f84-4b98-a09b-c98ddcac6028.TID284.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/29/1.delta
[2025-07-19T18:30:18.232+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=29),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/29] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/29/1.delta
[2025-07-19T18:30:18.234+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5839ae9d
[2025-07-19T18:30:18.234+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 29 (task 284, attempt 0, stage 5.0)
[2025-07-19T18:30:18.235+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=37, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.235+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 31 (task 285, attempt 0, stage 5.0)
[2025-07-19T18:30:18.235+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=37),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/37] for update
[2025-07-19T18:30:18.236+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 31.0 in stage 5.0 (TID 285). 6243 bytes result sent to driver
[2025-07-19T18:30:18.236+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 38.0 in stage 5.0 (TID 292) (8b44f3d35cfa, executor driver, partition 38, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.236+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 38.0 in stage 5.0 (TID 292)
[2025-07-19T18:30:18.236+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 31.0 in stage 5.0 (TID 285) in 93 ms on 8b44f3d35cfa (executor driver) (74/200)
[2025-07-19T18:30:18.236+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.236+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.238+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T18:30:18.238+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Checkins_raw
[2025-07-19T18:30:18.239+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Checkins_raw
[2025-07-19T18:30:18.239+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Checkins_raw
[2025-07-19T18:30:18.239+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 29 (task 284, attempt 0, stage 5.0)
[2025-07-19T18:30:18.241+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 29.0 in stage 5.0 (TID 284). 6243 bytes result sent to driver
[2025-07-19T18:30:18.241+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/32/.1.delta.165fc3b0-184a-43c6-82b8-ad921348e111.TID286.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/32/1.delta
[2025-07-19T18:30:18.241+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=32),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/32] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/32/1.delta
[2025-07-19T18:30:18.244+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@72b51a61
[2025-07-19T18:30:18.246+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 40.0 in stage 5.0 (TID 293) (8b44f3d35cfa, executor driver, partition 40, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.248+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 32 (task 286, attempt 0, stage 5.0)
[2025-07-19T18:30:18.249+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=35, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.250+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=35),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/35] for update
[2025-07-19T18:30:18.253+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/36/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/36/.1.delta.f57aa2a0-db5a-4043-8995-23386bf3cc88.TID290.tmp
[2025-07-19T18:30:18.254+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 40.0 in stage 5.0 (TID 293)
[2025-07-19T18:30:18.255+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 32 (task 286, attempt 0, stage 5.0)
[2025-07-19T18:30:18.256+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/37/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/37/.1.delta.19519df0-3691-4eab-b461-b085e41e15bb.TID291.tmp
[2025-07-19T18:30:18.256+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 29.0 in stage 5.0 (TID 284) in 118 ms on 8b44f3d35cfa (executor driver) (75/200)
[2025-07-19T18:30:18.257+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 32.0 in stage 5.0 (TID 286). 6243 bytes result sent to driver
[2025-07-19T18:30:18.258+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 42.0 in stage 5.0 (TID 294) (8b44f3d35cfa, executor driver, partition 42, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.259+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 42.0 in stage 5.0 (TID 294)
[2025-07-19T18:30:18.260+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 32.0 in stage 5.0 (TID 286) in 110 ms on 8b44f3d35cfa (executor driver) (76/200)
[2025-07-19T18:30:18.262+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.263+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.263+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T18:30:18.264+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.265+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.266+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/33/.1.delta.c9fdf440-17f3-4aed-8ef5-efbe6991cabc.TID287.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/33/1.delta
[2025-07-19T18:30:18.266+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=33),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/33] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/33/1.delta
[2025-07-19T18:30:18.267+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 33 (task 287, attempt 0, stage 5.0)
[2025-07-19T18:30:18.268+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40bb10e5
[2025-07-19T18:30:18.269+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=38, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.270+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=38),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/38] for update
[2025-07-19T18:30:18.271+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 33 (task 287, attempt 0, stage 5.0)
[2025-07-19T18:30:18.271+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 33.0 in stage 5.0 (TID 287). 6243 bytes result sent to driver
[2025-07-19T18:30:18.271+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.272+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 43.0 in stage 5.0 (TID 295) (8b44f3d35cfa, executor driver, partition 43, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.272+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Checkins_raw
[2025-07-19T18:30:18.272+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Checkins_raw
[2025-07-19T18:30:18.273+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Checkins_raw
[2025-07-19T18:30:18.273+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 33.0 in stage 5.0 (TID 287) in 93 ms on 8b44f3d35cfa (executor driver) (77/200)
[2025-07-19T18:30:18.274+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 43.0 in stage 5.0 (TID 295)
[2025-07-19T18:30:18.275+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/35/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/35/.1.delta.777615ef-9edf-484b-9b05-dcf723d38e86.TID289.tmp
[2025-07-19T18:30:18.276+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/34/.1.delta.590c5972-d8b6-47b0-bd9b-25d801224dbe.TID288.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/34/1.delta
[2025-07-19T18:30:18.276+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=34),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/34] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/34/1.delta
[2025-07-19T18:30:18.277+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.278+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.279+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 34 (task 288, attempt 0, stage 5.0)
[2025-07-19T18:30:18.279+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52ff7ef7
[2025-07-19T18:30:18.280+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=40, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.280+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=40),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/40] for update
[2025-07-19T18:30:18.280+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 209.0 KiB, free 433.2 MiB)
[2025-07-19T18:30:18.282+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 34 (task 288, attempt 0, stage 5.0)
[2025-07-19T18:30:18.283+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 34.0 in stage 5.0 (TID 288). 6243 bytes result sent to driver
[2025-07-19T18:30:18.283+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 44.0 in stage 5.0 (TID 296) (8b44f3d35cfa, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.288+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 44.0 in stage 5.0 (TID 296)
[2025-07-19T18:30:18.289+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 34.0 in stage 5.0 (TID 288) in 93 ms on 8b44f3d35cfa (executor driver) (78/200)
[2025-07-19T18:30:18.289+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.2 MiB)
[2025-07-19T18:30:18.289+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/36/.1.delta.f57aa2a0-db5a-4043-8995-23386bf3cc88.TID290.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/36/1.delta
[2025-07-19T18:30:18.289+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=36),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/36] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/36/1.delta
[2025-07-19T18:30:18.289+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.290+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/38/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/38/.1.delta.26da5ec2-a0b7-4076-81cf-2973916983e7.TID292.tmp
[2025-07-19T18:30:18.290+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 8b44f3d35cfa:40517 (size: 35.4 KiB, free: 434.1 MiB)
[2025-07-19T18:30:18.290+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 36 (task 290, attempt 0, stage 5.0)
[2025-07-19T18:30:18.291+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/37/.1.delta.19519df0-3691-4eab-b461-b085e41e15bb.TID291.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/37/1.delta
[2025-07-19T18:30:18.292+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=37),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/37] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/37/1.delta
[2025-07-19T18:30:18.294+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 36 (task 290, attempt 0, stage 5.0)
[2025-07-19T18:30:18.296+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 37 (task 291, attempt 0, stage 5.0)
[2025-07-19T18:30:18.297+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO SparkContext: Created broadcast 12 from start at <unknown>:0
[2025-07-19T18:30:18.298+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@9570a4d
[2025-07-19T18:30:18.299+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 36.0 in stage 5.0 (TID 290). 6243 bytes result sent to driver
[2025-07-19T18:30:18.300+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=42, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.301+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=42),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/42] for update
[2025-07-19T18:30:18.302+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 32.0 KiB, free 433.1 MiB)
[2025-07-19T18:30:18.302+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 45.0 in stage 5.0 (TID 297) (8b44f3d35cfa, executor driver, partition 45, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.303+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 36.0 in stage 5.0 (TID 290) in 91 ms on 8b44f3d35cfa (executor driver) (79/200)
[2025-07-19T18:30:18.304+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 45.0 in stage 5.0 (TID 297)
[2025-07-19T18:30:18.305+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/35/.1.delta.777615ef-9edf-484b-9b05-dcf723d38e86.TID289.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/35/1.delta
[2025-07-19T18:30:18.305+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=35),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/35] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/35/1.delta
[2025-07-19T18:30:18.306+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 433.1 MiB)
[2025-07-19T18:30:18.307+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.308+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 37 (task 291, attempt 0, stage 5.0)
[2025-07-19T18:30:18.309+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.309+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 8b44f3d35cfa:40517 (size: 29.5 KiB, free: 434.1 MiB)
[2025-07-19T18:30:18.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 37.0 in stage 5.0 (TID 291). 6243 bytes result sent to driver
[2025-07-19T18:30:18.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:18.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/40/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/40/.1.delta.00ad5293-60cd-4091-858b-12ecd52667b1.TID293.tmp
[2025-07-19T18:30:18.311+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 35 (task 289, attempt 0, stage 5.0)
[2025-07-19T18:30:18.311+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 46.0 in stage 5.0 (TID 298) (8b44f3d35cfa, executor driver, partition 46, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.311+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.311+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO SparkContext: Created broadcast 13 from start at <unknown>:0
[2025-07-19T18:30:18.311+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO WriteToDataSourceV2Exec: Start processing data source write support: MicroBatchWrite[epoch: 1, writer: IcebergStreamingWrite(table=my_catalog.bronze.Checkins_raw, format=PARQUET)]. The input RDD has 200 partitions.
[2025-07-19T18:30:18.312+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 46.0 in stage 5.0 (TID 298)
[2025-07-19T18:30:18.312+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 37.0 in stage 5.0 (TID 291) in 91 ms on 8b44f3d35cfa (executor driver) (80/200)
[2025-07-19T18:30:18.312+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7ea7ee36
[2025-07-19T18:30:18.312+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=43, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.312+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=43),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/43] for update
[2025-07-19T18:30:18.313+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.314+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO SparkContext: Starting job: start at <unknown>:0
[2025-07-19T18:30:18.315+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.316+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.316+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DAGScheduler: Registering RDD 27 (start at <unknown>:0) as input to shuffle 3
[2025-07-19T18:30:18.316+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DAGScheduler: Got job 3 (start at <unknown>:0) with 200 output partitions
[2025-07-19T18:30:18.317+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DAGScheduler: Final stage: ResultStage 7 (start at <unknown>:0)
[2025-07-19T18:30:18.318+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
[2025-07-19T18:30:18.319+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 35 (task 289, attempt 0, stage 5.0)
[2025-07-19T18:30:18.320+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DAGScheduler: Missing parents: List()
[2025-07-19T18:30:18.321+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/42/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/42/.1.delta.11df0833-2288-45e3-8c17-d0b21230e848.TID294.tmp
[2025-07-19T18:30:18.321+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DAGScheduler: Submitting ResultStage 7 (StateStoreRDD[29] at start at <unknown>:0), which has no missing parents
[2025-07-19T18:30:18.321+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ee5fcc8
[2025-07-19T18:30:18.322+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/43/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/43/.1.delta.90c6728d-8684-4daa-88ca-9c1c8c2a6043.TID295.tmp
[2025-07-19T18:30:18.322+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=45, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.323+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 35.0 in stage 5.0 (TID 289). 6243 bytes result sent to driver
[2025-07-19T18:30:18.325+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 35.0 in stage 5.0 (TID 289) in 114 ms on 8b44f3d35cfa (executor driver) (81/200)
[2025-07-19T18:30:18.327+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 47.0 in stage 5.0 (TID 299) (8b44f3d35cfa, executor driver, partition 47, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.328+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=45),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/45] for update
[2025-07-19T18:30:18.329+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 47.0 in stage 5.0 (TID 299)
[2025-07-19T18:30:18.330+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.330+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.331+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.332+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/38/.1.delta.26da5ec2-a0b7-4076-81cf-2973916983e7.TID292.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/38/1.delta
[2025-07-19T18:30:18.332+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=38),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/38] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/38/1.delta
[2025-07-19T18:30:18.333+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 38 (task 292, attempt 0, stage 5.0)
[2025-07-19T18:30:18.333+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c986fee
[2025-07-19T18:30:18.334+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/45/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/45/.1.delta.cfd19f35-96f5-441e-8c00-d66d7210343b.TID297.tmp
[2025-07-19T18:30:18.334+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=44, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.335+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=44),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/44] for update
[2025-07-19T18:30:18.336+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.337+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 38 (task 292, attempt 0, stage 5.0)
[2025-07-19T18:30:18.337+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 38.0 in stage 5.0 (TID 292). 6243 bytes result sent to driver
[2025-07-19T18:30:18.338+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 48.0 in stage 5.0 (TID 300) (8b44f3d35cfa, executor driver, partition 48, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.339+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 38.0 in stage 5.0 (TID 292) in 102 ms on 8b44f3d35cfa (executor driver) (82/200)
[2025-07-19T18:30:18.339+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 48.0 in stage 5.0 (TID 300)
[2025-07-19T18:30:18.340+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.340+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.341+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/40/.1.delta.00ad5293-60cd-4091-858b-12ecd52667b1.TID293.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/40/1.delta
[2025-07-19T18:30:18.341+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=40),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/40] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/40/1.delta
[2025-07-19T18:30:18.342+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 40 (task 293, attempt 0, stage 5.0)
[2025-07-19T18:30:18.343+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d81f610
[2025-07-19T18:30:18.343+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=47, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.343+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=47),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/47] for update
[2025-07-19T18:30:18.344+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/44/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/44/.1.delta.01a77b5f-c549-4723-9e49-fd4a9685ee56.TID296.tmp
[2025-07-19T18:30:18.344+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.344+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 40 (task 293, attempt 0, stage 5.0)
[2025-07-19T18:30:18.345+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 40.0 in stage 5.0 (TID 293). 6200 bytes result sent to driver
[2025-07-19T18:30:18.345+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@797b992f
[2025-07-19T18:30:18.346+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 49.0 in stage 5.0 (TID 301) (8b44f3d35cfa, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.346+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 40.0 in stage 5.0 (TID 293) in 100 ms on 8b44f3d35cfa (executor driver) (83/200)
[2025-07-19T18:30:18.347+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/43/.1.delta.90c6728d-8684-4daa-88ca-9c1c8c2a6043.TID295.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/43/1.delta
[2025-07-19T18:30:18.347+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=43),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/43] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/43/1.delta
[2025-07-19T18:30:18.347+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 49.0 in stage 5.0 (TID 301)
[2025-07-19T18:30:18.348+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/42/.1.delta.11df0833-2288-45e3-8c17-d0b21230e848.TID294.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/42/1.delta
[2025-07-19T18:30:18.348+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=42),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/42] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/42/1.delta
[2025-07-19T18:30:18.349+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/47/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/47/.1.delta.ba3a0cd7-3468-4bbc-b008-d532b77ac5b6.TID299.tmp
[2025-07-19T18:30:18.349+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.350+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=46, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.350+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=46),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/46] for update
[2025-07-19T18:30:18.352+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.353+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 43 (task 295, attempt 0, stage 5.0)
[2025-07-19T18:30:18.354+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.355+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 42 (task 294, attempt 0, stage 5.0)
[2025-07-19T18:30:18.356+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@422bbaab
[2025-07-19T18:30:18.357+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=48, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.358+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=48),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/48] for update
[2025-07-19T18:30:18.359+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/45/.1.delta.cfd19f35-96f5-441e-8c00-d66d7210343b.TID297.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/45/1.delta
[2025-07-19T18:30:18.359+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=45),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/45] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/45/1.delta
[2025-07-19T18:30:18.360+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.361+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 43 (task 295, attempt 0, stage 5.0)
[2025-07-19T18:30:18.362+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 45 (task 297, attempt 0, stage 5.0)
[2025-07-19T18:30:18.362+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 42 (task 294, attempt 0, stage 5.0)
[2025-07-19T18:30:18.363+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 42.0 in stage 5.0 (TID 294). 6200 bytes result sent to driver
[2025-07-19T18:30:18.365+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 50.0 in stage 5.0 (TID 302) (8b44f3d35cfa, executor driver, partition 50, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.366+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 50.0 in stage 5.0 (TID 302)
[2025-07-19T18:30:18.366+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6b9a8b83
[2025-07-19T18:30:18.366+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.367+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.368+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 43.0 in stage 5.0 (TID 295). 6200 bytes result sent to driver
[2025-07-19T18:30:18.368+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 42.0 in stage 5.0 (TID 294) in 106 ms on 8b44f3d35cfa (executor driver) (84/200)
[2025-07-19T18:30:18.369+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 45 (task 297, attempt 0, stage 5.0)
[2025-07-19T18:30:18.369+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=49, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.370+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=49),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/49] for update
[2025-07-19T18:30:18.371+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 45.0 in stage 5.0 (TID 297). 6200 bytes result sent to driver
[2025-07-19T18:30:18.371+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 51.0 in stage 5.0 (TID 303) (8b44f3d35cfa, executor driver, partition 51, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.372+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 51.0 in stage 5.0 (TID 303)
[2025-07-19T18:30:18.372+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.372+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.372+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.372+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3bd90a82
[2025-07-19T18:30:18.372+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 52.0 in stage 5.0 (TID 304) (8b44f3d35cfa, executor driver, partition 52, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.372+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=50, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.372+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=50),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/50] for update
[2025-07-19T18:30:18.372+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 52.0 in stage 5.0 (TID 304)
[2025-07-19T18:30:18.372+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/48/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/48/.1.delta.fc0a1621-0d04-4454-b04b-152de3f6f25f.TID300.tmp
[2025-07-19T18:30:18.373+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/46/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/46/.1.delta.b0e19808-6fa9-4be1-a48d-68f5d8a5b000.TID298.tmp
[2025-07-19T18:30:18.373+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 43.0 in stage 5.0 (TID 295) in 103 ms on 8b44f3d35cfa (executor driver) (85/200)
[2025-07-19T18:30:18.373+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.373+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 45.0 in stage 5.0 (TID 297) in 73 ms on 8b44f3d35cfa (executor driver) (86/200)
[2025-07-19T18:30:18.373+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/49/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/49/.1.delta.aae4580f-6f92-43d4-8c43-86d140d8473e.TID301.tmp
[2025-07-19T18:30:18.373+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55616c7b
[2025-07-19T18:30:18.373+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=51, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.373+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=51),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/51] for update
[2025-07-19T18:30:18.373+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.373+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 32.0 KiB, free 433.1 MiB)
[2025-07-19T18:30:18.374+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.374+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 15.9 KiB, free 433.0 MiB)
[2025-07-19T18:30:18.374+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 8b44f3d35cfa:40517 (size: 15.9 KiB, free: 434.1 MiB)
[2025-07-19T18:30:18.374+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.378+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1611
[2025-07-19T18:30:18.382+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3fd8aa0f
[2025-07-19T18:30:18.383+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 7 (StateStoreRDD[29] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-07-19T18:30:18.384+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSchedulerImpl: Adding task set 7.0 with 200 tasks resource profile 0
[2025-07-19T18:30:18.384+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=52, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.384+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=52),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/52] for update
[2025-07-19T18:30:18.384+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.392+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/44/.1.delta.01a77b5f-c549-4723-9e49-fd4a9685ee56.TID296.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/44/1.delta
[2025-07-19T18:30:18.392+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=44),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/44] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/44/1.delta
[2025-07-19T18:30:18.393+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 44 (task 296, attempt 0, stage 5.0)
[2025-07-19T18:30:18.402+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 44 (task 296, attempt 0, stage 5.0)
[2025-07-19T18:30:18.403+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/47/.1.delta.ba3a0cd7-3468-4bbc-b008-d532b77ac5b6.TID299.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/47/1.delta
[2025-07-19T18:30:18.403+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=47),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/47] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/47/1.delta
[2025-07-19T18:30:18.404+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 47 (task 299, attempt 0, stage 5.0)
[2025-07-19T18:30:18.405+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/51/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/51/.1.delta.d09bf60d-68fe-42f2-8165-c7a003e2a7a9.TID303.tmp
[2025-07-19T18:30:18.406+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/50/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/50/.1.delta.79b974ca-f90c-432b-ae07-686280919eb8.TID302.tmp
[2025-07-19T18:30:18.411+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 47 (task 299, attempt 0, stage 5.0)
[2025-07-19T18:30:18.412+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 47.0 in stage 5.0 (TID 299). 6243 bytes result sent to driver
[2025-07-19T18:30:18.412+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 44.0 in stage 5.0 (TID 296). 6243 bytes result sent to driver
[2025-07-19T18:30:18.412+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/52/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/52/.1.delta.d79b6c88-f2c3-4489-a001-daf1d0dfa299.TID304.tmp
[2025-07-19T18:30:18.413+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 53.0 in stage 5.0 (TID 305) (8b44f3d35cfa, executor driver, partition 53, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.413+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 53.0 in stage 5.0 (TID 305)
[2025-07-19T18:30:18.414+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.414+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.415+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 54.0 in stage 5.0 (TID 306) (8b44f3d35cfa, executor driver, partition 54, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.415+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 47.0 in stage 5.0 (TID 299) in 100 ms on 8b44f3d35cfa (executor driver) (87/200)
[2025-07-19T18:30:18.416+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 44.0 in stage 5.0 (TID 296) in 132 ms on 8b44f3d35cfa (executor driver) (88/200)
[2025-07-19T18:30:18.419+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 54.0 in stage 5.0 (TID 306)
[2025-07-19T18:30:18.422+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4625fcf8
[2025-07-19T18:30:18.423+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=53, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.424+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=53),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/53] for update
[2025-07-19T18:30:18.425+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.425+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.433+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/48/.1.delta.fc0a1621-0d04-4454-b04b-152de3f6f25f.TID300.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/48/1.delta
[2025-07-19T18:30:18.434+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=48),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/48] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/48/1.delta
[2025-07-19T18:30:18.434+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 48 (task 300, attempt 0, stage 5.0)
[2025-07-19T18:30:18.435+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.436+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/46/.1.delta.b0e19808-6fa9-4be1-a48d-68f5d8a5b000.TID298.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/46/1.delta
[2025-07-19T18:30:18.437+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=46),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/46] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/46/1.delta
[2025-07-19T18:30:18.437+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 46 (task 298, attempt 0, stage 5.0)
[2025-07-19T18:30:18.438+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 8b44f3d35cfa:40517 in memory (size: 35.4 KiB, free: 434.1 MiB)
[2025-07-19T18:30:18.438+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4178186b
[2025-07-19T18:30:18.439+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 48 (task 300, attempt 0, stage 5.0)
[2025-07-19T18:30:18.439+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=54, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.440+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 48.0 in stage 5.0 (TID 300). 6243 bytes result sent to driver
[2025-07-19T18:30:18.440+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=54),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/54] for update
[2025-07-19T18:30:18.441+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 55.0 in stage 5.0 (TID 307) (8b44f3d35cfa, executor driver, partition 55, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.445+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 46 (task 298, attempt 0, stage 5.0)
[2025-07-19T18:30:18.446+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 46.0 in stage 5.0 (TID 298). 6243 bytes result sent to driver
[2025-07-19T18:30:18.446+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 56.0 in stage 5.0 (TID 308) (8b44f3d35cfa, executor driver, partition 56, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.447+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 55.0 in stage 5.0 (TID 307)
[2025-07-19T18:30:18.447+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.448+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 48.0 in stage 5.0 (TID 300) in 113 ms on 8b44f3d35cfa (executor driver) (89/200)
[2025-07-19T18:30:18.449+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 46.0 in stage 5.0 (TID 298) in 145 ms on 8b44f3d35cfa (executor driver) (90/200)
[2025-07-19T18:30:18.450+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 56.0 in stage 5.0 (TID 308)
[2025-07-19T18:30:18.451+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/53/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/53/.1.delta.3fc78d7f-d407-4b42-879e-44214ed42e76.TID305.tmp
[2025-07-19T18:30:18.451+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.451+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.452+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.452+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.453+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/49/.1.delta.aae4580f-6f92-43d4-8c43-86d140d8473e.TID301.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/49/1.delta
[2025-07-19T18:30:18.453+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=49),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/49] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/49/1.delta
[2025-07-19T18:30:18.453+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 49 (task 301, attempt 0, stage 5.0)
[2025-07-19T18:30:18.457+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 49 (task 301, attempt 0, stage 5.0)
[2025-07-19T18:30:18.458+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 49.0 in stage 5.0 (TID 301). 6243 bytes result sent to driver
[2025-07-19T18:30:18.458+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 57.0 in stage 5.0 (TID 309) (8b44f3d35cfa, executor driver, partition 57, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.459+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 8b44f3d35cfa:40517 in memory (size: 29.6 KiB, free: 434.2 MiB)
[2025-07-19T18:30:18.460+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 57.0 in stage 5.0 (TID 309)
[2025-07-19T18:30:18.462+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 49.0 in stage 5.0 (TID 301) in 118 ms on 8b44f3d35cfa (executor driver) (91/200)
[2025-07-19T18:30:18.462+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b54ffd6
[2025-07-19T18:30:18.462+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=56, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.463+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=56),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/56] for update
[2025-07-19T18:30:18.463+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.463+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.464+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.467+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/50/.1.delta.79b974ca-f90c-432b-ae07-686280919eb8.TID302.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/50/1.delta
[2025-07-19T18:30:18.468+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=50),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/50] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/50/1.delta
[2025-07-19T18:30:18.468+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/54/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/54/.1.delta.b5049e5c-dd70-4ead-bfdc-f7eb1d140426.TID306.tmp
[2025-07-19T18:30:18.472+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 50 (task 302, attempt 0, stage 5.0)
[2025-07-19T18:30:18.472+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@699305bf
[2025-07-19T18:30:18.473+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=55, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.473+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=55),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/55] for update
[2025-07-19T18:30:18.474+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.475+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/52/.1.delta.d79b6c88-f2c3-4489-a001-daf1d0dfa299.TID304.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/52/1.delta
[2025-07-19T18:30:18.475+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 50 (task 302, attempt 0, stage 5.0)
[2025-07-19T18:30:18.475+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=52),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/52] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/52/1.delta
[2025-07-19T18:30:18.476+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 52 (task 304, attempt 0, stage 5.0)
[2025-07-19T18:30:18.478+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 50.0 in stage 5.0 (TID 302). 6286 bytes result sent to driver
[2025-07-19T18:30:18.480+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 52 (task 304, attempt 0, stage 5.0)
[2025-07-19T18:30:18.480+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 52.0 in stage 5.0 (TID 304). 6243 bytes result sent to driver
[2025-07-19T18:30:18.482+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 58.0 in stage 5.0 (TID 310) (8b44f3d35cfa, executor driver, partition 58, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.483+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 58.0 in stage 5.0 (TID 310)
[2025-07-19T18:30:18.484+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 50.0 in stage 5.0 (TID 302) in 128 ms on 8b44f3d35cfa (executor driver) (92/200)
[2025-07-19T18:30:18.485+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/51/.1.delta.d09bf60d-68fe-42f2-8165-c7a003e2a7a9.TID303.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/51/1.delta
[2025-07-19T18:30:18.486+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=51),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/51] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/51/1.delta
[2025-07-19T18:30:18.487+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 51 (task 303, attempt 0, stage 5.0)
[2025-07-19T18:30:18.487+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/56/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/56/.1.delta.969416fe-d967-4d7c-b2c1-4645c1d7b176.TID308.tmp
[2025-07-19T18:30:18.488+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d6947b3
[2025-07-19T18:30:18.488+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.488+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.489+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 59.0 in stage 5.0 (TID 311) (8b44f3d35cfa, executor driver, partition 59, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.489+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 59.0 in stage 5.0 (TID 311)
[2025-07-19T18:30:18.490+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 52.0 in stage 5.0 (TID 304) in 126 ms on 8b44f3d35cfa (executor driver) (93/200)
[2025-07-19T18:30:18.490+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=57, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.491+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=57),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/57] for update
[2025-07-19T18:30:18.491+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/55/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/55/.1.delta.7370745a-3d88-4167-bf7f-e2ac91906636.TID307.tmp
[2025-07-19T18:30:18.491+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.493+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.494+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.496+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 51 (task 303, attempt 0, stage 5.0)
[2025-07-19T18:30:18.496+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 51.0 in stage 5.0 (TID 303). 6243 bytes result sent to driver
[2025-07-19T18:30:18.497+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/53/.1.delta.3fc78d7f-d407-4b42-879e-44214ed42e76.TID305.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/53/1.delta
[2025-07-19T18:30:18.497+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=53),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/53] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/53/1.delta
[2025-07-19T18:30:18.498+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 53 (task 305, attempt 0, stage 5.0)
[2025-07-19T18:30:18.498+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 61.0 in stage 5.0 (TID 312) (8b44f3d35cfa, executor driver, partition 61, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.499+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 51.0 in stage 5.0 (TID 303) in 140 ms on 8b44f3d35cfa (executor driver) (94/200)
[2025-07-19T18:30:18.499+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 61.0 in stage 5.0 (TID 312)
[2025-07-19T18:30:18.500+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63fb19ce
[2025-07-19T18:30:18.503+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=59, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.504+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/57/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/57/.1.delta.da215021-d98d-45f1-ace4-60953edfa316.TID309.tmp
[2025-07-19T18:30:18.504+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=59),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/59] for update
[2025-07-19T18:30:18.505+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.505+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.505+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.506+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 53 (task 305, attempt 0, stage 5.0)
[2025-07-19T18:30:18.506+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 53.0 in stage 5.0 (TID 305). 6200 bytes result sent to driver
[2025-07-19T18:30:18.507+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 62.0 in stage 5.0 (TID 313) (8b44f3d35cfa, executor driver, partition 62, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.508+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 53.0 in stage 5.0 (TID 305) in 96 ms on 8b44f3d35cfa (executor driver) (95/200)
[2025-07-19T18:30:18.510+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 62.0 in stage 5.0 (TID 313)
[2025-07-19T18:30:18.510+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d392fc4
[2025-07-19T18:30:18.511+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=58, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.511+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=58),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/58] for update
[2025-07-19T18:30:18.512+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.513+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/59/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/59/.1.delta.f0e4ddb3-6538-4cea-a8fa-1cf5742c6e7f.TID311.tmp
[2025-07-19T18:30:18.516+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.517+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.519+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/54/.1.delta.b5049e5c-dd70-4ead-bfdc-f7eb1d140426.TID306.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/54/1.delta
[2025-07-19T18:30:18.519+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=54),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/54] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/54/1.delta
[2025-07-19T18:30:18.520+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 54 (task 306, attempt 0, stage 5.0)
[2025-07-19T18:30:18.522+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6aae7720
[2025-07-19T18:30:18.523+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=61, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.523+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=61),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/61] for update
[2025-07-19T18:30:18.523+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.526+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 54 (task 306, attempt 0, stage 5.0)
[2025-07-19T18:30:18.527+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 54.0 in stage 5.0 (TID 306). 6200 bytes result sent to driver
[2025-07-19T18:30:18.530+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@732d0d31
[2025-07-19T18:30:18.531+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/55/.1.delta.7370745a-3d88-4167-bf7f-e2ac91906636.TID307.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/55/1.delta
[2025-07-19T18:30:18.531+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=55),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/55] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/55/1.delta
[2025-07-19T18:30:18.532+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=62, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.533+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=62),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/62] for update
[2025-07-19T18:30:18.533+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 55 (task 307, attempt 0, stage 5.0)
[2025-07-19T18:30:18.533+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.533+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/58/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/58/.1.delta.236a815c-6a20-4768-8fbc-e78b6a801535.TID310.tmp
[2025-07-19T18:30:18.533+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 63.0 in stage 5.0 (TID 314) (8b44f3d35cfa, executor driver, partition 63, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.534+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/56/.1.delta.969416fe-d967-4d7c-b2c1-4645c1d7b176.TID308.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/56/1.delta
[2025-07-19T18:30:18.534+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=56),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/56] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/56/1.delta
[2025-07-19T18:30:18.534+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 63.0 in stage 5.0 (TID 314)
[2025-07-19T18:30:18.535+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 56 (task 308, attempt 0, stage 5.0)
[2025-07-19T18:30:18.535+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 54.0 in stage 5.0 (TID 306) in 120 ms on 8b44f3d35cfa (executor driver) (96/200)
[2025-07-19T18:30:18.536+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 55 (task 307, attempt 0, stage 5.0)
[2025-07-19T18:30:18.537+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 55.0 in stage 5.0 (TID 307). 6200 bytes result sent to driver
[2025-07-19T18:30:18.538+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 55.0 in stage 5.0 (TID 307) in 98 ms on 8b44f3d35cfa (executor driver) (97/200)
[2025-07-19T18:30:18.539+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/61/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/61/.1.delta.e7fce06f-67e6-446e-83bf-a031a6fc25ba.TID312.tmp
[2025-07-19T18:30:18.539+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 64.0 in stage 5.0 (TID 315) (8b44f3d35cfa, executor driver, partition 64, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.540+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 64.0 in stage 5.0 (TID 315)
[2025-07-19T18:30:18.542+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.542+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.543+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.543+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.544+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/57/.1.delta.da215021-d98d-45f1-ace4-60953edfa316.TID309.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/57/1.delta
[2025-07-19T18:30:18.545+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=57),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/57] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/57/1.delta
[2025-07-19T18:30:18.546+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 57 (task 309, attempt 0, stage 5.0)
[2025-07-19T18:30:18.546+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 56 (task 308, attempt 0, stage 5.0)
[2025-07-19T18:30:18.546+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 56.0 in stage 5.0 (TID 308). 6200 bytes result sent to driver
[2025-07-19T18:30:18.547+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 57 (task 309, attempt 0, stage 5.0)
[2025-07-19T18:30:18.547+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 65.0 in stage 5.0 (TID 316) (8b44f3d35cfa, executor driver, partition 65, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.548+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 57.0 in stage 5.0 (TID 309). 6200 bytes result sent to driver
[2025-07-19T18:30:18.548+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 56.0 in stage 5.0 (TID 308) in 103 ms on 8b44f3d35cfa (executor driver) (98/200)
[2025-07-19T18:30:18.549+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 68.0 in stage 5.0 (TID 317) (8b44f3d35cfa, executor driver, partition 68, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.549+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 57.0 in stage 5.0 (TID 309) in 91 ms on 8b44f3d35cfa (executor driver) (99/200)
[2025-07-19T18:30:18.549+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 68.0 in stage 5.0 (TID 317)
[2025-07-19T18:30:18.550+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.550+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 65.0 in stage 5.0 (TID 316)
[2025-07-19T18:30:18.551+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.552+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.552+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.553+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68f54cd5
[2025-07-19T18:30:18.554+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=63, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.556+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=63),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/63] for update
[2025-07-19T18:30:18.556+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/62/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/62/.1.delta.c4fb7a5c-f57f-4b84-8724-1893f2dca99a.TID313.tmp
[2025-07-19T18:30:18.557+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/59/.1.delta.f0e4ddb3-6538-4cea-a8fa-1cf5742c6e7f.TID311.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/59/1.delta
[2025-07-19T18:30:18.557+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=59),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/59] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/59/1.delta
[2025-07-19T18:30:18.558+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 59 (task 311, attempt 0, stage 5.0)
[2025-07-19T18:30:18.558+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.563+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 59 (task 311, attempt 0, stage 5.0)
[2025-07-19T18:30:18.564+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@788528c5
[2025-07-19T18:30:18.564+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 59.0 in stage 5.0 (TID 311). 6200 bytes result sent to driver
[2025-07-19T18:30:18.565+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=65, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.566+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=65),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/65] for update
[2025-07-19T18:30:18.567+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 69.0 in stage 5.0 (TID 318) (8b44f3d35cfa, executor driver, partition 69, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.568+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 69.0 in stage 5.0 (TID 318)
[2025-07-19T18:30:18.569+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 59.0 in stage 5.0 (TID 311) in 78 ms on 8b44f3d35cfa (executor driver) (100/200)
[2025-07-19T18:30:18.569+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.569+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/63/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/63/.1.delta.3b9895f6-ce0d-43ee-b412-8d97c0728d59.TID314.tmp
[2025-07-19T18:30:18.570+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.570+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.570+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39a8849
[2025-07-19T18:30:18.571+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=68, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.571+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=68),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/68] for update
[2025-07-19T18:30:18.571+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.572+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/65/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/65/.1.delta.6a7978e1-e9e9-49b2-838a-9343a27e1111.TID316.tmp
[2025-07-19T18:30:18.573+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/58/.1.delta.236a815c-6a20-4768-8fbc-e78b6a801535.TID310.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/58/1.delta
[2025-07-19T18:30:18.573+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=58),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/58] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/58/1.delta
[2025-07-19T18:30:18.573+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 58 (task 310, attempt 0, stage 5.0)
[2025-07-19T18:30:18.576+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/61/.1.delta.e7fce06f-67e6-446e-83bf-a031a6fc25ba.TID312.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/61/1.delta
[2025-07-19T18:30:18.577+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7efd46b1
[2025-07-19T18:30:18.577+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=61),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/61] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/61/1.delta
[2025-07-19T18:30:18.578+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 58 (task 310, attempt 0, stage 5.0)
[2025-07-19T18:30:18.579+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/68/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/68/.1.delta.9bc7cbc6-6862-4a15-b5f7-22f66b04b7c9.TID317.tmp
[2025-07-19T18:30:18.580+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=64, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.581+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=64),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/64] for update
[2025-07-19T18:30:18.583+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 61 (task 312, attempt 0, stage 5.0)
[2025-07-19T18:30:18.583+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 58.0 in stage 5.0 (TID 310). 6200 bytes result sent to driver
[2025-07-19T18:30:18.583+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 70.0 in stage 5.0 (TID 319) (8b44f3d35cfa, executor driver, partition 70, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.583+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 58.0 in stage 5.0 (TID 310) in 98 ms on 8b44f3d35cfa (executor driver) (101/200)
[2025-07-19T18:30:18.583+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 70.0 in stage 5.0 (TID 319)
[2025-07-19T18:30:18.584+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.584+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 61 (task 312, attempt 0, stage 5.0)
[2025-07-19T18:30:18.585+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 61.0 in stage 5.0 (TID 312). 6200 bytes result sent to driver
[2025-07-19T18:30:18.585+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 71.0 in stage 5.0 (TID 320) (8b44f3d35cfa, executor driver, partition 71, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.585+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 61.0 in stage 5.0 (TID 312) in 86 ms on 8b44f3d35cfa (executor driver) (102/200)
[2025-07-19T18:30:18.586+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 71.0 in stage 5.0 (TID 320)
[2025-07-19T18:30:18.587+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.587+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.587+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.588+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.588+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74c7b602
[2025-07-19T18:30:18.589+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=69, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.589+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=69),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/69] for update
[2025-07-19T18:30:18.589+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.594+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/64/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/64/.1.delta.48d09075-6238-4099-95ec-ec7fc0202d6d.TID315.tmp
[2025-07-19T18:30:18.595+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23d15f12
[2025-07-19T18:30:18.595+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/62/.1.delta.c4fb7a5c-f57f-4b84-8724-1893f2dca99a.TID313.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/62/1.delta
[2025-07-19T18:30:18.595+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=62),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/62] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/62/1.delta
[2025-07-19T18:30:18.596+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=71, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.596+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=71),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/71] for update
[2025-07-19T18:30:18.597+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 62 (task 313, attempt 0, stage 5.0)
[2025-07-19T18:30:18.597+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.598+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 62 (task 313, attempt 0, stage 5.0)
[2025-07-19T18:30:18.600+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/69/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/69/.1.delta.7c81e64b-49d7-4d05-82fa-e770611b9680.TID318.tmp
[2025-07-19T18:30:18.600+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 62.0 in stage 5.0 (TID 313). 6200 bytes result sent to driver
[2025-07-19T18:30:18.601+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/63/.1.delta.3b9895f6-ce0d-43ee-b412-8d97c0728d59.TID314.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/63/1.delta
[2025-07-19T18:30:18.604+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=63),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/63] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/63/1.delta
[2025-07-19T18:30:18.605+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 63 (task 314, attempt 0, stage 5.0)
[2025-07-19T18:30:18.606+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 72.0 in stage 5.0 (TID 321) (8b44f3d35cfa, executor driver, partition 72, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.606+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1448db5d
[2025-07-19T18:30:18.607+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=70, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.607+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 62.0 in stage 5.0 (TID 313) in 93 ms on 8b44f3d35cfa (executor driver) (103/200)
[2025-07-19T18:30:18.607+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=70),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/70] for update
[2025-07-19T18:30:18.608+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 72.0 in stage 5.0 (TID 321)
[2025-07-19T18:30:18.608+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.609+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 63 (task 314, attempt 0, stage 5.0)
[2025-07-19T18:30:18.609+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.610+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.610+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 63.0 in stage 5.0 (TID 314). 6200 bytes result sent to driver
[2025-07-19T18:30:18.610+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 73.0 in stage 5.0 (TID 322) (8b44f3d35cfa, executor driver, partition 73, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.611+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 73.0 in stage 5.0 (TID 322)
[2025-07-19T18:30:18.611+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 63.0 in stage 5.0 (TID 314) in 76 ms on 8b44f3d35cfa (executor driver) (104/200)
[2025-07-19T18:30:18.611+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.612+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/71/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/71/.1.delta.b14a4c33-1f2f-489b-94be-a36c1de06ee1.TID320.tmp
[2025-07-19T18:30:18.612+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:18.613+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/65/.1.delta.6a7978e1-e9e9-49b2-838a-9343a27e1111.TID316.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/65/1.delta
[2025-07-19T18:30:18.613+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=65),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/65] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/65/1.delta
[2025-07-19T18:30:18.614+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@cd1452a
[2025-07-19T18:30:18.614+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=72, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.615+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=72),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/72] for update
[2025-07-19T18:30:18.615+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 65 (task 316, attempt 0, stage 5.0)
[2025-07-19T18:30:18.617+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/68/.1.delta.9bc7cbc6-6862-4a15-b5f7-22f66b04b7c9.TID317.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/68/1.delta
[2025-07-19T18:30:18.618+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=68),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/68] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/68/1.delta
[2025-07-19T18:30:18.619+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 68 (task 317, attempt 0, stage 5.0)
[2025-07-19T18:30:18.620+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39e83e30
[2025-07-19T18:30:18.621+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/70/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/70/.1.delta.662f38a5-8b94-4d20-8035-d5b2df2d91fe.TID319.tmp
[2025-07-19T18:30:18.621+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.621+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=73, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.622+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=73),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/73] for update
[2025-07-19T18:30:18.622+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.625+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 65 (task 316, attempt 0, stage 5.0)
[2025-07-19T18:30:18.625+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 68 (task 317, attempt 0, stage 5.0)
[2025-07-19T18:30:18.626+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 68.0 in stage 5.0 (TID 317). 6200 bytes result sent to driver
[2025-07-19T18:30:18.626+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 74.0 in stage 5.0 (TID 323) (8b44f3d35cfa, executor driver, partition 74, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.627+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 65.0 in stage 5.0 (TID 316). 6200 bytes result sent to driver
[2025-07-19T18:30:18.627+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 74.0 in stage 5.0 (TID 323)
[2025-07-19T18:30:18.628+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 75.0 in stage 5.0 (TID 324) (8b44f3d35cfa, executor driver, partition 75, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.629+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 68.0 in stage 5.0 (TID 317) in 73 ms on 8b44f3d35cfa (executor driver) (105/200)
[2025-07-19T18:30:18.630+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 75.0 in stage 5.0 (TID 324)
[2025-07-19T18:30:18.630+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 65.0 in stage 5.0 (TID 316) in 75 ms on 8b44f3d35cfa (executor driver) (106/200)
[2025-07-19T18:30:18.631+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/64/.1.delta.48d09075-6238-4099-95ec-ec7fc0202d6d.TID315.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/64/1.delta
[2025-07-19T18:30:18.632+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.632+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=64),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/64] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/64/1.delta
[2025-07-19T18:30:18.633+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.633+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.633+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.634+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 64 (task 315, attempt 0, stage 5.0)
[2025-07-19T18:30:18.635+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/72/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/72/.1.delta.180fcdea-81a0-42d9-9ea0-f00a13d79bb0.TID321.tmp
[2025-07-19T18:30:18.635+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/69/.1.delta.7c81e64b-49d7-4d05-82fa-e770611b9680.TID318.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/69/1.delta
[2025-07-19T18:30:18.636+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=69),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/69] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/69/1.delta
[2025-07-19T18:30:18.636+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 69 (task 318, attempt 0, stage 5.0)
[2025-07-19T18:30:18.637+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 64 (task 315, attempt 0, stage 5.0)
[2025-07-19T18:30:18.639+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 64.0 in stage 5.0 (TID 315). 6200 bytes result sent to driver
[2025-07-19T18:30:18.641+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5589eb4c
[2025-07-19T18:30:18.641+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=75, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.641+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=75),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/75] for update
[2025-07-19T18:30:18.641+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 64.0 in stage 5.0 (TID 315) in 91 ms on 8b44f3d35cfa (executor driver) (107/200)
[2025-07-19T18:30:18.641+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 77.0 in stage 5.0 (TID 325) (8b44f3d35cfa, executor driver, partition 77, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.643+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 77.0 in stage 5.0 (TID 325)
[2025-07-19T18:30:18.643+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.643+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.644+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.644+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/73/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/73/.1.delta.358e9680-ef9f-44b9-ab9d-56083cb16820.TID322.tmp
[2025-07-19T18:30:18.644+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 69 (task 318, attempt 0, stage 5.0)
[2025-07-19T18:30:18.644+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 69.0 in stage 5.0 (TID 318). 6200 bytes result sent to driver
[2025-07-19T18:30:18.645+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 78.0 in stage 5.0 (TID 326) (8b44f3d35cfa, executor driver, partition 78, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.645+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 78.0 in stage 5.0 (TID 326)
[2025-07-19T18:30:18.646+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6f19ab44
[2025-07-19T18:30:18.646+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.648+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.648+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 69.0 in stage 5.0 (TID 318) in 78 ms on 8b44f3d35cfa (executor driver) (108/200)
[2025-07-19T18:30:18.649+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=74, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.649+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=74),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/74] for update
[2025-07-19T18:30:18.649+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/75/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/75/.1.delta.e118ddcf-476d-4ef0-9c3a-0dbea3f2d977.TID324.tmp
[2025-07-19T18:30:18.650+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/71/.1.delta.b14a4c33-1f2f-489b-94be-a36c1de06ee1.TID320.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/71/1.delta
[2025-07-19T18:30:18.650+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=71),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/71] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/71/1.delta
[2025-07-19T18:30:18.651+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 71 (task 320, attempt 0, stage 5.0)
[2025-07-19T18:30:18.651+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@60fe8d1c
[2025-07-19T18:30:18.653+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/70/.1.delta.662f38a5-8b94-4d20-8035-d5b2df2d91fe.TID319.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/70/1.delta
[2025-07-19T18:30:18.654+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=70),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/70] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/70/1.delta
[2025-07-19T18:30:18.654+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 70 (task 319, attempt 0, stage 5.0)
[2025-07-19T18:30:18.656+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=78, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.657+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=78),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/78] for update
[2025-07-19T18:30:18.657+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 70 (task 319, attempt 0, stage 5.0)
[2025-07-19T18:30:18.658+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 70.0 in stage 5.0 (TID 319). 6200 bytes result sent to driver
[2025-07-19T18:30:18.658+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.659+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 79.0 in stage 5.0 (TID 327) (8b44f3d35cfa, executor driver, partition 79, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.659+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 70.0 in stage 5.0 (TID 319) in 77 ms on 8b44f3d35cfa (executor driver) (109/200)
[2025-07-19T18:30:18.659+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.660+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 79.0 in stage 5.0 (TID 327)
[2025-07-19T18:30:18.660+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.661+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.662+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 71 (task 320, attempt 0, stage 5.0)
[2025-07-19T18:30:18.663+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/72/.1.delta.180fcdea-81a0-42d9-9ea0-f00a13d79bb0.TID321.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/72/1.delta
[2025-07-19T18:30:18.664+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=72),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/72] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/72/1.delta
[2025-07-19T18:30:18.664+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/73/.1.delta.358e9680-ef9f-44b9-ab9d-56083cb16820.TID322.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/73/1.delta
[2025-07-19T18:30:18.664+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=73),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/73] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/73/1.delta
[2025-07-19T18:30:18.665+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 72 (task 321, attempt 0, stage 5.0)
[2025-07-19T18:30:18.666+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 73 (task 322, attempt 0, stage 5.0)
[2025-07-19T18:30:18.667+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 71.0 in stage 5.0 (TID 320). 6200 bytes result sent to driver
[2025-07-19T18:30:18.668+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/78/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/78/.1.delta.3bee5166-db57-43b6-8ed1-e06859bd4fe0.TID326.tmp
[2025-07-19T18:30:18.670+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 80.0 in stage 5.0 (TID 328) (8b44f3d35cfa, executor driver, partition 80, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.671+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 80.0 in stage 5.0 (TID 328)
[2025-07-19T18:30:18.673+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ea8068c
[2025-07-19T18:30:18.676+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=77, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.676+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=77),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/77] for update
[2025-07-19T18:30:18.677+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 71.0 in stage 5.0 (TID 320) in 83 ms on 8b44f3d35cfa (executor driver) (110/200)
[2025-07-19T18:30:18.677+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/74/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/74/.1.delta.8474a324-26f9-4f71-93e1-8350b34b06b8.TID323.tmp
[2025-07-19T18:30:18.678+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.679+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 73 (task 322, attempt 0, stage 5.0)
[2025-07-19T18:30:18.680+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 73.0 in stage 5.0 (TID 322). 6200 bytes result sent to driver
[2025-07-19T18:30:18.680+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 72 (task 321, attempt 0, stage 5.0)
[2025-07-19T18:30:18.681+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 81.0 in stage 5.0 (TID 329) (8b44f3d35cfa, executor driver, partition 81, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.681+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 81.0 in stage 5.0 (TID 329)
[2025-07-19T18:30:18.682+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 72.0 in stage 5.0 (TID 321). 6200 bytes result sent to driver
[2025-07-19T18:30:18.683+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 73.0 in stage 5.0 (TID 322) in 65 ms on 8b44f3d35cfa (executor driver) (111/200)
[2025-07-19T18:30:18.683+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5949856a
[2025-07-19T18:30:18.684+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.684+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.685+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 72.0 in stage 5.0 (TID 321) in 73 ms on 8b44f3d35cfa (executor driver) (112/200)
[2025-07-19T18:30:18.685+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 84.0 in stage 5.0 (TID 330) (8b44f3d35cfa, executor driver, partition 84, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.686+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/75/.1.delta.e118ddcf-476d-4ef0-9c3a-0dbea3f2d977.TID324.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/75/1.delta
[2025-07-19T18:30:18.686+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=75),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/75] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/75/1.delta
[2025-07-19T18:30:18.687+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=79, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.687+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=79),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/79] for update
[2025-07-19T18:30:18.688+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 84.0 in stage 5.0 (TID 330)
[2025-07-19T18:30:18.688+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 75 (task 324, attempt 0, stage 5.0)
[2025-07-19T18:30:18.689+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.690+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:18.690+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.691+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.691+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.692+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/77/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/77/.1.delta.e4d4453a-6fe9-4f7c-b8f9-706f82628f57.TID325.tmp
[2025-07-19T18:30:18.692+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 75 (task 324, attempt 0, stage 5.0)
[2025-07-19T18:30:18.692+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 75.0 in stage 5.0 (TID 324). 6200 bytes result sent to driver
[2025-07-19T18:30:18.692+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@69eef34
[2025-07-19T18:30:18.692+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 85.0 in stage 5.0 (TID 331) (8b44f3d35cfa, executor driver, partition 85, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.692+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 85.0 in stage 5.0 (TID 331)
[2025-07-19T18:30:18.692+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/79/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/79/.1.delta.975bba94-7a04-421a-a498-8ac31815fbd4.TID327.tmp
[2025-07-19T18:30:18.692+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=80, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.692+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=80),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/80] for update
[2025-07-19T18:30:18.693+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 75.0 in stage 5.0 (TID 324) in 64 ms on 8b44f3d35cfa (executor driver) (113/200)
[2025-07-19T18:30:18.693+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.693+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.693+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.693+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@442047fa
[2025-07-19T18:30:18.693+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=81, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.693+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=81),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/81] for update
[2025-07-19T18:30:18.696+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.700+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2263dd91
[2025-07-19T18:30:18.702+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/80/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/80/.1.delta.f3a500db-869d-4be6-944d-500f0c818250.TID328.tmp
[2025-07-19T18:30:18.704+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=85, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.705+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=85),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/85] for update
[2025-07-19T18:30:18.706+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.711+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/81/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/81/.1.delta.f188638c-68dc-4f34-ab73-38e949e219df.TID329.tmp
[2025-07-19T18:30:18.712+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/74/.1.delta.8474a324-26f9-4f71-93e1-8350b34b06b8.TID323.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/74/1.delta
[2025-07-19T18:30:18.713+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=74),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/74] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/74/1.delta
[2025-07-19T18:30:18.714+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/78/.1.delta.3bee5166-db57-43b6-8ed1-e06859bd4fe0.TID326.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/78/1.delta
[2025-07-19T18:30:18.715+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b781939
[2025-07-19T18:30:18.715+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=78),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/78] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/78/1.delta
[2025-07-19T18:30:18.716+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 78 (task 326, attempt 0, stage 5.0)
[2025-07-19T18:30:18.716+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 74 (task 323, attempt 0, stage 5.0)
[2025-07-19T18:30:18.717+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=84, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.718+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=84),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/84] for update
[2025-07-19T18:30:18.719+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.720+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/85/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/85/.1.delta.2926f4a9-a81f-410c-9cef-b1d06e03d9dc.TID331.tmp
[2025-07-19T18:30:18.721+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 78 (task 326, attempt 0, stage 5.0)
[2025-07-19T18:30:18.721+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 74 (task 323, attempt 0, stage 5.0)
[2025-07-19T18:30:18.722+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 78.0 in stage 5.0 (TID 326). 6200 bytes result sent to driver
[2025-07-19T18:30:18.722+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 74.0 in stage 5.0 (TID 323). 6200 bytes result sent to driver
[2025-07-19T18:30:18.722+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 78.0 in stage 5.0 (TID 326) in 82 ms on 8b44f3d35cfa (executor driver) (114/200)
[2025-07-19T18:30:18.722+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/77/.1.delta.e4d4453a-6fe9-4f7c-b8f9-706f82628f57.TID325.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/77/1.delta
[2025-07-19T18:30:18.723+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=77),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/77] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/77/1.delta
[2025-07-19T18:30:18.723+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 86.0 in stage 5.0 (TID 332) (8b44f3d35cfa, executor driver, partition 86, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.724+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 87.0 in stage 5.0 (TID 333) (8b44f3d35cfa, executor driver, partition 87, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.724+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 86.0 in stage 5.0 (TID 332)
[2025-07-19T18:30:18.725+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 74.0 in stage 5.0 (TID 323) in 101 ms on 8b44f3d35cfa (executor driver) (115/200)
[2025-07-19T18:30:18.726+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 77 (task 325, attempt 0, stage 5.0)
[2025-07-19T18:30:18.727+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/84/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/84/.1.delta.d6c6649f-84f0-4ebe-821d-ba47650182dc.TID330.tmp
[2025-07-19T18:30:18.728+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 77 (task 325, attempt 0, stage 5.0)
[2025-07-19T18:30:18.729+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 77.0 in stage 5.0 (TID 325). 6200 bytes result sent to driver
[2025-07-19T18:30:18.729+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 87.0 in stage 5.0 (TID 333)
[2025-07-19T18:30:18.730+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/79/.1.delta.975bba94-7a04-421a-a498-8ac31815fbd4.TID327.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/79/1.delta
[2025-07-19T18:30:18.730+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=79),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/79] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/79/1.delta
[2025-07-19T18:30:18.731+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.731+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 79 (task 327, attempt 0, stage 5.0)
[2025-07-19T18:30:18.731+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.732+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 88.0 in stage 5.0 (TID 334) (8b44f3d35cfa, executor driver, partition 88, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.732+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.734+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T18:30:18.736+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 77.0 in stage 5.0 (TID 325) in 98 ms on 8b44f3d35cfa (executor driver) (116/200)
[2025-07-19T18:30:18.737+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 88.0 in stage 5.0 (TID 334)
[2025-07-19T18:30:18.738+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.739+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.739+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4fd5a164
[2025-07-19T18:30:18.740+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 79 (task 327, attempt 0, stage 5.0)
[2025-07-19T18:30:18.740+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/80/.1.delta.f3a500db-869d-4be6-944d-500f0c818250.TID328.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/80/1.delta
[2025-07-19T18:30:18.740+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=80),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/80] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/80/1.delta
[2025-07-19T18:30:18.741+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=87, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.741+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 79.0 in stage 5.0 (TID 327). 6200 bytes result sent to driver
[2025-07-19T18:30:18.741+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=87),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/87] for update
[2025-07-19T18:30:18.741+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 80 (task 328, attempt 0, stage 5.0)
[2025-07-19T18:30:18.741+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 89.0 in stage 5.0 (TID 335) (8b44f3d35cfa, executor driver, partition 89, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.741+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 79.0 in stage 5.0 (TID 327) in 80 ms on 8b44f3d35cfa (executor driver) (117/200)
[2025-07-19T18:30:18.742+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.742+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 89.0 in stage 5.0 (TID 335)
[2025-07-19T18:30:18.742+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 80 (task 328, attempt 0, stage 5.0)
[2025-07-19T18:30:18.742+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.743+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.743+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 80.0 in stage 5.0 (TID 328). 6200 bytes result sent to driver
[2025-07-19T18:30:18.744+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/87/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/87/.1.delta.3f5f05d4-a951-422b-96d6-c2e301efd20d.TID333.tmp
[2025-07-19T18:30:18.744+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/81/.1.delta.f188638c-68dc-4f34-ab73-38e949e219df.TID329.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/81/1.delta
[2025-07-19T18:30:18.744+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=81),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/81] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/81/1.delta
[2025-07-19T18:30:18.747+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 90.0 in stage 5.0 (TID 336) (8b44f3d35cfa, executor driver, partition 90, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.748+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 80.0 in stage 5.0 (TID 328) in 81 ms on 8b44f3d35cfa (executor driver) (118/200)
[2025-07-19T18:30:18.749+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 81 (task 329, attempt 0, stage 5.0)
[2025-07-19T18:30:18.749+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@619df4bd
[2025-07-19T18:30:18.750+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 90.0 in stage 5.0 (TID 336)
[2025-07-19T18:30:18.750+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=88, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.751+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=88),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/88] for update
[2025-07-19T18:30:18.751+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.752+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.752+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.752+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 81 (task 329, attempt 0, stage 5.0)
[2025-07-19T18:30:18.753+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@76b38085
[2025-07-19T18:30:18.754+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 81.0 in stage 5.0 (TID 329). 6200 bytes result sent to driver
[2025-07-19T18:30:18.754+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 91.0 in stage 5.0 (TID 337) (8b44f3d35cfa, executor driver, partition 91, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.755+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 91.0 in stage 5.0 (TID 337)
[2025-07-19T18:30:18.757+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/84/.1.delta.d6c6649f-84f0-4ebe-821d-ba47650182dc.TID330.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/84/1.delta
[2025-07-19T18:30:18.758+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=84),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/84] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/84/1.delta
[2025-07-19T18:30:18.758+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 84 (task 330, attempt 0, stage 5.0)
[2025-07-19T18:30:18.758+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=86, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.758+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 81.0 in stage 5.0 (TID 329) in 85 ms on 8b44f3d35cfa (executor driver) (119/200)
[2025-07-19T18:30:18.759+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=86),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/86] for update
[2025-07-19T18:30:18.760+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.760+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.760+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/85/.1.delta.2926f4a9-a81f-410c-9cef-b1d06e03d9dc.TID331.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/85/1.delta
[2025-07-19T18:30:18.761+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=85),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/85] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/85/1.delta
[2025-07-19T18:30:18.761+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 85 (task 331, attempt 0, stage 5.0)
[2025-07-19T18:30:18.761+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.762+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/88/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/88/.1.delta.6b644b47-1b47-4bb6-aa92-794b14a8ecc1.TID334.tmp
[2025-07-19T18:30:18.762+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 84 (task 330, attempt 0, stage 5.0)
[2025-07-19T18:30:18.763+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 84.0 in stage 5.0 (TID 330). 6200 bytes result sent to driver
[2025-07-19T18:30:18.763+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 92.0 in stage 5.0 (TID 338) (8b44f3d35cfa, executor driver, partition 92, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.764+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 92.0 in stage 5.0 (TID 338)
[2025-07-19T18:30:18.764+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53488967
[2025-07-19T18:30:18.764+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=91, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.765+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 84.0 in stage 5.0 (TID 330) in 89 ms on 8b44f3d35cfa (executor driver) (120/200)
[2025-07-19T18:30:18.765+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=91),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/91] for update
[2025-07-19T18:30:18.768+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.769+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.769+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.769+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 85 (task 331, attempt 0, stage 5.0)
[2025-07-19T18:30:18.769+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 85.0 in stage 5.0 (TID 331). 6200 bytes result sent to driver
[2025-07-19T18:30:18.769+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/86/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/86/.1.delta.e80d9f7f-c5b9-4538-aa81-a621bcd94ccd.TID332.tmp
[2025-07-19T18:30:18.769+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 93.0 in stage 5.0 (TID 339) (8b44f3d35cfa, executor driver, partition 93, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.770+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 85.0 in stage 5.0 (TID 331) in 87 ms on 8b44f3d35cfa (executor driver) (121/200)
[2025-07-19T18:30:18.770+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 93.0 in stage 5.0 (TID 339)
[2025-07-19T18:30:18.770+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2382faa2
[2025-07-19T18:30:18.770+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=90, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.770+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=90),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/90] for update
[2025-07-19T18:30:18.770+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.772+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/91/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/91/.1.delta.7673db77-974e-4195-9b38-ee71b60ad474.TID337.tmp
[2025-07-19T18:30:18.773+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.773+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.774+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@10913bed
[2025-07-19T18:30:18.775+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=89, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.775+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=89),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/89] for update
[2025-07-19T18:30:18.777+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/90/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/90/.1.delta.73606fe5-6784-49ff-ac7e-9ac8ada35991.TID336.tmp
[2025-07-19T18:30:18.778+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.780+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/87/.1.delta.3f5f05d4-a951-422b-96d6-c2e301efd20d.TID333.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/87/1.delta
[2025-07-19T18:30:18.780+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=87),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/87] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/87/1.delta
[2025-07-19T18:30:18.780+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 87 (task 333, attempt 0, stage 5.0)
[2025-07-19T18:30:18.785+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@69676d98
[2025-07-19T18:30:18.785+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 87 (task 333, attempt 0, stage 5.0)
[2025-07-19T18:30:18.786+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=93, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.787+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=93),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/93] for update
[2025-07-19T18:30:18.787+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 87.0 in stage 5.0 (TID 333). 6200 bytes result sent to driver
[2025-07-19T18:30:18.788+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/89/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/89/.1.delta.4cb22c3d-47cb-4d71-97eb-76fdf6a9d706.TID335.tmp
[2025-07-19T18:30:18.790+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 94.0 in stage 5.0 (TID 340) (8b44f3d35cfa, executor driver, partition 94, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.791+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 87.0 in stage 5.0 (TID 333) in 68 ms on 8b44f3d35cfa (executor driver) (122/200)
[2025-07-19T18:30:18.791+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 94.0 in stage 5.0 (TID 340)
[2025-07-19T18:30:18.791+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.792+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.792+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.799+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@32d5edf6
[2025-07-19T18:30:18.800+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=92, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.801+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=92),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/92] for update
[2025-07-19T18:30:18.801+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.802+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/93/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/93/.1.delta.e1ea82cb-f061-43e9-80ca-9539ad1689b2.TID339.tmp
[2025-07-19T18:30:18.808+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/88/.1.delta.6b644b47-1b47-4bb6-aa92-794b14a8ecc1.TID334.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/88/1.delta
[2025-07-19T18:30:18.810+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=88),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/88] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/88/1.delta
[2025-07-19T18:30:18.810+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 88 (task 334, attempt 0, stage 5.0)
[2025-07-19T18:30:18.811+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73dabcbd
[2025-07-19T18:30:18.812+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/86/.1.delta.e80d9f7f-c5b9-4538-aa81-a621bcd94ccd.TID332.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/86/1.delta
[2025-07-19T18:30:18.812+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=86),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/86] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/86/1.delta
[2025-07-19T18:30:18.813+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=94, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.813+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 86 (task 332, attempt 0, stage 5.0)
[2025-07-19T18:30:18.813+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=94),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/94] for update
[2025-07-19T18:30:18.814+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.819+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 88 (task 334, attempt 0, stage 5.0)
[2025-07-19T18:30:18.820+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/92/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/92/.1.delta.6ce0341e-7bd1-4c97-8b6e-776c00503c8b.TID338.tmp
[2025-07-19T18:30:18.821+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 88.0 in stage 5.0 (TID 334). 6243 bytes result sent to driver
[2025-07-19T18:30:18.822+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 86 (task 332, attempt 0, stage 5.0)
[2025-07-19T18:30:18.823+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 86.0 in stage 5.0 (TID 332). 6243 bytes result sent to driver
[2025-07-19T18:30:18.824+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 95.0 in stage 5.0 (TID 341) (8b44f3d35cfa, executor driver, partition 95, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.825+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 96.0 in stage 5.0 (TID 342) (8b44f3d35cfa, executor driver, partition 96, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.826+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 86.0 in stage 5.0 (TID 332) in 103 ms on 8b44f3d35cfa (executor driver) (123/200)
[2025-07-19T18:30:18.827+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/90/.1.delta.73606fe5-6784-49ff-ac7e-9ac8ada35991.TID336.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/90/1.delta
[2025-07-19T18:30:18.828+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=90),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/90] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/90/1.delta
[2025-07-19T18:30:18.828+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 96.0 in stage 5.0 (TID 342)
[2025-07-19T18:30:18.829+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.830+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 95.0 in stage 5.0 (TID 341)
[2025-07-19T18:30:18.830+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 88.0 in stage 5.0 (TID 334) in 98 ms on 8b44f3d35cfa (executor driver) (124/200)
[2025-07-19T18:30:18.831+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.831+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 90 (task 336, attempt 0, stage 5.0)
[2025-07-19T18:30:18.832+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/94/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/94/.1.delta.525a11c4-86c3-4ccf-83d0-a95674b88454.TID340.tmp
[2025-07-19T18:30:18.834+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 90 (task 336, attempt 0, stage 5.0)
[2025-07-19T18:30:18.835+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 90.0 in stage 5.0 (TID 336). 6243 bytes result sent to driver
[2025-07-19T18:30:18.836+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
[2025-07-19T18:30:18.837+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/91/.1.delta.7673db77-974e-4195-9b38-ee71b60ad474.TID337.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/91/1.delta
[2025-07-19T18:30:18.837+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=91),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/91] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/91/1.delta
[2025-07-19T18:30:18.837+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
[2025-07-19T18:30:18.838+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 97.0 in stage 5.0 (TID 343) (8b44f3d35cfa, executor driver, partition 97, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.838+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 90.0 in stage 5.0 (TID 336) in 91 ms on 8b44f3d35cfa (executor driver) (125/200)
[2025-07-19T18:30:18.839+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 91 (task 337, attempt 0, stage 5.0)
[2025-07-19T18:30:18.839+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 97.0 in stage 5.0 (TID 343)
[2025-07-19T18:30:18.839+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.839+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.840+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/89/.1.delta.4cb22c3d-47cb-4d71-97eb-76fdf6a9d706.TID335.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/89/1.delta
[2025-07-19T18:30:18.841+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=89),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/89] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/89/1.delta
[2025-07-19T18:30:18.844+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 89 (task 335, attempt 0, stage 5.0)
[2025-07-19T18:30:18.844+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3e6a3d38
[2025-07-19T18:30:18.845+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 91 (task 337, attempt 0, stage 5.0)
[2025-07-19T18:30:18.846+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=95, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.847+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=95),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/95] for update
[2025-07-19T18:30:18.847+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 91.0 in stage 5.0 (TID 337). 6243 bytes result sent to driver
[2025-07-19T18:30:18.848+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 98.0 in stage 5.0 (TID 344) (8b44f3d35cfa, executor driver, partition 98, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.848+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 98.0 in stage 5.0 (TID 344)
[2025-07-19T18:30:18.849+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 91.0 in stage 5.0 (TID 337) in 90 ms on 8b44f3d35cfa (executor driver) (126/200)
[2025-07-19T18:30:18.849+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.850+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.850+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.852+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 89 (task 335, attempt 0, stage 5.0)
[2025-07-19T18:30:18.852+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 89.0 in stage 5.0 (TID 335). 6243 bytes result sent to driver
[2025-07-19T18:30:18.852+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 99.0 in stage 5.0 (TID 345) (8b44f3d35cfa, executor driver, partition 99, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.853+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 89.0 in stage 5.0 (TID 335) in 113 ms on 8b44f3d35cfa (executor driver) (127/200)
[2025-07-19T18:30:18.853+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 99.0 in stage 5.0 (TID 345)
[2025-07-19T18:30:18.854+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1429f8b6
[2025-07-19T18:30:18.854+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=97, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.855+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=97),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/97] for update
[2025-07-19T18:30:18.856+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.856+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.856+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.857+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/92/.1.delta.6ce0341e-7bd1-4c97-8b6e-776c00503c8b.TID338.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/92/1.delta
[2025-07-19T18:30:18.857+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=92),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/92] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/92/1.delta
[2025-07-19T18:30:18.859+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@327657df
[2025-07-19T18:30:18.859+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=96, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.860+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 92 (task 338, attempt 0, stage 5.0)
[2025-07-19T18:30:18.862+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=96),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/96] for update
[2025-07-19T18:30:18.862+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/95/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/95/.1.delta.b15750aa-e235-41c6-8994-44e7ab843f2e.TID341.tmp
[2025-07-19T18:30:18.863+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/93/.1.delta.e1ea82cb-f061-43e9-80ca-9539ad1689b2.TID339.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/93/1.delta
[2025-07-19T18:30:18.863+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=93),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/93] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/93/1.delta
[2025-07-19T18:30:18.864+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.864+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@77b25d24
[2025-07-19T18:30:18.865+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 93 (task 339, attempt 0, stage 5.0)
[2025-07-19T18:30:18.865+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=99, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.865+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=99),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/99] for update
[2025-07-19T18:30:18.866+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.867+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 93 (task 339, attempt 0, stage 5.0)
[2025-07-19T18:30:18.867+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 93.0 in stage 5.0 (TID 339). 6243 bytes result sent to driver
[2025-07-19T18:30:18.868+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 92 (task 338, attempt 0, stage 5.0)
[2025-07-19T18:30:18.869+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 92.0 in stage 5.0 (TID 338). 6243 bytes result sent to driver
[2025-07-19T18:30:18.869+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/97/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/97/.1.delta.3524b33f-ca94-4c5f-8ad5-29269b1c90ed.TID343.tmp
[2025-07-19T18:30:18.870+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 100.0 in stage 5.0 (TID 346) (8b44f3d35cfa, executor driver, partition 100, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.870+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a5ac918
[2025-07-19T18:30:18.870+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 101.0 in stage 5.0 (TID 347) (8b44f3d35cfa, executor driver, partition 101, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.871+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=98, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.872+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 101.0 in stage 5.0 (TID 347)
[2025-07-19T18:30:18.872+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=98),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/98] for update
[2025-07-19T18:30:18.873+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/94/.1.delta.525a11c4-86c3-4ccf-83d0-a95674b88454.TID340.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/94/1.delta
[2025-07-19T18:30:18.873+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=94),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/94] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/94/1.delta
[2025-07-19T18:30:18.873+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 93.0 in stage 5.0 (TID 339) in 101 ms on 8b44f3d35cfa (executor driver) (128/200)
[2025-07-19T18:30:18.873+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/96/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/96/.1.delta.e4a2b9bc-cc0e-4fdd-8c11-9664c9349b28.TID342.tmp
[2025-07-19T18:30:18.873+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 92.0 in stage 5.0 (TID 338) in 109 ms on 8b44f3d35cfa (executor driver) (129/200)
[2025-07-19T18:30:18.873+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 100.0 in stage 5.0 (TID 346)
[2025-07-19T18:30:18.874+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 94 (task 340, attempt 0, stage 5.0)
[2025-07-19T18:30:18.875+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.875+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.875+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.875+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.876+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.876+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/99/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/99/.1.delta.055d3cc6-d3f9-4615-b2ea-d6db4a39a38b.TID345.tmp
[2025-07-19T18:30:18.882+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/98/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/98/.1.delta.51b9b51e-b68f-4865-829f-d8e510398295.TID344.tmp
[2025-07-19T18:30:18.882+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19248839
[2025-07-19T18:30:18.882+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=101, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.883+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=101),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/101] for update
[2025-07-19T18:30:18.885+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.888+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 94 (task 340, attempt 0, stage 5.0)
[2025-07-19T18:30:18.890+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1022ac77
[2025-07-19T18:30:18.891+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 94.0 in stage 5.0 (TID 340). 6243 bytes result sent to driver
[2025-07-19T18:30:18.893+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 102.0 in stage 5.0 (TID 348) (8b44f3d35cfa, executor driver, partition 102, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.893+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 102.0 in stage 5.0 (TID 348)
[2025-07-19T18:30:18.894+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 94.0 in stage 5.0 (TID 340) in 100 ms on 8b44f3d35cfa (executor driver) (130/200)
[2025-07-19T18:30:18.895+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=100, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.896+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=100),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/100] for update
[2025-07-19T18:30:18.897+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.898+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.899+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.900+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/101/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/101/.1.delta.1a6c62f5-d6e4-4cbb-96d1-35ad94924234.TID347.tmp
[2025-07-19T18:30:18.900+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/95/.1.delta.b15750aa-e235-41c6-8994-44e7ab843f2e.TID341.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/95/1.delta
[2025-07-19T18:30:18.901+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=95),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/95] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/95/1.delta
[2025-07-19T18:30:18.901+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 95 (task 341, attempt 0, stage 5.0)
[2025-07-19T18:30:18.901+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@476ce1c4
[2025-07-19T18:30:18.902+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=102, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.904+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=102),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/102] for update
[2025-07-19T18:30:18.905+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/100/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/100/.1.delta.4ec9b290-ba83-4036-a724-02172c98328a.TID346.tmp
[2025-07-19T18:30:18.906+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/97/.1.delta.3524b33f-ca94-4c5f-8ad5-29269b1c90ed.TID343.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/97/1.delta
[2025-07-19T18:30:18.906+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=97),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/97] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/97/1.delta
[2025-07-19T18:30:18.906+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 97 (task 343, attempt 0, stage 5.0)
[2025-07-19T18:30:18.907+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.912+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 95 (task 341, attempt 0, stage 5.0)
[2025-07-19T18:30:18.914+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/102/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/102/.1.delta.6720ba67-0867-44ea-a3e5-feff32289cc4.TID348.tmp
[2025-07-19T18:30:18.914+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 95.0 in stage 5.0 (TID 341). 6243 bytes result sent to driver
[2025-07-19T18:30:18.915+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 105.0 in stage 5.0 (TID 349) (8b44f3d35cfa, executor driver, partition 105, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.916+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 95.0 in stage 5.0 (TID 341) in 91 ms on 8b44f3d35cfa (executor driver) (131/200)
[2025-07-19T18:30:18.917+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/96/.1.delta.e4a2b9bc-cc0e-4fdd-8c11-9664c9349b28.TID342.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/96/1.delta
[2025-07-19T18:30:18.919+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=96),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/96] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/96/1.delta
[2025-07-19T18:30:18.920+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 105.0 in stage 5.0 (TID 349)
[2025-07-19T18:30:18.922+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 96 (task 342, attempt 0, stage 5.0)
[2025-07-19T18:30:18.923+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.923+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.924+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 97 (task 343, attempt 0, stage 5.0)
[2025-07-19T18:30:18.926+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/99/.1.delta.055d3cc6-d3f9-4615-b2ea-d6db4a39a38b.TID345.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/99/1.delta
[2025-07-19T18:30:18.927+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=99),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/99] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/99/1.delta
[2025-07-19T18:30:18.927+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 99 (task 345, attempt 0, stage 5.0)
[2025-07-19T18:30:18.928+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 97.0 in stage 5.0 (TID 343). 6243 bytes result sent to driver
[2025-07-19T18:30:18.928+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@26c33fef
[2025-07-19T18:30:18.929+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 106.0 in stage 5.0 (TID 350) (8b44f3d35cfa, executor driver, partition 106, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.929+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 97.0 in stage 5.0 (TID 343) in 85 ms on 8b44f3d35cfa (executor driver) (132/200)
[2025-07-19T18:30:18.930+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 106.0 in stage 5.0 (TID 350)
[2025-07-19T18:30:18.930+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=105, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.931+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=105),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/105] for update
[2025-07-19T18:30:18.931+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.931+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.932+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.932+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 99 (task 345, attempt 0, stage 5.0)
[2025-07-19T18:30:18.933+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 96 (task 342, attempt 0, stage 5.0)
[2025-07-19T18:30:18.933+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 99.0 in stage 5.0 (TID 345). 6243 bytes result sent to driver
[2025-07-19T18:30:18.933+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 96.0 in stage 5.0 (TID 342). 6243 bytes result sent to driver
[2025-07-19T18:30:18.933+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/98/.1.delta.51b9b51e-b68f-4865-829f-d8e510398295.TID344.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/98/1.delta
[2025-07-19T18:30:18.933+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=98),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/98] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/98/1.delta
[2025-07-19T18:30:18.934+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 107.0 in stage 5.0 (TID 351) (8b44f3d35cfa, executor driver, partition 107, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.934+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 99.0 in stage 5.0 (TID 345) in 81 ms on 8b44f3d35cfa (executor driver) (133/200)
[2025-07-19T18:30:18.935+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 98 (task 344, attempt 0, stage 5.0)
[2025-07-19T18:30:18.935+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/101/.1.delta.1a6c62f5-d6e4-4cbb-96d1-35ad94924234.TID347.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/101/1.delta
[2025-07-19T18:30:18.935+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=101),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/101] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/101/1.delta
[2025-07-19T18:30:18.937+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 108.0 in stage 5.0 (TID 352) (8b44f3d35cfa, executor driver, partition 108, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.937+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 107.0 in stage 5.0 (TID 351)
[2025-07-19T18:30:18.938+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/105/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/105/.1.delta.654534b7-0e80-433e-83b0-486e34ce3799.TID349.tmp
[2025-07-19T18:30:18.939+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 108.0 in stage 5.0 (TID 352)
[2025-07-19T18:30:18.940+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 96.0 in stage 5.0 (TID 342) in 111 ms on 8b44f3d35cfa (executor driver) (134/200)
[2025-07-19T18:30:18.940+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.941+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T18:30:18.941+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 101 (task 347, attempt 0, stage 5.0)
[2025-07-19T18:30:18.941+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.942+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T18:30:18.943+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 98 (task 344, attempt 0, stage 5.0)
[2025-07-19T18:30:18.943+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/100/.1.delta.4ec9b290-ba83-4036-a724-02172c98328a.TID346.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/100/1.delta
[2025-07-19T18:30:18.943+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=100),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/100] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/100/1.delta
[2025-07-19T18:30:18.943+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 98.0 in stage 5.0 (TID 344). 6243 bytes result sent to driver
[2025-07-19T18:30:18.944+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4561b30a
[2025-07-19T18:30:18.944+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 109.0 in stage 5.0 (TID 353) (8b44f3d35cfa, executor driver, partition 109, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.944+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 100 (task 346, attempt 0, stage 5.0)
[2025-07-19T18:30:18.945+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=106, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.945+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=106),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/106] for update
[2025-07-19T18:30:18.945+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.946+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 109.0 in stage 5.0 (TID 353)
[2025-07-19T18:30:18.946+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 101 (task 347, attempt 0, stage 5.0)
[2025-07-19T18:30:18.946+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 101.0 in stage 5.0 (TID 347). 6243 bytes result sent to driver
[2025-07-19T18:30:18.947+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 110.0 in stage 5.0 (TID 354) (8b44f3d35cfa, executor driver, partition 110, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.949+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.950+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.951+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 110.0 in stage 5.0 (TID 354)
[2025-07-19T18:30:18.952+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 101.0 in stage 5.0 (TID 347) in 81 ms on 8b44f3d35cfa (executor driver) (135/200)
[2025-07-19T18:30:18.952+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 98.0 in stage 5.0 (TID 344) in 107 ms on 8b44f3d35cfa (executor driver) (136/200)
[2025-07-19T18:30:18.954+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 100 (task 346, attempt 0, stage 5.0)
[2025-07-19T18:30:18.954+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.957+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.958+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 100.0 in stage 5.0 (TID 346). 6243 bytes result sent to driver
[2025-07-19T18:30:18.960+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@51a3adaf
[2025-07-19T18:30:18.961+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=107, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.962+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=107),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/107] for update
[2025-07-19T18:30:18.963+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 100.0 in stage 5.0 (TID 346) in 86 ms on 8b44f3d35cfa (executor driver) (137/200)
[2025-07-19T18:30:18.963+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 113.0 in stage 5.0 (TID 355) (8b44f3d35cfa, executor driver, partition 113, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.964+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 113.0 in stage 5.0 (TID 355)
[2025-07-19T18:30:18.966+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/102/.1.delta.6720ba67-0867-44ea-a3e5-feff32289cc4.TID348.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/102/1.delta
[2025-07-19T18:30:18.966+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=102),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/102] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/102/1.delta
[2025-07-19T18:30:18.967+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 102 (task 348, attempt 0, stage 5.0)
[2025-07-19T18:30:18.967+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/106/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/106/.1.delta.161380e4-d2e3-4252-adae-68a88f9f28a7.TID350.tmp
[2025-07-19T18:30:18.968+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.968+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.969+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:18.970+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/105/.1.delta.654534b7-0e80-433e-83b0-486e34ce3799.TID349.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/105/1.delta
[2025-07-19T18:30:18.971+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=105),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/105] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/105/1.delta
[2025-07-19T18:30:18.972+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 105 (task 349, attempt 0, stage 5.0)
[2025-07-19T18:30:18.972+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7766cfac
[2025-07-19T18:30:18.972+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 102 (task 348, attempt 0, stage 5.0)
[2025-07-19T18:30:18.972+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=108, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.972+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 102.0 in stage 5.0 (TID 348). 6200 bytes result sent to driver
[2025-07-19T18:30:18.973+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=108),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/108] for update
[2025-07-19T18:30:18.973+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 116.0 in stage 5.0 (TID 356) (8b44f3d35cfa, executor driver, partition 116, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.973+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 102.0 in stage 5.0 (TID 348) in 77 ms on 8b44f3d35cfa (executor driver) (138/200)
[2025-07-19T18:30:18.974+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 116.0 in stage 5.0 (TID 356)
[2025-07-19T18:30:18.974+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.974+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.974+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5509cdb0
[2025-07-19T18:30:18.974+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=113, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.974+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.974+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=113),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/113] for update
[2025-07-19T18:30:18.974+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/107/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/107/.1.delta.16232792-7e36-48f9-9cc1-06c7e67ce438.TID351.tmp
[2025-07-19T18:30:18.975+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 105 (task 349, attempt 0, stage 5.0)
[2025-07-19T18:30:18.975+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ce03356
[2025-07-19T18:30:18.975+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.975+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=110, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.975+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 105.0 in stage 5.0 (TID 349). 6200 bytes result sent to driver
[2025-07-19T18:30:18.975+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 119.0 in stage 5.0 (TID 357) (8b44f3d35cfa, executor driver, partition 119, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:18.975+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 119.0 in stage 5.0 (TID 357)
[2025-07-19T18:30:18.975+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 105.0 in stage 5.0 (TID 349) in 59 ms on 8b44f3d35cfa (executor driver) (139/200)
[2025-07-19T18:30:18.976+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=110),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/110] for update
[2025-07-19T18:30:18.976+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:18.976+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:18.976+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.977+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/108/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/108/.1.delta.945731b1-cf62-4672-9f2e-2c54a0e2c446.TID352.tmp
[2025-07-19T18:30:18.981+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/110/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/110/.1.delta.6f141175-241a-4ca3-ab52-167b6ccf8040.TID354.tmp
[2025-07-19T18:30:18.982+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@78fac317
[2025-07-19T18:30:18.982+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=109, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.983+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=109),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/109] for update
[2025-07-19T18:30:18.983+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.983+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@612090b2
[2025-07-19T18:30:18.985+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/113/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/113/.1.delta.857aea51-2580-46bc-a94a-e64c171f615a.TID355.tmp
[2025-07-19T18:30:18.987+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=119, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.988+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=119),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/119] for update
[2025-07-19T18:30:18.989+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/109/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/109/.1.delta.075ecb90-d8a0-4d3c-9be6-72db225f239b.TID353.tmp
[2025-07-19T18:30:18.991+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.991+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/106/.1.delta.161380e4-d2e3-4252-adae-68a88f9f28a7.TID350.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/106/1.delta
[2025-07-19T18:30:18.992+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=106),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/106] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/106/1.delta
[2025-07-19T18:30:18.995+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Commit authorized for partition 106 (task 350, attempt 0, stage 5.0)
[2025-07-19T18:30:18.996+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@279df563
[2025-07-19T18:30:18.997+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=116, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:18.997+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=116),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/116] for update
[2025-07-19T18:30:18.999+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:18.999+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO DataWritingSparkTask: Committed partition 106 (task 350, attempt 0, stage 5.0)
[2025-07-19T18:30:19.000+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Finished task 106.0 in stage 5.0 (TID 350). 6200 bytes result sent to driver
[2025-07-19T18:30:19.000+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Starting task 121.0 in stage 5.0 (TID 358) (8b44f3d35cfa, executor driver, partition 121, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.001+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO Executor: Running task 121.0 in stage 5.0 (TID 358)
[2025-07-19T18:30:19.001+0000] {subprocess.py:93} INFO - 25/07/19 18:30:18 INFO TaskSetManager: Finished task 106.0 in stage 5.0 (TID 350) in 79 ms on 8b44f3d35cfa (executor driver) (140/200)
[2025-07-19T18:30:19.001+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.002+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.004+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@15472ad8
[2025-07-19T18:30:19.005+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=121, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.006+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=121),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/121] for update
[2025-07-19T18:30:19.006+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/119/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/119/.1.delta.cc746a3c-1691-43b9-8891-6ec1f817ff99.TID357.tmp
[2025-07-19T18:30:19.007+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/107/.1.delta.16232792-7e36-48f9-9cc1-06c7e67ce438.TID351.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/107/1.delta
[2025-07-19T18:30:19.007+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=107),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/107] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/107/1.delta
[2025-07-19T18:30:19.008+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.008+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 107 (task 351, attempt 0, stage 5.0)
[2025-07-19T18:30:19.011+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 107 (task 351, attempt 0, stage 5.0)
[2025-07-19T18:30:19.013+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/108/.1.delta.945731b1-cf62-4672-9f2e-2c54a0e2c446.TID352.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/108/1.delta
[2025-07-19T18:30:19.013+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=108),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/108] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/108/1.delta
[2025-07-19T18:30:19.013+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/113/.1.delta.857aea51-2580-46bc-a94a-e64c171f615a.TID355.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/113/1.delta
[2025-07-19T18:30:19.015+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=113),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/113] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/113/1.delta
[2025-07-19T18:30:19.016+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 107.0 in stage 5.0 (TID 351). 6200 bytes result sent to driver
[2025-07-19T18:30:19.016+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 113 (task 355, attempt 0, stage 5.0)
[2025-07-19T18:30:19.017+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 108 (task 352, attempt 0, stage 5.0)
[2025-07-19T18:30:19.017+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 122.0 in stage 5.0 (TID 359) (8b44f3d35cfa, executor driver, partition 122, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.018+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 122.0 in stage 5.0 (TID 359)
[2025-07-19T18:30:19.018+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 107.0 in stage 5.0 (TID 351) in 85 ms on 8b44f3d35cfa (executor driver) (141/200)
[2025-07-19T18:30:19.018+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/116/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/116/.1.delta.7f042f91-1af2-4e17-b7a2-ec5a5a7d9748.TID356.tmp
[2025-07-19T18:30:19.020+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/121/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/121/.1.delta.c26c34ff-7953-4c62-b778-9c0c6b592f1f.TID358.tmp
[2025-07-19T18:30:19.021+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 113 (task 355, attempt 0, stage 5.0)
[2025-07-19T18:30:19.022+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 113.0 in stage 5.0 (TID 355). 6200 bytes result sent to driver
[2025-07-19T18:30:19.022+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.023+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T18:30:19.023+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/110/.1.delta.6f141175-241a-4ca3-ab52-167b6ccf8040.TID354.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/110/1.delta
[2025-07-19T18:30:19.023+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=110),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/110] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/110/1.delta
[2025-07-19T18:30:19.024+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 108 (task 352, attempt 0, stage 5.0)
[2025-07-19T18:30:19.024+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 108.0 in stage 5.0 (TID 352). 6200 bytes result sent to driver
[2025-07-19T18:30:19.024+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 123.0 in stage 5.0 (TID 360) (8b44f3d35cfa, executor driver, partition 123, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.024+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 110 (task 354, attempt 0, stage 5.0)
[2025-07-19T18:30:19.025+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 124.0 in stage 5.0 (TID 361) (8b44f3d35cfa, executor driver, partition 124, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.025+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 113.0 in stage 5.0 (TID 355) in 68 ms on 8b44f3d35cfa (executor driver) (142/200)
[2025-07-19T18:30:19.025+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 108.0 in stage 5.0 (TID 352) in 90 ms on 8b44f3d35cfa (executor driver) (143/200)
[2025-07-19T18:30:19.026+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 124.0 in stage 5.0 (TID 361)
[2025-07-19T18:30:19.026+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 123.0 in stage 5.0 (TID 360)
[2025-07-19T18:30:19.026+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1690bedd
[2025-07-19T18:30:19.027+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.027+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.028+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=122, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.028+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=122),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/122] for update
[2025-07-19T18:30:19.028+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 110 (task 354, attempt 0, stage 5.0)
[2025-07-19T18:30:19.029+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 110.0 in stage 5.0 (TID 354). 6200 bytes result sent to driver
[2025-07-19T18:30:19.030+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 126.0 in stage 5.0 (TID 362) (8b44f3d35cfa, executor driver, partition 126, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.030+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 126.0 in stage 5.0 (TID 362)
[2025-07-19T18:30:19.031+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 110.0 in stage 5.0 (TID 354) in 85 ms on 8b44f3d35cfa (executor driver) (144/200)
[2025-07-19T18:30:19.033+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.035+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/109/.1.delta.075ecb90-d8a0-4d3c-9be6-72db225f239b.TID353.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/109/1.delta
[2025-07-19T18:30:19.036+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=109),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/109] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/109/1.delta
[2025-07-19T18:30:19.036+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.037+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 109 (task 353, attempt 0, stage 5.0)
[2025-07-19T18:30:19.038+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:19.038+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43a679d5
[2025-07-19T18:30:19.039+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=123, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.039+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=123),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/123] for update
[2025-07-19T18:30:19.041+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 109 (task 353, attempt 0, stage 5.0)
[2025-07-19T18:30:19.042+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 109.0 in stage 5.0 (TID 353). 6200 bytes result sent to driver
[2025-07-19T18:30:19.042+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.043+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 127.0 in stage 5.0 (TID 363) (8b44f3d35cfa, executor driver, partition 127, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.043+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.043+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 15 ms
[2025-07-19T18:30:19.043+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 127.0 in stage 5.0 (TID 363)
[2025-07-19T18:30:19.044+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 109.0 in stage 5.0 (TID 353) in 104 ms on 8b44f3d35cfa (executor driver) (145/200)
[2025-07-19T18:30:19.046+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.046+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.049+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d7ac32a
[2025-07-19T18:30:19.050+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/122/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/122/.1.delta.a9a0f8bd-f8ad-4179-8068-01307c43955b.TID359.tmp
[2025-07-19T18:30:19.051+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=126, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.051+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=126),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/126] for update
[2025-07-19T18:30:19.053+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.053+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/116/.1.delta.7f042f91-1af2-4e17-b7a2-ec5a5a7d9748.TID356.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/116/1.delta
[2025-07-19T18:30:19.053+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=116),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/116] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/116/1.delta
[2025-07-19T18:30:19.054+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 116 (task 356, attempt 0, stage 5.0)
[2025-07-19T18:30:19.054+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/119/.1.delta.cc746a3c-1691-43b9-8891-6ec1f817ff99.TID357.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/119/1.delta
[2025-07-19T18:30:19.054+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=119),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/119] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/119/1.delta
[2025-07-19T18:30:19.054+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 119 (task 357, attempt 0, stage 5.0)
[2025-07-19T18:30:19.055+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 116 (task 356, attempt 0, stage 5.0)
[2025-07-19T18:30:19.057+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 116.0 in stage 5.0 (TID 356). 6200 bytes result sent to driver
[2025-07-19T18:30:19.058+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/123/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/123/.1.delta.18aac681-a1dc-40cc-98f1-2afbc6e3e193.TID360.tmp
[2025-07-19T18:30:19.058+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 128.0 in stage 5.0 (TID 364) (8b44f3d35cfa, executor driver, partition 128, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.059+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 128.0 in stage 5.0 (TID 364)
[2025-07-19T18:30:19.059+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 116.0 in stage 5.0 (TID 356) in 95 ms on 8b44f3d35cfa (executor driver) (146/200)
[2025-07-19T18:30:19.060+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68fe5d95
[2025-07-19T18:30:19.060+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=127, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.061+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 119 (task 357, attempt 0, stage 5.0)
[2025-07-19T18:30:19.061+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 119.0 in stage 5.0 (TID 357). 6200 bytes result sent to driver
[2025-07-19T18:30:19.062+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 129.0 in stage 5.0 (TID 365) (8b44f3d35cfa, executor driver, partition 129, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.062+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 119.0 in stage 5.0 (TID 357) in 88 ms on 8b44f3d35cfa (executor driver) (147/200)
[2025-07-19T18:30:19.062+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=127),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/127] for update
[2025-07-19T18:30:19.062+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 129.0 in stage 5.0 (TID 365)
[2025-07-19T18:30:19.062+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.062+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.062+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.063+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.063+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/121/.1.delta.c26c34ff-7953-4c62-b778-9c0c6b592f1f.TID358.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/121/1.delta
[2025-07-19T18:30:19.063+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=121),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/121] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/121/1.delta
[2025-07-19T18:30:19.064+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/126/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/126/.1.delta.c6d043e5-e480-4472-86e8-d909e594e9c8.TID362.tmp
[2025-07-19T18:30:19.064+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 121 (task 358, attempt 0, stage 5.0)
[2025-07-19T18:30:19.065+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.068+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@44f2a18
[2025-07-19T18:30:19.068+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=128, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.068+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=128),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/128] for update
[2025-07-19T18:30:19.070+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19ab8379
[2025-07-19T18:30:19.071+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=124, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.071+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=124),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/124] for update
[2025-07-19T18:30:19.072+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/127/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/127/.1.delta.7b25f7d3-9de7-438b-aa0d-18a1e79ba766.TID363.tmp
[2025-07-19T18:30:19.073+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 121 (task 358, attempt 0, stage 5.0)
[2025-07-19T18:30:19.073+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 121.0 in stage 5.0 (TID 358). 6200 bytes result sent to driver
[2025-07-19T18:30:19.073+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.076+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 131.0 in stage 5.0 (TID 366) (8b44f3d35cfa, executor driver, partition 131, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.076+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.076+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 131.0 in stage 5.0 (TID 366)
[2025-07-19T18:30:19.076+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 121.0 in stage 5.0 (TID 358) in 77 ms on 8b44f3d35cfa (executor driver) (148/200)
[2025-07-19T18:30:19.083+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@453b4ddb
[2025-07-19T18:30:19.083+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=129, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.085+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=129),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/129] for update
[2025-07-19T18:30:19.085+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.086+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.087+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.087+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/124/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/124/.1.delta.ef9f711e-d5d3-479a-af47-cdc701fc6210.TID361.tmp
[2025-07-19T18:30:19.087+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/122/.1.delta.a9a0f8bd-f8ad-4179-8068-01307c43955b.TID359.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/122/1.delta
[2025-07-19T18:30:19.088+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=122),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/122] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/122/1.delta
[2025-07-19T18:30:19.089+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 122 (task 359, attempt 0, stage 5.0)
[2025-07-19T18:30:19.090+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@45a5cee5
[2025-07-19T18:30:19.091+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=131, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.091+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=131),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/131] for update
[2025-07-19T18:30:19.092+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.093+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/123/.1.delta.18aac681-a1dc-40cc-98f1-2afbc6e3e193.TID360.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/123/1.delta
[2025-07-19T18:30:19.093+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=123),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/123] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/123/1.delta
[2025-07-19T18:30:19.093+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/128/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/128/.1.delta.5c8342e5-269d-4a4e-9649-e5283529494d.TID364.tmp
[2025-07-19T18:30:19.093+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 123 (task 360, attempt 0, stage 5.0)
[2025-07-19T18:30:19.094+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/129/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/129/.1.delta.c44908e9-57ce-40d4-8365-f3acb97f81c7.TID365.tmp
[2025-07-19T18:30:19.095+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 122 (task 359, attempt 0, stage 5.0)
[2025-07-19T18:30:19.098+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 122.0 in stage 5.0 (TID 359). 6243 bytes result sent to driver
[2025-07-19T18:30:19.099+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 123 (task 360, attempt 0, stage 5.0)
[2025-07-19T18:30:19.099+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 123.0 in stage 5.0 (TID 360). 6243 bytes result sent to driver
[2025-07-19T18:30:19.099+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 132.0 in stage 5.0 (TID 367) (8b44f3d35cfa, executor driver, partition 132, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.102+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 132.0 in stage 5.0 (TID 367)
[2025-07-19T18:30:19.102+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 136.0 in stage 5.0 (TID 368) (8b44f3d35cfa, executor driver, partition 136, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.103+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 122.0 in stage 5.0 (TID 359) in 89 ms on 8b44f3d35cfa (executor driver) (149/200)
[2025-07-19T18:30:19.104+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 136.0 in stage 5.0 (TID 368)
[2025-07-19T18:30:19.104+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 123.0 in stage 5.0 (TID 360) in 81 ms on 8b44f3d35cfa (executor driver) (150/200)
[2025-07-19T18:30:19.104+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/131/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/131/.1.delta.6f19ceb4-791a-434b-9437-66c1dab753c8.TID366.tmp
[2025-07-19T18:30:19.105+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.105+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.106+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.106+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.109+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@49c71bcf
[2025-07-19T18:30:19.110+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=136, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.111+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=136),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/136] for update
[2025-07-19T18:30:19.111+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/126/.1.delta.c6d043e5-e480-4472-86e8-d909e594e9c8.TID362.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/126/1.delta
[2025-07-19T18:30:19.112+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=126),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/126] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/126/1.delta
[2025-07-19T18:30:19.112+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 126 (task 362, attempt 0, stage 5.0)
[2025-07-19T18:30:19.113+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.119+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@62b5f97d
[2025-07-19T18:30:19.120+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 126 (task 362, attempt 0, stage 5.0)
[2025-07-19T18:30:19.121+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=132, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.121+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=132),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/132] for update
[2025-07-19T18:30:19.122+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 126.0 in stage 5.0 (TID 362). 6243 bytes result sent to driver
[2025-07-19T18:30:19.123+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 137.0 in stage 5.0 (TID 369) (8b44f3d35cfa, executor driver, partition 137, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.123+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/136/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/136/.1.delta.3b74014a-0938-4632-859c-f04be8cb2f24.TID368.tmp
[2025-07-19T18:30:19.123+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.124+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 126.0 in stage 5.0 (TID 362) in 94 ms on 8b44f3d35cfa (executor driver) (151/200)
[2025-07-19T18:30:19.124+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 137.0 in stage 5.0 (TID 369)
[2025-07-19T18:30:19.125+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/124/.1.delta.ef9f711e-d5d3-479a-af47-cdc701fc6210.TID361.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/124/1.delta
[2025-07-19T18:30:19.125+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=124),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/124] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/124/1.delta
[2025-07-19T18:30:19.126+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 124 (task 361, attempt 0, stage 5.0)
[2025-07-19T18:30:19.127+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.127+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.127+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/127/.1.delta.7b25f7d3-9de7-438b-aa0d-18a1e79ba766.TID363.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/127/1.delta
[2025-07-19T18:30:19.128+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=127),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/127] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/127/1.delta
[2025-07-19T18:30:19.131+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 127 (task 363, attempt 0, stage 5.0)
[2025-07-19T18:30:19.132+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@230acd5c
[2025-07-19T18:30:19.135+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=137, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.135+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/132/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/132/.1.delta.bdaf9530-3f46-4a40-9e90-ff37acfa6145.TID367.tmp
[2025-07-19T18:30:19.135+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=137),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/137] for update
[2025-07-19T18:30:19.136+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 124 (task 361, attempt 0, stage 5.0)
[2025-07-19T18:30:19.136+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.136+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/128/.1.delta.5c8342e5-269d-4a4e-9649-e5283529494d.TID364.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/128/1.delta
[2025-07-19T18:30:19.136+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 124.0 in stage 5.0 (TID 361). 6243 bytes result sent to driver
[2025-07-19T18:30:19.136+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=128),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/128] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/128/1.delta
[2025-07-19T18:30:19.137+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 128 (task 364, attempt 0, stage 5.0)
[2025-07-19T18:30:19.137+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 138.0 in stage 5.0 (TID 370) (8b44f3d35cfa, executor driver, partition 138, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.137+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 138.0 in stage 5.0 (TID 370)
[2025-07-19T18:30:19.137+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 124.0 in stage 5.0 (TID 361) in 116 ms on 8b44f3d35cfa (executor driver) (152/200)
[2025-07-19T18:30:19.144+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 127 (task 363, attempt 0, stage 5.0)
[2025-07-19T18:30:19.145+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 127.0 in stage 5.0 (TID 363). 6243 bytes result sent to driver
[2025-07-19T18:30:19.146+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.146+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 127.0 in stage 5.0 (TID 363) in 101 ms on 8b44f3d35cfa (executor driver) (153/200)
[2025-07-19T18:30:19.147+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.148+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 140.0 in stage 5.0 (TID 371) (8b44f3d35cfa, executor driver, partition 140, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.149+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 140.0 in stage 5.0 (TID 371)
[2025-07-19T18:30:19.149+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/129/.1.delta.c44908e9-57ce-40d4-8365-f3acb97f81c7.TID365.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/129/1.delta
[2025-07-19T18:30:19.150+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=129),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/129] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/129/1.delta
[2025-07-19T18:30:19.151+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 129 (task 365, attempt 0, stage 5.0)
[2025-07-19T18:30:19.152+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.152+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.153+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d5edcb4
[2025-07-19T18:30:19.154+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/137/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/137/.1.delta.cbfd92af-a2f4-45ae-95c2-9df958b63858.TID369.tmp
[2025-07-19T18:30:19.155+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=138, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.155+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=138),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/138] for update
[2025-07-19T18:30:19.156+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/131/.1.delta.6f19ceb4-791a-434b-9437-66c1dab753c8.TID366.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/131/1.delta
[2025-07-19T18:30:19.156+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=131),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/131] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/131/1.delta
[2025-07-19T18:30:19.156+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 131 (task 366, attempt 0, stage 5.0)
[2025-07-19T18:30:19.157+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 131 (task 366, attempt 0, stage 5.0)
[2025-07-19T18:30:19.157+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@76b6f975
[2025-07-19T18:30:19.157+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=140, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.158+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=140),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/140] for update
[2025-07-19T18:30:19.158+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.163+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 128 (task 364, attempt 0, stage 5.0)
[2025-07-19T18:30:19.163+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 131.0 in stage 5.0 (TID 366). 6243 bytes result sent to driver
[2025-07-19T18:30:19.164+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 128.0 in stage 5.0 (TID 364). 6243 bytes result sent to driver
[2025-07-19T18:30:19.164+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 141.0 in stage 5.0 (TID 372) (8b44f3d35cfa, executor driver, partition 141, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.164+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 131.0 in stage 5.0 (TID 366) in 87 ms on 8b44f3d35cfa (executor driver) (154/200)
[2025-07-19T18:30:19.164+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 128.0 in stage 5.0 (TID 364) in 107 ms on 8b44f3d35cfa (executor driver) (155/200)
[2025-07-19T18:30:19.165+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 141.0 in stage 5.0 (TID 372)
[2025-07-19T18:30:19.165+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 145.0 in stage 5.0 (TID 373) (8b44f3d35cfa, executor driver, partition 145, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.166+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 145.0 in stage 5.0 (TID 373)
[2025-07-19T18:30:19.167+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.168+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.169+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/138/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/138/.1.delta.31d9bf58-71bf-48eb-b3fe-cfbb0f26fdca.TID370.tmp
[2025-07-19T18:30:19.170+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.170+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:19.170+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 129 (task 365, attempt 0, stage 5.0)
[2025-07-19T18:30:19.170+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 129.0 in stage 5.0 (TID 365). 6243 bytes result sent to driver
[2025-07-19T18:30:19.171+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 146.0 in stage 5.0 (TID 374) (8b44f3d35cfa, executor driver, partition 146, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.172+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 146.0 in stage 5.0 (TID 374)
[2025-07-19T18:30:19.172+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 129.0 in stage 5.0 (TID 365) in 112 ms on 8b44f3d35cfa (executor driver) (156/200)
[2025-07-19T18:30:19.173+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.173+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.173+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/136/.1.delta.3b74014a-0938-4632-859c-f04be8cb2f24.TID368.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/136/1.delta
[2025-07-19T18:30:19.174+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=136),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/136] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/136/1.delta
[2025-07-19T18:30:19.174+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 136 (task 368, attempt 0, stage 5.0)
[2025-07-19T18:30:19.177+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 136 (task 368, attempt 0, stage 5.0)
[2025-07-19T18:30:19.177+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 136.0 in stage 5.0 (TID 368). 6200 bytes result sent to driver
[2025-07-19T18:30:19.179+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 148.0 in stage 5.0 (TID 375) (8b44f3d35cfa, executor driver, partition 148, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.179+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 148.0 in stage 5.0 (TID 375)
[2025-07-19T18:30:19.180+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 136.0 in stage 5.0 (TID 368) in 79 ms on 8b44f3d35cfa (executor driver) (157/200)
[2025-07-19T18:30:19.181+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/137/.1.delta.cbfd92af-a2f4-45ae-95c2-9df958b63858.TID369.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/137/1.delta
[2025-07-19T18:30:19.181+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=137),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/137] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/137/1.delta
[2025-07-19T18:30:19.182+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 137 (task 369, attempt 0, stage 5.0)
[2025-07-19T18:30:19.182+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.183+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.183+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@93eab06
[2025-07-19T18:30:19.184+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 137 (task 369, attempt 0, stage 5.0)
[2025-07-19T18:30:19.185+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/132/.1.delta.bdaf9530-3f46-4a40-9e90-ff37acfa6145.TID367.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/132/1.delta
[2025-07-19T18:30:19.185+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=132),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/132] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/132/1.delta
[2025-07-19T18:30:19.185+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 132 (task 367, attempt 0, stage 5.0)
[2025-07-19T18:30:19.185+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=145, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.185+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=145),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/145] for update
[2025-07-19T18:30:19.186+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.187+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@70683176
[2025-07-19T18:30:19.187+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=148, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.187+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=148),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/148] for update
[2025-07-19T18:30:19.190+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.192+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.192+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 137.0 in stage 5.0 (TID 369). 6200 bytes result sent to driver
[2025-07-19T18:30:19.192+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 150.0 in stage 5.0 (TID 376) (8b44f3d35cfa, executor driver, partition 150, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.192+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/138/.1.delta.31d9bf58-71bf-48eb-b3fe-cfbb0f26fdca.TID370.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/138/1.delta
[2025-07-19T18:30:19.192+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=138),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/138] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/138/1.delta
[2025-07-19T18:30:19.192+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 137.0 in stage 5.0 (TID 369) in 71 ms on 8b44f3d35cfa (executor driver) (158/200)
[2025-07-19T18:30:19.192+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 138 (task 370, attempt 0, stage 5.0)
[2025-07-19T18:30:19.192+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 150.0 in stage 5.0 (TID 376)
[2025-07-19T18:30:19.193+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/145/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/145/.1.delta.64145426-9d6a-416a-bbb0-962beb5ca4de.TID373.tmp
[2025-07-19T18:30:19.196+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.198+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 138 (task 370, attempt 0, stage 5.0)
[2025-07-19T18:30:19.199+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.200+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 138.0 in stage 5.0 (TID 370). 6200 bytes result sent to driver
[2025-07-19T18:30:19.201+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/148/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/148/.1.delta.16524855-e421-4857-aae7-6bb950ed93da.TID375.tmp
[2025-07-19T18:30:19.201+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/140/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/140/.1.delta.8efcf984-0d8f-4400-809e-c1b81166a8ad.TID371.tmp
[2025-07-19T18:30:19.202+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39e35b2b
[2025-07-19T18:30:19.202+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 152.0 in stage 5.0 (TID 377) (8b44f3d35cfa, executor driver, partition 152, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.202+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 132 (task 367, attempt 0, stage 5.0)
[2025-07-19T18:30:19.203+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=146, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.203+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 132.0 in stage 5.0 (TID 367). 6200 bytes result sent to driver
[2025-07-19T18:30:19.204+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=146),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/146] for update
[2025-07-19T18:30:19.204+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 138.0 in stage 5.0 (TID 370) in 66 ms on 8b44f3d35cfa (executor driver) (159/200)
[2025-07-19T18:30:19.205+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 155.0 in stage 5.0 (TID 378) (8b44f3d35cfa, executor driver, partition 155, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.205+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.205+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 152.0 in stage 5.0 (TID 377)
[2025-07-19T18:30:19.205+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.206+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.206+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 132.0 in stage 5.0 (TID 367) in 105 ms on 8b44f3d35cfa (executor driver) (160/200)
[2025-07-19T18:30:19.206+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 155.0 in stage 5.0 (TID 378)
[2025-07-19T18:30:19.208+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/146/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/146/.1.delta.21e3396a-bd4f-4411-856e-69c6ba073aa2.TID374.tmp
[2025-07-19T18:30:19.210+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@61c205cf
[2025-07-19T18:30:19.211+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=141, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.212+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=141),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/141] for update
[2025-07-19T18:30:19.212+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.213+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.213+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.217+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/141/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/141/.1.delta.7ad427a9-4966-42c7-a4f4-bb2e540d3511.TID372.tmp
[2025-07-19T18:30:19.218+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@298323bf
[2025-07-19T18:30:19.218+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=155, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.218+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=155),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/155] for update
[2025-07-19T18:30:19.218+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/145/.1.delta.64145426-9d6a-416a-bbb0-962beb5ca4de.TID373.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/145/1.delta
[2025-07-19T18:30:19.218+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=145),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/145] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/145/1.delta
[2025-07-19T18:30:19.218+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 145 (task 373, attempt 0, stage 5.0)
[2025-07-19T18:30:19.221+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/148/.1.delta.16524855-e421-4857-aae7-6bb950ed93da.TID375.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/148/1.delta
[2025-07-19T18:30:19.222+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=148),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/148] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/148/1.delta
[2025-07-19T18:30:19.222+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.222+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 148 (task 375, attempt 0, stage 5.0)
[2025-07-19T18:30:19.222+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 145 (task 373, attempt 0, stage 5.0)
[2025-07-19T18:30:19.226+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/140/.1.delta.8efcf984-0d8f-4400-809e-c1b81166a8ad.TID371.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/140/1.delta
[2025-07-19T18:30:19.227+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=140),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/140] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/140/1.delta
[2025-07-19T18:30:19.228+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ee9d6ae
[2025-07-19T18:30:19.228+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 140 (task 371, attempt 0, stage 5.0)
[2025-07-19T18:30:19.229+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=152, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.229+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 145.0 in stage 5.0 (TID 373). 6200 bytes result sent to driver
[2025-07-19T18:30:19.229+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=152),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/152] for update
[2025-07-19T18:30:19.230+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 156.0 in stage 5.0 (TID 379) (8b44f3d35cfa, executor driver, partition 156, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.230+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 156.0 in stage 5.0 (TID 379)
[2025-07-19T18:30:19.230+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.231+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 145.0 in stage 5.0 (TID 373) in 63 ms on 8b44f3d35cfa (executor driver) (161/200)
[2025-07-19T18:30:19.232+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.233+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.234+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 140 (task 371, attempt 0, stage 5.0)
[2025-07-19T18:30:19.234+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 140.0 in stage 5.0 (TID 371). 6200 bytes result sent to driver
[2025-07-19T18:30:19.234+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 148 (task 375, attempt 0, stage 5.0)
[2025-07-19T18:30:19.235+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 148.0 in stage 5.0 (TID 375). 6200 bytes result sent to driver
[2025-07-19T18:30:19.235+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 157.0 in stage 5.0 (TID 380) (8b44f3d35cfa, executor driver, partition 157, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.236+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/146/.1.delta.21e3396a-bd4f-4411-856e-69c6ba073aa2.TID374.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/146/1.delta
[2025-07-19T18:30:19.236+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=146),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/146] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/146/1.delta
[2025-07-19T18:30:19.236+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/152/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/152/.1.delta.d4055047-ca74-48cd-bc85-2a6cfc4a1063.TID377.tmp
[2025-07-19T18:30:19.237+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 160.0 in stage 5.0 (TID 381) (8b44f3d35cfa, executor driver, partition 160, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.237+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 146 (task 374, attempt 0, stage 5.0)
[2025-07-19T18:30:19.237+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 140.0 in stage 5.0 (TID 371) in 90 ms on 8b44f3d35cfa (executor driver) (162/200)
[2025-07-19T18:30:19.238+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33c75905
[2025-07-19T18:30:19.238+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 148.0 in stage 5.0 (TID 375) in 56 ms on 8b44f3d35cfa (executor driver) (163/200)
[2025-07-19T18:30:19.238+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 160.0 in stage 5.0 (TID 381)
[2025-07-19T18:30:19.238+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/155/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/155/.1.delta.7d3c26bb-0f12-4ad8-940a-9c748eb1cb24.TID378.tmp
[2025-07-19T18:30:19.238+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.238+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.238+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 146 (task 374, attempt 0, stage 5.0)
[2025-07-19T18:30:19.238+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 157.0 in stage 5.0 (TID 380)
[2025-07-19T18:30:19.238+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=150, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.239+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 146.0 in stage 5.0 (TID 374). 6200 bytes result sent to driver
[2025-07-19T18:30:19.239+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=150),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/150] for update
[2025-07-19T18:30:19.239+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.239+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.240+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.242+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 161.0 in stage 5.0 (TID 382) (8b44f3d35cfa, executor driver, partition 161, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.245+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/150/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/150/.1.delta.7d4f71c4-2725-4800-b00d-da90c9af1a28.TID376.tmp
[2025-07-19T18:30:19.246+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@305e0417
[2025-07-19T18:30:19.246+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 146.0 in stage 5.0 (TID 374) in 76 ms on 8b44f3d35cfa (executor driver) (164/200)
[2025-07-19T18:30:19.247+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 161.0 in stage 5.0 (TID 382)
[2025-07-19T18:30:19.248+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/141/.1.delta.7ad427a9-4966-42c7-a4f4-bb2e540d3511.TID372.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/141/1.delta
[2025-07-19T18:30:19.249+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=141),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/141] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/141/1.delta
[2025-07-19T18:30:19.250+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=157, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.251+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=157),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/157] for update
[2025-07-19T18:30:19.251+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 141 (task 372, attempt 0, stage 5.0)
[2025-07-19T18:30:19.253+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.253+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.254+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.255+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/152/.1.delta.d4055047-ca74-48cd-bc85-2a6cfc4a1063.TID377.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/152/1.delta
[2025-07-19T18:30:19.256+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=152),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/152] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/152/1.delta
[2025-07-19T18:30:19.257+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d6362
[2025-07-19T18:30:19.259+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 152 (task 377, attempt 0, stage 5.0)
[2025-07-19T18:30:19.259+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=160, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.260+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=160),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/160] for update
[2025-07-19T18:30:19.260+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 141 (task 372, attempt 0, stage 5.0)
[2025-07-19T18:30:19.260+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.260+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 152 (task 377, attempt 0, stage 5.0)
[2025-07-19T18:30:19.261+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 141.0 in stage 5.0 (TID 372). 6200 bytes result sent to driver
[2025-07-19T18:30:19.261+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 152.0 in stage 5.0 (TID 377). 6200 bytes result sent to driver
[2025-07-19T18:30:19.262+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/157/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/157/.1.delta.b47205d2-ccc7-48dc-8b1f-553ce6cf6a80.TID380.tmp
[2025-07-19T18:30:19.264+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/155/.1.delta.7d3c26bb-0f12-4ad8-940a-9c748eb1cb24.TID378.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/155/1.delta
[2025-07-19T18:30:19.268+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=155),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/155] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/155/1.delta
[2025-07-19T18:30:19.270+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 162.0 in stage 5.0 (TID 383) (8b44f3d35cfa, executor driver, partition 162, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.270+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28690bf0
[2025-07-19T18:30:19.270+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 163.0 in stage 5.0 (TID 384) (8b44f3d35cfa, executor driver, partition 163, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.271+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 155 (task 378, attempt 0, stage 5.0)
[2025-07-19T18:30:19.271+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=156, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.272+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=156),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/156] for update
[2025-07-19T18:30:19.274+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 141.0 in stage 5.0 (TID 372) in 103 ms on 8b44f3d35cfa (executor driver) (165/200)
[2025-07-19T18:30:19.275+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 162.0 in stage 5.0 (TID 383)
[2025-07-19T18:30:19.276+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.277+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 152.0 in stage 5.0 (TID 377) in 67 ms on 8b44f3d35cfa (executor driver) (166/200)
[2025-07-19T18:30:19.278+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 163.0 in stage 5.0 (TID 384)
[2025-07-19T18:30:19.279+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/160/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/160/.1.delta.c3511130-dff5-459d-bc45-d5c77ddc7659.TID381.tmp
[2025-07-19T18:30:19.281+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 155 (task 378, attempt 0, stage 5.0)
[2025-07-19T18:30:19.282+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 155.0 in stage 5.0 (TID 378). 6200 bytes result sent to driver
[2025-07-19T18:30:19.282+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.283+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.284+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 164.0 in stage 5.0 (TID 385) (8b44f3d35cfa, executor driver, partition 164, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.284+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5436ed17
[2025-07-19T18:30:19.286+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=161, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.286+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=161),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/161] for update
[2025-07-19T18:30:19.287+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 155.0 in stage 5.0 (TID 378) in 71 ms on 8b44f3d35cfa (executor driver) (167/200)
[2025-07-19T18:30:19.287+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 164.0 in stage 5.0 (TID 385)
[2025-07-19T18:30:19.288+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.288+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.289+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:19.289+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/150/.1.delta.7d4f71c4-2725-4800-b00d-da90c9af1a28.TID376.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/150/1.delta
[2025-07-19T18:30:19.290+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=150),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/150] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/150/1.delta
[2025-07-19T18:30:19.291+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 150 (task 376, attempt 0, stage 5.0)
[2025-07-19T18:30:19.291+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.292+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.292+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1aa57eab
[2025-07-19T18:30:19.292+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 150 (task 376, attempt 0, stage 5.0)
[2025-07-19T18:30:19.292+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=163, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.292+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=163),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/163] for update
[2025-07-19T18:30:19.293+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 150.0 in stage 5.0 (TID 376). 6200 bytes result sent to driver
[2025-07-19T18:30:19.294+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/156/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/156/.1.delta.63f73b44-502b-428e-be20-7e118b80c68b.TID379.tmp
[2025-07-19T18:30:19.295+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 165.0 in stage 5.0 (TID 386) (8b44f3d35cfa, executor driver, partition 165, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.296+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 150.0 in stage 5.0 (TID 376) in 91 ms on 8b44f3d35cfa (executor driver) (168/200)
[2025-07-19T18:30:19.296+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 165.0 in stage 5.0 (TID 386)
[2025-07-19T18:30:19.297+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.297+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.298+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.299+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/161/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/161/.1.delta.8aa084ab-8c16-4d30-84e4-8c6d6f4ad5e6.TID382.tmp
[2025-07-19T18:30:19.299+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@27a263bf
[2025-07-19T18:30:19.300+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=164, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.300+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=164),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/164] for update
[2025-07-19T18:30:19.300+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/157/.1.delta.b47205d2-ccc7-48dc-8b1f-553ce6cf6a80.TID380.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/157/1.delta
[2025-07-19T18:30:19.301+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=157),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/157] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/157/1.delta
[2025-07-19T18:30:19.301+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 157 (task 380, attempt 0, stage 5.0)
[2025-07-19T18:30:19.301+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.302+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/163/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/163/.1.delta.39c0bc36-d20f-4b73-b9ea-90cec51d5e9a.TID384.tmp
[2025-07-19T18:30:19.302+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ab618a6
[2025-07-19T18:30:19.302+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=162, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.302+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=162),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/162] for update
[2025-07-19T18:30:19.303+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 157 (task 380, attempt 0, stage 5.0)
[2025-07-19T18:30:19.303+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 157.0 in stage 5.0 (TID 380). 6200 bytes result sent to driver
[2025-07-19T18:30:19.303+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.304+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 166.0 in stage 5.0 (TID 387) (8b44f3d35cfa, executor driver, partition 166, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.304+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 157.0 in stage 5.0 (TID 380) in 71 ms on 8b44f3d35cfa (executor driver) (169/200)
[2025-07-19T18:30:19.305+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/160/.1.delta.c3511130-dff5-459d-bc45-d5c77ddc7659.TID381.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/160/1.delta
[2025-07-19T18:30:19.305+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=160),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/160] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/160/1.delta
[2025-07-19T18:30:19.307+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 160 (task 381, attempt 0, stage 5.0)
[2025-07-19T18:30:19.309+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 166.0 in stage 5.0 (TID 387)
[2025-07-19T18:30:19.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/162/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/162/.1.delta.692f1b64-7d24-406a-970d-a6978c4577bc.TID383.tmp
[2025-07-19T18:30:19.311+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d3ef32b
[2025-07-19T18:30:19.311+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.312+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 160 (task 381, attempt 0, stage 5.0)
[2025-07-19T18:30:19.313+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=165, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.313+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.314+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=165),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/165] for update
[2025-07-19T18:30:19.314+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 160.0 in stage 5.0 (TID 381). 6200 bytes result sent to driver
[2025-07-19T18:30:19.315+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 168.0 in stage 5.0 (TID 388) (8b44f3d35cfa, executor driver, partition 168, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.315+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 168.0 in stage 5.0 (TID 388)
[2025-07-19T18:30:19.315+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 160.0 in stage 5.0 (TID 381) in 79 ms on 8b44f3d35cfa (executor driver) (170/200)
[2025-07-19T18:30:19.316+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.316+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.317+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.317+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b6b85e0
[2025-07-19T18:30:19.318+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/164/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/164/.1.delta.72c9d1e1-6707-4577-a2af-f89ae136db86.TID385.tmp
[2025-07-19T18:30:19.319+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/156/.1.delta.63f73b44-502b-428e-be20-7e118b80c68b.TID379.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/156/1.delta
[2025-07-19T18:30:19.319+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=166, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.320+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=156),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/156] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/156/1.delta
[2025-07-19T18:30:19.320+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=166),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/166] for update
[2025-07-19T18:30:19.321+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 156 (task 379, attempt 0, stage 5.0)
[2025-07-19T18:30:19.323+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@b272607
[2025-07-19T18:30:19.324+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.324+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 156 (task 379, attempt 0, stage 5.0)
[2025-07-19T18:30:19.325+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=168, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.325+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 156.0 in stage 5.0 (TID 379). 6200 bytes result sent to driver
[2025-07-19T18:30:19.328+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=168),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/168] for update
[2025-07-19T18:30:19.328+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 169.0 in stage 5.0 (TID 389) (8b44f3d35cfa, executor driver, partition 169, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.328+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 156.0 in stage 5.0 (TID 379) in 99 ms on 8b44f3d35cfa (executor driver) (171/200)
[2025-07-19T18:30:19.329+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.329+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/165/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/165/.1.delta.96b28128-023d-4da7-a8f6-cdc8ab576921.TID386.tmp
[2025-07-19T18:30:19.330+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 169.0 in stage 5.0 (TID 389)
[2025-07-19T18:30:19.330+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.331+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.332+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/161/.1.delta.8aa084ab-8c16-4d30-84e4-8c6d6f4ad5e6.TID382.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/161/1.delta
[2025-07-19T18:30:19.335+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=161),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/161] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/161/1.delta
[2025-07-19T18:30:19.335+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 161 (task 382, attempt 0, stage 5.0)
[2025-07-19T18:30:19.336+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@79483782
[2025-07-19T18:30:19.338+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=169, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.340+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=169),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/169] for update
[2025-07-19T18:30:19.340+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/168/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/168/.1.delta.a74ca759-c22b-45b5-b499-99da2fadd5b7.TID388.tmp
[2025-07-19T18:30:19.341+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 161 (task 382, attempt 0, stage 5.0)
[2025-07-19T18:30:19.341+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 161.0 in stage 5.0 (TID 382). 6200 bytes result sent to driver
[2025-07-19T18:30:19.342+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/166/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/166/.1.delta.08b4d364-2e6d-471d-ae60-44f77f0912ff.TID387.tmp
[2025-07-19T18:30:19.343+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 161.0 in stage 5.0 (TID 382) in 97 ms on 8b44f3d35cfa (executor driver) (172/200)
[2025-07-19T18:30:19.343+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 172.0 in stage 5.0 (TID 390) (8b44f3d35cfa, executor driver, partition 172, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.343+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 172.0 in stage 5.0 (TID 390)
[2025-07-19T18:30:19.344+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.344+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.344+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.348+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@60811e5f
[2025-07-19T18:30:19.348+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=172, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.349+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=172),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/172] for update
[2025-07-19T18:30:19.349+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.351+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/163/.1.delta.39c0bc36-d20f-4b73-b9ea-90cec51d5e9a.TID384.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/163/1.delta
[2025-07-19T18:30:19.351+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=163),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/163] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/163/1.delta
[2025-07-19T18:30:19.353+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/162/.1.delta.692f1b64-7d24-406a-970d-a6978c4577bc.TID383.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/162/1.delta
[2025-07-19T18:30:19.353+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=162),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/162] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/162/1.delta
[2025-07-19T18:30:19.354+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 162 (task 383, attempt 0, stage 5.0)
[2025-07-19T18:30:19.354+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/169/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/169/.1.delta.8ec7e799-e553-49bf-a4a8-2add59e7ca3b.TID389.tmp
[2025-07-19T18:30:19.355+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 163 (task 384, attempt 0, stage 5.0)
[2025-07-19T18:30:19.356+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 163 (task 384, attempt 0, stage 5.0)
[2025-07-19T18:30:19.358+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 163.0 in stage 5.0 (TID 384). 6200 bytes result sent to driver
[2025-07-19T18:30:19.359+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 162 (task 383, attempt 0, stage 5.0)
[2025-07-19T18:30:19.361+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 173.0 in stage 5.0 (TID 391) (8b44f3d35cfa, executor driver, partition 173, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.361+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 162.0 in stage 5.0 (TID 383). 6200 bytes result sent to driver
[2025-07-19T18:30:19.362+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 174.0 in stage 5.0 (TID 392) (8b44f3d35cfa, executor driver, partition 174, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.362+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 163.0 in stage 5.0 (TID 384) in 94 ms on 8b44f3d35cfa (executor driver) (173/200)
[2025-07-19T18:30:19.362+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 174.0 in stage 5.0 (TID 392)
[2025-07-19T18:30:19.362+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 173.0 in stage 5.0 (TID 391)
[2025-07-19T18:30:19.362+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/172/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/172/.1.delta.72f41570-d984-4da1-8bbf-52f6b0d187dd.TID390.tmp
[2025-07-19T18:30:19.362+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 162.0 in stage 5.0 (TID 383) in 100 ms on 8b44f3d35cfa (executor driver) (174/200)
[2025-07-19T18:30:19.362+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/164/.1.delta.72c9d1e1-6707-4577-a2af-f89ae136db86.TID385.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/164/1.delta
[2025-07-19T18:30:19.362+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=164),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/164] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/164/1.delta
[2025-07-19T18:30:19.362+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.363+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.364+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 164 (task 385, attempt 0, stage 5.0)
[2025-07-19T18:30:19.365+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.366+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.366+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 164 (task 385, attempt 0, stage 5.0)
[2025-07-19T18:30:19.366+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 164.0 in stage 5.0 (TID 385). 6200 bytes result sent to driver
[2025-07-19T18:30:19.366+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 175.0 in stage 5.0 (TID 393) (8b44f3d35cfa, executor driver, partition 175, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.366+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 175.0 in stage 5.0 (TID 393)
[2025-07-19T18:30:19.367+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 164.0 in stage 5.0 (TID 385) in 95 ms on 8b44f3d35cfa (executor driver) (175/200)
[2025-07-19T18:30:19.367+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/165/.1.delta.96b28128-023d-4da7-a8f6-cdc8ab576921.TID386.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/165/1.delta
[2025-07-19T18:30:19.367+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@cc1d369
[2025-07-19T18:30:19.368+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=165),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/165] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/165/1.delta
[2025-07-19T18:30:19.368+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=174, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.368+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=174),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/174] for update
[2025-07-19T18:30:19.368+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.369+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.369+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 165 (task 386, attempt 0, stage 5.0)
[2025-07-19T18:30:19.370+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.371+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/166/.1.delta.08b4d364-2e6d-471d-ae60-44f77f0912ff.TID387.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/166/1.delta
[2025-07-19T18:30:19.372+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=166),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/166] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/166/1.delta
[2025-07-19T18:30:19.372+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 166 (task 387, attempt 0, stage 5.0)
[2025-07-19T18:30:19.373+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/168/.1.delta.a74ca759-c22b-45b5-b499-99da2fadd5b7.TID388.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/168/1.delta
[2025-07-19T18:30:19.373+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=168),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/168] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/168/1.delta
[2025-07-19T18:30:19.374+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 168 (task 388, attempt 0, stage 5.0)
[2025-07-19T18:30:19.374+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/174/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/174/.1.delta.f4212393-fc6a-4de7-9526-dd143b2b67f9.TID392.tmp
[2025-07-19T18:30:19.374+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c860a14
[2025-07-19T18:30:19.377+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 166 (task 387, attempt 0, stage 5.0)
[2025-07-19T18:30:19.379+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 165 (task 386, attempt 0, stage 5.0)
[2025-07-19T18:30:19.380+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 166.0 in stage 5.0 (TID 387). 6200 bytes result sent to driver
[2025-07-19T18:30:19.380+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=175, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.380+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=175),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/175] for update
[2025-07-19T18:30:19.381+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 165.0 in stage 5.0 (TID 386). 6200 bytes result sent to driver
[2025-07-19T18:30:19.381+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 176.0 in stage 5.0 (TID 394) (8b44f3d35cfa, executor driver, partition 176, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.381+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.381+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 166.0 in stage 5.0 (TID 387) in 76 ms on 8b44f3d35cfa (executor driver) (176/200)
[2025-07-19T18:30:19.381+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 177.0 in stage 5.0 (TID 395) (8b44f3d35cfa, executor driver, partition 177, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.382+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 176.0 in stage 5.0 (TID 394)
[2025-07-19T18:30:19.382+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 168 (task 388, attempt 0, stage 5.0)
[2025-07-19T18:30:19.383+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 177.0 in stage 5.0 (TID 395)
[2025-07-19T18:30:19.383+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 168.0 in stage 5.0 (TID 388). 6200 bytes result sent to driver
[2025-07-19T18:30:19.384+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 178.0 in stage 5.0 (TID 396) (8b44f3d35cfa, executor driver, partition 178, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.384+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 178.0 in stage 5.0 (TID 396)
[2025-07-19T18:30:19.385+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 168.0 in stage 5.0 (TID 388) in 72 ms on 8b44f3d35cfa (executor driver) (177/200)
[2025-07-19T18:30:19.386+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 165.0 in stage 5.0 (TID 386) in 102 ms on 8b44f3d35cfa (executor driver) (178/200)
[2025-07-19T18:30:19.387+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.387+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.387+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.388+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.388+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/169/.1.delta.8ec7e799-e553-49bf-a4a8-2add59e7ca3b.TID389.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/169/1.delta
[2025-07-19T18:30:19.388+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=169),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/169] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/169/1.delta
[2025-07-19T18:30:19.389+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.390+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:19.390+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@62ead667
[2025-07-19T18:30:19.390+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 169 (task 389, attempt 0, stage 5.0)
[2025-07-19T18:30:19.391+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=173, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.394+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=173),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/173] for update
[2025-07-19T18:30:19.394+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.394+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/175/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/175/.1.delta.7cc20e41-575a-4de7-acbf-7e753b3328d7.TID393.tmp
[2025-07-19T18:30:19.395+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 169 (task 389, attempt 0, stage 5.0)
[2025-07-19T18:30:19.395+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 169.0 in stage 5.0 (TID 389). 6200 bytes result sent to driver
[2025-07-19T18:30:19.395+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4079422a
[2025-07-19T18:30:19.396+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=178, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.396+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=178),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/178] for update
[2025-07-19T18:30:19.396+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 179.0 in stage 5.0 (TID 397) (8b44f3d35cfa, executor driver, partition 179, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.396+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 169.0 in stage 5.0 (TID 389) in 68 ms on 8b44f3d35cfa (executor driver) (179/200)
[2025-07-19T18:30:19.396+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 179.0 in stage 5.0 (TID 397)
[2025-07-19T18:30:19.396+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.396+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.396+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.398+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/173/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/173/.1.delta.195d3485-3ad0-4b62-8db1-cce58192ce33.TID391.tmp
[2025-07-19T18:30:19.399+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/172/.1.delta.72f41570-d984-4da1-8bbf-52f6b0d187dd.TID390.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/172/1.delta
[2025-07-19T18:30:19.399+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=172),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/172] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/172/1.delta
[2025-07-19T18:30:19.400+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 172 (task 390, attempt 0, stage 5.0)
[2025-07-19T18:30:19.401+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@199754d2
[2025-07-19T18:30:19.401+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/178/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/178/.1.delta.200f35bb-220f-49dd-a233-6c7cbe804eea.TID396.tmp
[2025-07-19T18:30:19.402+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=176, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.402+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=176),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/176] for update
[2025-07-19T18:30:19.402+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/174/.1.delta.f4212393-fc6a-4de7-9526-dd143b2b67f9.TID392.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/174/1.delta
[2025-07-19T18:30:19.402+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=174),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/174] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/174/1.delta
[2025-07-19T18:30:19.403+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 174 (task 392, attempt 0, stage 5.0)
[2025-07-19T18:30:19.404+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 172 (task 390, attempt 0, stage 5.0)
[2025-07-19T18:30:19.404+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 172.0 in stage 5.0 (TID 390). 6200 bytes result sent to driver
[2025-07-19T18:30:19.406+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.410+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 180.0 in stage 5.0 (TID 398) (8b44f3d35cfa, executor driver, partition 180, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.410+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 180.0 in stage 5.0 (TID 398)
[2025-07-19T18:30:19.410+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ae20137
[2025-07-19T18:30:19.411+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 174 (task 392, attempt 0, stage 5.0)
[2025-07-19T18:30:19.412+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 172.0 in stage 5.0 (TID 390) in 69 ms on 8b44f3d35cfa (executor driver) (180/200)
[2025-07-19T18:30:19.412+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=177, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.413+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=177),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/177] for update
[2025-07-19T18:30:19.413+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 174.0 in stage 5.0 (TID 392). 6200 bytes result sent to driver
[2025-07-19T18:30:19.413+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.414+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.414+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 181.0 in stage 5.0 (TID 399) (8b44f3d35cfa, executor driver, partition 181, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.415+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.415+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 181.0 in stage 5.0 (TID 399)
[2025-07-19T18:30:19.415+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4caa95bb
[2025-07-19T18:30:19.416+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=180, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.416+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 174.0 in stage 5.0 (TID 392) in 54 ms on 8b44f3d35cfa (executor driver) (181/200)
[2025-07-19T18:30:19.416+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=180),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/180] for update
[2025-07-19T18:30:19.417+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.417+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.418+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.419+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/176/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/176/.1.delta.3e848e65-4005-4911-bf90-c156342b710a.TID394.tmp
[2025-07-19T18:30:19.419+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/177/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/177/.1.delta.8d22381c-b14a-498a-8c00-3393397216a0.TID395.tmp
[2025-07-19T18:30:19.422+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/175/.1.delta.7cc20e41-575a-4de7-acbf-7e753b3328d7.TID393.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/175/1.delta
[2025-07-19T18:30:19.422+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=175),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/175] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/175/1.delta
[2025-07-19T18:30:19.422+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a22e91d
[2025-07-19T18:30:19.423+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 175 (task 393, attempt 0, stage 5.0)
[2025-07-19T18:30:19.423+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=179, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.423+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=179),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/179] for update
[2025-07-19T18:30:19.423+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.424+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 175 (task 393, attempt 0, stage 5.0)
[2025-07-19T18:30:19.425+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 175.0 in stage 5.0 (TID 393). 6200 bytes result sent to driver
[2025-07-19T18:30:19.425+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 182.0 in stage 5.0 (TID 400) (8b44f3d35cfa, executor driver, partition 182, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.425+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 182.0 in stage 5.0 (TID 400)
[2025-07-19T18:30:19.426+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 175.0 in stage 5.0 (TID 393) in 60 ms on 8b44f3d35cfa (executor driver) (182/200)
[2025-07-19T18:30:19.426+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/180/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/180/.1.delta.0ce1f467-424a-4a8c-933e-12ca561f3bb4.TID398.tmp
[2025-07-19T18:30:19.427+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.428+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3a376667
[2025-07-19T18:30:19.428+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.428+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=181, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.429+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=181),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/181] for update
[2025-07-19T18:30:19.429+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/179/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/179/.1.delta.ba5007c2-11da-4011-9c99-2d509afb056a.TID397.tmp
[2025-07-19T18:30:19.430+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.435+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/178/.1.delta.200f35bb-220f-49dd-a233-6c7cbe804eea.TID396.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/178/1.delta
[2025-07-19T18:30:19.435+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=178),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/178] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/178/1.delta
[2025-07-19T18:30:19.436+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2a0fb219
[2025-07-19T18:30:19.436+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=182, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.436+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 178 (task 396, attempt 0, stage 5.0)
[2025-07-19T18:30:19.436+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=182),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/182] for update
[2025-07-19T18:30:19.437+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/173/.1.delta.195d3485-3ad0-4b62-8db1-cce58192ce33.TID391.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/173/1.delta
[2025-07-19T18:30:19.437+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=173),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/173] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/173/1.delta
[2025-07-19T18:30:19.437+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.437+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 173 (task 391, attempt 0, stage 5.0)
[2025-07-19T18:30:19.438+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 178 (task 396, attempt 0, stage 5.0)
[2025-07-19T18:30:19.445+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 178.0 in stage 5.0 (TID 396). 6286 bytes result sent to driver
[2025-07-19T18:30:19.445+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 185.0 in stage 5.0 (TID 401) (8b44f3d35cfa, executor driver, partition 185, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.445+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/181/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/181/.1.delta.19e8f5ec-a60c-40ce-8983-4f1c933383f8.TID399.tmp
[2025-07-19T18:30:19.445+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 185.0 in stage 5.0 (TID 401)
[2025-07-19T18:30:19.446+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 173 (task 391, attempt 0, stage 5.0)
[2025-07-19T18:30:19.446+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 173.0 in stage 5.0 (TID 391). 6243 bytes result sent to driver
[2025-07-19T18:30:19.447+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 186.0 in stage 5.0 (TID 402) (8b44f3d35cfa, executor driver, partition 186, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.448+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.448+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 178.0 in stage 5.0 (TID 396) in 64 ms on 8b44f3d35cfa (executor driver) (183/200)
[2025-07-19T18:30:19.448+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 186.0 in stage 5.0 (TID 402)
[2025-07-19T18:30:19.449+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.449+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 173.0 in stage 5.0 (TID 391) in 90 ms on 8b44f3d35cfa (executor driver) (184/200)
[2025-07-19T18:30:19.449+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/182/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/182/.1.delta.407b0762-6c12-4e8f-adb2-d0f7f10f030d.TID400.tmp
[2025-07-19T18:30:19.449+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.449+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.451+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ad454bf
[2025-07-19T18:30:19.452+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=185, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.452+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=185),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/185] for update
[2025-07-19T18:30:19.453+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/176/.1.delta.3e848e65-4005-4911-bf90-c156342b710a.TID394.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/176/1.delta
[2025-07-19T18:30:19.453+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=176),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/176] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/176/1.delta
[2025-07-19T18:30:19.453+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 176 (task 394, attempt 0, stage 5.0)
[2025-07-19T18:30:19.454+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.454+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/180/.1.delta.0ce1f467-424a-4a8c-933e-12ca561f3bb4.TID398.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/180/1.delta
[2025-07-19T18:30:19.455+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=180),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/180] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/180/1.delta
[2025-07-19T18:30:19.455+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 180 (task 398, attempt 0, stage 5.0)
[2025-07-19T18:30:19.458+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a6ae350
[2025-07-19T18:30:19.459+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 176 (task 394, attempt 0, stage 5.0)
[2025-07-19T18:30:19.459+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=186, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.461+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 176.0 in stage 5.0 (TID 394). 6243 bytes result sent to driver
[2025-07-19T18:30:19.462+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=186),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/186] for update
[2025-07-19T18:30:19.463+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 188.0 in stage 5.0 (TID 403) (8b44f3d35cfa, executor driver, partition 188, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.464+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 176.0 in stage 5.0 (TID 394) in 81 ms on 8b44f3d35cfa (executor driver) (185/200)
[2025-07-19T18:30:19.464+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 188.0 in stage 5.0 (TID 403)
[2025-07-19T18:30:19.465+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.465+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 180 (task 398, attempt 0, stage 5.0)
[2025-07-19T18:30:19.466+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.466+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 180.0 in stage 5.0 (TID 398). 6243 bytes result sent to driver
[2025-07-19T18:30:19.466+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.467+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/177/.1.delta.8d22381c-b14a-498a-8c00-3393397216a0.TID395.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/177/1.delta
[2025-07-19T18:30:19.467+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=177),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/177] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/177/1.delta
[2025-07-19T18:30:19.467+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 190.0 in stage 5.0 (TID 404) (8b44f3d35cfa, executor driver, partition 190, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.468+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 177 (task 395, attempt 0, stage 5.0)
[2025-07-19T18:30:19.468+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 180.0 in stage 5.0 (TID 398) in 56 ms on 8b44f3d35cfa (executor driver) (186/200)
[2025-07-19T18:30:19.469+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/185/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/185/.1.delta.b05379b1-8ec3-47a8-8423-16c4dbd579ae.TID401.tmp
[2025-07-19T18:30:19.470+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 190.0 in stage 5.0 (TID 404)
[2025-07-19T18:30:19.471+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/179/.1.delta.ba5007c2-11da-4011-9c99-2d509afb056a.TID397.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/179/1.delta
[2025-07-19T18:30:19.471+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=179),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/179] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/179/1.delta
[2025-07-19T18:30:19.472+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.472+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.472+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4cf8f216
[2025-07-19T18:30:19.473+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 179 (task 397, attempt 0, stage 5.0)
[2025-07-19T18:30:19.473+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=188, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.474+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=188),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/188] for update
[2025-07-19T18:30:19.474+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.474+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 177 (task 395, attempt 0, stage 5.0)
[2025-07-19T18:30:19.474+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 179 (task 397, attempt 0, stage 5.0)
[2025-07-19T18:30:19.475+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 179.0 in stage 5.0 (TID 397). 6243 bytes result sent to driver
[2025-07-19T18:30:19.475+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 177.0 in stage 5.0 (TID 395). 6243 bytes result sent to driver
[2025-07-19T18:30:19.477+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 191.0 in stage 5.0 (TID 405) (8b44f3d35cfa, executor driver, partition 191, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.477+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 193.0 in stage 5.0 (TID 406) (8b44f3d35cfa, executor driver, partition 193, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.478+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/186/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/186/.1.delta.42bf4076-dd09-4fa0-b65a-984c1e60baf4.TID402.tmp
[2025-07-19T18:30:19.479+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 193.0 in stage 5.0 (TID 406)
[2025-07-19T18:30:19.479+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 191.0 in stage 5.0 (TID 405)
[2025-07-19T18:30:19.479+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 179.0 in stage 5.0 (TID 397) in 79 ms on 8b44f3d35cfa (executor driver) (187/200)
[2025-07-19T18:30:19.479+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 177.0 in stage 5.0 (TID 395) in 93 ms on 8b44f3d35cfa (executor driver) (188/200)
[2025-07-19T18:30:19.480+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.480+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.481+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.481+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.481+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/188/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/188/.1.delta.6bea8dd1-121e-47a5-bdae-6d93f38115ae.TID403.tmp
[2025-07-19T18:30:19.482+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35e00e24
[2025-07-19T18:30:19.482+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=190, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.482+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=190),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/190] for update
[2025-07-19T18:30:19.483+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/181/.1.delta.19e8f5ec-a60c-40ce-8983-4f1c933383f8.TID399.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/181/1.delta
[2025-07-19T18:30:19.484+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=181),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/181] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/181/1.delta
[2025-07-19T18:30:19.484+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.485+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 181 (task 399, attempt 0, stage 5.0)
[2025-07-19T18:30:19.487+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/182/.1.delta.407b0762-6c12-4e8f-adb2-d0f7f10f030d.TID400.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/182/1.delta
[2025-07-19T18:30:19.488+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=182),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/182] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/182/1.delta
[2025-07-19T18:30:19.489+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 181 (task 399, attempt 0, stage 5.0)
[2025-07-19T18:30:19.489+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b93ad0d
[2025-07-19T18:30:19.490+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 182 (task 400, attempt 0, stage 5.0)
[2025-07-19T18:30:19.491+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=193, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.491+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=193),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/193] for update
[2025-07-19T18:30:19.492+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 181.0 in stage 5.0 (TID 399). 6243 bytes result sent to driver
[2025-07-19T18:30:19.492+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 182 (task 400, attempt 0, stage 5.0)
[2025-07-19T18:30:19.492+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 195.0 in stage 5.0 (TID 407) (8b44f3d35cfa, executor driver, partition 195, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.492+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 195.0 in stage 5.0 (TID 407)
[2025-07-19T18:30:19.492+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 181.0 in stage 5.0 (TID 399) in 80 ms on 8b44f3d35cfa (executor driver) (189/200)
[2025-07-19T18:30:19.492+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.493+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 182.0 in stage 5.0 (TID 400). 6243 bytes result sent to driver
[2025-07-19T18:30:19.493+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.493+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.493+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/190/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/190/.1.delta.86d8bc61-0bee-434c-8299-c8a00a1bad4c.TID404.tmp
[2025-07-19T18:30:19.493+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 196.0 in stage 5.0 (TID 408) (8b44f3d35cfa, executor driver, partition 196, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.493+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 196.0 in stage 5.0 (TID 408)
[2025-07-19T18:30:19.499+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 182.0 in stage 5.0 (TID 400) in 75 ms on 8b44f3d35cfa (executor driver) (190/200)
[2025-07-19T18:30:19.500+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7587d4fa
[2025-07-19T18:30:19.501+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=191, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.501+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=191),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/191] for update
[2025-07-19T18:30:19.502+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.502+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.502+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.505+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f5ed43d
[2025-07-19T18:30:19.506+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=195, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.507+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=195),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/195] for update
[2025-07-19T18:30:19.507+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.508+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/193/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/193/.1.delta.f75bd2f6-0bf6-40d1-bd76-330594d59470.TID406.tmp
[2025-07-19T18:30:19.510+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/185/.1.delta.b05379b1-8ec3-47a8-8423-16c4dbd579ae.TID401.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/185/1.delta
[2025-07-19T18:30:19.510+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=185),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/185] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/185/1.delta
[2025-07-19T18:30:19.511+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/191/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/191/.1.delta.2ef2b78e-caed-40aa-b1e3-231e3aa8d5cf.TID405.tmp
[2025-07-19T18:30:19.511+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/186/.1.delta.42bf4076-dd09-4fa0-b65a-984c1e60baf4.TID402.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/186/1.delta
[2025-07-19T18:30:19.512+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=186),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/186] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/186/1.delta
[2025-07-19T18:30:19.512+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/195/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/195/.1.delta.4e73c921-8534-4d43-a5bc-618ffa086e93.TID407.tmp
[2025-07-19T18:30:19.517+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d1dd5d8
[2025-07-19T18:30:19.518+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 185 (task 401, attempt 0, stage 5.0)
[2025-07-19T18:30:19.518+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 186 (task 402, attempt 0, stage 5.0)
[2025-07-19T18:30:19.519+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=196, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.519+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=196),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/196] for update
[2025-07-19T18:30:19.520+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.521+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/188/.1.delta.6bea8dd1-121e-47a5-bdae-6d93f38115ae.TID403.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/188/1.delta
[2025-07-19T18:30:19.522+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=188),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/188] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/188/1.delta
[2025-07-19T18:30:19.523+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 186 (task 402, attempt 0, stage 5.0)
[2025-07-19T18:30:19.524+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 185 (task 401, attempt 0, stage 5.0)
[2025-07-19T18:30:19.525+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 188 (task 403, attempt 0, stage 5.0)
[2025-07-19T18:30:19.526+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 186.0 in stage 5.0 (TID 402). 6243 bytes result sent to driver
[2025-07-19T18:30:19.526+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 185.0 in stage 5.0 (TID 401). 6243 bytes result sent to driver
[2025-07-19T18:30:19.527+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 198.0 in stage 5.0 (TID 409) (8b44f3d35cfa, executor driver, partition 198, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.527+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 198.0 in stage 5.0 (TID 409)
[2025-07-19T18:30:19.527+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/196/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/196/.1.delta.9af7ef34-99b6-4102-a1f4-a90e1a0557d0.TID408.tmp
[2025-07-19T18:30:19.527+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 199.0 in stage 5.0 (TID 410) (8b44f3d35cfa, executor driver, partition 199, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.527+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 186.0 in stage 5.0 (TID 402) in 79 ms on 8b44f3d35cfa (executor driver) (191/200)
[2025-07-19T18:30:19.528+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 185.0 in stage 5.0 (TID 401) in 83 ms on 8b44f3d35cfa (executor driver) (192/200)
[2025-07-19T18:30:19.528+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 199.0 in stage 5.0 (TID 410)
[2025-07-19T18:30:19.529+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.529+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:19.530+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.531+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.532+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 188 (task 403, attempt 0, stage 5.0)
[2025-07-19T18:30:19.532+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/190/.1.delta.86d8bc61-0bee-434c-8299-c8a00a1bad4c.TID404.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/190/1.delta
[2025-07-19T18:30:19.532+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=190),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/190] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/190/1.delta
[2025-07-19T18:30:19.532+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 190 (task 404, attempt 0, stage 5.0)
[2025-07-19T18:30:19.534+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5196abc4
[2025-07-19T18:30:19.534+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=198, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.535+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=198),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/198] for update
[2025-07-19T18:30:19.535+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.536+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 188.0 in stage 5.0 (TID 403). 6243 bytes result sent to driver
[2025-07-19T18:30:19.538+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/193/.1.delta.f75bd2f6-0bf6-40d1-bd76-330594d59470.TID406.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/193/1.delta
[2025-07-19T18:30:19.539+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=193),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/193] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/193/1.delta
[2025-07-19T18:30:19.540+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@502843fa
[2025-07-19T18:30:19.541+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 193 (task 406, attempt 0, stage 5.0)
[2025-07-19T18:30:19.541+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=199, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:19.541+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=199),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/199] for update
[2025-07-19T18:30:19.541+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 26.0 in stage 1.0 (TID 411) (8b44f3d35cfa, executor driver, partition 26, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.542+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 188.0 in stage 5.0 (TID 403) in 81 ms on 8b44f3d35cfa (executor driver) (193/200)
[2025-07-19T18:30:19.542+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.543+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 190 (task 404, attempt 0, stage 5.0)
[2025-07-19T18:30:19.543+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/195/.1.delta.4e73c921-8534-4d43-a5bc-618ffa086e93.TID407.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/195/1.delta
[2025-07-19T18:30:19.544+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=195),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/195] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/195/1.delta
[2025-07-19T18:30:19.544+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 195 (task 407, attempt 0, stage 5.0)
[2025-07-19T18:30:19.544+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 193 (task 406, attempt 0, stage 5.0)
[2025-07-19T18:30:19.544+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 193.0 in stage 5.0 (TID 406). 6243 bytes result sent to driver
[2025-07-19T18:30:19.544+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 30.0 in stage 1.0 (TID 412) (8b44f3d35cfa, executor driver, partition 30, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.545+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 26.0 in stage 1.0 (TID 411)
[2025-07-19T18:30:19.545+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/191/.1.delta.2ef2b78e-caed-40aa-b1e3-231e3aa8d5cf.TID405.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/191/1.delta
[2025-07-19T18:30:19.545+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=191),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/191] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/191/1.delta
[2025-07-19T18:30:19.545+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 30.0 in stage 1.0 (TID 412)
[2025-07-19T18:30:19.545+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 191 (task 405, attempt 0, stage 5.0)
[2025-07-19T18:30:19.546+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 193.0 in stage 5.0 (TID 406) in 74 ms on 8b44f3d35cfa (executor driver) (194/200)
[2025-07-19T18:30:19.547+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.547+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.548+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 195 (task 407, attempt 0, stage 5.0)
[2025-07-19T18:30:19.549+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 191 (task 405, attempt 0, stage 5.0)
[2025-07-19T18:30:19.550+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 195.0 in stage 5.0 (TID 407). 6243 bytes result sent to driver
[2025-07-19T18:30:19.550+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/198/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/198/.1.delta.a3adef2d-33c3-4e87-a1e3-6ee058625d4d.TID409.tmp
[2025-07-19T18:30:19.551+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 191.0 in stage 5.0 (TID 405). 6243 bytes result sent to driver
[2025-07-19T18:30:19.552+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 37.0 in stage 1.0 (TID 413) (8b44f3d35cfa, executor driver, partition 37, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.552+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/199/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/199/.1.delta.aff6fc53-8cec-40e5-a390-92e5c4c38fea.TID410.tmp
[2025-07-19T18:30:19.553+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 38.0 in stage 1.0 (TID 414) (8b44f3d35cfa, executor driver, partition 38, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.553+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 195.0 in stage 5.0 (TID 407) in 62 ms on 8b44f3d35cfa (executor driver) (195/200)
[2025-07-19T18:30:19.553+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 191.0 in stage 5.0 (TID 405) in 79 ms on 8b44f3d35cfa (executor driver) (196/200)
[2025-07-19T18:30:19.554+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 37.0 in stage 1.0 (TID 413)
[2025-07-19T18:30:19.554+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 38.0 in stage 1.0 (TID 414)
[2025-07-19T18:30:19.556+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 190.0 in stage 5.0 (TID 404). 6243 bytes result sent to driver
[2025-07-19T18:30:19.556+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.557+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.558+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 41.0 in stage 1.0 (TID 415) (8b44f3d35cfa, executor driver, partition 41, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.558+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.558+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.558+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 41.0 in stage 1.0 (TID 415)
[2025-07-19T18:30:19.558+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 190.0 in stage 5.0 (TID 404) in 90 ms on 8b44f3d35cfa (executor driver) (197/200)
[2025-07-19T18:30:19.558+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@429077bf
[2025-07-19T18:30:19.559+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.560+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.560+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=30, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:19.561+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=30),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/30] for update
[2025-07-19T18:30:19.561+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/196/.1.delta.9af7ef34-99b6-4102-a1f4-a90e1a0557d0.TID408.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/196/1.delta
[2025-07-19T18:30:19.562+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=196),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/196] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/196/1.delta
[2025-07-19T18:30:19.562+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.563+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.564+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.564+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 196 (task 408, attempt 0, stage 5.0)
[2025-07-19T18:30:19.564+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 196 (task 408, attempt 0, stage 5.0)
[2025-07-19T18:30:19.565+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 196.0 in stage 5.0 (TID 408). 6243 bytes result sent to driver
[2025-07-19T18:30:19.565+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3fb55e47
[2025-07-19T18:30:19.565+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 196.0 in stage 5.0 (TID 408) in 67 ms on 8b44f3d35cfa (executor driver) (198/200)
[2025-07-19T18:30:19.565+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 43.0 in stage 1.0 (TID 416) (8b44f3d35cfa, executor driver, partition 43, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.566+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 43.0 in stage 1.0 (TID 416)
[2025-07-19T18:30:19.567+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=37, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:19.568+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=37),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/37] for update
[2025-07-19T18:30:19.569+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.569+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.570+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.570+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@136e97c8
[2025-07-19T18:30:19.571+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=38, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:19.571+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=38),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/38] for update
[2025-07-19T18:30:19.571+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/30/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/30/.1.delta.05037f76-0a9d-4934-b746-f22f28524ef8.TID412.tmp
[2025-07-19T18:30:19.571+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.571+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/37/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/37/.1.delta.8b0de8b3-ed20-4817-afb1-f7aec9f48518.TID413.tmp
[2025-07-19T18:30:19.571+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@61598685
[2025-07-19T18:30:19.576+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=26, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:19.576+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=26),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/26] for update
[2025-07-19T18:30:19.576+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.579+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/198/.1.delta.a3adef2d-33c3-4e87-a1e3-6ee058625d4d.TID409.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/198/1.delta
[2025-07-19T18:30:19.580+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=198),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/198] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/198/1.delta
[2025-07-19T18:30:19.580+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 198 (task 409, attempt 0, stage 5.0)
[2025-07-19T18:30:19.581+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/38/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/38/.1.delta.2d47aefc-cc44-4080-9603-8b7d2ab1c050.TID414.tmp
[2025-07-19T18:30:19.582+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39e1b03a
[2025-07-19T18:30:19.583+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=43, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:19.584+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=43),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/43] for update
[2025-07-19T18:30:19.584+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 198 (task 409, attempt 0, stage 5.0)
[2025-07-19T18:30:19.585+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/26/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/26/.1.delta.08a3f2b3-ba59-4df7-830a-31fe4ecb68e8.TID411.tmp
[2025-07-19T18:30:19.587+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 198.0 in stage 5.0 (TID 409). 6200 bytes result sent to driver
[2025-07-19T18:30:19.588+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 46.0 in stage 1.0 (TID 417) (8b44f3d35cfa, executor driver, partition 46, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.588+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 46.0 in stage 1.0 (TID 417)
[2025-07-19T18:30:19.588+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.589+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 198.0 in stage 5.0 (TID 409) in 63 ms on 8b44f3d35cfa (executor driver) (199/200)
[2025-07-19T18:30:19.589+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.590+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.591+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/199/.1.delta.aff6fc53-8cec-40e5-a390-92e5c4c38fea.TID410.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/199/1.delta
[2025-07-19T18:30:19.592+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=199),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/199] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/199/1.delta
[2025-07-19T18:30:19.593+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 199 (task 410, attempt 0, stage 5.0)
[2025-07-19T18:30:19.594+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@14726349
[2025-07-19T18:30:19.596+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=41, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:19.597+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=41),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/41] for update
[2025-07-19T18:30:19.598+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.599+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 199 (task 410, attempt 0, stage 5.0)
[2025-07-19T18:30:19.599+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/43/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/43/.1.delta.e936ce76-45a4-43d4-b346-b100da172212.TID416.tmp
[2025-07-19T18:30:19.601+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 199.0 in stage 5.0 (TID 410). 6200 bytes result sent to driver
[2025-07-19T18:30:19.601+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 47.0 in stage 1.0 (TID 418) (8b44f3d35cfa, executor driver, partition 47, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.601+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 199.0 in stage 5.0 (TID 410) in 73 ms on 8b44f3d35cfa (executor driver) (200/200)
[2025-07-19T18:30:19.602+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2025-07-19T18:30:19.602+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 47.0 in stage 1.0 (TID 418)
[2025-07-19T18:30:19.602+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DAGScheduler: ResultStage 5 (start at <unknown>:0) finished in 6.309 s
[2025-07-19T18:30:19.602+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-19T18:30:19.603+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
[2025-07-19T18:30:19.604+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DAGScheduler: Job 1 finished: start at <unknown>:0, took 7.607828 s
[2025-07-19T18:30:19.604+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@45b277b3
[2025-07-19T18:30:19.605+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=46, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:19.605+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=46),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/46] for update
[2025-07-19T18:30:19.606+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Feedback_raw, format=PARQUET)] is committing.
[2025-07-19T18:30:19.607+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO SparkWrite: Committing epoch 0 for query 8f08e6eb-a24d-42b2-b7ec-753236e406e1 in append mode
[2025-07-19T18:30:19.608+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.609+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.609+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.610+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/30/.1.delta.05037f76-0a9d-4934-b746-f22f28524ef8.TID412.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/30/1.delta
[2025-07-19T18:30:19.610+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=30),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/30] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/30/1.delta
[2025-07-19T18:30:19.612+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 30 (task 412, attempt 0, stage 1.0)
[2025-07-19T18:30:19.613+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1dc8fb1c
[2025-07-19T18:30:19.613+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/41/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/41/.1.delta.100ef7ad-0f35-4bed-8003-47e5ad39b125.TID415.tmp
[2025-07-19T18:30:19.613+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=47, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:19.614+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=47),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/47] for update
[2025-07-19T18:30:19.614+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/46/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/46/.1.delta.1fe12534-62f3-4937-a063-dd604a1fc426.TID417.tmp
[2025-07-19T18:30:19.618+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/37/.1.delta.8b0de8b3-ed20-4817-afb1-f7aec9f48518.TID413.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/37/1.delta
[2025-07-19T18:30:19.619+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=37),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/37] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/37/1.delta
[2025-07-19T18:30:19.621+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 37 (task 413, attempt 0, stage 1.0)
[2025-07-19T18:30:19.622+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.625+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/38/.1.delta.2d47aefc-cc44-4080-9603-8b7d2ab1c050.TID414.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/38/1.delta
[2025-07-19T18:30:19.625+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=38),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/38] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/38/1.delta
[2025-07-19T18:30:19.629+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 38 (task 414, attempt 0, stage 1.0)
[2025-07-19T18:30:19.630+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO SparkWrite: Committing streaming append with 58 new data files to table my_catalog.bronze.Feedback_raw
[2025-07-19T18:30:19.630+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/47/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/47/.1.delta.570ab0fa-2bf7-45a1-ae33-8e6d62f2a60f.TID418.tmp
[2025-07-19T18:30:19.632+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/26/.1.delta.08a3f2b3-ba59-4df7-830a-31fe4ecb68e8.TID411.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/26/1.delta
[2025-07-19T18:30:19.634+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=26),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/26] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/26/1.delta
[2025-07-19T18:30:19.636+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 26 (task 411, attempt 0, stage 1.0)
[2025-07-19T18:30:19.636+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 30 (task 412, attempt 0, stage 1.0)
[2025-07-19T18:30:19.637+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 30.0 in stage 1.0 (TID 412). 9035 bytes result sent to driver
[2025-07-19T18:30:19.637+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 48.0 in stage 1.0 (TID 419) (8b44f3d35cfa, executor driver, partition 48, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.638+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 30.0 in stage 1.0 (TID 412) in 92 ms on 8b44f3d35cfa (executor driver) (9/200)
[2025-07-19T18:30:19.638+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 48.0 in stage 1.0 (TID 419)
[2025-07-19T18:30:19.640+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/43/.1.delta.e936ce76-45a4-43d4-b346-b100da172212.TID416.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/43/1.delta
[2025-07-19T18:30:19.641+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=43),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/43] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/43/1.delta
[2025-07-19T18:30:19.642+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 43 (task 416, attempt 0, stage 1.0)
[2025-07-19T18:30:19.642+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.642+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.649+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 37 (task 413, attempt 0, stage 1.0)
[2025-07-19T18:30:19.651+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@397fbdea
[2025-07-19T18:30:19.652+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=48, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:19.652+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=48),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/48] for update
[2025-07-19T18:30:19.654+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 37.0 in stage 1.0 (TID 413). 9078 bytes result sent to driver
[2025-07-19T18:30:19.654+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 51.0 in stage 1.0 (TID 420) (8b44f3d35cfa, executor driver, partition 51, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.654+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 37.0 in stage 1.0 (TID 413) in 101 ms on 8b44f3d35cfa (executor driver) (10/200)
[2025-07-19T18:30:19.656+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 51.0 in stage 1.0 (TID 420)
[2025-07-19T18:30:19.657+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 38 (task 414, attempt 0, stage 1.0)
[2025-07-19T18:30:19.658+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.659+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 38.0 in stage 1.0 (TID 414). 9074 bytes result sent to driver
[2025-07-19T18:30:19.660+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 26 (task 411, attempt 0, stage 1.0)
[2025-07-19T18:30:19.660+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 52.0 in stage 1.0 (TID 421) (8b44f3d35cfa, executor driver, partition 52, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.661+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/41/.1.delta.100ef7ad-0f35-4bed-8003-47e5ad39b125.TID415.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/41/1.delta
[2025-07-19T18:30:19.661+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=41),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/41] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/41/1.delta
[2025-07-19T18:30:19.662+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 26.0 in stage 1.0 (TID 411). 9030 bytes result sent to driver
[2025-07-19T18:30:19.662+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.662+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.664+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 41 (task 415, attempt 0, stage 1.0)
[2025-07-19T18:30:19.664+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 53.0 in stage 1.0 (TID 422) (8b44f3d35cfa, executor driver, partition 53, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.666+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 52.0 in stage 1.0 (TID 421)
[2025-07-19T18:30:19.667+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/46/.1.delta.1fe12534-62f3-4937-a063-dd604a1fc426.TID417.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/46/1.delta
[2025-07-19T18:30:19.668+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 53.0 in stage 1.0 (TID 422)
[2025-07-19T18:30:19.668+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 26.0 in stage 1.0 (TID 411) in 119 ms on 8b44f3d35cfa (executor driver) (11/200)
[2025-07-19T18:30:19.669+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/48/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/48/.1.delta.5bb94b61-073f-4e89-a99b-8ac6b85b3e06.TID419.tmp
[2025-07-19T18:30:19.670+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.670+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T18:30:19.672+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=46),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/46] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/46/1.delta
[2025-07-19T18:30:19.674+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 38.0 in stage 1.0 (TID 414) in 112 ms on 8b44f3d35cfa (executor driver) (12/200)
[2025-07-19T18:30:19.675+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.676+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T18:30:19.676+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 46 (task 417, attempt 0, stage 1.0)
[2025-07-19T18:30:19.676+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e341a6f
[2025-07-19T18:30:19.676+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=51, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:19.676+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=51),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/51] for update
[2025-07-19T18:30:19.677+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 43 (task 416, attempt 0, stage 1.0)
[2025-07-19T18:30:19.678+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/47/.1.delta.570ab0fa-2bf7-45a1-ae33-8e6d62f2a60f.TID418.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/47/1.delta
[2025-07-19T18:30:19.678+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=47),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/47] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/47/1.delta
[2025-07-19T18:30:19.679+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 47 (task 418, attempt 0, stage 1.0)
[2025-07-19T18:30:19.680+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 43.0 in stage 1.0 (TID 416). 9033 bytes result sent to driver
[2025-07-19T18:30:19.680+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.681+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 58.0 in stage 1.0 (TID 423) (8b44f3d35cfa, executor driver, partition 58, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.681+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 43.0 in stage 1.0 (TID 416) in 117 ms on 8b44f3d35cfa (executor driver) (13/200)
[2025-07-19T18:30:19.682+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 41 (task 415, attempt 0, stage 1.0)
[2025-07-19T18:30:19.682+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 41.0 in stage 1.0 (TID 415). 9033 bytes result sent to driver
[2025-07-19T18:30:19.683+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 58.0 in stage 1.0 (TID 423)
[2025-07-19T18:30:19.685+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 63.0 in stage 1.0 (TID 424) (8b44f3d35cfa, executor driver, partition 63, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.686+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@13a6fc02
[2025-07-19T18:30:19.687+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.688+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:19.688+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 41.0 in stage 1.0 (TID 415) in 133 ms on 8b44f3d35cfa (executor driver) (14/200)
[2025-07-19T18:30:19.689+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 63.0 in stage 1.0 (TID 424)
[2025-07-19T18:30:19.689+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=52, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:19.690+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=52),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/52] for update
[2025-07-19T18:30:19.691+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.692+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.693+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.694+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/51/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/51/.1.delta.12676023-5d0b-4b7f-9bbd-1cf1b849097e.TID420.tmp
[2025-07-19T18:30:19.696+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@657d99f4
[2025-07-19T18:30:19.698+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/52/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/52/.1.delta.19b14e91-4854-4422-a609-f4492c5bf543.TID421.tmp
[2025-07-19T18:30:19.699+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=53, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:19.700+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=53),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/53] for update
[2025-07-19T18:30:19.701+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 46 (task 417, attempt 0, stage 1.0)
[2025-07-19T18:30:19.702+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 46.0 in stage 1.0 (TID 417). 9039 bytes result sent to driver
[2025-07-19T18:30:19.703+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.703+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 64.0 in stage 1.0 (TID 425) (8b44f3d35cfa, executor driver, partition 64, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.703+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 46.0 in stage 1.0 (TID 417) in 113 ms on 8b44f3d35cfa (executor driver) (15/200)
[2025-07-19T18:30:19.704+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 64.0 in stage 1.0 (TID 425)
[2025-07-19T18:30:19.704+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 47 (task 418, attempt 0, stage 1.0)
[2025-07-19T18:30:19.704+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.704+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.704+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 47.0 in stage 1.0 (TID 418). 9018 bytes result sent to driver
[2025-07-19T18:30:19.704+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 66.0 in stage 1.0 (TID 426) (8b44f3d35cfa, executor driver, partition 66, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.704+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1fdffdeb
[2025-07-19T18:30:19.708+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 66.0 in stage 1.0 (TID 426)
[2025-07-19T18:30:19.708+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 47.0 in stage 1.0 (TID 418) in 108 ms on 8b44f3d35cfa (executor driver) (16/200)
[2025-07-19T18:30:19.709+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/53/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/53/.1.delta.f6ac5428-b23b-4ffc-a9a9-e550d12875ae.TID422.tmp
[2025-07-19T18:30:19.711+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=58, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:19.711+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=58),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/58] for update
[2025-07-19T18:30:19.711+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.712+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.712+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.713+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/48/.1.delta.5bb94b61-073f-4e89-a99b-8ac6b85b3e06.TID419.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/48/1.delta
[2025-07-19T18:30:19.713+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=48),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/48] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/48/1.delta
[2025-07-19T18:30:19.714+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 48 (task 419, attempt 0, stage 1.0)
[2025-07-19T18:30:19.716+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2cd863cb
[2025-07-19T18:30:19.717+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=63, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:19.717+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=63),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/63] for update
[2025-07-19T18:30:19.717+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.719+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/58/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/58/.1.delta.fbc530df-d8c9-4e9b-ab4c-c215293f1f61.TID423.tmp
[2025-07-19T18:30:19.721+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63ff8dc8
[2025-07-19T18:30:19.724+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=66, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:19.725+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=66),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/66] for update
[2025-07-19T18:30:19.725+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.729+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/63/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/63/.1.delta.336b18be-434d-41a5-9ef4-8a182be015b2.TID424.tmp
[2025-07-19T18:30:19.732+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@48ae8f5b
[2025-07-19T18:30:19.733+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=64, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:19.734+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=64),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/64] for update
[2025-07-19T18:30:19.734+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 48 (task 419, attempt 0, stage 1.0)
[2025-07-19T18:30:19.734+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/51/.1.delta.12676023-5d0b-4b7f-9bbd-1cf1b849097e.TID420.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/51/1.delta
[2025-07-19T18:30:19.734+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=51),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/51] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/51/1.delta
[2025-07-19T18:30:19.734+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 51 (task 420, attempt 0, stage 1.0)
[2025-07-19T18:30:19.734+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.735+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 48.0 in stage 1.0 (TID 419). 9035 bytes result sent to driver
[2025-07-19T18:30:19.735+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 68.0 in stage 1.0 (TID 427) (8b44f3d35cfa, executor driver, partition 68, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.735+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 68.0 in stage 1.0 (TID 427)
[2025-07-19T18:30:19.736+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 48.0 in stage 1.0 (TID 419) in 99 ms on 8b44f3d35cfa (executor driver) (17/200)
[2025-07-19T18:30:19.736+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/66/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/66/.1.delta.35cde18d-573b-4641-b66c-09039f1882ee.TID426.tmp
[2025-07-19T18:30:19.736+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/52/.1.delta.19b14e91-4854-4422-a609-f4492c5bf543.TID421.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/52/1.delta
[2025-07-19T18:30:19.736+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=52),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/52] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/52/1.delta
[2025-07-19T18:30:19.737+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 52 (task 421, attempt 0, stage 1.0)
[2025-07-19T18:30:19.738+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.739+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.743+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/53/.1.delta.f6ac5428-b23b-4ffc-a9a9-e550d12875ae.TID422.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/53/1.delta
[2025-07-19T18:30:19.744+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=53),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/53] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/53/1.delta
[2025-07-19T18:30:19.745+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3331f9fa
[2025-07-19T18:30:19.746+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 53 (task 422, attempt 0, stage 1.0)
[2025-07-19T18:30:19.746+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/64/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/64/.1.delta.818930d0-aded-4211-ae49-782f73e878af.TID425.tmp
[2025-07-19T18:30:19.747+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=68, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:19.748+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=68),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/68] for update
[2025-07-19T18:30:19.749+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/58/.1.delta.fbc530df-d8c9-4e9b-ab4c-c215293f1f61.TID423.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/58/1.delta
[2025-07-19T18:30:19.750+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=58),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/58] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/58/1.delta
[2025-07-19T18:30:19.750+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.750+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 58 (task 423, attempt 0, stage 1.0)
[2025-07-19T18:30:19.760+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/68/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/68/.1.delta.be7b6dc2-af74-4d93-9e53-ebbbc779fb1d.TID427.tmp
[2025-07-19T18:30:19.763+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 51 (task 420, attempt 0, stage 1.0)
[2025-07-19T18:30:19.769+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 52 (task 421, attempt 0, stage 1.0)
[2025-07-19T18:30:19.770+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 51.0 in stage 1.0 (TID 420). 9129 bytes result sent to driver
[2025-07-19T18:30:19.771+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 52.0 in stage 1.0 (TID 421). 9070 bytes result sent to driver
[2025-07-19T18:30:19.772+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 53 (task 422, attempt 0, stage 1.0)
[2025-07-19T18:30:19.773+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 53.0 in stage 1.0 (TID 422). 9082 bytes result sent to driver
[2025-07-19T18:30:19.773+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/63/.1.delta.336b18be-434d-41a5-9ef4-8a182be015b2.TID424.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/63/1.delta
[2025-07-19T18:30:19.774+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=63),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/63] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/63/1.delta
[2025-07-19T18:30:19.774+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 72.0 in stage 1.0 (TID 428) (8b44f3d35cfa, executor driver, partition 72, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.776+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 63 (task 424, attempt 0, stage 1.0)
[2025-07-19T18:30:19.776+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 73.0 in stage 1.0 (TID 429) (8b44f3d35cfa, executor driver, partition 73, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.777+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 72.0 in stage 1.0 (TID 428)
[2025-07-19T18:30:19.778+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 83.0 in stage 1.0 (TID 430) (8b44f3d35cfa, executor driver, partition 83, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.779+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 73.0 in stage 1.0 (TID 429)
[2025-07-19T18:30:19.780+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.780+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.780+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 83.0 in stage 1.0 (TID 430)
[2025-07-19T18:30:19.781+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 51.0 in stage 1.0 (TID 420) in 127 ms on 8b44f3d35cfa (executor driver) (18/200)
[2025-07-19T18:30:19.781+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 53.0 in stage 1.0 (TID 422) in 121 ms on 8b44f3d35cfa (executor driver) (19/200)
[2025-07-19T18:30:19.781+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.782+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.782+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 52.0 in stage 1.0 (TID 421) in 127 ms on 8b44f3d35cfa (executor driver) (20/200)
[2025-07-19T18:30:19.783+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.783+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.784+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 58 (task 423, attempt 0, stage 1.0)
[2025-07-19T18:30:19.784+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 58.0 in stage 1.0 (TID 423). 9082 bytes result sent to driver
[2025-07-19T18:30:19.786+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@495909e3
[2025-07-19T18:30:19.786+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 85.0 in stage 1.0 (TID 431) (8b44f3d35cfa, executor driver, partition 85, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.789+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=73, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:19.789+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 58.0 in stage 1.0 (TID 423) in 111 ms on 8b44f3d35cfa (executor driver) (21/200)
[2025-07-19T18:30:19.790+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=73),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/73] for update
[2025-07-19T18:30:19.790+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/66/.1.delta.35cde18d-573b-4641-b66c-09039f1882ee.TID426.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/66/1.delta
[2025-07-19T18:30:19.791+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=66),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/66] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/66/1.delta
[2025-07-19T18:30:19.791+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 85.0 in stage 1.0 (TID 431)
[2025-07-19T18:30:19.792+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.792+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.792+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.793+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/64/.1.delta.818930d0-aded-4211-ae49-782f73e878af.TID425.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/64/1.delta
[2025-07-19T18:30:19.794+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 66 (task 426, attempt 0, stage 1.0)
[2025-07-19T18:30:19.796+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=64),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/64] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/64/1.delta
[2025-07-19T18:30:19.801+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 64 (task 425, attempt 0, stage 1.0)
[2025-07-19T18:30:19.802+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7e522d9d
[2025-07-19T18:30:19.803+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/73/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/73/.1.delta.198548c7-b314-4de1-9dff-cf403aed9a39.TID429.tmp
[2025-07-19T18:30:19.803+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=72, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:19.804+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=72),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/72] for update
[2025-07-19T18:30:19.804+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/68/.1.delta.be7b6dc2-af74-4d93-9e53-ebbbc779fb1d.TID427.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/68/1.delta
[2025-07-19T18:30:19.804+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=68),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/68] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/68/1.delta
[2025-07-19T18:30:19.804+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 63 (task 424, attempt 0, stage 1.0)
[2025-07-19T18:30:19.805+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 68 (task 427, attempt 0, stage 1.0)
[2025-07-19T18:30:19.808+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 63.0 in stage 1.0 (TID 424). 9136 bytes result sent to driver
[2025-07-19T18:30:19.809+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HadoopTableOperations: Committed a new metadata file s3a://warehouse/bronze/Feedback_raw/metadata/v18.metadata.json
[2025-07-19T18:30:19.815+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.820+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 87.0 in stage 1.0 (TID 432) (8b44f3d35cfa, executor driver, partition 87, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.822+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 87.0 in stage 1.0 (TID 432)
[2025-07-19T18:30:19.824+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1def97dd
[2025-07-19T18:30:19.825+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 63.0 in stage 1.0 (TID 424) in 134 ms on 8b44f3d35cfa (executor driver) (22/200)
[2025-07-19T18:30:19.825+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=83, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:19.826+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=83),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/83] for update
[2025-07-19T18:30:19.827+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 64 (task 425, attempt 0, stage 1.0)
[2025-07-19T18:30:19.828+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 64.0 in stage 1.0 (TID 425). 9072 bytes result sent to driver
[2025-07-19T18:30:19.828+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.829+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.829+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 94.0 in stage 1.0 (TID 433) (8b44f3d35cfa, executor driver, partition 94, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.830+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 66 (task 426, attempt 0, stage 1.0)
[2025-07-19T18:30:19.832+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.833+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 64.0 in stage 1.0 (TID 425) in 127 ms on 8b44f3d35cfa (executor driver) (23/200)
[2025-07-19T18:30:19.833+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 94.0 in stage 1.0 (TID 433)
[2025-07-19T18:30:19.833+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 8b44f3d35cfa:40517 in memory (size: 19.3 KiB, free: 434.2 MiB)
[2025-07-19T18:30:19.833+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 66.0 in stage 1.0 (TID 426). 9086 bytes result sent to driver
[2025-07-19T18:30:19.833+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 95.0 in stage 1.0 (TID 434) (8b44f3d35cfa, executor driver, partition 95, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.834+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 95.0 in stage 1.0 (TID 434)
[2025-07-19T18:30:19.834+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 66.0 in stage 1.0 (TID 426) in 122 ms on 8b44f3d35cfa (executor driver) (24/200)
[2025-07-19T18:30:19.834+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.834+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.834+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.834+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.834+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25976f94
[2025-07-19T18:30:19.835+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=85, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:19.835+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=85),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/85] for update
[2025-07-19T18:30:19.835+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/72/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/72/.1.delta.0c3d06b4-829f-4f2b-afd9-a6928c909a2a.TID428.tmp
[2025-07-19T18:30:19.836+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 68 (task 427, attempt 0, stage 1.0)
[2025-07-19T18:30:19.837+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.837+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 68.0 in stage 1.0 (TID 427). 9072 bytes result sent to driver
[2025-07-19T18:30:19.838+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 100.0 in stage 1.0 (TID 435) (8b44f3d35cfa, executor driver, partition 100, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.838+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 68.0 in stage 1.0 (TID 427) in 105 ms on 8b44f3d35cfa (executor driver) (25/200)
[2025-07-19T18:30:19.841+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a2c65e0
[2025-07-19T18:30:19.842+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=87, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:19.842+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 100.0 in stage 1.0 (TID 435)
[2025-07-19T18:30:19.843+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=87),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/87] for update
[2025-07-19T18:30:19.843+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.844+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.845+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/85/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/85/.1.delta.d23b342b-2dc3-409a-b83c-7914d68372cc.TID431.tmp
[2025-07-19T18:30:19.846+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.847+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@365eb7cb
[2025-07-19T18:30:19.848+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=94, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:19.848+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=94),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/94] for update
[2025-07-19T18:30:19.852+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/83/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/83/.1.delta.de9704b0-ef97-43d9-a77b-6ec386f301dc.TID430.tmp
[2025-07-19T18:30:19.852+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.855+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7125c636
[2025-07-19T18:30:19.856+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=95, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:19.857+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=95),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/95] for update
[2025-07-19T18:30:19.857+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.858+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/73/.1.delta.198548c7-b314-4de1-9dff-cf403aed9a39.TID429.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/73/1.delta
[2025-07-19T18:30:19.860+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=73),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/73] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/73/1.delta
[2025-07-19T18:30:19.860+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 73 (task 429, attempt 0, stage 1.0)
[2025-07-19T18:30:19.861+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/87/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/87/.1.delta.b8e96150-ff84-4122-89da-d621dadd9caa.TID432.tmp
[2025-07-19T18:30:19.867+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/94/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/94/.1.delta.f28dc33f-566f-4a09-981b-bbf0d3e84c58.TID433.tmp
[2025-07-19T18:30:19.868+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@191cd430
[2025-07-19T18:30:19.869+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=100, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:19.870+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=100),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/100] for update
[2025-07-19T18:30:19.870+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.871+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 73 (task 429, attempt 0, stage 1.0)
[2025-07-19T18:30:19.873+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 73.0 in stage 1.0 (TID 429). 9027 bytes result sent to driver
[2025-07-19T18:30:19.874+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/72/.1.delta.0c3d06b4-829f-4f2b-afd9-a6928c909a2a.TID428.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/72/1.delta
[2025-07-19T18:30:19.875+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 106.0 in stage 1.0 (TID 436) (8b44f3d35cfa, executor driver, partition 106, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.876+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=72),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/72] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/72/1.delta
[2025-07-19T18:30:19.876+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 106.0 in stage 1.0 (TID 436)
[2025-07-19T18:30:19.876+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 73.0 in stage 1.0 (TID 429) in 101 ms on 8b44f3d35cfa (executor driver) (26/200)
[2025-07-19T18:30:19.876+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/95/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/95/.1.delta.599c8654-838b-4844-a9c1-aa1e6657f4c7.TID434.tmp
[2025-07-19T18:30:19.876+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 72 (task 428, attempt 0, stage 1.0)
[2025-07-19T18:30:19.876+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO SnapshotProducer: Committed snapshot 1074946122931769771 (FastAppend)
[2025-07-19T18:30:19.877+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.879+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.881+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/100/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/100/.1.delta.c87caa59-2314-42c6-958d-2d4b7adb74a3.TID435.tmp
[2025-07-19T18:30:19.883+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/85/.1.delta.d23b342b-2dc3-409a-b83c-7914d68372cc.TID431.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/85/1.delta
[2025-07-19T18:30:19.884+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=85),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/85] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/85/1.delta
[2025-07-19T18:30:19.884+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 85 (task 431, attempt 0, stage 1.0)
[2025-07-19T18:30:19.887+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52af6412
[2025-07-19T18:30:19.887+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=106, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:19.889+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=106),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/106] for update
[2025-07-19T18:30:19.890+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.890+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/83/.1.delta.de9704b0-ef97-43d9-a77b-6ec386f301dc.TID430.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/83/1.delta
[2025-07-19T18:30:19.891+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=83),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/83] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/83/1.delta
[2025-07-19T18:30:19.893+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 83 (task 430, attempt 0, stage 1.0)
[2025-07-19T18:30:19.893+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 72 (task 428, attempt 0, stage 1.0)
[2025-07-19T18:30:19.894+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 72.0 in stage 1.0 (TID 428). 9027 bytes result sent to driver
[2025-07-19T18:30:19.895+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 107.0 in stage 1.0 (TID 437) (8b44f3d35cfa, executor driver, partition 107, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.895+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 107.0 in stage 1.0 (TID 437)
[2025-07-19T18:30:19.896+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 72.0 in stage 1.0 (TID 428) in 124 ms on 8b44f3d35cfa (executor driver) (27/200)
[2025-07-19T18:30:19.897+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.898+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.898+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/106/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/106/.1.delta.fe99c687-5c13-4358-83e3-a526e1edc4a1.TID436.tmp
[2025-07-19T18:30:19.899+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/87/.1.delta.b8e96150-ff84-4122-89da-d621dadd9caa.TID432.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/87/1.delta
[2025-07-19T18:30:19.899+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=87),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/87] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/87/1.delta
[2025-07-19T18:30:19.899+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 87 (task 432, attempt 0, stage 1.0)
[2025-07-19T18:30:19.901+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d0b41b6
[2025-07-19T18:30:19.905+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/94/.1.delta.f28dc33f-566f-4a09-981b-bbf0d3e84c58.TID433.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/94/1.delta
[2025-07-19T18:30:19.907+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=94),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/94] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/94/1.delta
[2025-07-19T18:30:19.908+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=107, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:19.909+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=107),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/107] for update
[2025-07-19T18:30:19.910+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 94 (task 433, attempt 0, stage 1.0)
[2025-07-19T18:30:19.911+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/95/.1.delta.599c8654-838b-4844-a9c1-aa1e6657f4c7.TID434.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/95/1.delta
[2025-07-19T18:30:19.911+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=95),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/95] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/95/1.delta
[2025-07-19T18:30:19.912+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.912+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 95 (task 434, attempt 0, stage 1.0)
[2025-07-19T18:30:19.913+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 83 (task 430, attempt 0, stage 1.0)
[2025-07-19T18:30:19.914+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 83.0 in stage 1.0 (TID 430). 9029 bytes result sent to driver
[2025-07-19T18:30:19.914+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO LoggingMetricsReporter: Received metrics report: CommitReport{tableName=my_catalog.bronze.Feedback_raw, snapshotId=1074946122931769771, sequenceNumber=17, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.2830125S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=CounterResult{unit=COUNT, value=58}, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=433}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=CounterResult{unit=COUNT, value=69}, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=513}, addedFilesSizeInBytes=CounterResult{unit=BYTES, value=167010}, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=1244297}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}}, metadata={engine-version=3.5.6, app-id=local-1752949808869, engine-name=spark, iceberg-version=Apache Iceberg 1.4.0 (commit 10367c380098c2e06a49521a33681ac7f6c64b2c)}}
[2025-07-19T18:30:19.917+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO SparkWrite: Committed in 284 ms
[2025-07-19T18:30:19.918+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Feedback_raw, format=PARQUET)] committed.
[2025-07-19T18:30:19.919+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO WatermarkTracker: Updating event-time watermark from 0 to 1752777003000 ms
[2025-07-19T18:30:19.919+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 85 (task 431, attempt 0, stage 1.0)
[2025-07-19T18:30:19.919+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 110.0 in stage 1.0 (TID 438) (8b44f3d35cfa, executor driver, partition 110, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.919+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 87 (task 432, attempt 0, stage 1.0)
[2025-07-19T18:30:19.919+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/100/.1.delta.c87caa59-2314-42c6-958d-2d4b7adb74a3.TID435.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/100/1.delta
[2025-07-19T18:30:19.919+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 83.0 in stage 1.0 (TID 430) in 143 ms on 8b44f3d35cfa (executor driver) (28/200)
[2025-07-19T18:30:19.919+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=100),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/100] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/100/1.delta
[2025-07-19T18:30:19.919+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 110.0 in stage 1.0 (TID 438)
[2025-07-19T18:30:19.919+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 85.0 in stage 1.0 (TID 431). 9048 bytes result sent to driver
[2025-07-19T18:30:19.920+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 87.0 in stage 1.0 (TID 432). 9033 bytes result sent to driver
[2025-07-19T18:30:19.920+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.920+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.923+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 100 (task 435, attempt 0, stage 1.0)
[2025-07-19T18:30:19.924+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 111.0 in stage 1.0 (TID 439) (8b44f3d35cfa, executor driver, partition 111, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.926+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 113.0 in stage 1.0 (TID 440) (8b44f3d35cfa, executor driver, partition 113, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.927+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 94 (task 433, attempt 0, stage 1.0)
[2025-07-19T18:30:19.927+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/commits/0 using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/commits/.0.4a744b7c-c793-427c-885f-962fbfd221f9.tmp
[2025-07-19T18:30:19.929+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 111.0 in stage 1.0 (TID 439)
[2025-07-19T18:30:19.930+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 94.0 in stage 1.0 (TID 433). 9077 bytes result sent to driver
[2025-07-19T18:30:19.930+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 87.0 in stage 1.0 (TID 432) in 110 ms on 8b44f3d35cfa (executor driver) (29/200)
[2025-07-19T18:30:19.932+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 113.0 in stage 1.0 (TID 440)
[2025-07-19T18:30:19.933+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 123.0 in stage 1.0 (TID 441) (8b44f3d35cfa, executor driver, partition 123, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.935+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 94.0 in stage 1.0 (TID 433) in 105 ms on 8b44f3d35cfa (executor driver) (30/200)
[2025-07-19T18:30:19.935+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 85.0 in stage 1.0 (TID 431) in 142 ms on 8b44f3d35cfa (executor driver) (31/200)
[2025-07-19T18:30:19.936+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1199a0fd
[2025-07-19T18:30:19.936+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=110, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:19.936+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=110),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/110] for update
[2025-07-19T18:30:19.937+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/106/.1.delta.fe99c687-5c13-4358-83e3-a526e1edc4a1.TID436.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/106/1.delta
[2025-07-19T18:30:19.937+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=106),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/106] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/106/1.delta
[2025-07-19T18:30:19.938+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/107/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/107/.1.delta.1cf4be54-bc25-4ccc-a5cb-968d6f2781ae.TID437.tmp
[2025-07-19T18:30:19.938+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 123.0 in stage 1.0 (TID 441)
[2025-07-19T18:30:19.938+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 106 (task 436, attempt 0, stage 1.0)
[2025-07-19T18:30:19.938+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.939+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.940+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 95 (task 434, attempt 0, stage 1.0)
[2025-07-19T18:30:19.940+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 95.0 in stage 1.0 (TID 434). 9037 bytes result sent to driver
[2025-07-19T18:30:19.940+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 128.0 in stage 1.0 (TID 442) (8b44f3d35cfa, executor driver, partition 128, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.941+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.942+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.942+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.942+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.943+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.943+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 95.0 in stage 1.0 (TID 434) in 114 ms on 8b44f3d35cfa (executor driver) (32/200)
[2025-07-19T18:30:19.944+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19493ed7
[2025-07-19T18:30:19.944+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=113, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:19.946+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=113),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/113] for update
[2025-07-19T18:30:19.947+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 128.0 in stage 1.0 (TID 442)
[2025-07-19T18:30:19.947+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.947+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.948+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.950+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 100 (task 435, attempt 0, stage 1.0)
[2025-07-19T18:30:19.951+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 100.0 in stage 1.0 (TID 435). 9035 bytes result sent to driver
[2025-07-19T18:30:19.951+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 136.0 in stage 1.0 (TID 443) (8b44f3d35cfa, executor driver, partition 136, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.951+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 136.0 in stage 1.0 (TID 443)
[2025-07-19T18:30:19.951+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4bf52e8b
[2025-07-19T18:30:19.951+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 100.0 in stage 1.0 (TID 435) in 110 ms on 8b44f3d35cfa (executor driver) (33/200)
[2025-07-19T18:30:19.952+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=111, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:19.952+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=111),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/111] for update
[2025-07-19T18:30:19.952+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.952+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.952+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.952+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/110/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/110/.1.delta.86ab3a12-bb7d-4fdb-8b3f-d68a90896ecd.TID438.tmp
[2025-07-19T18:30:19.954+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74190994
[2025-07-19T18:30:19.955+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/113/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/113/.1.delta.4569b373-e1c2-492c-a841-f273f3be1f44.TID440.tmp
[2025-07-19T18:30:19.957+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/111/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/111/.1.delta.35c53e9e-7ed6-4fb9-8767-b2024f03595d.TID439.tmp
[2025-07-19T18:30:19.959+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=123, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:19.960+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=123),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/123] for update
[2025-07-19T18:30:19.960+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.963+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Committed partition 106 (task 436, attempt 0, stage 1.0)
[2025-07-19T18:30:19.964+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Finished task 106.0 in stage 1.0 (TID 436). 9035 bytes result sent to driver
[2025-07-19T18:30:19.966+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Starting task 137.0 in stage 1.0 (TID 444) (8b44f3d35cfa, executor driver, partition 137, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:19.968+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/commits/.0.4a744b7c-c793-427c-885f-962fbfd221f9.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/commits/0
[2025-07-19T18:30:19.969+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4126187c
[2025-07-19T18:30:19.970+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO TaskSetManager: Finished task 106.0 in stage 1.0 (TID 436) in 94 ms on 8b44f3d35cfa (executor driver) (34/200)
[2025-07-19T18:30:19.971+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=136, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:19.972+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO Executor: Running task 137.0 in stage 1.0 (TID 444)
[2025-07-19T18:30:19.972+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=136),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/136] for update
[2025-07-19T18:30:19.973+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:19.974+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:19.974+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:19.975+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/107/.1.delta.1cf4be54-bc25-4ccc-a5cb-968d6f2781ae.TID437.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/107/1.delta
[2025-07-19T18:30:19.975+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=107),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/107] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/107/1.delta
[2025-07-19T18:30:19.976+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO MicroBatchExecution: Streaming query made progress: {
[2025-07-19T18:30:19.977+0000] {subprocess.py:93} INFO -   "id" : "8f08e6eb-a24d-42b2-b7ec-753236e406e1",
[2025-07-19T18:30:19.978+0000] {subprocess.py:93} INFO -   "runId" : "648e1751-6c40-4a55-ad88-6fed441ec877",
[2025-07-19T18:30:19.979+0000] {subprocess.py:93} INFO -   "name" : null,
[2025-07-19T18:30:19.979+0000] {subprocess.py:93} INFO -   "timestamp" : "2025-07-19T18:30:10.904Z",
[2025-07-19T18:30:19.980+0000] {subprocess.py:93} INFO -   "batchId" : 0,
[2025-07-19T18:30:19.980+0000] {subprocess.py:93} INFO -   "numInputRows" : 69,
[2025-07-19T18:30:19.980+0000] {subprocess.py:93} INFO -   "inputRowsPerSecond" : 0.0,
[2025-07-19T18:30:19.981+0000] {subprocess.py:93} INFO -   "processedRowsPerSecond" : 7.615894039735099,
[2025-07-19T18:30:19.983+0000] {subprocess.py:93} INFO -   "durationMs" : {
[2025-07-19T18:30:19.984+0000] {subprocess.py:93} INFO -     "addBatch" : 8420,
[2025-07-19T18:30:19.985+0000] {subprocess.py:93} INFO -     "commitOffsets" : 53,
[2025-07-19T18:30:19.985+0000] {subprocess.py:93} INFO -     "getBatch" : 5,
[2025-07-19T18:30:19.985+0000] {subprocess.py:93} INFO -     "latestOffset" : 174,
[2025-07-19T18:30:19.985+0000] {subprocess.py:93} INFO -     "queryPlanning" : 378,
[2025-07-19T18:30:19.985+0000] {subprocess.py:93} INFO -     "triggerExecution" : 9060,
[2025-07-19T18:30:19.986+0000] {subprocess.py:93} INFO -     "walCommit" : 26
[2025-07-19T18:30:19.987+0000] {subprocess.py:93} INFO -   },
[2025-07-19T18:30:19.987+0000] {subprocess.py:93} INFO -   "eventTime" : {
[2025-07-19T18:30:19.988+0000] {subprocess.py:93} INFO -     "avg" : "2025-07-19T18:12:55.565Z",
[2025-07-19T18:30:19.989+0000] {subprocess.py:93} INFO -     "max" : "2025-07-19T18:30:03.000Z",
[2025-07-19T18:30:19.990+0000] {subprocess.py:93} INFO -     "min" : "2025-07-19T18:00:01.000Z",
[2025-07-19T18:30:19.990+0000] {subprocess.py:93} INFO -     "watermark" : "1970-01-01T00:00:00.000Z"
[2025-07-19T18:30:19.991+0000] {subprocess.py:93} INFO -   },
[2025-07-19T18:30:19.992+0000] {subprocess.py:93} INFO -   "stateOperators" : [ {
[2025-07-19T18:30:19.993+0000] {subprocess.py:93} INFO -     "operatorName" : "dedupe",
[2025-07-19T18:30:19.993+0000] {subprocess.py:93} INFO -     "numRowsTotal" : 69,
[2025-07-19T18:30:19.994+0000] {subprocess.py:93} INFO -     "numRowsUpdated" : 69,
[2025-07-19T18:30:19.996+0000] {subprocess.py:93} INFO -     "allUpdatesTimeMs" : 1024,
[2025-07-19T18:30:19.996+0000] {subprocess.py:93} INFO -     "numRowsRemoved" : 0,
[2025-07-19T18:30:19.996+0000] {subprocess.py:93} INFO -     "allRemovalsTimeMs" : 90,
[2025-07-19T18:30:19.996+0000] {subprocess.py:93} INFO -     "commitTimeMs" : 10038,
[2025-07-19T18:30:19.997+0000] {subprocess.py:93} INFO -     "memoryUsedBytes" : 65336,
[2025-07-19T18:30:19.997+0000] {subprocess.py:93} INFO -     "numRowsDroppedByWatermark" : 0,
[2025-07-19T18:30:19.999+0000] {subprocess.py:93} INFO -     "numShufflePartitions" : 200,
[2025-07-19T18:30:19.999+0000] {subprocess.py:93} INFO -     "numStateStoreInstances" : 200,
[2025-07-19T18:30:20.000+0000] {subprocess.py:93} INFO -     "customMetrics" : {
[2025-07-19T18:30:20.001+0000] {subprocess.py:93} INFO -       "loadedMapCacheHitCount" : 0,
[2025-07-19T18:30:20.002+0000] {subprocess.py:93} INFO -       "loadedMapCacheMissCount" : 0,
[2025-07-19T18:30:20.003+0000] {subprocess.py:93} INFO -       "numDroppedDuplicateRows" : 0,
[2025-07-19T18:30:20.003+0000] {subprocess.py:93} INFO -       "stateOnCurrentVersionSizeBytes" : 36536
[2025-07-19T18:30:20.003+0000] {subprocess.py:93} INFO -     }
[2025-07-19T18:30:20.003+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T18:30:20.003+0000] {subprocess.py:93} INFO -   "sources" : [ {
[2025-07-19T18:30:20.003+0000] {subprocess.py:93} INFO -     "description" : "KafkaV2[Subscribe[feedback]]",
[2025-07-19T18:30:20.003+0000] {subprocess.py:93} INFO -     "startOffset" : null,
[2025-07-19T18:30:20.004+0000] {subprocess.py:93} INFO -     "endOffset" : {
[2025-07-19T18:30:20.004+0000] {subprocess.py:93} INFO -       "feedback" : {
[2025-07-19T18:30:20.004+0000] {subprocess.py:93} INFO -         "0" : 69
[2025-07-19T18:30:20.005+0000] {subprocess.py:93} INFO -       }
[2025-07-19T18:30:20.008+0000] {subprocess.py:93} INFO -     },
[2025-07-19T18:30:20.009+0000] {subprocess.py:93} INFO -     "latestOffset" : {
[2025-07-19T18:30:20.009+0000] {subprocess.py:93} INFO -       "feedback" : {
[2025-07-19T18:30:20.009+0000] {subprocess.py:93} INFO -         "0" : 69
[2025-07-19T18:30:20.009+0000] {subprocess.py:93} INFO -       }
[2025-07-19T18:30:20.010+0000] {subprocess.py:93} INFO -     },
[2025-07-19T18:30:20.010+0000] {subprocess.py:93} INFO -     "numInputRows" : 69,
[2025-07-19T18:30:20.010+0000] {subprocess.py:93} INFO -     "inputRowsPerSecond" : 0.0,
[2025-07-19T18:30:20.010+0000] {subprocess.py:93} INFO -     "processedRowsPerSecond" : 7.615894039735099,
[2025-07-19T18:30:20.010+0000] {subprocess.py:93} INFO -     "metrics" : {
[2025-07-19T18:30:20.010+0000] {subprocess.py:93} INFO -       "avgOffsetsBehindLatest" : "0.0",
[2025-07-19T18:30:20.010+0000] {subprocess.py:93} INFO -       "maxOffsetsBehindLatest" : "0",
[2025-07-19T18:30:20.010+0000] {subprocess.py:93} INFO -       "minOffsetsBehindLatest" : "0"
[2025-07-19T18:30:20.010+0000] {subprocess.py:93} INFO -     }
[2025-07-19T18:30:20.010+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T18:30:20.010+0000] {subprocess.py:93} INFO -   "sink" : {
[2025-07-19T18:30:20.011+0000] {subprocess.py:93} INFO -     "description" : "my_catalog.bronze.Feedback_raw",
[2025-07-19T18:30:20.011+0000] {subprocess.py:93} INFO -     "numOutputRows" : 69
[2025-07-19T18:30:20.011+0000] {subprocess.py:93} INFO -   }
[2025-07-19T18:30:20.011+0000] {subprocess.py:93} INFO - }
[2025-07-19T18:30:20.011+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@62768622
[2025-07-19T18:30:20.012+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/123/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/123/.1.delta.bcaf4b21-0c74-4db6-b28f-27676446f023.TID441.tmp
[2025-07-19T18:30:20.012+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/136/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/136/.1.delta.323eb709-cda6-4f4d-91cd-9cbc1527f814.TID443.tmp
[2025-07-19T18:30:20.012+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=128, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.013+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=128),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/128] for update
[2025-07-19T18:30:20.014+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 107 (task 437, attempt 0, stage 1.0)
[2025-07-19T18:30:20.017+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.018+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/110/.1.delta.86ab3a12-bb7d-4fdb-8b3f-d68a90896ecd.TID438.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/110/1.delta
[2025-07-19T18:30:20.018+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=110),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/110] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/110/1.delta
[2025-07-19T18:30:20.018+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 110 (task 438, attempt 0, stage 1.0)
[2025-07-19T18:30:20.018+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@64f6f9f6
[2025-07-19T18:30:20.018+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=137, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.019+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=137),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/137] for update
[2025-07-19T18:30:20.019+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/128/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/128/.1.delta.26a14f91-ad89-41bc-8615-8b2d01fff023.TID442.tmp
[2025-07-19T18:30:20.019+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.020+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/111/.1.delta.35c53e9e-7ed6-4fb9-8767-b2024f03595d.TID439.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/111/1.delta
[2025-07-19T18:30:20.020+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=111),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/111] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/111/1.delta
[2025-07-19T18:30:20.020+0000] {subprocess.py:93} INFO - 25/07/19 18:30:19 INFO DataWritingSparkTask: Commit authorized for partition 111 (task 439, attempt 0, stage 1.0)
[2025-07-19T18:30:20.020+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/137/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/137/.1.delta.ad61526f-a786-4014-9fde-7e57170f6c06.TID444.tmp
[2025-07-19T18:30:20.020+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 107 (task 437, attempt 0, stage 1.0)
[2025-07-19T18:30:20.020+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 107.0 in stage 1.0 (TID 437). 9041 bytes result sent to driver
[2025-07-19T18:30:20.021+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 140.0 in stage 1.0 (TID 445) (8b44f3d35cfa, executor driver, partition 140, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.021+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/113/.1.delta.4569b373-e1c2-492c-a841-f273f3be1f44.TID440.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/113/1.delta
[2025-07-19T18:30:20.021+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=113),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/113] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/113/1.delta
[2025-07-19T18:30:20.021+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 140.0 in stage 1.0 (TID 445)
[2025-07-19T18:30:20.021+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 107.0 in stage 1.0 (TID 437) in 124 ms on 8b44f3d35cfa (executor driver) (35/200)
[2025-07-19T18:30:20.021+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 110 (task 438, attempt 0, stage 1.0)
[2025-07-19T18:30:20.022+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 110.0 in stage 1.0 (TID 438). 9018 bytes result sent to driver
[2025-07-19T18:30:20.022+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 144.0 in stage 1.0 (TID 446) (8b44f3d35cfa, executor driver, partition 144, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.022+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 110.0 in stage 1.0 (TID 438) in 104 ms on 8b44f3d35cfa (executor driver) (36/200)
[2025-07-19T18:30:20.023+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 144.0 in stage 1.0 (TID 446)
[2025-07-19T18:30:20.023+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/offsets/1 using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/offsets/.1.20dcd7fc-f712-4ee3-bc66-2193cbcb8e49.tmp
[2025-07-19T18:30:20.023+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.028+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
[2025-07-19T18:30:20.029+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/123/.1.delta.bcaf4b21-0c74-4db6-b28f-27676446f023.TID441.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/123/1.delta
[2025-07-19T18:30:20.030+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=123),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/123] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/123/1.delta
[2025-07-19T18:30:20.030+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/128/.1.delta.26a14f91-ad89-41bc-8615-8b2d01fff023.TID442.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/128/1.delta
[2025-07-19T18:30:20.030+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 113 (task 440, attempt 0, stage 1.0)
[2025-07-19T18:30:20.031+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=128),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/128] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/128/1.delta
[2025-07-19T18:30:20.031+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 111 (task 439, attempt 0, stage 1.0)
[2025-07-19T18:30:20.031+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 123 (task 441, attempt 0, stage 1.0)
[2025-07-19T18:30:20.031+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.031+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
[2025-07-19T18:30:20.031+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 128 (task 442, attempt 0, stage 1.0)
[2025-07-19T18:30:20.031+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 111.0 in stage 1.0 (TID 439). 9034 bytes result sent to driver
[2025-07-19T18:30:20.031+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 111.0 in stage 1.0 (TID 439) in 107 ms on 8b44f3d35cfa (executor driver) (37/200)
[2025-07-19T18:30:20.031+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 145.0 in stage 1.0 (TID 447) (8b44f3d35cfa, executor driver, partition 145, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.031+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 145.0 in stage 1.0 (TID 447)
[2025-07-19T18:30:20.036+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/136/.1.delta.323eb709-cda6-4f4d-91cd-9cbc1527f814.TID443.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/136/1.delta
[2025-07-19T18:30:20.038+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=136),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/136] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/136/1.delta
[2025-07-19T18:30:20.038+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4851b1ed
[2025-07-19T18:30:20.039+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 136 (task 443, attempt 0, stage 1.0)
[2025-07-19T18:30:20.040+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=140, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.040+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=140),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/140] for update
[2025-07-19T18:30:20.042+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.043+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:20.044+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/137/.1.delta.ad61526f-a786-4014-9fde-7e57170f6c06.TID444.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/137/1.delta
[2025-07-19T18:30:20.044+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=137),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/137] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/137/1.delta
[2025-07-19T18:30:20.044+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 137 (task 444, attempt 0, stage 1.0)
[2025-07-19T18:30:20.045+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.047+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@27a9000
[2025-07-19T18:30:20.048+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=145, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.048+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=145),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/145] for update
[2025-07-19T18:30:20.052+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.053+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 123 (task 441, attempt 0, stage 1.0)
[2025-07-19T18:30:20.054+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/offsets/.1.20dcd7fc-f712-4ee3-bc66-2193cbcb8e49.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/offsets/1
[2025-07-19T18:30:20.054+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO MicroBatchExecution: Committed offsets for batch 1. Metadata OffsetSeqMetadata(1752777003000,1752949819994,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.optimizer.pruneFiltersCanPruneStreamingSubplan -> false, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2025-07-19T18:30:20.054+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 128 (task 442, attempt 0, stage 1.0)
[2025-07-19T18:30:20.055+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 123.0 in stage 1.0 (TID 441). 9029 bytes result sent to driver
[2025-07-19T18:30:20.055+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 128.0 in stage 1.0 (TID 442). 9025 bytes result sent to driver
[2025-07-19T18:30:20.055+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 149.0 in stage 1.0 (TID 448) (8b44f3d35cfa, executor driver, partition 149, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.055+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 149.0 in stage 1.0 (TID 448)
[2025-07-19T18:30:20.057+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.057+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 150.0 in stage 1.0 (TID 449) (8b44f3d35cfa, executor driver, partition 150, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.058+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.058+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 123.0 in stage 1.0 (TID 441) in 131 ms on 8b44f3d35cfa (executor driver) (38/200)
[2025-07-19T18:30:20.058+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 128.0 in stage 1.0 (TID 442) in 123 ms on 8b44f3d35cfa (executor driver) (39/200)
[2025-07-19T18:30:20.058+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 150.0 in stage 1.0 (TID 449)
[2025-07-19T18:30:20.060+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 113 (task 440, attempt 0, stage 1.0)
[2025-07-19T18:30:20.061+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/145/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/145/.1.delta.c2576fd5-59ee-47f5-aebc-c8f5f8876582.TID447.tmp
[2025-07-19T18:30:20.061+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 113.0 in stage 1.0 (TID 440). 9031 bytes result sent to driver
[2025-07-19T18:30:20.061+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 153.0 in stage 1.0 (TID 450) (8b44f3d35cfa, executor driver, partition 153, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.061+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 153.0 in stage 1.0 (TID 450)
[2025-07-19T18:30:20.062+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@75fd0903
[2025-07-19T18:30:20.062+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/140/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/140/.1.delta.bf2674bc-3afd-4244-957d-12b98f4cca01.TID445.tmp
[2025-07-19T18:30:20.062+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 136 (task 443, attempt 0, stage 1.0)
[2025-07-19T18:30:20.062+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 136.0 in stage 1.0 (TID 443). 9035 bytes result sent to driver
[2025-07-19T18:30:20.062+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 113.0 in stage 1.0 (TID 440) in 138 ms on 8b44f3d35cfa (executor driver) (40/200)
[2025-07-19T18:30:20.063+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 137 (task 444, attempt 0, stage 1.0)
[2025-07-19T18:30:20.063+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.063+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.063+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 137.0 in stage 1.0 (TID 444). 9045 bytes result sent to driver
[2025-07-19T18:30:20.063+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.063+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.064+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 155.0 in stage 1.0 (TID 451) (8b44f3d35cfa, executor driver, partition 155, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.068+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 155.0 in stage 1.0 (TID 451)
[2025-07-19T18:30:20.069+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Feedback_raw
[2025-07-19T18:30:20.069+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Feedback_raw
[2025-07-19T18:30:20.070+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Feedback_raw
[2025-07-19T18:30:20.070+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 158.0 in stage 1.0 (TID 452) (8b44f3d35cfa, executor driver, partition 158, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.072+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 137.0 in stage 1.0 (TID 444) in 104 ms on 8b44f3d35cfa (executor driver) (41/200)
[2025-07-19T18:30:20.072+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 136.0 in stage 1.0 (TID 443) in 124 ms on 8b44f3d35cfa (executor driver) (42/200)
[2025-07-19T18:30:20.072+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=144, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.072+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=144),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/144] for update
[2025-07-19T18:30:20.073+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.074+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 158.0 in stage 1.0 (TID 452)
[2025-07-19T18:30:20.074+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.078+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/144/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/144/.1.delta.3b26f5ff-b908-4a17-9211-1a4ad14f6c40.TID446.tmp
[2025-07-19T18:30:20.081+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T18:30:20.081+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@75f07c68
[2025-07-19T18:30:20.082+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.082+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.082+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=150, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.082+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=150),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/150] for update
[2025-07-19T18:30:20.083+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Feedback_raw
[2025-07-19T18:30:20.083+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Feedback_raw
[2025-07-19T18:30:20.083+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Feedback_raw
[2025-07-19T18:30:20.083+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.090+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d40c9f3
[2025-07-19T18:30:20.091+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/140/.1.delta.bf2674bc-3afd-4244-957d-12b98f4cca01.TID445.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/140/1.delta
[2025-07-19T18:30:20.092+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=140),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/140] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/140/1.delta
[2025-07-19T18:30:20.093+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=153, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.093+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 140 (task 445, attempt 0, stage 1.0)
[2025-07-19T18:30:20.093+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=153),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/153] for update
[2025-07-19T18:30:20.094+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/150/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/150/.1.delta.684ac3a2-b9a5-4c1d-8c95-5b03794c11e7.TID449.tmp
[2025-07-19T18:30:20.094+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.094+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5b14db71
[2025-07-19T18:30:20.095+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=149, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.095+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=149),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/149] for update
[2025-07-19T18:30:20.097+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Feedback_raw
[2025-07-19T18:30:20.098+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Feedback_raw
[2025-07-19T18:30:20.098+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Feedback_raw
[2025-07-19T18:30:20.099+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.099+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/145/.1.delta.c2576fd5-59ee-47f5-aebc-c8f5f8876582.TID447.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/145/1.delta
[2025-07-19T18:30:20.101+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=145),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/145] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/145/1.delta
[2025-07-19T18:30:20.102+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 145 (task 447, attempt 0, stage 1.0)
[2025-07-19T18:30:20.103+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/153/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/153/.1.delta.45ae2094-d934-4385-a157-f203da26976b.TID450.tmp
[2025-07-19T18:30:20.104+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@36c414de
[2025-07-19T18:30:20.106+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=155, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.107+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=155),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/155] for update
[2025-07-19T18:30:20.107+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.107+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/144/.1.delta.3b26f5ff-b908-4a17-9211-1a4ad14f6c40.TID446.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/144/1.delta
[2025-07-19T18:30:20.107+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=144),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/144] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/144/1.delta
[2025-07-19T18:30:20.108+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 144 (task 446, attempt 0, stage 1.0)
[2025-07-19T18:30:20.109+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@30ef6ccb
[2025-07-19T18:30:20.110+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=158, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.111+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=158),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/158] for update
[2025-07-19T18:30:20.111+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/155/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/155/.1.delta.56fa27cf-49d3-42f2-a081-fad4383621d4.TID451.tmp
[2025-07-19T18:30:20.112+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.115+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/149/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/149/.1.delta.5338b754-efff-4893-b9dc-abe1a4a4d1f1.TID448.tmp
[2025-07-19T18:30:20.115+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 140 (task 445, attempt 0, stage 1.0)
[2025-07-19T18:30:20.116+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/150/.1.delta.684ac3a2-b9a5-4c1d-8c95-5b03794c11e7.TID449.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/150/1.delta
[2025-07-19T18:30:20.116+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=150),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/150] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/150/1.delta
[2025-07-19T18:30:20.117+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 150 (task 449, attempt 0, stage 1.0)
[2025-07-19T18:30:20.117+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 140.0 in stage 1.0 (TID 445). 9082 bytes result sent to driver
[2025-07-19T18:30:20.119+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 160.0 in stage 1.0 (TID 453) (8b44f3d35cfa, executor driver, partition 160, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.120+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 140.0 in stage 1.0 (TID 445) in 110 ms on 8b44f3d35cfa (executor driver) (43/200)
[2025-07-19T18:30:20.123+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/158/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/158/.1.delta.b0aea95c-30a8-4d17-9a3f-a9b663b5d2a3.TID452.tmp
[2025-07-19T18:30:20.124+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 145 (task 447, attempt 0, stage 1.0)
[2025-07-19T18:30:20.125+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 160.0 in stage 1.0 (TID 453)
[2025-07-19T18:30:20.126+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.127+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:20.127+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 145.0 in stage 1.0 (TID 447). 9037 bytes result sent to driver
[2025-07-19T18:30:20.130+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 150 (task 449, attempt 0, stage 1.0)
[2025-07-19T18:30:20.131+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 150.0 in stage 1.0 (TID 449). 9040 bytes result sent to driver
[2025-07-19T18:30:20.132+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/153/.1.delta.45ae2094-d934-4385-a157-f203da26976b.TID450.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/153/1.delta
[2025-07-19T18:30:20.134+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=153),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/153] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/153/1.delta
[2025-07-19T18:30:20.135+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 145.0 in stage 1.0 (TID 447) in 100 ms on 8b44f3d35cfa (executor driver) (44/200)
[2025-07-19T18:30:20.136+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 153 (task 450, attempt 0, stage 1.0)
[2025-07-19T18:30:20.136+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 161.0 in stage 1.0 (TID 454) (8b44f3d35cfa, executor driver, partition 161, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.136+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 209.0 KiB, free 433.2 MiB)
[2025-07-19T18:30:20.136+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 161.0 in stage 1.0 (TID 454)
[2025-07-19T18:30:20.136+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 150.0 in stage 1.0 (TID 449) in 78 ms on 8b44f3d35cfa (executor driver) (45/200)
[2025-07-19T18:30:20.136+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 163.0 in stage 1.0 (TID 455) (8b44f3d35cfa, executor driver, partition 163, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.136+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 163.0 in stage 1.0 (TID 455)
[2025-07-19T18:30:20.137+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.137+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.137+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.2 MiB)
[2025-07-19T18:30:20.138+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.138+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.139+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 8b44f3d35cfa:40517 (size: 35.4 KiB, free: 434.1 MiB)
[2025-07-19T18:30:20.141+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO SparkContext: Created broadcast 15 from start at <unknown>:0
[2025-07-19T18:30:20.141+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 32.0 KiB, free 433.1 MiB)
[2025-07-19T18:30:20.142+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 433.1 MiB)
[2025-07-19T18:30:20.142+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@273f51
[2025-07-19T18:30:20.142+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 8b44f3d35cfa:40517 (size: 29.5 KiB, free: 434.1 MiB)
[2025-07-19T18:30:20.142+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO SparkContext: Created broadcast 16 from start at <unknown>:0
[2025-07-19T18:30:20.143+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO WriteToDataSourceV2Exec: Start processing data source write support: MicroBatchWrite[epoch: 1, writer: IcebergStreamingWrite(table=my_catalog.bronze.Feedback_raw, format=PARQUET)]. The input RDD has 200 partitions.
[2025-07-19T18:30:20.143+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO SparkContext: Starting job: start at <unknown>:0
[2025-07-19T18:30:20.143+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DAGScheduler: Registering RDD 33 (start at <unknown>:0) as input to shuffle 4
[2025-07-19T18:30:20.144+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DAGScheduler: Got job 4 (start at <unknown>:0) with 200 output partitions
[2025-07-19T18:30:20.144+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DAGScheduler: Final stage: ResultStage 9 (start at <unknown>:0)
[2025-07-19T18:30:20.145+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
[2025-07-19T18:30:20.145+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DAGScheduler: Missing parents: List()
[2025-07-19T18:30:20.146+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=160, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.146+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=160),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/160] for update
[2025-07-19T18:30:20.146+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/155/.1.delta.56fa27cf-49d3-42f2-a081-fad4383621d4.TID451.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/155/1.delta
[2025-07-19T18:30:20.146+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=155),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/155] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/155/1.delta
[2025-07-19T18:30:20.146+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DAGScheduler: Submitting ResultStage 9 (StateStoreRDD[35] at start at <unknown>:0), which has no missing parents
[2025-07-19T18:30:20.146+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 155 (task 451, attempt 0, stage 1.0)
[2025-07-19T18:30:20.147+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/149/.1.delta.5338b754-efff-4893-b9dc-abe1a4a4d1f1.TID448.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/149/1.delta
[2025-07-19T18:30:20.148+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=149),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/149] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/149/1.delta
[2025-07-19T18:30:20.150+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 149 (task 448, attempt 0, stage 1.0)
[2025-07-19T18:30:20.151+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63205c01
[2025-07-19T18:30:20.151+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.152+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=163, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.153+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=163),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/163] for update
[2025-07-19T18:30:20.154+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.157+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 153 (task 450, attempt 0, stage 1.0)
[2025-07-19T18:30:20.158+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/158/.1.delta.b0aea95c-30a8-4d17-9a3f-a9b663b5d2a3.TID452.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/158/1.delta
[2025-07-19T18:30:20.159+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=158),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/158] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/158/1.delta
[2025-07-19T18:30:20.159+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 153.0 in stage 1.0 (TID 450). 9039 bytes result sent to driver
[2025-07-19T18:30:20.160+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 169.0 in stage 1.0 (TID 456) (8b44f3d35cfa, executor driver, partition 169, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.160+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 169.0 in stage 1.0 (TID 456)
[2025-07-19T18:30:20.160+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 153.0 in stage 1.0 (TID 450) in 100 ms on 8b44f3d35cfa (executor driver) (46/200)
[2025-07-19T18:30:20.163+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.163+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.164+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 158 (task 452, attempt 0, stage 1.0)
[2025-07-19T18:30:20.164+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7aa01a5b
[2025-07-19T18:30:20.165+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 149 (task 448, attempt 0, stage 1.0)
[2025-07-19T18:30:20.166+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 155 (task 451, attempt 0, stage 1.0)
[2025-07-19T18:30:20.166+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/160/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/160/.1.delta.e6af008b-da2d-4996-8a8f-6c86fdaa051d.TID453.tmp
[2025-07-19T18:30:20.169+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 144 (task 446, attempt 0, stage 1.0)
[2025-07-19T18:30:20.169+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 144.0 in stage 1.0 (TID 446). 9031 bytes result sent to driver
[2025-07-19T18:30:20.170+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=161, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.170+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=161),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/161] for update
[2025-07-19T18:30:20.171+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/163/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/163/.1.delta.0c18e456-1c41-4657-9138-3f5e24e67ec9.TID455.tmp
[2025-07-19T18:30:20.172+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 149.0 in stage 1.0 (TID 448). 9041 bytes result sent to driver
[2025-07-19T18:30:20.172+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.173+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 155.0 in stage 1.0 (TID 451). 9050 bytes result sent to driver
[2025-07-19T18:30:20.173+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 170.0 in stage 1.0 (TID 457) (8b44f3d35cfa, executor driver, partition 170, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.173+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 170.0 in stage 1.0 (TID 457)
[2025-07-19T18:30:20.174+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 179.0 in stage 1.0 (TID 458) (8b44f3d35cfa, executor driver, partition 179, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.174+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 181.0 in stage 1.0 (TID 459) (8b44f3d35cfa, executor driver, partition 181, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.175+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 149.0 in stage 1.0 (TID 448) in 117 ms on 8b44f3d35cfa (executor driver) (47/200)
[2025-07-19T18:30:20.175+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 144.0 in stage 1.0 (TID 446) in 155 ms on 8b44f3d35cfa (executor driver) (48/200)
[2025-07-19T18:30:20.175+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 155.0 in stage 1.0 (TID 451) in 107 ms on 8b44f3d35cfa (executor driver) (49/200)
[2025-07-19T18:30:20.176+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 181.0 in stage 1.0 (TID 459)
[2025-07-19T18:30:20.176+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 179.0 in stage 1.0 (TID 458)
[2025-07-19T18:30:20.177+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.177+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.182+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43ed08ff
[2025-07-19T18:30:20.182+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=169, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.183+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=169),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/169] for update
[2025-07-19T18:30:20.183+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.183+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.184+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.188+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 158 (task 452, attempt 0, stage 1.0)
[2025-07-19T18:30:20.190+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 158.0 in stage 1.0 (TID 452). 9042 bytes result sent to driver
[2025-07-19T18:30:20.190+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 183.0 in stage 1.0 (TID 460) (8b44f3d35cfa, executor driver, partition 183, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.190+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 183.0 in stage 1.0 (TID 460)
[2025-07-19T18:30:20.191+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 158.0 in stage 1.0 (TID 452) in 121 ms on 8b44f3d35cfa (executor driver) (50/200)
[2025-07-19T18:30:20.191+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.191+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T18:30:20.191+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.192+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.192+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/161/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/161/.1.delta.5d55a51a-481f-4709-a598-3691355d11ae.TID454.tmp
[2025-07-19T18:30:20.201+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f63245a
[2025-07-19T18:30:20.201+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=179, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.202+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=179),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/179] for update
[2025-07-19T18:30:20.202+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.207+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/169/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/169/.1.delta.00c1be6f-be1a-4a7f-ba2a-33339c2a232b.TID456.tmp
[2025-07-19T18:30:20.208+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 31.7 KiB, free 433.1 MiB)
[2025-07-19T18:30:20.208+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 15.8 KiB, free 433.1 MiB)
[2025-07-19T18:30:20.209+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/160/.1.delta.e6af008b-da2d-4996-8a8f-6c86fdaa051d.TID453.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/160/1.delta
[2025-07-19T18:30:20.209+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=160),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/160] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/160/1.delta
[2025-07-19T18:30:20.211+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 8b44f3d35cfa:40517 (size: 15.8 KiB, free: 434.1 MiB)
[2025-07-19T18:30:20.212+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b5a33b1
[2025-07-19T18:30:20.213+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 160 (task 453, attempt 0, stage 1.0)
[2025-07-19T18:30:20.214+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/179/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/179/.1.delta.5bd03580-3de9-42e5-ae59-6b29d3e896ad.TID458.tmp
[2025-07-19T18:30:20.214+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1611
[2025-07-19T18:30:20.216+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/163/.1.delta.0c18e456-1c41-4657-9138-3f5e24e67ec9.TID455.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/163/1.delta
[2025-07-19T18:30:20.216+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=163),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/163] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/163/1.delta
[2025-07-19T18:30:20.218+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 9 (StateStoreRDD[35] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-07-19T18:30:20.218+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSchedulerImpl: Adding task set 9.0 with 200 tasks resource profile 0
[2025-07-19T18:30:20.219+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=170, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.219+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=170),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/170] for update
[2025-07-19T18:30:20.219+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 163 (task 455, attempt 0, stage 1.0)
[2025-07-19T18:30:20.220+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.226+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55bcac09
[2025-07-19T18:30:20.227+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/170/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/170/.1.delta.228db00f-0fa4-49d5-9e6d-dde71fc823d2.TID457.tmp
[2025-07-19T18:30:20.230+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=183, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.232+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=183),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/183] for update
[2025-07-19T18:30:20.233+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 163 (task 455, attempt 0, stage 1.0)
[2025-07-19T18:30:20.233+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.234+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 163.0 in stage 1.0 (TID 455). 9070 bytes result sent to driver
[2025-07-19T18:30:20.234+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 190.0 in stage 1.0 (TID 461) (8b44f3d35cfa, executor driver, partition 190, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.234+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 163.0 in stage 1.0 (TID 455) in 100 ms on 8b44f3d35cfa (executor driver) (51/200)
[2025-07-19T18:30:20.234+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 160 (task 453, attempt 0, stage 1.0)
[2025-07-19T18:30:20.234+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 160.0 in stage 1.0 (TID 453). 9076 bytes result sent to driver
[2025-07-19T18:30:20.235+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 160.0 in stage 1.0 (TID 453) in 115 ms on 8b44f3d35cfa (executor driver) (52/200)
[2025-07-19T18:30:20.235+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 190.0 in stage 1.0 (TID 461)
[2025-07-19T18:30:20.235+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 192.0 in stage 1.0 (TID 462) (8b44f3d35cfa, executor driver, partition 192, NODE_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.235+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 192.0 in stage 1.0 (TID 462)
[2025-07-19T18:30:20.238+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.239+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.239+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.239+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:20.241+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3910c1f8
[2025-07-19T18:30:20.242+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=181, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.242+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=181),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/181] for update
[2025-07-19T18:30:20.244+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/161/.1.delta.5d55a51a-481f-4709-a598-3691355d11ae.TID454.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/161/1.delta
[2025-07-19T18:30:20.245+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=161),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/161] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/161/1.delta
[2025-07-19T18:30:20.246+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/183/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/183/.1.delta.fedfc5fb-8c9b-41c3-94cf-778474adea21.TID460.tmp
[2025-07-19T18:30:20.247+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 161 (task 454, attempt 0, stage 1.0)
[2025-07-19T18:30:20.249+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.250+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ef0647
[2025-07-19T18:30:20.251+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=190, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.252+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=190),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/190] for update
[2025-07-19T18:30:20.254+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.254+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/169/.1.delta.00c1be6f-be1a-4a7f-ba2a-33339c2a232b.TID456.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/169/1.delta
[2025-07-19T18:30:20.255+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=169),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/169] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/169/1.delta
[2025-07-19T18:30:20.256+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 169 (task 456, attempt 0, stage 1.0)
[2025-07-19T18:30:20.260+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/190/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/190/.1.delta.1bd0d231-15d3-4e75-bb5b-b59ef4fc179b.TID461.tmp
[2025-07-19T18:30:20.260+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@347776b5
[2025-07-19T18:30:20.261+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/181/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/181/.1.delta.d56f5af1-325e-471b-a33d-85bfff2394dd.TID459.tmp
[2025-07-19T18:30:20.262+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=192, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.263+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=192),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/192] for update
[2025-07-19T18:30:20.263+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.266+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/179/.1.delta.5bd03580-3de9-42e5-ae59-6b29d3e896ad.TID458.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/179/1.delta
[2025-07-19T18:30:20.266+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=179),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/179] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/179/1.delta
[2025-07-19T18:30:20.266+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 179 (task 458, attempt 0, stage 1.0)
[2025-07-19T18:30:20.273+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 161 (task 454, attempt 0, stage 1.0)
[2025-07-19T18:30:20.276+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 161.0 in stage 1.0 (TID 454). 9078 bytes result sent to driver
[2025-07-19T18:30:20.277+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 463) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.277+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 161.0 in stage 1.0 (TID 454) in 145 ms on 8b44f3d35cfa (executor driver) (53/200)
[2025-07-19T18:30:20.278+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 0.0 in stage 1.0 (TID 463)
[2025-07-19T18:30:20.278+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.278+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.280+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/170/.1.delta.228db00f-0fa4-49d5-9e6d-dde71fc823d2.TID457.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/170/1.delta
[2025-07-19T18:30:20.280+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=170),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/170] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/170/1.delta
[2025-07-19T18:30:20.281+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 170 (task 457, attempt 0, stage 1.0)
[2025-07-19T18:30:20.285+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/192/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/192/.1.delta.22e99672-2a34-4708-ba9d-b87f5776c5ce.TID462.tmp
[2025-07-19T18:30:20.286+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 169 (task 456, attempt 0, stage 1.0)
[2025-07-19T18:30:20.287+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 169.0 in stage 1.0 (TID 456). 9053 bytes result sent to driver
[2025-07-19T18:30:20.291+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 464) (8b44f3d35cfa, executor driver, partition 1, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.291+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 169.0 in stage 1.0 (TID 456) in 128 ms on 8b44f3d35cfa (executor driver) (54/200)
[2025-07-19T18:30:20.292+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 1.0 in stage 1.0 (TID 464)
[2025-07-19T18:30:20.292+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.294+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.295+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 179 (task 458, attempt 0, stage 1.0)
[2025-07-19T18:30:20.296+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 179.0 in stage 1.0 (TID 458). 9087 bytes result sent to driver
[2025-07-19T18:30:20.296+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/183/.1.delta.fedfc5fb-8c9b-41c3-94cf-778474adea21.TID460.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/183/1.delta
[2025-07-19T18:30:20.296+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=183),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/183] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/183/1.delta
[2025-07-19T18:30:20.296+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 183 (task 460, attempt 0, stage 1.0)
[2025-07-19T18:30:20.296+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 465) (8b44f3d35cfa, executor driver, partition 2, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.297+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 179.0 in stage 1.0 (TID 458) in 124 ms on 8b44f3d35cfa (executor driver) (55/200)
[2025-07-19T18:30:20.297+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 2.0 in stage 1.0 (TID 465)
[2025-07-19T18:30:20.298+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 170 (task 457, attempt 0, stage 1.0)
[2025-07-19T18:30:20.298+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 170.0 in stage 1.0 (TID 457). 9082 bytes result sent to driver
[2025-07-19T18:30:20.299+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/190/.1.delta.1bd0d231-15d3-4e75-bb5b-b59ef4fc179b.TID461.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/190/1.delta
[2025-07-19T18:30:20.299+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=190),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/190] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/190/1.delta
[2025-07-19T18:30:20.300+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 466) (8b44f3d35cfa, executor driver, partition 4, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.301+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.302+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.302+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/0/_metadata/schema using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/0/_metadata/.schema.3fbe990b-1845-4b00-b6ee-b7faaa63d4be.TID463.tmp
[2025-07-19T18:30:20.303+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/181/.1.delta.d56f5af1-325e-471b-a33d-85bfff2394dd.TID459.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/181/1.delta
[2025-07-19T18:30:20.303+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=181),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/181] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/181/1.delta
[2025-07-19T18:30:20.304+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 181 (task 459, attempt 0, stage 1.0)
[2025-07-19T18:30:20.304+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 4.0 in stage 1.0 (TID 466)
[2025-07-19T18:30:20.304+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 170.0 in stage 1.0 (TID 457) in 134 ms on 8b44f3d35cfa (executor driver) (56/200)
[2025-07-19T18:30:20.305+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 190 (task 461, attempt 0, stage 1.0)
[2025-07-19T18:30:20.306+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.306+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.311+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 183 (task 460, attempt 0, stage 1.0)
[2025-07-19T18:30:20.311+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 183.0 in stage 1.0 (TID 460). 9074 bytes result sent to driver
[2025-07-19T18:30:20.313+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 467) (8b44f3d35cfa, executor driver, partition 6, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.313+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 183.0 in stage 1.0 (TID 460) in 126 ms on 8b44f3d35cfa (executor driver) (57/200)
[2025-07-19T18:30:20.315+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 6.0 in stage 1.0 (TID 467)
[2025-07-19T18:30:20.318+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.318+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.319+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 181 (task 459, attempt 0, stage 1.0)
[2025-07-19T18:30:20.319+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/192/.1.delta.22e99672-2a34-4708-ba9d-b87f5776c5ce.TID462.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/192/1.delta
[2025-07-19T18:30:20.319+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=192),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/192] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/192/1.delta
[2025-07-19T18:30:20.319+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 192 (task 462, attempt 0, stage 1.0)
[2025-07-19T18:30:20.319+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 181.0 in stage 1.0 (TID 459). 9080 bytes result sent to driver
[2025-07-19T18:30:20.320+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 468) (8b44f3d35cfa, executor driver, partition 7, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.320+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 181.0 in stage 1.0 (TID 459) in 149 ms on 8b44f3d35cfa (executor driver) (58/200)
[2025-07-19T18:30:20.321+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 7.0 in stage 1.0 (TID 468)
[2025-07-19T18:30:20.321+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/0/_metadata/.schema.3fbe990b-1845-4b00-b6ee-b7faaa63d4be.TID463.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/0/_metadata/schema
[2025-07-19T18:30:20.322+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@782876db
[2025-07-19T18:30:20.322+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=0, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.323+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/0] for update
[2025-07-19T18:30:20.323+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.323+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.324+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.326+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@34546203
[2025-07-19T18:30:20.326+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=6, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.327+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/6] for update
[2025-07-19T18:30:20.328+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.329+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 192 (task 462, attempt 0, stage 1.0)
[2025-07-19T18:30:20.329+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 192.0 in stage 1.0 (TID 462). 9074 bytes result sent to driver
[2025-07-19T18:30:20.330+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@291e831a
[2025-07-19T18:30:20.330+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 8.0 in stage 1.0 (TID 469) (8b44f3d35cfa, executor driver, partition 8, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.331+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=4, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.331+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/4] for update
[2025-07-19T18:30:20.332+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 192.0 in stage 1.0 (TID 462) in 96 ms on 8b44f3d35cfa (executor driver) (59/200)
[2025-07-19T18:30:20.332+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/0/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/0/.1.delta.e7fb045f-c95c-4697-a7f7-c4f5ab499692.TID463.tmp
[2025-07-19T18:30:20.332+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 8.0 in stage 1.0 (TID 469)
[2025-07-19T18:30:20.333+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.333+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.334+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.334+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/6/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/6/.1.delta.614fc6d8-9fa8-44a9-bd41-9bd570ef52f9.TID467.tmp
[2025-07-19T18:30:20.334+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@660f1b30
[2025-07-19T18:30:20.334+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=2, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.335+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/2] for update
[2025-07-19T18:30:20.336+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.337+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/4/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/4/.1.delta.4a0ab8ee-ccaa-42b1-8c7c-a331f071f403.TID466.tmp
[2025-07-19T18:30:20.340+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b8ce6b7
[2025-07-19T18:30:20.340+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=1, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.340+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/1] for update
[2025-07-19T18:30:20.341+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/2/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/2/.1.delta.3b685280-f8ba-4955-867b-cf6a7b1660b6.TID465.tmp
[2025-07-19T18:30:20.341+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.343+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1215557b
[2025-07-19T18:30:20.344+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=8, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.345+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/8] for update
[2025-07-19T18:30:20.346+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.346+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/1/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/1/.1.delta.70dcabdc-b984-41f7-8e89-ca622f325b45.TID464.tmp
[2025-07-19T18:30:20.347+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/0/.1.delta.e7fb045f-c95c-4697-a7f7-c4f5ab499692.TID463.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/0/1.delta
[2025-07-19T18:30:20.347+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/0] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/0/1.delta
[2025-07-19T18:30:20.347+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 463, attempt 0, stage 1.0)
[2025-07-19T18:30:20.350+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3cc47a1
[2025-07-19T18:30:20.350+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=7, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.350+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/7] for update
[2025-07-19T18:30:20.352+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.353+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 0 (task 463, attempt 0, stage 1.0)
[2025-07-19T18:30:20.353+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 0.0 in stage 1.0 (TID 463). 6200 bytes result sent to driver
[2025-07-19T18:30:20.354+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/8/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/8/.1.delta.59756945-4980-4b81-bed4-7a4c958c0de9.TID469.tmp
[2025-07-19T18:30:20.355+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 9.0 in stage 1.0 (TID 470) (8b44f3d35cfa, executor driver, partition 9, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.355+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 463) in 81 ms on 8b44f3d35cfa (executor driver) (60/200)
[2025-07-19T18:30:20.356+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 9.0 in stage 1.0 (TID 470)
[2025-07-19T18:30:20.357+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/6/.1.delta.614fc6d8-9fa8-44a9-bd41-9bd570ef52f9.TID467.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/6/1.delta
[2025-07-19T18:30:20.357+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/6] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/6/1.delta
[2025-07-19T18:30:20.358+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 6 (task 467, attempt 0, stage 1.0)
[2025-07-19T18:30:20.358+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.358+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.360+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/4/.1.delta.4a0ab8ee-ccaa-42b1-8c7c-a331f071f403.TID466.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/4/1.delta
[2025-07-19T18:30:20.361+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/4] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/4/1.delta
[2025-07-19T18:30:20.363+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 4 (task 466, attempt 0, stage 1.0)
[2025-07-19T18:30:20.364+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 6 (task 467, attempt 0, stage 1.0)
[2025-07-19T18:30:20.364+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/7/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/7/.1.delta.f430b6d9-3498-465c-8c92-2443bae11e54.TID468.tmp
[2025-07-19T18:30:20.365+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c1154ea
[2025-07-19T18:30:20.365+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/2/.1.delta.3b685280-f8ba-4955-867b-cf6a7b1660b6.TID465.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/2/1.delta
[2025-07-19T18:30:20.366+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/2] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/2/1.delta
[2025-07-19T18:30:20.366+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 4 (task 466, attempt 0, stage 1.0)
[2025-07-19T18:30:20.366+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 2 (task 465, attempt 0, stage 1.0)
[2025-07-19T18:30:20.366+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 4.0 in stage 1.0 (TID 466). 6200 bytes result sent to driver
[2025-07-19T18:30:20.367+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 6.0 in stage 1.0 (TID 467). 6200 bytes result sent to driver
[2025-07-19T18:30:20.367+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 10.0 in stage 1.0 (TID 471) (8b44f3d35cfa, executor driver, partition 10, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.368+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=9, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.368+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/9] for update
[2025-07-19T18:30:20.368+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.369+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 190 (task 461, attempt 0, stage 1.0)
[2025-07-19T18:30:20.369+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 2 (task 465, attempt 0, stage 1.0)
[2025-07-19T18:30:20.370+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 10.0 in stage 1.0 (TID 471)
[2025-07-19T18:30:20.370+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 2.0 in stage 1.0 (TID 465). 6200 bytes result sent to driver
[2025-07-19T18:30:20.371+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.371+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 190.0 in stage 1.0 (TID 461). 9084 bytes result sent to driver
[2025-07-19T18:30:20.372+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 13.0 in stage 1.0 (TID 472) (8b44f3d35cfa, executor driver, partition 13, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.372+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 13.0 in stage 1.0 (TID 472)
[2025-07-19T18:30:20.373+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 466) in 71 ms on 8b44f3d35cfa (executor driver) (61/200)
[2025-07-19T18:30:20.374+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 6.0 in stage 1.0 (TID 467) in 57 ms on 8b44f3d35cfa (executor driver) (62/200)
[2025-07-19T18:30:20.374+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/9/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/9/.1.delta.5508423d-a3f6-49d3-926c-84e5dd331f1a.TID470.tmp
[2025-07-19T18:30:20.374+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/1/.1.delta.70dcabdc-b984-41f7-8e89-ca622f325b45.TID464.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/1/1.delta
[2025-07-19T18:30:20.375+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/1] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/1/1.delta
[2025-07-19T18:30:20.375+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 15.0 in stage 1.0 (TID 473) (8b44f3d35cfa, executor driver, partition 15, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.376+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 1 (task 464, attempt 0, stage 1.0)
[2025-07-19T18:30:20.376+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 16.0 in stage 1.0 (TID 474) (8b44f3d35cfa, executor driver, partition 16, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.376+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 15.0 in stage 1.0 (TID 473)
[2025-07-19T18:30:20.377+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.377+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.378+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.379+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.380+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T18:30:20.380+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 16.0 in stage 1.0 (TID 474)
[2025-07-19T18:30:20.381+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 465) in 81 ms on 8b44f3d35cfa (executor driver) (63/200)
[2025-07-19T18:30:20.381+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 190.0 in stage 1.0 (TID 461) in 144 ms on 8b44f3d35cfa (executor driver) (64/200)
[2025-07-19T18:30:20.382+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/8/.1.delta.59756945-4980-4b81-bed4-7a4c958c0de9.TID469.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/8/1.delta
[2025-07-19T18:30:20.383+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/8] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/8/1.delta
[2025-07-19T18:30:20.383+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 8 (task 469, attempt 0, stage 1.0)
[2025-07-19T18:30:20.384+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7bdb8a40
[2025-07-19T18:30:20.385+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=13, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.385+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=13),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/13] for update
[2025-07-19T18:30:20.386+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 8 (task 469, attempt 0, stage 1.0)
[2025-07-19T18:30:20.387+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 8.0 in stage 1.0 (TID 469). 6200 bytes result sent to driver
[2025-07-19T18:30:20.387+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.388+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/7/.1.delta.f430b6d9-3498-465c-8c92-2443bae11e54.TID468.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/7/1.delta
[2025-07-19T18:30:20.388+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/7] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/7/1.delta
[2025-07-19T18:30:20.389+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 1 (task 464, attempt 0, stage 1.0)
[2025-07-19T18:30:20.392+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 1.0 in stage 1.0 (TID 464). 6200 bytes result sent to driver
[2025-07-19T18:30:20.393+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.393+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.394+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5792c10d
[2025-07-19T18:30:20.395+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 7 (task 468, attempt 0, stage 1.0)
[2025-07-19T18:30:20.396+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=10, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.397+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=10),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/10] for update
[2025-07-19T18:30:20.398+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/13/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/13/.1.delta.d62bd16e-b14a-4602-bb9e-cc43672927d7.TID472.tmp
[2025-07-19T18:30:20.399+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.399+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1133b47
[2025-07-19T18:30:20.399+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=15, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.400+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=15),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/15] for update
[2025-07-19T18:30:20.400+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 17.0 in stage 1.0 (TID 475) (8b44f3d35cfa, executor driver, partition 17, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.400+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 18.0 in stage 1.0 (TID 476) (8b44f3d35cfa, executor driver, partition 18, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.400+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.401+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 17.0 in stage 1.0 (TID 475)
[2025-07-19T18:30:20.402+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 18.0 in stage 1.0 (TID 476)
[2025-07-19T18:30:20.402+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 8.0 in stage 1.0 (TID 469) in 61 ms on 8b44f3d35cfa (executor driver) (65/200)
[2025-07-19T18:30:20.403+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 464) in 105 ms on 8b44f3d35cfa (executor driver) (66/200)
[2025-07-19T18:30:20.403+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/9/.1.delta.5508423d-a3f6-49d3-926c-84e5dd331f1a.TID470.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/9/1.delta
[2025-07-19T18:30:20.404+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/9] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/9/1.delta
[2025-07-19T18:30:20.404+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 9 (task 470, attempt 0, stage 1.0)
[2025-07-19T18:30:20.404+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.405+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.406+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.406+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 7 (task 468, attempt 0, stage 1.0)
[2025-07-19T18:30:20.407+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/10/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/10/.1.delta.30cb5ad5-6c27-44d8-b83c-22051975dfa5.TID471.tmp
[2025-07-19T18:30:20.407+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 7.0 in stage 1.0 (TID 468). 6200 bytes result sent to driver
[2025-07-19T18:30:20.407+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 9 (task 470, attempt 0, stage 1.0)
[2025-07-19T18:30:20.407+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 9.0 in stage 1.0 (TID 470). 6200 bytes result sent to driver
[2025-07-19T18:30:20.408+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 19.0 in stage 1.0 (TID 477) (8b44f3d35cfa, executor driver, partition 19, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.408+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T18:30:20.409+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3a82add8
[2025-07-19T18:30:20.409+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 7.0 in stage 1.0 (TID 468) in 77 ms on 8b44f3d35cfa (executor driver) (67/200)
[2025-07-19T18:30:20.409+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=16, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.410+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=16),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/16] for update
[2025-07-19T18:30:20.411+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 19.0 in stage 1.0 (TID 477)
[2025-07-19T18:30:20.412+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 9.0 in stage 1.0 (TID 470) in 43 ms on 8b44f3d35cfa (executor driver) (68/200)
[2025-07-19T18:30:20.412+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 20.0 in stage 1.0 (TID 478) (8b44f3d35cfa, executor driver, partition 20, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.413+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 20.0 in stage 1.0 (TID 478)
[2025-07-19T18:30:20.413+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.413+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.413+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.413+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.413+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.413+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/15/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/15/.1.delta.40bdd83d-84aa-4363-a5d7-353073336675.TID473.tmp
[2025-07-19T18:30:20.413+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@78856b2
[2025-07-19T18:30:20.413+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=18, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.413+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=18),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/18] for update
[2025-07-19T18:30:20.414+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/16/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/16/.1.delta.5e362aab-28fe-42ea-bda0-34e1a00a4ac4.TID474.tmp
[2025-07-19T18:30:20.414+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.414+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@561f1308
[2025-07-19T18:30:20.414+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=17, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.414+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=17),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/17] for update
[2025-07-19T18:30:20.414+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.416+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e588311
[2025-07-19T18:30:20.416+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/18/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/18/.1.delta.0b20c2c5-ab7f-4037-bc29-f99e513878c0.TID476.tmp
[2025-07-19T18:30:20.416+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=20, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.417+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=20),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/20] for update
[2025-07-19T18:30:20.419+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.421+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/17/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/17/.1.delta.e333c0e6-6278-476f-be75-25f4d7602161.TID475.tmp
[2025-07-19T18:30:20.422+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/13/.1.delta.d62bd16e-b14a-4602-bb9e-cc43672927d7.TID472.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/13/1.delta
[2025-07-19T18:30:20.423+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=13),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/13] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/13/1.delta
[2025-07-19T18:30:20.423+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 13 (task 472, attempt 0, stage 1.0)
[2025-07-19T18:30:20.423+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/10/.1.delta.30cb5ad5-6c27-44d8-b83c-22051975dfa5.TID471.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/10/1.delta
[2025-07-19T18:30:20.425+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=10),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/10] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/10/1.delta
[2025-07-19T18:30:20.425+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 10 (task 471, attempt 0, stage 1.0)
[2025-07-19T18:30:20.426+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/20/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/20/.1.delta.42c6aaea-768f-4b1a-acbc-2cb9dfecc631.TID478.tmp
[2025-07-19T18:30:20.426+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ac0e00b
[2025-07-19T18:30:20.426+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=19, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.427+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=19),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/19] for update
[2025-07-19T18:30:20.429+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/15/.1.delta.40bdd83d-84aa-4363-a5d7-353073336675.TID473.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/15/1.delta
[2025-07-19T18:30:20.429+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=15),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/15] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/15/1.delta
[2025-07-19T18:30:20.430+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 15 (task 473, attempt 0, stage 1.0)
[2025-07-19T18:30:20.433+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 15 (task 473, attempt 0, stage 1.0)
[2025-07-19T18:30:20.434+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 15.0 in stage 1.0 (TID 473). 6200 bytes result sent to driver
[2025-07-19T18:30:20.435+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 22.0 in stage 1.0 (TID 479) (8b44f3d35cfa, executor driver, partition 22, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.436+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.437+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 15.0 in stage 1.0 (TID 473) in 62 ms on 8b44f3d35cfa (executor driver) (69/200)
[2025-07-19T18:30:20.438+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 22.0 in stage 1.0 (TID 479)
[2025-07-19T18:30:20.439+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 13 (task 472, attempt 0, stage 1.0)
[2025-07-19T18:30:20.440+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/16/.1.delta.5e362aab-28fe-42ea-bda0-34e1a00a4ac4.TID474.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/16/1.delta
[2025-07-19T18:30:20.440+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=16),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/16] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/16/1.delta
[2025-07-19T18:30:20.440+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 16 (task 474, attempt 0, stage 1.0)
[2025-07-19T18:30:20.441+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 10 (task 471, attempt 0, stage 1.0)
[2025-07-19T18:30:20.442+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 10.0 in stage 1.0 (TID 471). 6200 bytes result sent to driver
[2025-07-19T18:30:20.442+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 23.0 in stage 1.0 (TID 480) (8b44f3d35cfa, executor driver, partition 23, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.442+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 13.0 in stage 1.0 (TID 472). 6200 bytes result sent to driver
[2025-07-19T18:30:20.442+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 27.0 in stage 1.0 (TID 481) (8b44f3d35cfa, executor driver, partition 27, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.442+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 23.0 in stage 1.0 (TID 480)
[2025-07-19T18:30:20.443+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 27.0 in stage 1.0 (TID 481)
[2025-07-19T18:30:20.443+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.443+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.443+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 10.0 in stage 1.0 (TID 471) in 73 ms on 8b44f3d35cfa (executor driver) (70/200)
[2025-07-19T18:30:20.443+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.444+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.444+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 13.0 in stage 1.0 (TID 472) in 75 ms on 8b44f3d35cfa (executor driver) (71/200)
[2025-07-19T18:30:20.445+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 16 (task 474, attempt 0, stage 1.0)
[2025-07-19T18:30:20.445+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 16.0 in stage 1.0 (TID 474). 6200 bytes result sent to driver
[2025-07-19T18:30:20.445+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 16.0 in stage 1.0 (TID 474) in 70 ms on 8b44f3d35cfa (executor driver) (72/200)
[2025-07-19T18:30:20.445+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.445+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:20.445+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 28.0 in stage 1.0 (TID 482) (8b44f3d35cfa, executor driver, partition 28, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.445+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f54b3bd
[2025-07-19T18:30:20.445+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 28.0 in stage 1.0 (TID 482)
[2025-07-19T18:30:20.446+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=22, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.446+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=22),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/22] for update
[2025-07-19T18:30:20.446+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.446+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/19/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/19/.1.delta.352d734c-66f2-4040-b79b-46af2d5c083e.TID477.tmp
[2025-07-19T18:30:20.447+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3eb68a99
[2025-07-19T18:30:20.448+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=27, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.448+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=27),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/27] for update
[2025-07-19T18:30:20.448+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.448+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.448+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.449+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/18/.1.delta.0b20c2c5-ab7f-4037-bc29-f99e513878c0.TID476.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/18/1.delta
[2025-07-19T18:30:20.449+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=18),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/18] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/18/1.delta
[2025-07-19T18:30:20.449+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/22/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/22/.1.delta.57af20ba-bced-49a6-aebf-2f13f11f43c2.TID479.tmp
[2025-07-19T18:30:20.450+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 18 (task 476, attempt 0, stage 1.0)
[2025-07-19T18:30:20.451+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/20/.1.delta.42c6aaea-768f-4b1a-acbc-2cb9dfecc631.TID478.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/20/1.delta
[2025-07-19T18:30:20.453+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=20),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/20] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/20/1.delta
[2025-07-19T18:30:20.454+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 20 (task 478, attempt 0, stage 1.0)
[2025-07-19T18:30:20.454+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/17/.1.delta.e333c0e6-6278-476f-be75-25f4d7602161.TID475.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/17/1.delta
[2025-07-19T18:30:20.454+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=17),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/17] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/17/1.delta
[2025-07-19T18:30:20.455+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 17 (task 475, attempt 0, stage 1.0)
[2025-07-19T18:30:20.455+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56852a97
[2025-07-19T18:30:20.456+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=28, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.456+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=28),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/28] for update
[2025-07-19T18:30:20.456+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/27/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/27/.1.delta.cb3ae3fa-ab5b-4967-bd39-d1bc592c3772.TID481.tmp
[2025-07-19T18:30:20.457+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.457+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 20 (task 478, attempt 0, stage 1.0)
[2025-07-19T18:30:20.458+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 20.0 in stage 1.0 (TID 478). 6200 bytes result sent to driver
[2025-07-19T18:30:20.459+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 17 (task 475, attempt 0, stage 1.0)
[2025-07-19T18:30:20.460+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5334c554
[2025-07-19T18:30:20.463+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 17.0 in stage 1.0 (TID 475). 6286 bytes result sent to driver
[2025-07-19T18:30:20.466+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 29.0 in stage 1.0 (TID 483) (8b44f3d35cfa, executor driver, partition 29, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.467+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=23, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.468+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 31.0 in stage 1.0 (TID 484) (8b44f3d35cfa, executor driver, partition 31, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.468+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=23),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/23] for update
[2025-07-19T18:30:20.468+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 17.0 in stage 1.0 (TID 475) in 76 ms on 8b44f3d35cfa (executor driver) (73/200)
[2025-07-19T18:30:20.469+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 29.0 in stage 1.0 (TID 483)
[2025-07-19T18:30:20.469+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 31.0 in stage 1.0 (TID 484)
[2025-07-19T18:30:20.469+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 20.0 in stage 1.0 (TID 478) in 70 ms on 8b44f3d35cfa (executor driver) (74/200)
[2025-07-19T18:30:20.469+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 18 (task 476, attempt 0, stage 1.0)
[2025-07-19T18:30:20.475+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 18.0 in stage 1.0 (TID 476). 6286 bytes result sent to driver
[2025-07-19T18:30:20.476+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 32.0 in stage 1.0 (TID 485) (8b44f3d35cfa, executor driver, partition 32, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.477+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 18.0 in stage 1.0 (TID 476) in 84 ms on 8b44f3d35cfa (executor driver) (75/200)
[2025-07-19T18:30:20.478+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 32.0 in stage 1.0 (TID 485)
[2025-07-19T18:30:20.478+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.479+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.479+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/28/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/28/.1.delta.913d2c0c-46bb-4984-ab0f-2d8e8c080a1f.TID482.tmp
[2025-07-19T18:30:20.481+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.481+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.481+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.482+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.482+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.482+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@566b7713
[2025-07-19T18:30:20.485+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=31, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.486+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=31),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/31] for update
[2025-07-19T18:30:20.486+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.488+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/23/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/23/.1.delta.8e48e36d-4993-44f5-956f-ad04db18f021.TID480.tmp
[2025-07-19T18:30:20.489+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/19/.1.delta.352d734c-66f2-4040-b79b-46af2d5c083e.TID477.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/19/1.delta
[2025-07-19T18:30:20.489+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=19),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/19] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/19/1.delta
[2025-07-19T18:30:20.491+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 19 (task 477, attempt 0, stage 1.0)
[2025-07-19T18:30:20.492+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/22/.1.delta.57af20ba-bced-49a6-aebf-2f13f11f43c2.TID479.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/22/1.delta
[2025-07-19T18:30:20.493+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=22),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/22] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/22/1.delta
[2025-07-19T18:30:20.494+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@299c6a1d
[2025-07-19T18:30:20.495+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 22 (task 479, attempt 0, stage 1.0)
[2025-07-19T18:30:20.495+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=29, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.497+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=29),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/29] for update
[2025-07-19T18:30:20.498+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.499+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/31/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/31/.1.delta.326cec9b-4dce-40d8-8013-3d9fdc44513c.TID484.tmp
[2025-07-19T18:30:20.499+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 22 (task 479, attempt 0, stage 1.0)
[2025-07-19T18:30:20.500+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c2aedd7
[2025-07-19T18:30:20.501+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=32, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.502+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 22.0 in stage 1.0 (TID 479). 6243 bytes result sent to driver
[2025-07-19T18:30:20.503+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=32),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/32] for update
[2025-07-19T18:30:20.503+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 33.0 in stage 1.0 (TID 486) (8b44f3d35cfa, executor driver, partition 33, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.504+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 33.0 in stage 1.0 (TID 486)
[2025-07-19T18:30:20.504+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 19 (task 477, attempt 0, stage 1.0)
[2025-07-19T18:30:20.505+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 22.0 in stage 1.0 (TID 479) in 69 ms on 8b44f3d35cfa (executor driver) (76/200)
[2025-07-19T18:30:20.506+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 19.0 in stage 1.0 (TID 477). 6243 bytes result sent to driver
[2025-07-19T18:30:20.507+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.508+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.508+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.509+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 34.0 in stage 1.0 (TID 487) (8b44f3d35cfa, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.511+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 19.0 in stage 1.0 (TID 477) in 110 ms on 8b44f3d35cfa (executor driver) (77/200)
[2025-07-19T18:30:20.512+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 34.0 in stage 1.0 (TID 487)
[2025-07-19T18:30:20.512+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/27/.1.delta.cb3ae3fa-ab5b-4967-bd39-d1bc592c3772.TID481.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/27/1.delta
[2025-07-19T18:30:20.512+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=27),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/27] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/27/1.delta
[2025-07-19T18:30:20.512+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 27 (task 481, attempt 0, stage 1.0)
[2025-07-19T18:30:20.512+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.512+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.513+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 27 (task 481, attempt 0, stage 1.0)
[2025-07-19T18:30:20.516+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/29/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/29/.1.delta.ff0ff1cf-ccbe-459e-895f-09ac7c718d78.TID483.tmp
[2025-07-19T18:30:20.517+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 27.0 in stage 1.0 (TID 481). 6243 bytes result sent to driver
[2025-07-19T18:30:20.517+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 35.0 in stage 1.0 (TID 488) (8b44f3d35cfa, executor driver, partition 35, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.517+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 27.0 in stage 1.0 (TID 481) in 75 ms on 8b44f3d35cfa (executor driver) (78/200)
[2025-07-19T18:30:20.518+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58a627a9
[2025-07-19T18:30:20.520+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 35.0 in stage 1.0 (TID 488)
[2025-07-19T18:30:20.520+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=33, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.520+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=33),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/33] for update
[2025-07-19T18:30:20.521+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.521+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.522+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 8b44f3d35cfa:40517 in memory (size: 35.4 KiB, free: 434.1 MiB)
[2025-07-19T18:30:20.523+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.524+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/32/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/32/.1.delta.dfb068c1-5d5f-4837-b2a8-a3a35898b88a.TID485.tmp
[2025-07-19T18:30:20.528+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@487b307
[2025-07-19T18:30:20.530+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/28/.1.delta.913d2c0c-46bb-4984-ab0f-2d8e8c080a1f.TID482.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/28/1.delta
[2025-07-19T18:30:20.531+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=28),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/28] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/28/1.delta
[2025-07-19T18:30:20.532+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=34, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.533+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=34),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/34] for update
[2025-07-19T18:30:20.533+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 28 (task 482, attempt 0, stage 1.0)
[2025-07-19T18:30:20.533+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.534+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 28 (task 482, attempt 0, stage 1.0)
[2025-07-19T18:30:20.535+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 28.0 in stage 1.0 (TID 482). 6243 bytes result sent to driver
[2025-07-19T18:30:20.536+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 36.0 in stage 1.0 (TID 489) (8b44f3d35cfa, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.536+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 28.0 in stage 1.0 (TID 482) in 95 ms on 8b44f3d35cfa (executor driver) (79/200)
[2025-07-19T18:30:20.536+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 36.0 in stage 1.0 (TID 489)
[2025-07-19T18:30:20.538+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 8b44f3d35cfa:40517 in memory (size: 29.5 KiB, free: 434.2 MiB)
[2025-07-19T18:30:20.538+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/33/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/33/.1.delta.07874a09-360c-41b1-92e8-1d9df56298dc.TID486.tmp
[2025-07-19T18:30:20.539+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/23/.1.delta.8e48e36d-4993-44f5-956f-ad04db18f021.TID480.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/23/1.delta
[2025-07-19T18:30:20.540+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=23),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/23] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/23/1.delta
[2025-07-19T18:30:20.541+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.541+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.542+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 23 (task 480, attempt 0, stage 1.0)
[2025-07-19T18:30:20.542+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@11c0c856
[2025-07-19T18:30:20.542+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=35, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.543+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=35),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/35] for update
[2025-07-19T18:30:20.543+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.545+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 23 (task 480, attempt 0, stage 1.0)
[2025-07-19T18:30:20.545+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/34/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/34/.1.delta.594e8ba2-50db-4b50-a0fa-ea3e0b858490.TID487.tmp
[2025-07-19T18:30:20.546+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 23.0 in stage 1.0 (TID 480). 6243 bytes result sent to driver
[2025-07-19T18:30:20.547+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c6d8e11
[2025-07-19T18:30:20.548+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 23.0 in stage 1.0 (TID 480) in 112 ms on 8b44f3d35cfa (executor driver) (80/200)
[2025-07-19T18:30:20.548+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=36, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.548+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=36),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/36] for update
[2025-07-19T18:30:20.549+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 39.0 in stage 1.0 (TID 490) (8b44f3d35cfa, executor driver, partition 39, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.549+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 39.0 in stage 1.0 (TID 490)
[2025-07-19T18:30:20.550+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.554+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/29/.1.delta.ff0ff1cf-ccbe-459e-895f-09ac7c718d78.TID483.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/29/1.delta
[2025-07-19T18:30:20.554+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=29),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/29] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/29/1.delta
[2025-07-19T18:30:20.555+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.555+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.556+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 29 (task 483, attempt 0, stage 1.0)
[2025-07-19T18:30:20.556+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/35/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/35/.1.delta.8c2cbe18-47a2-415e-b52a-771ac25ee1d3.TID488.tmp
[2025-07-19T18:30:20.556+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7533cb45
[2025-07-19T18:30:20.556+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=39, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.557+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=39),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/39] for update
[2025-07-19T18:30:20.557+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.559+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/36/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/36/.1.delta.1a4a8ab4-3c23-4eae-9b46-8363baf305dc.TID489.tmp
[2025-07-19T18:30:20.559+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 29 (task 483, attempt 0, stage 1.0)
[2025-07-19T18:30:20.560+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 29.0 in stage 1.0 (TID 483). 6243 bytes result sent to driver
[2025-07-19T18:30:20.561+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 40.0 in stage 1.0 (TID 491) (8b44f3d35cfa, executor driver, partition 40, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.561+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 40.0 in stage 1.0 (TID 491)
[2025-07-19T18:30:20.562+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/31/.1.delta.326cec9b-4dce-40d8-8013-3d9fdc44513c.TID484.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/31/1.delta
[2025-07-19T18:30:20.562+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=31),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/31] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/31/1.delta
[2025-07-19T18:30:20.563+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.564+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.564+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 29.0 in stage 1.0 (TID 483) in 97 ms on 8b44f3d35cfa (executor driver) (81/200)
[2025-07-19T18:30:20.564+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 31 (task 484, attempt 0, stage 1.0)
[2025-07-19T18:30:20.566+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/32/.1.delta.dfb068c1-5d5f-4837-b2a8-a3a35898b88a.TID485.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/32/1.delta
[2025-07-19T18:30:20.566+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@13eaf081
[2025-07-19T18:30:20.566+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=32),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/32] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/32/1.delta
[2025-07-19T18:30:20.566+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 32 (task 485, attempt 0, stage 1.0)
[2025-07-19T18:30:20.567+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=40, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.567+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=40),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/40] for update
[2025-07-19T18:30:20.569+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 31 (task 484, attempt 0, stage 1.0)
[2025-07-19T18:30:20.569+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 31.0 in stage 1.0 (TID 484). 6243 bytes result sent to driver
[2025-07-19T18:30:20.569+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 32 (task 485, attempt 0, stage 1.0)
[2025-07-19T18:30:20.569+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 32.0 in stage 1.0 (TID 485). 6200 bytes result sent to driver
[2025-07-19T18:30:20.570+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.573+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/39/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/39/.1.delta.99edfd13-5a9e-4e10-8559-c27eb01210a0.TID490.tmp
[2025-07-19T18:30:20.573+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 42.0 in stage 1.0 (TID 492) (8b44f3d35cfa, executor driver, partition 42, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.573+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 44.0 in stage 1.0 (TID 493) (8b44f3d35cfa, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.575+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 32.0 in stage 1.0 (TID 485) in 99 ms on 8b44f3d35cfa (executor driver) (82/200)
[2025-07-19T18:30:20.575+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 31.0 in stage 1.0 (TID 484) in 107 ms on 8b44f3d35cfa (executor driver) (83/200)
[2025-07-19T18:30:20.576+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 42.0 in stage 1.0 (TID 492)
[2025-07-19T18:30:20.576+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 44.0 in stage 1.0 (TID 493)
[2025-07-19T18:30:20.577+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/33/.1.delta.07874a09-360c-41b1-92e8-1d9df56298dc.TID486.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/33/1.delta
[2025-07-19T18:30:20.577+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=33),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/33] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/33/1.delta
[2025-07-19T18:30:20.578+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 33 (task 486, attempt 0, stage 1.0)
[2025-07-19T18:30:20.578+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.579+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.579+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.579+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.580+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/34/.1.delta.594e8ba2-50db-4b50-a0fa-ea3e0b858490.TID487.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/34/1.delta
[2025-07-19T18:30:20.582+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=34),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/34] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/34/1.delta
[2025-07-19T18:30:20.582+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/40/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/40/.1.delta.6fb08367-cda0-4a75-aa90-b891428953aa.TID491.tmp
[2025-07-19T18:30:20.584+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 34 (task 487, attempt 0, stage 1.0)
[2025-07-19T18:30:20.585+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d665aca
[2025-07-19T18:30:20.585+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/36/.1.delta.1a4a8ab4-3c23-4eae-9b46-8363baf305dc.TID489.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/36/1.delta
[2025-07-19T18:30:20.586+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=36),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/36] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/36/1.delta
[2025-07-19T18:30:20.586+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 33 (task 486, attempt 0, stage 1.0)
[2025-07-19T18:30:20.587+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 36 (task 489, attempt 0, stage 1.0)
[2025-07-19T18:30:20.587+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=44, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.587+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 33.0 in stage 1.0 (TID 486). 6200 bytes result sent to driver
[2025-07-19T18:30:20.587+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 34 (task 487, attempt 0, stage 1.0)
[2025-07-19T18:30:20.587+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 45.0 in stage 1.0 (TID 494) (8b44f3d35cfa, executor driver, partition 45, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.587+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=44),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/44] for update
[2025-07-19T18:30:20.587+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 33.0 in stage 1.0 (TID 486) in 84 ms on 8b44f3d35cfa (executor driver) (84/200)
[2025-07-19T18:30:20.588+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 34.0 in stage 1.0 (TID 487). 6200 bytes result sent to driver
[2025-07-19T18:30:20.589+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 45.0 in stage 1.0 (TID 494)
[2025-07-19T18:30:20.590+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 34.0 in stage 1.0 (TID 487) in 80 ms on 8b44f3d35cfa (executor driver) (85/200)
[2025-07-19T18:30:20.590+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 49.0 in stage 1.0 (TID 495) (8b44f3d35cfa, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.591+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 49.0 in stage 1.0 (TID 495)
[2025-07-19T18:30:20.592+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/35/.1.delta.8c2cbe18-47a2-415e-b52a-771ac25ee1d3.TID488.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/35/1.delta
[2025-07-19T18:30:20.593+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=35),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/35] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/35/1.delta
[2025-07-19T18:30:20.594+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 36 (task 489, attempt 0, stage 1.0)
[2025-07-19T18:30:20.594+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.594+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.594+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 36.0 in stage 1.0 (TID 489). 6200 bytes result sent to driver
[2025-07-19T18:30:20.594+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.594+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.595+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 35 (task 488, attempt 0, stage 1.0)
[2025-07-19T18:30:20.595+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 50.0 in stage 1.0 (TID 496) (8b44f3d35cfa, executor driver, partition 50, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.596+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 50.0 in stage 1.0 (TID 496)
[2025-07-19T18:30:20.596+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 36.0 in stage 1.0 (TID 489) in 54 ms on 8b44f3d35cfa (executor driver) (86/200)
[2025-07-19T18:30:20.596+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25e97bb3
[2025-07-19T18:30:20.597+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=42, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.597+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=42),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/42] for update
[2025-07-19T18:30:20.598+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.599+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.600+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.600+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:20.600+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@437d73fb
[2025-07-19T18:30:20.601+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 35 (task 488, attempt 0, stage 1.0)
[2025-07-19T18:30:20.601+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/39/.1.delta.99edfd13-5a9e-4e10-8559-c27eb01210a0.TID490.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/39/1.delta
[2025-07-19T18:30:20.601+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=49, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.601+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=39),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/39] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/39/1.delta
[2025-07-19T18:30:20.601+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=49),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/49] for update
[2025-07-19T18:30:20.601+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 39 (task 490, attempt 0, stage 1.0)
[2025-07-19T18:30:20.601+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 35.0 in stage 1.0 (TID 488). 6200 bytes result sent to driver
[2025-07-19T18:30:20.601+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.601+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 54.0 in stage 1.0 (TID 497) (8b44f3d35cfa, executor driver, partition 54, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.602+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 54.0 in stage 1.0 (TID 497)
[2025-07-19T18:30:20.602+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 35.0 in stage 1.0 (TID 488) in 87 ms on 8b44f3d35cfa (executor driver) (87/200)
[2025-07-19T18:30:20.602+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.602+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.602+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 39 (task 490, attempt 0, stage 1.0)
[2025-07-19T18:30:20.602+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 39.0 in stage 1.0 (TID 490). 6200 bytes result sent to driver
[2025-07-19T18:30:20.603+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 55.0 in stage 1.0 (TID 498) (8b44f3d35cfa, executor driver, partition 55, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.604+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 39.0 in stage 1.0 (TID 490) in 53 ms on 8b44f3d35cfa (executor driver) (88/200)
[2025-07-19T18:30:20.604+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 55.0 in stage 1.0 (TID 498)
[2025-07-19T18:30:20.604+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20d8fd9a
[2025-07-19T18:30:20.605+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/44/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/44/.1.delta.e7a1f1c8-016f-4c26-ac15-3ba41535e44c.TID493.tmp
[2025-07-19T18:30:20.605+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=45, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.606+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/42/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/42/.1.delta.dc6cbea1-3922-45ba-ba14-cea403597c1a.TID492.tmp
[2025-07-19T18:30:20.606+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=45),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/45] for update
[2025-07-19T18:30:20.607+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.607+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.607+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b6c5b26
[2025-07-19T18:30:20.608+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/49/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/49/.1.delta.b0c38433-1ea2-4ffc-8263-ff179c4fda99.TID495.tmp
[2025-07-19T18:30:20.608+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=55, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.608+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.609+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=55),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/55] for update
[2025-07-19T18:30:20.609+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.611+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/40/.1.delta.6fb08367-cda0-4a75-aa90-b891428953aa.TID491.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/40/1.delta
[2025-07-19T18:30:20.612+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=40),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/40] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/40/1.delta
[2025-07-19T18:30:20.612+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 40 (task 491, attempt 0, stage 1.0)
[2025-07-19T18:30:20.615+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 40 (task 491, attempt 0, stage 1.0)
[2025-07-19T18:30:20.618+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 40.0 in stage 1.0 (TID 491). 6200 bytes result sent to driver
[2025-07-19T18:30:20.619+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e6fd22d
[2025-07-19T18:30:20.619+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=54, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.619+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=54),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/54] for update
[2025-07-19T18:30:20.619+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 56.0 in stage 1.0 (TID 499) (8b44f3d35cfa, executor driver, partition 56, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.620+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 40.0 in stage 1.0 (TID 491) in 56 ms on 8b44f3d35cfa (executor driver) (89/200)
[2025-07-19T18:30:20.620+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 56.0 in stage 1.0 (TID 499)
[2025-07-19T18:30:20.620+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.621+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/45/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/45/.1.delta.9fcfb7db-94b6-413c-88ec-d6af522508dc.TID494.tmp
[2025-07-19T18:30:20.621+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.621+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.621+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@30f97e6c
[2025-07-19T18:30:20.621+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=50, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.621+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=50),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/50] for update
[2025-07-19T18:30:20.622+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.623+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/55/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/55/.1.delta.52a1e24d-656c-4c70-a76a-d9345663c37e.TID498.tmp
[2025-07-19T18:30:20.629+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43b40b24
[2025-07-19T18:30:20.632+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=56, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.632+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/54/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/54/.1.delta.9f333799-d73e-404d-8630-60aa85fdf15d.TID497.tmp
[2025-07-19T18:30:20.633+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=56),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/56] for update
[2025-07-19T18:30:20.633+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.634+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/42/.1.delta.dc6cbea1-3922-45ba-ba14-cea403597c1a.TID492.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/42/1.delta
[2025-07-19T18:30:20.634+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=42),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/42] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/42/1.delta
[2025-07-19T18:30:20.635+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 42 (task 492, attempt 0, stage 1.0)
[2025-07-19T18:30:20.638+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/50/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/50/.1.delta.6664493c-1c81-4c3f-8b1a-7224be571f90.TID496.tmp
[2025-07-19T18:30:20.638+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/44/.1.delta.e7a1f1c8-016f-4c26-ac15-3ba41535e44c.TID493.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/44/1.delta
[2025-07-19T18:30:20.639+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=44),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/44] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/44/1.delta
[2025-07-19T18:30:20.639+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 44 (task 493, attempt 0, stage 1.0)
[2025-07-19T18:30:20.640+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 42 (task 492, attempt 0, stage 1.0)
[2025-07-19T18:30:20.641+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 42.0 in stage 1.0 (TID 492). 6200 bytes result sent to driver
[2025-07-19T18:30:20.642+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 42.0 in stage 1.0 (TID 492) in 72 ms on 8b44f3d35cfa (executor driver) (90/200)
[2025-07-19T18:30:20.643+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 57.0 in stage 1.0 (TID 500) (8b44f3d35cfa, executor driver, partition 57, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.643+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/56/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/56/.1.delta.ce801966-6789-4553-ae1f-aea710c0f894.TID499.tmp
[2025-07-19T18:30:20.643+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 57.0 in stage 1.0 (TID 500)
[2025-07-19T18:30:20.643+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 44 (task 493, attempt 0, stage 1.0)
[2025-07-19T18:30:20.644+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/49/.1.delta.b0c38433-1ea2-4ffc-8263-ff179c4fda99.TID495.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/49/1.delta
[2025-07-19T18:30:20.645+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=49),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/49] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/49/1.delta
[2025-07-19T18:30:20.645+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 44.0 in stage 1.0 (TID 493). 6200 bytes result sent to driver
[2025-07-19T18:30:20.645+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 49 (task 495, attempt 0, stage 1.0)
[2025-07-19T18:30:20.645+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.645+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.648+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 59.0 in stage 1.0 (TID 501) (8b44f3d35cfa, executor driver, partition 59, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.649+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 44.0 in stage 1.0 (TID 493) in 75 ms on 8b44f3d35cfa (executor driver) (91/200)
[2025-07-19T18:30:20.650+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/45/.1.delta.9fcfb7db-94b6-413c-88ec-d6af522508dc.TID494.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/45/1.delta
[2025-07-19T18:30:20.650+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=45),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/45] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/45/1.delta
[2025-07-19T18:30:20.652+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 45 (task 494, attempt 0, stage 1.0)
[2025-07-19T18:30:20.652+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ce2f7dd
[2025-07-19T18:30:20.653+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=57, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.654+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=57),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/57] for update
[2025-07-19T18:30:20.654+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 59.0 in stage 1.0 (TID 501)
[2025-07-19T18:30:20.654+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.654+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.655+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.655+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 49 (task 495, attempt 0, stage 1.0)
[2025-07-19T18:30:20.656+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 49.0 in stage 1.0 (TID 495). 6200 bytes result sent to driver
[2025-07-19T18:30:20.656+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 60.0 in stage 1.0 (TID 502) (8b44f3d35cfa, executor driver, partition 60, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.656+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 49.0 in stage 1.0 (TID 495) in 71 ms on 8b44f3d35cfa (executor driver) (92/200)
[2025-07-19T18:30:20.661+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 45 (task 494, attempt 0, stage 1.0)
[2025-07-19T18:30:20.662+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 60.0 in stage 1.0 (TID 502)
[2025-07-19T18:30:20.663+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 45.0 in stage 1.0 (TID 494). 6200 bytes result sent to driver
[2025-07-19T18:30:20.664+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 61.0 in stage 1.0 (TID 503) (8b44f3d35cfa, executor driver, partition 61, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.664+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/55/.1.delta.52a1e24d-656c-4c70-a76a-d9345663c37e.TID498.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/55/1.delta
[2025-07-19T18:30:20.665+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=55),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/55] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/55/1.delta
[2025-07-19T18:30:20.666+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 55 (task 498, attempt 0, stage 1.0)
[2025-07-19T18:30:20.667+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 45.0 in stage 1.0 (TID 494) in 77 ms on 8b44f3d35cfa (executor driver) (93/200)
[2025-07-19T18:30:20.667+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/57/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/57/.1.delta.5e6e2a4a-a1cb-447a-8e01-dc6cb8fe42e1.TID500.tmp
[2025-07-19T18:30:20.668+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/54/.1.delta.9f333799-d73e-404d-8630-60aa85fdf15d.TID497.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/54/1.delta
[2025-07-19T18:30:20.668+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=54),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/54] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/54/1.delta
[2025-07-19T18:30:20.669+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 54 (task 497, attempt 0, stage 1.0)
[2025-07-19T18:30:20.669+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1f674cf4
[2025-07-19T18:30:20.670+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=59, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.671+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=59),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/59] for update
[2025-07-19T18:30:20.672+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 61.0 in stage 1.0 (TID 503)
[2025-07-19T18:30:20.673+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 55 (task 498, attempt 0, stage 1.0)
[2025-07-19T18:30:20.674+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 55.0 in stage 1.0 (TID 498). 6200 bytes result sent to driver
[2025-07-19T18:30:20.674+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.675+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.675+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.675+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 62.0 in stage 1.0 (TID 504) (8b44f3d35cfa, executor driver, partition 62, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.677+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 55.0 in stage 1.0 (TID 498) in 65 ms on 8b44f3d35cfa (executor driver) (94/200)
[2025-07-19T18:30:20.677+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.677+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:20.677+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 62.0 in stage 1.0 (TID 504)
[2025-07-19T18:30:20.679+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@36c2361b
[2025-07-19T18:30:20.679+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/50/.1.delta.6664493c-1c81-4c3f-8b1a-7224be571f90.TID496.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/50/1.delta
[2025-07-19T18:30:20.680+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=50),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/50] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/50/1.delta
[2025-07-19T18:30:20.680+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 54 (task 497, attempt 0, stage 1.0)
[2025-07-19T18:30:20.681+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=60, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.681+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 50 (task 496, attempt 0, stage 1.0)
[2025-07-19T18:30:20.683+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=60),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/60] for update
[2025-07-19T18:30:20.684+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.685+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.685+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.686+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/56/.1.delta.ce801966-6789-4553-ae1f-aea710c0f894.TID499.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/56/1.delta
[2025-07-19T18:30:20.686+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=56),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/56] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/56/1.delta
[2025-07-19T18:30:20.688+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 50 (task 496, attempt 0, stage 1.0)
[2025-07-19T18:30:20.689+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 56 (task 499, attempt 0, stage 1.0)
[2025-07-19T18:30:20.690+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 54.0 in stage 1.0 (TID 497). 6200 bytes result sent to driver
[2025-07-19T18:30:20.690+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/59/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/59/.1.delta.9617683f-e6f8-4014-901f-333c5f5e086d.TID501.tmp
[2025-07-19T18:30:20.690+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 65.0 in stage 1.0 (TID 505) (8b44f3d35cfa, executor driver, partition 65, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.690+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 65.0 in stage 1.0 (TID 505)
[2025-07-19T18:30:20.691+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 54.0 in stage 1.0 (TID 497) in 83 ms on 8b44f3d35cfa (executor driver) (95/200)
[2025-07-19T18:30:20.691+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5b08fde1
[2025-07-19T18:30:20.691+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=61, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.691+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 50.0 in stage 1.0 (TID 496). 6200 bytes result sent to driver
[2025-07-19T18:30:20.691+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 67.0 in stage 1.0 (TID 506) (8b44f3d35cfa, executor driver, partition 67, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.692+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 50.0 in stage 1.0 (TID 496) in 96 ms on 8b44f3d35cfa (executor driver) (96/200)
[2025-07-19T18:30:20.692+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.692+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:20.692+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 67.0 in stage 1.0 (TID 506)
[2025-07-19T18:30:20.692+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=61),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/61] for update
[2025-07-19T18:30:20.693+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 56 (task 499, attempt 0, stage 1.0)
[2025-07-19T18:30:20.693+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 56.0 in stage 1.0 (TID 499). 6200 bytes result sent to driver
[2025-07-19T18:30:20.693+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/60/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/60/.1.delta.1325fc6b-9239-44ea-b305-1d5ac1f8ffb3.TID502.tmp
[2025-07-19T18:30:20.694+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 69.0 in stage 1.0 (TID 507) (8b44f3d35cfa, executor driver, partition 69, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.694+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@57f46f5a
[2025-07-19T18:30:20.694+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 56.0 in stage 1.0 (TID 499) in 72 ms on 8b44f3d35cfa (executor driver) (97/200)
[2025-07-19T18:30:20.694+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 69.0 in stage 1.0 (TID 507)
[2025-07-19T18:30:20.694+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=62, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.695+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=62),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/62] for update
[2025-07-19T18:30:20.695+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.695+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:20.696+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.696+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.697+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/57/.1.delta.5e6e2a4a-a1cb-447a-8e01-dc6cb8fe42e1.TID500.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/57/1.delta
[2025-07-19T18:30:20.697+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=57),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/57] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/57/1.delta
[2025-07-19T18:30:20.698+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 57 (task 500, attempt 0, stage 1.0)
[2025-07-19T18:30:20.698+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.699+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.700+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 57 (task 500, attempt 0, stage 1.0)
[2025-07-19T18:30:20.700+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 57.0 in stage 1.0 (TID 500). 6200 bytes result sent to driver
[2025-07-19T18:30:20.701+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 70.0 in stage 1.0 (TID 508) (8b44f3d35cfa, executor driver, partition 70, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.701+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1f6a7de7
[2025-07-19T18:30:20.701+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=65, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.702+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=65),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/65] for update
[2025-07-19T18:30:20.702+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/61/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/61/.1.delta.deaa76de-a36f-49cb-8b9a-ddc97ff3c23e.TID503.tmp
[2025-07-19T18:30:20.702+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 70.0 in stage 1.0 (TID 508)
[2025-07-19T18:30:20.702+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 57.0 in stage 1.0 (TID 500) in 58 ms on 8b44f3d35cfa (executor driver) (98/200)
[2025-07-19T18:30:20.702+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.703+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/62/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/62/.1.delta.a80368fc-74bc-4073-be06-d090908fa950.TID504.tmp
[2025-07-19T18:30:20.705+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53a3a086
[2025-07-19T18:30:20.709+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=69, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.709+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=69),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/69] for update
[2025-07-19T18:30:20.709+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.710+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:20.710+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/65/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/65/.1.delta.130063fb-c277-4b3f-9da8-8f01afdf2c53.TID505.tmp
[2025-07-19T18:30:20.710+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.712+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b436b15
[2025-07-19T18:30:20.713+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=70, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.713+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=70),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/70] for update
[2025-07-19T18:30:20.715+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.718+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/69/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/69/.1.delta.39eac1dd-b5ac-44c2-908a-8634b600f257.TID507.tmp
[2025-07-19T18:30:20.719+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2a76b39e
[2025-07-19T18:30:20.720+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/60/.1.delta.1325fc6b-9239-44ea-b305-1d5ac1f8ffb3.TID502.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/60/1.delta
[2025-07-19T18:30:20.721+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=60),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/60] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/60/1.delta
[2025-07-19T18:30:20.722+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=67, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.722+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=67),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/67] for update
[2025-07-19T18:30:20.723+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 60 (task 502, attempt 0, stage 1.0)
[2025-07-19T18:30:20.723+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.723+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/59/.1.delta.9617683f-e6f8-4014-901f-333c5f5e086d.TID501.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/59/1.delta
[2025-07-19T18:30:20.724+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=59),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/59] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/59/1.delta
[2025-07-19T18:30:20.724+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 59 (task 501, attempt 0, stage 1.0)
[2025-07-19T18:30:20.727+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/70/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/70/.1.delta.443c24ed-4c9a-4804-af95-84ac0e71405b.TID508.tmp
[2025-07-19T18:30:20.727+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 60 (task 502, attempt 0, stage 1.0)
[2025-07-19T18:30:20.728+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 60.0 in stage 1.0 (TID 502). 6200 bytes result sent to driver
[2025-07-19T18:30:20.733+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 71.0 in stage 1.0 (TID 509) (8b44f3d35cfa, executor driver, partition 71, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.736+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 59 (task 501, attempt 0, stage 1.0)
[2025-07-19T18:30:20.737+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 60.0 in stage 1.0 (TID 502) in 82 ms on 8b44f3d35cfa (executor driver) (99/200)
[2025-07-19T18:30:20.738+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 71.0 in stage 1.0 (TID 509)
[2025-07-19T18:30:20.739+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.739+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.739+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 59.0 in stage 1.0 (TID 501). 6200 bytes result sent to driver
[2025-07-19T18:30:20.740+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 74.0 in stage 1.0 (TID 510) (8b44f3d35cfa, executor driver, partition 74, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.740+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 74.0 in stage 1.0 (TID 510)
[2025-07-19T18:30:20.740+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 59.0 in stage 1.0 (TID 501) in 94 ms on 8b44f3d35cfa (executor driver) (100/200)
[2025-07-19T18:30:20.742+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/61/.1.delta.deaa76de-a36f-49cb-8b9a-ddc97ff3c23e.TID503.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/61/1.delta
[2025-07-19T18:30:20.743+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=61),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/61] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/61/1.delta
[2025-07-19T18:30:20.743+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.744+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.744+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 61 (task 503, attempt 0, stage 1.0)
[2025-07-19T18:30:20.745+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@676dc3d1
[2025-07-19T18:30:20.745+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/67/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/67/.1.delta.85af8f50-7f59-4257-a293-1ad1cd3a4bd5.TID506.tmp
[2025-07-19T18:30:20.745+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=71, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.745+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=71),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/71] for update
[2025-07-19T18:30:20.746+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.746+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/62/.1.delta.a80368fc-74bc-4073-be06-d090908fa950.TID504.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/62/1.delta
[2025-07-19T18:30:20.746+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=62),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/62] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/62/1.delta
[2025-07-19T18:30:20.747+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 62 (task 504, attempt 0, stage 1.0)
[2025-07-19T18:30:20.749+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 61 (task 503, attempt 0, stage 1.0)
[2025-07-19T18:30:20.750+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 61.0 in stage 1.0 (TID 503). 6200 bytes result sent to driver
[2025-07-19T18:30:20.751+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 62 (task 504, attempt 0, stage 1.0)
[2025-07-19T18:30:20.752+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 75.0 in stage 1.0 (TID 511) (8b44f3d35cfa, executor driver, partition 75, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.752+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 62.0 in stage 1.0 (TID 504). 6200 bytes result sent to driver
[2025-07-19T18:30:20.753+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 61.0 in stage 1.0 (TID 503) in 93 ms on 8b44f3d35cfa (executor driver) (101/200)
[2025-07-19T18:30:20.753+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 76.0 in stage 1.0 (TID 512) (8b44f3d35cfa, executor driver, partition 76, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.754+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@24433109
[2025-07-19T18:30:20.754+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 62.0 in stage 1.0 (TID 504) in 86 ms on 8b44f3d35cfa (executor driver) (102/200)
[2025-07-19T18:30:20.755+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 75.0 in stage 1.0 (TID 511)
[2025-07-19T18:30:20.755+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/71/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/71/.1.delta.49611d46-5287-4f81-94c6-aac9e9e06fcc.TID509.tmp
[2025-07-19T18:30:20.755+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 76.0 in stage 1.0 (TID 512)
[2025-07-19T18:30:20.756+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=74, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.758+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=74),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/74] for update
[2025-07-19T18:30:20.759+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/70/.1.delta.443c24ed-4c9a-4804-af95-84ac0e71405b.TID508.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/70/1.delta
[2025-07-19T18:30:20.760+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=70),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/70] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/70/1.delta
[2025-07-19T18:30:20.761+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/65/.1.delta.130063fb-c277-4b3f-9da8-8f01afdf2c53.TID505.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/65/1.delta
[2025-07-19T18:30:20.761+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=65),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/65] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/65/1.delta
[2025-07-19T18:30:20.762+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 70 (task 508, attempt 0, stage 1.0)
[2025-07-19T18:30:20.762+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.763+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.764+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.765+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.766+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 65 (task 505, attempt 0, stage 1.0)
[2025-07-19T18:30:20.768+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.768+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 65 (task 505, attempt 0, stage 1.0)
[2025-07-19T18:30:20.769+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 70 (task 508, attempt 0, stage 1.0)
[2025-07-19T18:30:20.769+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 70.0 in stage 1.0 (TID 508). 6200 bytes result sent to driver
[2025-07-19T18:30:20.770+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 65.0 in stage 1.0 (TID 505). 6200 bytes result sent to driver
[2025-07-19T18:30:20.770+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 77.0 in stage 1.0 (TID 513) (8b44f3d35cfa, executor driver, partition 77, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.770+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/69/.1.delta.39eac1dd-b5ac-44c2-908a-8634b600f257.TID507.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/69/1.delta
[2025-07-19T18:30:20.771+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=69),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/69] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/69/1.delta
[2025-07-19T18:30:20.771+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 78.0 in stage 1.0 (TID 514) (8b44f3d35cfa, executor driver, partition 78, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.772+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 69 (task 507, attempt 0, stage 1.0)
[2025-07-19T18:30:20.772+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 65.0 in stage 1.0 (TID 505) in 84 ms on 8b44f3d35cfa (executor driver) (103/200)
[2025-07-19T18:30:20.772+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 70.0 in stage 1.0 (TID 508) in 66 ms on 8b44f3d35cfa (executor driver) (104/200)
[2025-07-19T18:30:20.773+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 78.0 in stage 1.0 (TID 514)
[2025-07-19T18:30:20.775+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 77.0 in stage 1.0 (TID 513)
[2025-07-19T18:30:20.776+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23592dd3
[2025-07-19T18:30:20.777+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=76, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.779+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=76),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/76] for update
[2025-07-19T18:30:20.780+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 69 (task 507, attempt 0, stage 1.0)
[2025-07-19T18:30:20.784+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 69.0 in stage 1.0 (TID 507). 6200 bytes result sent to driver
[2025-07-19T18:30:20.785+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 79.0 in stage 1.0 (TID 515) (8b44f3d35cfa, executor driver, partition 79, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.785+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 69.0 in stage 1.0 (TID 507) in 80 ms on 8b44f3d35cfa (executor driver) (105/200)
[2025-07-19T18:30:20.785+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 79.0 in stage 1.0 (TID 515)
[2025-07-19T18:30:20.786+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/74/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/74/.1.delta.9a85aef5-741e-4533-b3c1-77d85eeeb712.TID510.tmp
[2025-07-19T18:30:20.787+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.787+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e671399
[2025-07-19T18:30:20.787+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=75, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.788+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=75),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/75] for update
[2025-07-19T18:30:20.788+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.788+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.789+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.789+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3af28b8c
[2025-07-19T18:30:20.790+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=78, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.790+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=78),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/78] for update
[2025-07-19T18:30:20.791+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.791+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.792+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.792+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.792+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.793+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/67/.1.delta.85af8f50-7f59-4257-a293-1ad1cd3a4bd5.TID506.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/67/1.delta
[2025-07-19T18:30:20.794+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=67),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/67] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/67/1.delta
[2025-07-19T18:30:20.795+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 67 (task 506, attempt 0, stage 1.0)
[2025-07-19T18:30:20.795+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/76/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/76/.1.delta.1907426f-2fb3-4f13-b625-74425ec64b01.TID512.tmp
[2025-07-19T18:30:20.795+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/71/.1.delta.49611d46-5287-4f81-94c6-aac9e9e06fcc.TID509.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/71/1.delta
[2025-07-19T18:30:20.795+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=71),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/71] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/71/1.delta
[2025-07-19T18:30:20.796+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 71 (task 509, attempt 0, stage 1.0)
[2025-07-19T18:30:20.796+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6498be25
[2025-07-19T18:30:20.796+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 67 (task 506, attempt 0, stage 1.0)
[2025-07-19T18:30:20.796+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 71 (task 509, attempt 0, stage 1.0)
[2025-07-19T18:30:20.797+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 71.0 in stage 1.0 (TID 509). 6200 bytes result sent to driver
[2025-07-19T18:30:20.797+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 80.0 in stage 1.0 (TID 516) (8b44f3d35cfa, executor driver, partition 80, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.797+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 71.0 in stage 1.0 (TID 509) in 62 ms on 8b44f3d35cfa (executor driver) (106/200)
[2025-07-19T18:30:20.797+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 67.0 in stage 1.0 (TID 506). 6200 bytes result sent to driver
[2025-07-19T18:30:20.798+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=79, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.798+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=79),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/79] for update
[2025-07-19T18:30:20.798+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 80.0 in stage 1.0 (TID 516)
[2025-07-19T18:30:20.798+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 81.0 in stage 1.0 (TID 517) (8b44f3d35cfa, executor driver, partition 81, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.799+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.799+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 67.0 in stage 1.0 (TID 506) in 114 ms on 8b44f3d35cfa (executor driver) (107/200)
[2025-07-19T18:30:20.800+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.800+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 81.0 in stage 1.0 (TID 517)
[2025-07-19T18:30:20.801+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.801+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.801+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/78/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/78/.1.delta.82912e1c-8d1b-4a93-9b47-d416e6ac0302.TID514.tmp
[2025-07-19T18:30:20.801+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@57c022ac
[2025-07-19T18:30:20.801+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=77, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.802+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=77),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/77] for update
[2025-07-19T18:30:20.803+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/75/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/75/.1.delta.d216d267-17f3-4194-8b07-810746292459.TID511.tmp
[2025-07-19T18:30:20.806+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@241f0ca4
[2025-07-19T18:30:20.807+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=81, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.807+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=81),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/81] for update
[2025-07-19T18:30:20.810+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/74/.1.delta.9a85aef5-741e-4533-b3c1-77d85eeeb712.TID510.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/74/1.delta
[2025-07-19T18:30:20.811+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=74),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/74] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/74/1.delta
[2025-07-19T18:30:20.812+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 74 (task 510, attempt 0, stage 1.0)
[2025-07-19T18:30:20.813+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.814+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@573a98f6
[2025-07-19T18:30:20.814+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=80, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.814+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=80),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/80] for update
[2025-07-19T18:30:20.814+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.815+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 74 (task 510, attempt 0, stage 1.0)
[2025-07-19T18:30:20.815+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.815+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 74.0 in stage 1.0 (TID 510). 6200 bytes result sent to driver
[2025-07-19T18:30:20.815+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.815+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 82.0 in stage 1.0 (TID 518) (8b44f3d35cfa, executor driver, partition 82, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.815+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 82.0 in stage 1.0 (TID 518)
[2025-07-19T18:30:20.815+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 74.0 in stage 1.0 (TID 510) in 75 ms on 8b44f3d35cfa (executor driver) (108/200)
[2025-07-19T18:30:20.816+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.816+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.826+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b16c70b
[2025-07-19T18:30:20.827+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=82, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.827+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=82),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/82] for update
[2025-07-19T18:30:20.827+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/78/.1.delta.82912e1c-8d1b-4a93-9b47-d416e6ac0302.TID514.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/78/1.delta
[2025-07-19T18:30:20.827+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=78),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/78] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/78/1.delta
[2025-07-19T18:30:20.827+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/81/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/81/.1.delta.e8fb8276-c4a7-41cf-9bbd-6aa726a3642d.TID517.tmp
[2025-07-19T18:30:20.828+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/80/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/80/.1.delta.5781d4b2-8d90-40a8-a6bf-7b6931e9126d.TID516.tmp
[2025-07-19T18:30:20.828+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.828+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/77/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/77/.1.delta.ab84e709-9bd3-4cbc-a3b8-b559b5145dfc.TID513.tmp
[2025-07-19T18:30:20.828+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 78 (task 514, attempt 0, stage 1.0)
[2025-07-19T18:30:20.830+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/76/.1.delta.1907426f-2fb3-4f13-b625-74425ec64b01.TID512.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/76/1.delta
[2025-07-19T18:30:20.830+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=76),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/76] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/76/1.delta
[2025-07-19T18:30:20.831+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 76 (task 512, attempt 0, stage 1.0)
[2025-07-19T18:30:20.832+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 78 (task 514, attempt 0, stage 1.0)
[2025-07-19T18:30:20.834+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/79/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/79/.1.delta.2a5a7e69-c232-47c5-a61a-a9428adbd59e.TID515.tmp
[2025-07-19T18:30:20.835+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 78.0 in stage 1.0 (TID 514). 6200 bytes result sent to driver
[2025-07-19T18:30:20.835+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 84.0 in stage 1.0 (TID 519) (8b44f3d35cfa, executor driver, partition 84, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.836+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 84.0 in stage 1.0 (TID 519)
[2025-07-19T18:30:20.836+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 78.0 in stage 1.0 (TID 514) in 72 ms on 8b44f3d35cfa (executor driver) (109/200)
[2025-07-19T18:30:20.838+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.839+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.840+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 76 (task 512, attempt 0, stage 1.0)
[2025-07-19T18:30:20.840+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 76.0 in stage 1.0 (TID 512). 6200 bytes result sent to driver
[2025-07-19T18:30:20.841+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 86.0 in stage 1.0 (TID 520) (8b44f3d35cfa, executor driver, partition 86, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.841+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 86.0 in stage 1.0 (TID 520)
[2025-07-19T18:30:20.842+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/82/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/82/.1.delta.1307b618-c758-410e-93ed-c45aa066b212.TID518.tmp
[2025-07-19T18:30:20.842+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 76.0 in stage 1.0 (TID 512) in 89 ms on 8b44f3d35cfa (executor driver) (110/200)
[2025-07-19T18:30:20.844+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.845+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.845+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19f43880
[2025-07-19T18:30:20.846+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=84, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.847+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=84),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/84] for update
[2025-07-19T18:30:20.847+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/75/.1.delta.d216d267-17f3-4194-8b07-810746292459.TID511.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/75/1.delta
[2025-07-19T18:30:20.848+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=75),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/75] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/75/1.delta
[2025-07-19T18:30:20.848+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 75 (task 511, attempt 0, stage 1.0)
[2025-07-19T18:30:20.850+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.850+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 75 (task 511, attempt 0, stage 1.0)
[2025-07-19T18:30:20.853+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 75.0 in stage 1.0 (TID 511). 6200 bytes result sent to driver
[2025-07-19T18:30:20.860+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 88.0 in stage 1.0 (TID 521) (8b44f3d35cfa, executor driver, partition 88, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.861+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 88.0 in stage 1.0 (TID 521)
[2025-07-19T18:30:20.861+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 75.0 in stage 1.0 (TID 511) in 108 ms on 8b44f3d35cfa (executor driver) (111/200)
[2025-07-19T18:30:20.862+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@647e2f71
[2025-07-19T18:30:20.863+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=86, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.863+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/84/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/84/.1.delta.637af58c-b25f-46a9-aebe-22635f4ea1dc.TID519.tmp
[2025-07-19T18:30:20.864+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=86),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/86] for update
[2025-07-19T18:30:20.865+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/81/.1.delta.e8fb8276-c4a7-41cf-9bbd-6aa726a3642d.TID517.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/81/1.delta
[2025-07-19T18:30:20.865+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.866+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=81),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/81] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/81/1.delta
[2025-07-19T18:30:20.866+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 81 (task 517, attempt 0, stage 1.0)
[2025-07-19T18:30:20.867+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.868+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.872+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 81 (task 517, attempt 0, stage 1.0)
[2025-07-19T18:30:20.873+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@21b56d6e
[2025-07-19T18:30:20.874+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/80/.1.delta.5781d4b2-8d90-40a8-a6bf-7b6931e9126d.TID516.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/80/1.delta
[2025-07-19T18:30:20.874+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=80),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/80] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/80/1.delta
[2025-07-19T18:30:20.875+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 81.0 in stage 1.0 (TID 517). 6243 bytes result sent to driver
[2025-07-19T18:30:20.875+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/79/.1.delta.2a5a7e69-c232-47c5-a61a-a9428adbd59e.TID515.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/79/1.delta
[2025-07-19T18:30:20.879+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=79),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/79] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/79/1.delta
[2025-07-19T18:30:20.879+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/77/.1.delta.ab84e709-9bd3-4cbc-a3b8-b559b5145dfc.TID513.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/77/1.delta
[2025-07-19T18:30:20.880+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=77),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/77] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/77/1.delta
[2025-07-19T18:30:20.881+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=88, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.882+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 77 (task 513, attempt 0, stage 1.0)
[2025-07-19T18:30:20.882+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=88),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/88] for update
[2025-07-19T18:30:20.883+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 89.0 in stage 1.0 (TID 522) (8b44f3d35cfa, executor driver, partition 89, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.883+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 80 (task 516, attempt 0, stage 1.0)
[2025-07-19T18:30:20.883+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 89.0 in stage 1.0 (TID 522)
[2025-07-19T18:30:20.885+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 79 (task 515, attempt 0, stage 1.0)
[2025-07-19T18:30:20.885+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 81.0 in stage 1.0 (TID 517) in 79 ms on 8b44f3d35cfa (executor driver) (112/200)
[2025-07-19T18:30:20.885+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.887+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/86/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/86/.1.delta.8e9e92c0-f443-44f8-b842-7f0e73eab91b.TID520.tmp
[2025-07-19T18:30:20.888+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 77 (task 513, attempt 0, stage 1.0)
[2025-07-19T18:30:20.889+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 80 (task 516, attempt 0, stage 1.0)
[2025-07-19T18:30:20.889+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.890+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.890+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 80.0 in stage 1.0 (TID 516). 6243 bytes result sent to driver
[2025-07-19T18:30:20.891+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 77.0 in stage 1.0 (TID 513). 6243 bytes result sent to driver
[2025-07-19T18:30:20.892+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 90.0 in stage 1.0 (TID 523) (8b44f3d35cfa, executor driver, partition 90, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.892+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 79 (task 515, attempt 0, stage 1.0)
[2025-07-19T18:30:20.893+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 91.0 in stage 1.0 (TID 524) (8b44f3d35cfa, executor driver, partition 91, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.894+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 79.0 in stage 1.0 (TID 515). 6243 bytes result sent to driver
[2025-07-19T18:30:20.894+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 90.0 in stage 1.0 (TID 523)
[2025-07-19T18:30:20.894+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 91.0 in stage 1.0 (TID 524)
[2025-07-19T18:30:20.895+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 92.0 in stage 1.0 (TID 525) (8b44f3d35cfa, executor driver, partition 92, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.896+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 80.0 in stage 1.0 (TID 516) in 88 ms on 8b44f3d35cfa (executor driver) (113/200)
[2025-07-19T18:30:20.896+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 79.0 in stage 1.0 (TID 515) in 113 ms on 8b44f3d35cfa (executor driver) (114/200)
[2025-07-19T18:30:20.896+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.897+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.898+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 77.0 in stage 1.0 (TID 513) in 120 ms on 8b44f3d35cfa (executor driver) (115/200)
[2025-07-19T18:30:20.898+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 92.0 in stage 1.0 (TID 525)
[2025-07-19T18:30:20.899+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.899+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.899+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/82/.1.delta.1307b618-c758-410e-93ed-c45aa066b212.TID518.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/82/1.delta
[2025-07-19T18:30:20.900+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=82),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/82] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/82/1.delta
[2025-07-19T18:30:20.901+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.901+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:20.902+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@238f2ac9
[2025-07-19T18:30:20.902+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=89, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.903+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=89),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/89] for update
[2025-07-19T18:30:20.903+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 82 (task 518, attempt 0, stage 1.0)
[2025-07-19T18:30:20.903+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.904+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/88/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/88/.1.delta.8ca317ab-3426-444f-868b-1b3373dc3b4f.TID521.tmp
[2025-07-19T18:30:20.904+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 82 (task 518, attempt 0, stage 1.0)
[2025-07-19T18:30:20.904+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 82.0 in stage 1.0 (TID 518). 6243 bytes result sent to driver
[2025-07-19T18:30:20.905+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 93.0 in stage 1.0 (TID 526) (8b44f3d35cfa, executor driver, partition 93, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.906+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 82.0 in stage 1.0 (TID 518) in 77 ms on 8b44f3d35cfa (executor driver) (116/200)
[2025-07-19T18:30:20.906+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 93.0 in stage 1.0 (TID 526)
[2025-07-19T18:30:20.906+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@551c1ea3
[2025-07-19T18:30:20.907+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.907+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.907+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=91, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.908+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=91),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/91] for update
[2025-07-19T18:30:20.908+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.909+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/89/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/89/.1.delta.8ee37365-25fd-4fb0-8831-d1ef25115040.TID522.tmp
[2025-07-19T18:30:20.909+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3aa8cc4f
[2025-07-19T18:30:20.909+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=92, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.910+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=92),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/92] for update
[2025-07-19T18:30:20.910+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/84/.1.delta.637af58c-b25f-46a9-aebe-22635f4ea1dc.TID519.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/84/1.delta
[2025-07-19T18:30:20.910+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=84),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/84] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/84/1.delta
[2025-07-19T18:30:20.910+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.911+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 84 (task 519, attempt 0, stage 1.0)
[2025-07-19T18:30:20.911+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 84 (task 519, attempt 0, stage 1.0)
[2025-07-19T18:30:20.911+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 84.0 in stage 1.0 (TID 519). 6243 bytes result sent to driver
[2025-07-19T18:30:20.911+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 96.0 in stage 1.0 (TID 527) (8b44f3d35cfa, executor driver, partition 96, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.911+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 96.0 in stage 1.0 (TID 527)
[2025-07-19T18:30:20.911+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 84.0 in stage 1.0 (TID 519) in 73 ms on 8b44f3d35cfa (executor driver) (117/200)
[2025-07-19T18:30:20.912+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/91/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/91/.1.delta.23669989-803e-450a-aa3e-8bb49ce8379a.TID524.tmp
[2025-07-19T18:30:20.913+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3416d614
[2025-07-19T18:30:20.913+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.913+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.914+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=90, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.914+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=90),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/90] for update
[2025-07-19T18:30:20.916+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/86/.1.delta.8e9e92c0-f443-44f8-b842-7f0e73eab91b.TID520.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/86/1.delta
[2025-07-19T18:30:20.916+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=86),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/86] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/86/1.delta
[2025-07-19T18:30:20.918+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 86 (task 520, attempt 0, stage 1.0)
[2025-07-19T18:30:20.918+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.918+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/92/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/92/.1.delta.699ff0b8-2df3-4eea-9f0f-3a07b04a132b.TID525.tmp
[2025-07-19T18:30:20.918+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1290b49c
[2025-07-19T18:30:20.920+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=96, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.921+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=96),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/96] for update
[2025-07-19T18:30:20.922+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 86 (task 520, attempt 0, stage 1.0)
[2025-07-19T18:30:20.923+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 86.0 in stage 1.0 (TID 520). 6243 bytes result sent to driver
[2025-07-19T18:30:20.923+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 97.0 in stage 1.0 (TID 528) (8b44f3d35cfa, executor driver, partition 97, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.923+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 86.0 in stage 1.0 (TID 520) in 83 ms on 8b44f3d35cfa (executor driver) (118/200)
[2025-07-19T18:30:20.924+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 97.0 in stage 1.0 (TID 528)
[2025-07-19T18:30:20.926+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/88/.1.delta.8ca317ab-3426-444f-868b-1b3373dc3b4f.TID521.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/88/1.delta
[2025-07-19T18:30:20.926+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=88),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/88] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/88/1.delta
[2025-07-19T18:30:20.926+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2caf52d3
[2025-07-19T18:30:20.926+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 88 (task 521, attempt 0, stage 1.0)
[2025-07-19T18:30:20.927+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=93, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.927+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=93),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/93] for update
[2025-07-19T18:30:20.927+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.927+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T18:30:20.929+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.931+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 88 (task 521, attempt 0, stage 1.0)
[2025-07-19T18:30:20.931+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 88.0 in stage 1.0 (TID 521). 6243 bytes result sent to driver
[2025-07-19T18:30:20.931+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/90/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/90/.1.delta.932ffc8a-75cc-4d73-8c67-21abf66dc8ae.TID523.tmp
[2025-07-19T18:30:20.931+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 98.0 in stage 1.0 (TID 529) (8b44f3d35cfa, executor driver, partition 98, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.932+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 88.0 in stage 1.0 (TID 521) in 77 ms on 8b44f3d35cfa (executor driver) (119/200)
[2025-07-19T18:30:20.932+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.933+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 98.0 in stage 1.0 (TID 529)
[2025-07-19T18:30:20.933+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@402f48fb
[2025-07-19T18:30:20.934+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.935+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.935+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=97, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.936+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=97),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/97] for update
[2025-07-19T18:30:20.936+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/89/.1.delta.8ee37365-25fd-4fb0-8831-d1ef25115040.TID522.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/89/1.delta
[2025-07-19T18:30:20.936+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=89),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/89] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/89/1.delta
[2025-07-19T18:30:20.937+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 89 (task 522, attempt 0, stage 1.0)
[2025-07-19T18:30:20.937+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.941+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/96/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/96/.1.delta.2161a452-b28f-47c9-8d35-fc4c7adf08e9.TID527.tmp
[2025-07-19T18:30:20.941+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 89 (task 522, attempt 0, stage 1.0)
[2025-07-19T18:30:20.942+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 89.0 in stage 1.0 (TID 522). 6243 bytes result sent to driver
[2025-07-19T18:30:20.942+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 99.0 in stage 1.0 (TID 530) (8b44f3d35cfa, executor driver, partition 99, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.943+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@75076fdd
[2025-07-19T18:30:20.943+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 89.0 in stage 1.0 (TID 522) in 70 ms on 8b44f3d35cfa (executor driver) (120/200)
[2025-07-19T18:30:20.944+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 99.0 in stage 1.0 (TID 530)
[2025-07-19T18:30:20.948+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=98, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.949+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=98),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/98] for update
[2025-07-19T18:30:20.949+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/91/.1.delta.23669989-803e-450a-aa3e-8bb49ce8379a.TID524.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/91/1.delta
[2025-07-19T18:30:20.949+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=91),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/91] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/91/1.delta
[2025-07-19T18:30:20.949+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/93/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/93/.1.delta.c9318f1c-d1f8-45f5-94ef-d88ace74c239.TID526.tmp
[2025-07-19T18:30:20.951+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.952+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.952+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 91 (task 524, attempt 0, stage 1.0)
[2025-07-19T18:30:20.952+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.953+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 91 (task 524, attempt 0, stage 1.0)
[2025-07-19T18:30:20.954+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 91.0 in stage 1.0 (TID 524). 6243 bytes result sent to driver
[2025-07-19T18:30:20.954+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 101.0 in stage 1.0 (TID 531) (8b44f3d35cfa, executor driver, partition 101, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.955+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 101.0 in stage 1.0 (TID 531)
[2025-07-19T18:30:20.955+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/97/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/97/.1.delta.83405bf9-5377-4853-a694-4842445d2a0e.TID528.tmp
[2025-07-19T18:30:20.955+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 91.0 in stage 1.0 (TID 524) in 73 ms on 8b44f3d35cfa (executor driver) (121/200)
[2025-07-19T18:30:20.955+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.955+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.956+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/98/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/98/.1.delta.49bb6464-5d09-4a8c-a537-54d2c566a502.TID529.tmp
[2025-07-19T18:30:20.956+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@24560740
[2025-07-19T18:30:20.956+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=99, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.958+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=99),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/99] for update
[2025-07-19T18:30:20.959+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.959+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/92/.1.delta.699ff0b8-2df3-4eea-9f0f-3a07b04a132b.TID525.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/92/1.delta
[2025-07-19T18:30:20.959+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=92),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/92] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/92/1.delta
[2025-07-19T18:30:20.960+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 92 (task 525, attempt 0, stage 1.0)
[2025-07-19T18:30:20.960+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/90/.1.delta.932ffc8a-75cc-4d73-8c67-21abf66dc8ae.TID523.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/90/1.delta
[2025-07-19T18:30:20.960+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=90),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/90] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/90/1.delta
[2025-07-19T18:30:20.960+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 90 (task 523, attempt 0, stage 1.0)
[2025-07-19T18:30:20.961+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@72537755
[2025-07-19T18:30:20.962+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=101, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.964+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=101),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/101] for update
[2025-07-19T18:30:20.964+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 90 (task 523, attempt 0, stage 1.0)
[2025-07-19T18:30:20.964+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 90.0 in stage 1.0 (TID 523). 6243 bytes result sent to driver
[2025-07-19T18:30:20.965+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.966+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 102.0 in stage 1.0 (TID 532) (8b44f3d35cfa, executor driver, partition 102, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.967+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 92 (task 525, attempt 0, stage 1.0)
[2025-07-19T18:30:20.967+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 92.0 in stage 1.0 (TID 525). 6200 bytes result sent to driver
[2025-07-19T18:30:20.968+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 102.0 in stage 1.0 (TID 532)
[2025-07-19T18:30:20.968+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 103.0 in stage 1.0 (TID 533) (8b44f3d35cfa, executor driver, partition 103, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.968+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.968+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.968+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/99/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/99/.1.delta.94236f4b-13ec-4254-afe5-1984bd171404.TID530.tmp
[2025-07-19T18:30:20.968+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 92.0 in stage 1.0 (TID 525) in 88 ms on 8b44f3d35cfa (executor driver) (122/200)
[2025-07-19T18:30:20.968+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 103.0 in stage 1.0 (TID 533)
[2025-07-19T18:30:20.968+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 90.0 in stage 1.0 (TID 523) in 90 ms on 8b44f3d35cfa (executor driver) (123/200)
[2025-07-19T18:30:20.970+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.970+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.974+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@64449018
[2025-07-19T18:30:20.975+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=102, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.975+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=102),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/102] for update
[2025-07-19T18:30:20.976+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/101/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/101/.1.delta.ba27b8a4-99d2-4283-a6ed-0926ddb030a7.TID531.tmp
[2025-07-19T18:30:20.976+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.976+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/93/.1.delta.c9318f1c-d1f8-45f5-94ef-d88ace74c239.TID526.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/93/1.delta
[2025-07-19T18:30:20.977+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=93),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/93] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/93/1.delta
[2025-07-19T18:30:20.980+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 93 (task 526, attempt 0, stage 1.0)
[2025-07-19T18:30:20.980+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 93 (task 526, attempt 0, stage 1.0)
[2025-07-19T18:30:20.981+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ffa8c2
[2025-07-19T18:30:20.982+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 93.0 in stage 1.0 (TID 526). 6243 bytes result sent to driver
[2025-07-19T18:30:20.982+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=103, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.983+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/96/.1.delta.2161a452-b28f-47c9-8d35-fc4c7adf08e9.TID527.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/96/1.delta
[2025-07-19T18:30:20.984+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=96),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/96] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/96/1.delta
[2025-07-19T18:30:20.984+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=103),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/103] for update
[2025-07-19T18:30:20.985+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 104.0 in stage 1.0 (TID 534) (8b44f3d35cfa, executor driver, partition 104, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.986+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 93.0 in stage 1.0 (TID 526) in 92 ms on 8b44f3d35cfa (executor driver) (124/200)
[2025-07-19T18:30:20.986+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 96 (task 527, attempt 0, stage 1.0)
[2025-07-19T18:30:20.987+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 104.0 in stage 1.0 (TID 534)
[2025-07-19T18:30:20.987+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.988+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/97/.1.delta.83405bf9-5377-4853-a694-4842445d2a0e.TID528.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/97/1.delta
[2025-07-19T18:30:20.988+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=97),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/97] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/97/1.delta
[2025-07-19T18:30:20.988+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:20.988+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:20.988+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/98/.1.delta.49bb6464-5d09-4a8c-a537-54d2c566a502.TID529.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/98/1.delta
[2025-07-19T18:30:20.988+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=98),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/98] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/98/1.delta
[2025-07-19T18:30:20.988+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 97 (task 528, attempt 0, stage 1.0)
[2025-07-19T18:30:20.988+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/102/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/102/.1.delta.1a71fe69-349d-45da-a9c9-22c0ff945e6d.TID532.tmp
[2025-07-19T18:30:20.988+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 98 (task 529, attempt 0, stage 1.0)
[2025-07-19T18:30:20.991+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2df4e95d
[2025-07-19T18:30:20.991+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=104, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:20.992+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=104),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/104] for update
[2025-07-19T18:30:20.995+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 96 (task 527, attempt 0, stage 1.0)
[2025-07-19T18:30:20.996+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:20.997+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 96.0 in stage 1.0 (TID 527). 6243 bytes result sent to driver
[2025-07-19T18:30:20.997+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/103/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/103/.1.delta.ed27cb02-e311-4d92-b982-4be0feeb3665.TID533.tmp
[2025-07-19T18:30:20.997+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 105.0 in stage 1.0 (TID 535) (8b44f3d35cfa, executor driver, partition 105, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:20.998+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 96.0 in stage 1.0 (TID 527) in 87 ms on 8b44f3d35cfa (executor driver) (125/200)
[2025-07-19T18:30:20.999+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 98 (task 529, attempt 0, stage 1.0)
[2025-07-19T18:30:20.999+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 105.0 in stage 1.0 (TID 535)
[2025-07-19T18:30:20.999+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 97 (task 528, attempt 0, stage 1.0)
[2025-07-19T18:30:21.000+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 98.0 in stage 1.0 (TID 529). 6200 bytes result sent to driver
[2025-07-19T18:30:21.001+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 97.0 in stage 1.0 (TID 528). 6200 bytes result sent to driver
[2025-07-19T18:30:21.002+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 108.0 in stage 1.0 (TID 536) (8b44f3d35cfa, executor driver, partition 108, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.002+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 109.0 in stage 1.0 (TID 537) (8b44f3d35cfa, executor driver, partition 109, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.003+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 108.0 in stage 1.0 (TID 536)
[2025-07-19T18:30:21.003+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 97.0 in stage 1.0 (TID 528) in 72 ms on 8b44f3d35cfa (executor driver) (126/200)
[2025-07-19T18:30:21.003+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 98.0 in stage 1.0 (TID 529) in 65 ms on 8b44f3d35cfa (executor driver) (127/200)
[2025-07-19T18:30:21.003+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 109.0 in stage 1.0 (TID 537)
[2025-07-19T18:30:21.003+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/99/.1.delta.94236f4b-13ec-4254-afe5-1984bd171404.TID530.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/99/1.delta
[2025-07-19T18:30:21.003+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=99),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/99] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/99/1.delta
[2025-07-19T18:30:21.004+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Commit authorized for partition 99 (task 530, attempt 0, stage 1.0)
[2025-07-19T18:30:21.004+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.004+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.004+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.005+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.005+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/104/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/104/.1.delta.624894c7-c708-444c-bf1c-e03af53a04f7.TID534.tmp
[2025-07-19T18:30:21.005+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.005+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T18:30:21.005+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO DataWritingSparkTask: Committed partition 99 (task 530, attempt 0, stage 1.0)
[2025-07-19T18:30:21.005+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Finished task 99.0 in stage 1.0 (TID 530). 6200 bytes result sent to driver
[2025-07-19T18:30:21.005+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Starting task 112.0 in stage 1.0 (TID 538) (8b44f3d35cfa, executor driver, partition 112, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.005+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO Executor: Running task 112.0 in stage 1.0 (TID 538)
[2025-07-19T18:30:21.006+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@41e3cc3d
[2025-07-19T18:30:21.006+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO TaskSetManager: Finished task 99.0 in stage 1.0 (TID 530) in 58 ms on 8b44f3d35cfa (executor driver) (128/200)
[2025-07-19T18:30:21.006+0000] {subprocess.py:93} INFO - 25/07/19 18:30:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=109, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.006+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=109),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/109] for update
[2025-07-19T18:30:21.007+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.007+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.008+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.008+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/101/.1.delta.ba27b8a4-99d2-4283-a6ed-0926ddb030a7.TID531.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/101/1.delta
[2025-07-19T18:30:21.009+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=101),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/101] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/101/1.delta
[2025-07-19T18:30:21.010+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 101 (task 531, attempt 0, stage 1.0)
[2025-07-19T18:30:21.010+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@dd537d9
[2025-07-19T18:30:21.011+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=105, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.011+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=105),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/105] for update
[2025-07-19T18:30:21.012+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 101 (task 531, attempt 0, stage 1.0)
[2025-07-19T18:30:21.012+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 101.0 in stage 1.0 (TID 531). 6200 bytes result sent to driver
[2025-07-19T18:30:21.013+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/109/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/109/.1.delta.f34d2ff8-af96-4728-a60e-c2de5093bd43.TID537.tmp
[2025-07-19T18:30:21.013+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 114.0 in stage 1.0 (TID 539) (8b44f3d35cfa, executor driver, partition 114, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.014+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 114.0 in stage 1.0 (TID 539)
[2025-07-19T18:30:21.014+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 101.0 in stage 1.0 (TID 531) in 60 ms on 8b44f3d35cfa (executor driver) (129/200)
[2025-07-19T18:30:21.014+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.015+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f93a7dd
[2025-07-19T18:30:21.016+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=108, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.016+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.017+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.017+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=108),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/108] for update
[2025-07-19T18:30:21.018+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/102/.1.delta.1a71fe69-349d-45da-a9c9-22c0ff945e6d.TID532.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/102/1.delta
[2025-07-19T18:30:21.018+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=102),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/102] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/102/1.delta
[2025-07-19T18:30:21.019+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 102 (task 532, attempt 0, stage 1.0)
[2025-07-19T18:30:21.020+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@327a0bbf
[2025-07-19T18:30:21.021+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=114, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.021+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=114),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/114] for update
[2025-07-19T18:30:21.022+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.023+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.024+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 102 (task 532, attempt 0, stage 1.0)
[2025-07-19T18:30:21.024+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/105/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/105/.1.delta.7513570a-7887-4b01-b4c0-4f38ee83bcf2.TID535.tmp
[2025-07-19T18:30:21.024+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/103/.1.delta.ed27cb02-e311-4d92-b982-4be0feeb3665.TID533.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/103/1.delta
[2025-07-19T18:30:21.024+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=103),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/103] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/103/1.delta
[2025-07-19T18:30:21.024+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 102.0 in stage 1.0 (TID 532). 6200 bytes result sent to driver
[2025-07-19T18:30:21.025+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 103 (task 533, attempt 0, stage 1.0)
[2025-07-19T18:30:21.025+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 115.0 in stage 1.0 (TID 540) (8b44f3d35cfa, executor driver, partition 115, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.025+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 115.0 in stage 1.0 (TID 540)
[2025-07-19T18:30:21.025+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 102.0 in stage 1.0 (TID 532) in 56 ms on 8b44f3d35cfa (executor driver) (130/200)
[2025-07-19T18:30:21.025+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.025+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.026+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23244cb
[2025-07-19T18:30:21.026+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=112, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.026+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=112),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/112] for update
[2025-07-19T18:30:21.027+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/114/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/114/.1.delta.74a5f092-803a-4a59-854c-8b1a5ce3c481.TID539.tmp
[2025-07-19T18:30:21.027+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.028+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/104/.1.delta.624894c7-c708-444c-bf1c-e03af53a04f7.TID534.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/104/1.delta
[2025-07-19T18:30:21.028+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=104),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/104] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/104/1.delta
[2025-07-19T18:30:21.028+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 103 (task 533, attempt 0, stage 1.0)
[2025-07-19T18:30:21.029+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@9419a29
[2025-07-19T18:30:21.030+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 104 (task 534, attempt 0, stage 1.0)
[2025-07-19T18:30:21.030+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 103.0 in stage 1.0 (TID 533). 6200 bytes result sent to driver
[2025-07-19T18:30:21.030+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=115, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.031+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 116.0 in stage 1.0 (TID 541) (8b44f3d35cfa, executor driver, partition 116, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.031+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/108/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/108/.1.delta.05ec7351-d0d5-4e31-9a0e-47d71765d866.TID536.tmp
[2025-07-19T18:30:21.031+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=115),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/115] for update
[2025-07-19T18:30:21.031+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 116.0 in stage 1.0 (TID 541)
[2025-07-19T18:30:21.031+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 103.0 in stage 1.0 (TID 533) in 64 ms on 8b44f3d35cfa (executor driver) (131/200)
[2025-07-19T18:30:21.034+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.036+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.037+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.038+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 104 (task 534, attempt 0, stage 1.0)
[2025-07-19T18:30:21.038+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 104.0 in stage 1.0 (TID 534). 6200 bytes result sent to driver
[2025-07-19T18:30:21.040+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 117.0 in stage 1.0 (TID 542) (8b44f3d35cfa, executor driver, partition 117, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.040+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 104.0 in stage 1.0 (TID 534) in 57 ms on 8b44f3d35cfa (executor driver) (132/200)
[2025-07-19T18:30:21.041+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 117.0 in stage 1.0 (TID 542)
[2025-07-19T18:30:21.041+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/109/.1.delta.f34d2ff8-af96-4728-a60e-c2de5093bd43.TID537.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/109/1.delta
[2025-07-19T18:30:21.041+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=109),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/109] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/109/1.delta
[2025-07-19T18:30:21.041+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 109 (task 537, attempt 0, stage 1.0)
[2025-07-19T18:30:21.042+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.047+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.049+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f74eba4
[2025-07-19T18:30:21.050+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=116, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.050+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=116),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/116] for update
[2025-07-19T18:30:21.051+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/115/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/115/.1.delta.4b86436a-33d6-41cd-8df4-9740c306e3b8.TID540.tmp
[2025-07-19T18:30:21.051+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/112/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/112/.1.delta.a5f783ac-e138-4bb5-94c8-42dd82c3a8f1.TID538.tmp
[2025-07-19T18:30:21.051+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 109 (task 537, attempt 0, stage 1.0)
[2025-07-19T18:30:21.051+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 109.0 in stage 1.0 (TID 537). 6200 bytes result sent to driver
[2025-07-19T18:30:21.052+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 118.0 in stage 1.0 (TID 543) (8b44f3d35cfa, executor driver, partition 118, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.052+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.052+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 118.0 in stage 1.0 (TID 543)
[2025-07-19T18:30:21.052+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 109.0 in stage 1.0 (TID 537) in 53 ms on 8b44f3d35cfa (executor driver) (133/200)
[2025-07-19T18:30:21.053+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.054+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.054+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23f14e26
[2025-07-19T18:30:21.055+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=117, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.056+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/114/.1.delta.74a5f092-803a-4a59-854c-8b1a5ce3c481.TID539.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/114/1.delta
[2025-07-19T18:30:21.057+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=114),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/114] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/114/1.delta
[2025-07-19T18:30:21.057+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 114 (task 539, attempt 0, stage 1.0)
[2025-07-19T18:30:21.058+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=117),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/117] for update
[2025-07-19T18:30:21.058+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/116/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/116/.1.delta.a38699b6-86e9-4b12-a35c-5ec73be918a7.TID541.tmp
[2025-07-19T18:30:21.058+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.059+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 114 (task 539, attempt 0, stage 1.0)
[2025-07-19T18:30:21.059+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 114.0 in stage 1.0 (TID 539). 6200 bytes result sent to driver
[2025-07-19T18:30:21.061+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 119.0 in stage 1.0 (TID 544) (8b44f3d35cfa, executor driver, partition 119, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.061+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/105/.1.delta.7513570a-7887-4b01-b4c0-4f38ee83bcf2.TID535.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/105/1.delta
[2025-07-19T18:30:21.061+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=105),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/105] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/105/1.delta
[2025-07-19T18:30:21.061+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 105 (task 535, attempt 0, stage 1.0)
[2025-07-19T18:30:21.061+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 114.0 in stage 1.0 (TID 539) in 52 ms on 8b44f3d35cfa (executor driver) (134/200)
[2025-07-19T18:30:21.061+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 119.0 in stage 1.0 (TID 544)
[2025-07-19T18:30:21.062+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5309046
[2025-07-19T18:30:21.064+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=118, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.065+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=118),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/118] for update
[2025-07-19T18:30:21.065+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.066+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.067+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.067+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 105 (task 535, attempt 0, stage 1.0)
[2025-07-19T18:30:21.067+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/108/.1.delta.05ec7351-d0d5-4e31-9a0e-47d71765d866.TID536.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/108/1.delta
[2025-07-19T18:30:21.068+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/117/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/117/.1.delta.8b91c4a1-4331-4936-a08a-21f40ee4abca.TID542.tmp
[2025-07-19T18:30:21.068+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=108),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/108] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/108/1.delta
[2025-07-19T18:30:21.070+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 108 (task 536, attempt 0, stage 1.0)
[2025-07-19T18:30:21.071+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 105.0 in stage 1.0 (TID 535). 6200 bytes result sent to driver
[2025-07-19T18:30:21.071+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 120.0 in stage 1.0 (TID 545) (8b44f3d35cfa, executor driver, partition 120, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.071+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 120.0 in stage 1.0 (TID 545)
[2025-07-19T18:30:21.072+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 105.0 in stage 1.0 (TID 535) in 79 ms on 8b44f3d35cfa (executor driver) (135/200)
[2025-07-19T18:30:21.072+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.073+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.076+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 108 (task 536, attempt 0, stage 1.0)
[2025-07-19T18:30:21.079+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 108.0 in stage 1.0 (TID 536). 6200 bytes result sent to driver
[2025-07-19T18:30:21.080+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 121.0 in stage 1.0 (TID 546) (8b44f3d35cfa, executor driver, partition 121, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.082+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 121.0 in stage 1.0 (TID 546)
[2025-07-19T18:30:21.082+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 108.0 in stage 1.0 (TID 536) in 80 ms on 8b44f3d35cfa (executor driver) (136/200)
[2025-07-19T18:30:21.082+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55bd45e2
[2025-07-19T18:30:21.082+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/118/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/118/.1.delta.52f003cb-18b5-4290-9943-acb3af00de4e.TID543.tmp
[2025-07-19T18:30:21.083+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=119, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.084+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=119),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/119] for update
[2025-07-19T18:30:21.084+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.086+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.086+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.086+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/112/.1.delta.a5f783ac-e138-4bb5-94c8-42dd82c3a8f1.TID538.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/112/1.delta
[2025-07-19T18:30:21.086+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=112),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/112] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/112/1.delta
[2025-07-19T18:30:21.086+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 112 (task 538, attempt 0, stage 1.0)
[2025-07-19T18:30:21.086+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 112 (task 538, attempt 0, stage 1.0)
[2025-07-19T18:30:21.086+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 112.0 in stage 1.0 (TID 538). 6200 bytes result sent to driver
[2025-07-19T18:30:21.089+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 122.0 in stage 1.0 (TID 547) (8b44f3d35cfa, executor driver, partition 122, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.090+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/115/.1.delta.4b86436a-33d6-41cd-8df4-9740c306e3b8.TID540.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/115/1.delta
[2025-07-19T18:30:21.091+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=115),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/115] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/115/1.delta
[2025-07-19T18:30:21.092+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 122.0 in stage 1.0 (TID 547)
[2025-07-19T18:30:21.092+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@37f4bf07
[2025-07-19T18:30:21.093+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 115 (task 540, attempt 0, stage 1.0)
[2025-07-19T18:30:21.093+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/119/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/119/.1.delta.ebee9306-9fea-47d9-9aac-df9caad6cf27.TID544.tmp
[2025-07-19T18:30:21.094+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 112.0 in stage 1.0 (TID 538) in 91 ms on 8b44f3d35cfa (executor driver) (137/200)
[2025-07-19T18:30:21.094+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=120, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.095+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=120),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/120] for update
[2025-07-19T18:30:21.095+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.095+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.095+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.096+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 115 (task 540, attempt 0, stage 1.0)
[2025-07-19T18:30:21.096+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 115.0 in stage 1.0 (TID 540). 6200 bytes result sent to driver
[2025-07-19T18:30:21.097+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 124.0 in stage 1.0 (TID 548) (8b44f3d35cfa, executor driver, partition 124, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.098+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/116/.1.delta.a38699b6-86e9-4b12-a35c-5ec73be918a7.TID541.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/116/1.delta
[2025-07-19T18:30:21.098+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=116),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/116] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/116/1.delta
[2025-07-19T18:30:21.099+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 116 (task 541, attempt 0, stage 1.0)
[2025-07-19T18:30:21.099+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 115.0 in stage 1.0 (TID 540) in 77 ms on 8b44f3d35cfa (executor driver) (138/200)
[2025-07-19T18:30:21.100+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 124.0 in stage 1.0 (TID 548)
[2025-07-19T18:30:21.101+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3867a88c
[2025-07-19T18:30:21.101+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=122, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.102+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.102+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.102+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=122),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/122] for update
[2025-07-19T18:30:21.103+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 116 (task 541, attempt 0, stage 1.0)
[2025-07-19T18:30:21.103+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.104+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 116.0 in stage 1.0 (TID 541). 6200 bytes result sent to driver
[2025-07-19T18:30:21.105+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/120/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/120/.1.delta.c477d383-4739-4da8-bb22-9e1b71d0f265.TID545.tmp
[2025-07-19T18:30:21.106+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/117/.1.delta.8b91c4a1-4331-4936-a08a-21f40ee4abca.TID542.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/117/1.delta
[2025-07-19T18:30:21.106+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=117),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/117] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/117/1.delta
[2025-07-19T18:30:21.108+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/122/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/122/.1.delta.e4ef26dc-2de0-40b2-b380-ef3bb6eb758b.TID547.tmp
[2025-07-19T18:30:21.109+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 117 (task 542, attempt 0, stage 1.0)
[2025-07-19T18:30:21.109+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@62b1ec32
[2025-07-19T18:30:21.110+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 125.0 in stage 1.0 (TID 549) (8b44f3d35cfa, executor driver, partition 125, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.110+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=121, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.111+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=121),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/121] for update
[2025-07-19T18:30:21.111+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 125.0 in stage 1.0 (TID 549)
[2025-07-19T18:30:21.111+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 116.0 in stage 1.0 (TID 541) in 80 ms on 8b44f3d35cfa (executor driver) (139/200)
[2025-07-19T18:30:21.113+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.113+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.114+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.114+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@21c3c27a
[2025-07-19T18:30:21.114+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=124, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.115+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=124),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/124] for update
[2025-07-19T18:30:21.117+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/118/.1.delta.52f003cb-18b5-4290-9943-acb3af00de4e.TID543.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/118/1.delta
[2025-07-19T18:30:21.118+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=118),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/118] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/118/1.delta
[2025-07-19T18:30:21.118+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.118+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 117 (task 542, attempt 0, stage 1.0)
[2025-07-19T18:30:21.119+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 118 (task 543, attempt 0, stage 1.0)
[2025-07-19T18:30:21.119+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 117.0 in stage 1.0 (TID 542). 6200 bytes result sent to driver
[2025-07-19T18:30:21.122+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 126.0 in stage 1.0 (TID 550) (8b44f3d35cfa, executor driver, partition 126, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.122+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 117.0 in stage 1.0 (TID 542) in 85 ms on 8b44f3d35cfa (executor driver) (140/200)
[2025-07-19T18:30:21.123+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 126.0 in stage 1.0 (TID 550)
[2025-07-19T18:30:21.123+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43dab41e
[2025-07-19T18:30:21.124+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=125, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.125+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=125),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/125] for update
[2025-07-19T18:30:21.127+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/119/.1.delta.ebee9306-9fea-47d9-9aac-df9caad6cf27.TID544.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/119/1.delta
[2025-07-19T18:30:21.128+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=119),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/119] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/119/1.delta
[2025-07-19T18:30:21.128+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.128+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 119 (task 544, attempt 0, stage 1.0)
[2025-07-19T18:30:21.128+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.129+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 118 (task 543, attempt 0, stage 1.0)
[2025-07-19T18:30:21.129+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/121/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/121/.1.delta.b03b0e96-f62a-47e1-a740-998e67811aa0.TID546.tmp
[2025-07-19T18:30:21.129+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.132+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 118.0 in stage 1.0 (TID 543). 6243 bytes result sent to driver
[2025-07-19T18:30:21.133+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/124/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/124/.1.delta.42ba3a64-4d52-45fa-b759-81a0dd7bb0f2.TID548.tmp
[2025-07-19T18:30:21.134+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 118.0 in stage 1.0 (TID 543) in 87 ms on 8b44f3d35cfa (executor driver) (141/200)
[2025-07-19T18:30:21.134+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 127.0 in stage 1.0 (TID 551) (8b44f3d35cfa, executor driver, partition 127, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.134+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 127.0 in stage 1.0 (TID 551)
[2025-07-19T18:30:21.135+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 119 (task 544, attempt 0, stage 1.0)
[2025-07-19T18:30:21.135+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6150dd9c
[2025-07-19T18:30:21.135+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.135+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.135+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 119.0 in stage 1.0 (TID 544). 6200 bytes result sent to driver
[2025-07-19T18:30:21.137+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 119.0 in stage 1.0 (TID 544) in 76 ms on 8b44f3d35cfa (executor driver) (142/200)
[2025-07-19T18:30:21.137+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=126, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.138+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=126),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/126] for update
[2025-07-19T18:30:21.138+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.143+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 129.0 in stage 1.0 (TID 552) (8b44f3d35cfa, executor driver, partition 129, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.143+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 129.0 in stage 1.0 (TID 552)
[2025-07-19T18:30:21.147+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.147+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@509c8b40
[2025-07-19T18:30:21.149+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.149+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=127, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.149+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=127),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/127] for update
[2025-07-19T18:30:21.149+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.158+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/125/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/125/.1.delta.5f70badb-cbfd-4a3e-ba7b-6045f204702d.TID549.tmp
[2025-07-19T18:30:21.159+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d9459d6
[2025-07-19T18:30:21.159+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=129, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.160+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=129),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/129] for update
[2025-07-19T18:30:21.161+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.166+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/120/.1.delta.c477d383-4739-4da8-bb22-9e1b71d0f265.TID545.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/120/1.delta
[2025-07-19T18:30:21.167+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=120),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/120] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/120/1.delta
[2025-07-19T18:30:21.167+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 120 (task 545, attempt 0, stage 1.0)
[2025-07-19T18:30:21.169+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/126/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/126/.1.delta.4815d061-7990-4a35-8a57-751ebca68af2.TID550.tmp
[2025-07-19T18:30:21.170+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/127/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/127/.1.delta.46f76f2a-8c21-4250-b789-29673ab5c0cd.TID551.tmp
[2025-07-19T18:30:21.170+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/122/.1.delta.e4ef26dc-2de0-40b2-b380-ef3bb6eb758b.TID547.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/122/1.delta
[2025-07-19T18:30:21.171+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=122),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/122] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/122/1.delta
[2025-07-19T18:30:21.174+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 122 (task 547, attempt 0, stage 1.0)
[2025-07-19T18:30:21.175+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 120 (task 545, attempt 0, stage 1.0)
[2025-07-19T18:30:21.175+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 120.0 in stage 1.0 (TID 545). 6243 bytes result sent to driver
[2025-07-19T18:30:21.180+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 122 (task 547, attempt 0, stage 1.0)
[2025-07-19T18:30:21.181+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 130.0 in stage 1.0 (TID 553) (8b44f3d35cfa, executor driver, partition 130, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.182+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 120.0 in stage 1.0 (TID 545) in 111 ms on 8b44f3d35cfa (executor driver) (143/200)
[2025-07-19T18:30:21.183+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 130.0 in stage 1.0 (TID 553)
[2025-07-19T18:30:21.183+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 122.0 in stage 1.0 (TID 547). 6243 bytes result sent to driver
[2025-07-19T18:30:21.183+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 131.0 in stage 1.0 (TID 554) (8b44f3d35cfa, executor driver, partition 131, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.183+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 122.0 in stage 1.0 (TID 547) in 94 ms on 8b44f3d35cfa (executor driver) (144/200)
[2025-07-19T18:30:21.183+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 131.0 in stage 1.0 (TID 554)
[2025-07-19T18:30:21.185+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/129/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/129/.1.delta.792e1970-bf3c-4744-a507-6f7e7b632a0c.TID552.tmp
[2025-07-19T18:30:21.185+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.185+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.185+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.186+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.192+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4682e4f7
[2025-07-19T18:30:21.192+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=131, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.193+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=131),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/131] for update
[2025-07-19T18:30:21.194+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.194+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/124/.1.delta.42ba3a64-4d52-45fa-b759-81a0dd7bb0f2.TID548.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/124/1.delta
[2025-07-19T18:30:21.194+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=124),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/124] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/124/1.delta
[2025-07-19T18:30:21.196+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 124 (task 548, attempt 0, stage 1.0)
[2025-07-19T18:30:21.197+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/121/.1.delta.b03b0e96-f62a-47e1-a740-998e67811aa0.TID546.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/121/1.delta
[2025-07-19T18:30:21.198+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=121),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/121] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/121/1.delta
[2025-07-19T18:30:21.198+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 121 (task 546, attempt 0, stage 1.0)
[2025-07-19T18:30:21.202+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 121 (task 546, attempt 0, stage 1.0)
[2025-07-19T18:30:21.204+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 124 (task 548, attempt 0, stage 1.0)
[2025-07-19T18:30:21.204+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 124.0 in stage 1.0 (TID 548). 6243 bytes result sent to driver
[2025-07-19T18:30:21.204+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 121.0 in stage 1.0 (TID 546). 6243 bytes result sent to driver
[2025-07-19T18:30:21.205+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 124.0 in stage 1.0 (TID 548) in 109 ms on 8b44f3d35cfa (executor driver) (145/200)
[2025-07-19T18:30:21.206+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 132.0 in stage 1.0 (TID 555) (8b44f3d35cfa, executor driver, partition 132, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.207+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@61e4abbb
[2025-07-19T18:30:21.208+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 132.0 in stage 1.0 (TID 555)
[2025-07-19T18:30:21.209+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=130, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.210+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=130),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/130] for update
[2025-07-19T18:30:21.210+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 133.0 in stage 1.0 (TID 556) (8b44f3d35cfa, executor driver, partition 133, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.210+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.210+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.210+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 121.0 in stage 1.0 (TID 546) in 135 ms on 8b44f3d35cfa (executor driver) (146/200)
[2025-07-19T18:30:21.211+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 133.0 in stage 1.0 (TID 556)
[2025-07-19T18:30:21.211+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.220+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/131/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/131/.1.delta.191023b4-119f-4b74-9b5a-b846c7535608.TID554.tmp
[2025-07-19T18:30:21.220+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.220+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.223+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/127/.1.delta.46f76f2a-8c21-4250-b789-29673ab5c0cd.TID551.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/127/1.delta
[2025-07-19T18:30:21.223+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=127),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/127] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/127/1.delta
[2025-07-19T18:30:21.224+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@350d8440
[2025-07-19T18:30:21.224+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 127 (task 551, attempt 0, stage 1.0)
[2025-07-19T18:30:21.224+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=132, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.224+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=132),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/132] for update
[2025-07-19T18:30:21.225+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/130/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/130/.1.delta.5c20228a-9d10-4b39-b39b-374d0fbeb2cb.TID553.tmp
[2025-07-19T18:30:21.229+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.231+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d460655
[2025-07-19T18:30:21.231+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=133, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.231+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=133),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/133] for update
[2025-07-19T18:30:21.231+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/125/.1.delta.5f70badb-cbfd-4a3e-ba7b-6045f204702d.TID549.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/125/1.delta
[2025-07-19T18:30:21.231+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=125),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/125] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/125/1.delta
[2025-07-19T18:30:21.231+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 125 (task 549, attempt 0, stage 1.0)
[2025-07-19T18:30:21.231+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 127 (task 551, attempt 0, stage 1.0)
[2025-07-19T18:30:21.231+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 127.0 in stage 1.0 (TID 551). 6243 bytes result sent to driver
[2025-07-19T18:30:21.231+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 134.0 in stage 1.0 (TID 557) (8b44f3d35cfa, executor driver, partition 134, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.231+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/126/.1.delta.4815d061-7990-4a35-8a57-751ebca68af2.TID550.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/126/1.delta
[2025-07-19T18:30:21.231+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 127.0 in stage 1.0 (TID 551) in 98 ms on 8b44f3d35cfa (executor driver) (147/200)
[2025-07-19T18:30:21.232+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=126),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/126] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/126/1.delta
[2025-07-19T18:30:21.232+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 134.0 in stage 1.0 (TID 557)
[2025-07-19T18:30:21.232+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 126 (task 550, attempt 0, stage 1.0)
[2025-07-19T18:30:21.232+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.235+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 125 (task 549, attempt 0, stage 1.0)
[2025-07-19T18:30:21.237+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 125.0 in stage 1.0 (TID 549). 6243 bytes result sent to driver
[2025-07-19T18:30:21.238+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 135.0 in stage 1.0 (TID 558) (8b44f3d35cfa, executor driver, partition 135, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.238+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/132/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/132/.1.delta.14f4dd2f-4c82-4ee8-8799-4bb0b8c3d614.TID555.tmp
[2025-07-19T18:30:21.238+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 125.0 in stage 1.0 (TID 549) in 128 ms on 8b44f3d35cfa (executor driver) (148/200)
[2025-07-19T18:30:21.238+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 135.0 in stage 1.0 (TID 558)
[2025-07-19T18:30:21.240+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 126 (task 550, attempt 0, stage 1.0)
[2025-07-19T18:30:21.240+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 126.0 in stage 1.0 (TID 550). 6243 bytes result sent to driver
[2025-07-19T18:30:21.241+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 138.0 in stage 1.0 (TID 559) (8b44f3d35cfa, executor driver, partition 138, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.241+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 126.0 in stage 1.0 (TID 550) in 117 ms on 8b44f3d35cfa (executor driver) (149/200)
[2025-07-19T18:30:21.241+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 138.0 in stage 1.0 (TID 559)
[2025-07-19T18:30:21.241+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.241+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.241+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.241+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T18:30:21.244+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/129/.1.delta.792e1970-bf3c-4744-a507-6f7e7b632a0c.TID552.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/129/1.delta
[2025-07-19T18:30:21.244+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=129),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/129] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/129/1.delta
[2025-07-19T18:30:21.245+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.245+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.246+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 129 (task 552, attempt 0, stage 1.0)
[2025-07-19T18:30:21.249+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 129 (task 552, attempt 0, stage 1.0)
[2025-07-19T18:30:21.249+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@51678c2a
[2025-07-19T18:30:21.250+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=134, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.250+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 129.0 in stage 1.0 (TID 552). 6243 bytes result sent to driver
[2025-07-19T18:30:21.250+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/133/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/133/.1.delta.0dfd26ed-3f41-4394-bff3-63ae1f283987.TID556.tmp
[2025-07-19T18:30:21.250+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=134),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/134] for update
[2025-07-19T18:30:21.251+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 139.0 in stage 1.0 (TID 560) (8b44f3d35cfa, executor driver, partition 139, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.251+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 129.0 in stage 1.0 (TID 552) in 106 ms on 8b44f3d35cfa (executor driver) (150/200)
[2025-07-19T18:30:21.251+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 139.0 in stage 1.0 (TID 560)
[2025-07-19T18:30:21.252+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.252+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5b715ad0
[2025-07-19T18:30:21.255+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.255+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=138, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.256+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.256+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=138),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/138] for update
[2025-07-19T18:30:21.257+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.257+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@34ba5270
[2025-07-19T18:30:21.258+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=139, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.258+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=139),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/139] for update
[2025-07-19T18:30:21.259+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/134/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/134/.1.delta.5c6b48e2-c37d-404a-89c1-b670dcfc2c29.TID557.tmp
[2025-07-19T18:30:21.259+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.260+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/138/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/138/.1.delta.7f54b8a9-e924-4356-a946-ea4a82d52dfd.TID559.tmp
[2025-07-19T18:30:21.261+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@407d72d8
[2025-07-19T18:30:21.262+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=135, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.262+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/131/.1.delta.191023b4-119f-4b74-9b5a-b846c7535608.TID554.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/131/1.delta
[2025-07-19T18:30:21.262+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=131),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/131] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/131/1.delta
[2025-07-19T18:30:21.262+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 131 (task 554, attempt 0, stage 1.0)
[2025-07-19T18:30:21.264+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=135),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/135] for update
[2025-07-19T18:30:21.265+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/130/.1.delta.5c20228a-9d10-4b39-b39b-374d0fbeb2cb.TID553.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/130/1.delta
[2025-07-19T18:30:21.265+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=130),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/130] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/130/1.delta
[2025-07-19T18:30:21.265+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 130 (task 553, attempt 0, stage 1.0)
[2025-07-19T18:30:21.266+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.267+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 130 (task 553, attempt 0, stage 1.0)
[2025-07-19T18:30:21.268+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 131 (task 554, attempt 0, stage 1.0)
[2025-07-19T18:30:21.269+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 131.0 in stage 1.0 (TID 554). 6200 bytes result sent to driver
[2025-07-19T18:30:21.270+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 130.0 in stage 1.0 (TID 553). 6200 bytes result sent to driver
[2025-07-19T18:30:21.271+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 131.0 in stage 1.0 (TID 554) in 87 ms on 8b44f3d35cfa (executor driver) (151/200)
[2025-07-19T18:30:21.272+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 141.0 in stage 1.0 (TID 561) (8b44f3d35cfa, executor driver, partition 141, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.272+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 142.0 in stage 1.0 (TID 562) (8b44f3d35cfa, executor driver, partition 142, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.272+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 142.0 in stage 1.0 (TID 562)
[2025-07-19T18:30:21.272+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/132/.1.delta.14f4dd2f-4c82-4ee8-8799-4bb0b8c3d614.TID555.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/132/1.delta
[2025-07-19T18:30:21.272+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=132),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/132] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/132/1.delta
[2025-07-19T18:30:21.272+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 130.0 in stage 1.0 (TID 553) in 91 ms on 8b44f3d35cfa (executor driver) (152/200)
[2025-07-19T18:30:21.272+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 141.0 in stage 1.0 (TID 561)
[2025-07-19T18:30:21.272+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 132 (task 555, attempt 0, stage 1.0)
[2025-07-19T18:30:21.272+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/139/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/139/.1.delta.410232ee-9334-499e-ab7a-8b29014beae1.TID560.tmp
[2025-07-19T18:30:21.272+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.273+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.273+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.273+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.276+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 132 (task 555, attempt 0, stage 1.0)
[2025-07-19T18:30:21.277+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/135/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/135/.1.delta.ffb9e800-3181-4966-be14-6b74d3764db6.TID558.tmp
[2025-07-19T18:30:21.278+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/133/.1.delta.0dfd26ed-3f41-4394-bff3-63ae1f283987.TID556.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/133/1.delta
[2025-07-19T18:30:21.278+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=133),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/133] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/133/1.delta
[2025-07-19T18:30:21.279+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 132.0 in stage 1.0 (TID 555). 6200 bytes result sent to driver
[2025-07-19T18:30:21.280+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 133 (task 556, attempt 0, stage 1.0)
[2025-07-19T18:30:21.281+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 143.0 in stage 1.0 (TID 563) (8b44f3d35cfa, executor driver, partition 143, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.281+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 132.0 in stage 1.0 (TID 555) in 74 ms on 8b44f3d35cfa (executor driver) (153/200)
[2025-07-19T18:30:21.282+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ff52110
[2025-07-19T18:30:21.282+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 143.0 in stage 1.0 (TID 563)
[2025-07-19T18:30:21.283+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=142, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.283+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=142),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/142] for update
[2025-07-19T18:30:21.283+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.284+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.284+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.285+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 133 (task 556, attempt 0, stage 1.0)
[2025-07-19T18:30:21.285+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 133.0 in stage 1.0 (TID 556). 6200 bytes result sent to driver
[2025-07-19T18:30:21.285+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 146.0 in stage 1.0 (TID 564) (8b44f3d35cfa, executor driver, partition 146, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.286+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 146.0 in stage 1.0 (TID 564)
[2025-07-19T18:30:21.286+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 133.0 in stage 1.0 (TID 556) in 75 ms on 8b44f3d35cfa (executor driver) (154/200)
[2025-07-19T18:30:21.286+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.286+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.286+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c1cf4b9
[2025-07-19T18:30:21.287+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=141, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.288+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=141),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/141] for update
[2025-07-19T18:30:21.289+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.289+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/134/.1.delta.5c6b48e2-c37d-404a-89c1-b670dcfc2c29.TID557.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/134/1.delta
[2025-07-19T18:30:21.289+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=134),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/134] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/134/1.delta
[2025-07-19T18:30:21.289+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 134 (task 557, attempt 0, stage 1.0)
[2025-07-19T18:30:21.290+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/142/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/142/.1.delta.222822af-9021-4155-ac32-2bbf793c0f6a.TID562.tmp
[2025-07-19T18:30:21.290+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 134 (task 557, attempt 0, stage 1.0)
[2025-07-19T18:30:21.291+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 134.0 in stage 1.0 (TID 557). 6200 bytes result sent to driver
[2025-07-19T18:30:21.291+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 147.0 in stage 1.0 (TID 565) (8b44f3d35cfa, executor driver, partition 147, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.291+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 147.0 in stage 1.0 (TID 565)
[2025-07-19T18:30:21.291+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 134.0 in stage 1.0 (TID 557) in 62 ms on 8b44f3d35cfa (executor driver) (155/200)
[2025-07-19T18:30:21.294+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@42997d1b
[2025-07-19T18:30:21.295+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=146, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.296+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=146),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/146] for update
[2025-07-19T18:30:21.296+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/138/.1.delta.7f54b8a9-e924-4356-a946-ea4a82d52dfd.TID559.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/138/1.delta
[2025-07-19T18:30:21.297+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=138),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/138] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/138/1.delta
[2025-07-19T18:30:21.297+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 138 (task 559, attempt 0, stage 1.0)
[2025-07-19T18:30:21.297+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.297+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.297+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.298+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/141/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/141/.1.delta.9e48a279-3067-4810-a362-05491d96853d.TID561.tmp
[2025-07-19T18:30:21.299+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2cd8ba61
[2025-07-19T18:30:21.299+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=143, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.299+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=143),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/143] for update
[2025-07-19T18:30:21.300+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.301+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 138 (task 559, attempt 0, stage 1.0)
[2025-07-19T18:30:21.302+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/139/.1.delta.410232ee-9334-499e-ab7a-8b29014beae1.TID560.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/139/1.delta
[2025-07-19T18:30:21.302+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=139),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/139] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/139/1.delta
[2025-07-19T18:30:21.302+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 138.0 in stage 1.0 (TID 559). 6200 bytes result sent to driver
[2025-07-19T18:30:21.303+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 139 (task 560, attempt 0, stage 1.0)
[2025-07-19T18:30:21.303+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 148.0 in stage 1.0 (TID 566) (8b44f3d35cfa, executor driver, partition 148, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.305+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@9dde36c
[2025-07-19T18:30:21.306+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 148.0 in stage 1.0 (TID 566)
[2025-07-19T18:30:21.306+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 138.0 in stage 1.0 (TID 559) in 65 ms on 8b44f3d35cfa (executor driver) (156/200)
[2025-07-19T18:30:21.307+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/146/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/146/.1.delta.fcd30a33-88bb-4a4d-abfd-fd3e60d4eb4d.TID564.tmp
[2025-07-19T18:30:21.307+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=147, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.307+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=147),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/147] for update
[2025-07-19T18:30:21.308+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.308+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 139 (task 560, attempt 0, stage 1.0)
[2025-07-19T18:30:21.309+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.309+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 139.0 in stage 1.0 (TID 560). 6200 bytes result sent to driver
[2025-07-19T18:30:21.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 151.0 in stage 1.0 (TID 567) (8b44f3d35cfa, executor driver, partition 151, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.312+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 151.0 in stage 1.0 (TID 567)
[2025-07-19T18:30:21.312+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 139.0 in stage 1.0 (TID 560) in 59 ms on 8b44f3d35cfa (executor driver) (157/200)
[2025-07-19T18:30:21.312+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/135/.1.delta.ffb9e800-3181-4966-be14-6b74d3764db6.TID558.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/135/1.delta
[2025-07-19T18:30:21.313+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=135),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/135] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/135/1.delta
[2025-07-19T18:30:21.313+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.313+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.313+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 135 (task 558, attempt 0, stage 1.0)
[2025-07-19T18:30:21.314+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/147/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/147/.1.delta.1c0c3a84-f652-4310-be44-9eb7297d457d.TID565.tmp
[2025-07-19T18:30:21.315+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/143/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/143/.1.delta.032930c6-6074-4834-a7f2-e95eb207e1a2.TID563.tmp
[2025-07-19T18:30:21.316+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f8dd647
[2025-07-19T18:30:21.316+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=148, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.316+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=148),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/148] for update
[2025-07-19T18:30:21.317+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.318+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 135 (task 558, attempt 0, stage 1.0)
[2025-07-19T18:30:21.318+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 135.0 in stage 1.0 (TID 558). 6200 bytes result sent to driver
[2025-07-19T18:30:21.319+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2dc647d
[2025-07-19T18:30:21.319+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 152.0 in stage 1.0 (TID 568) (8b44f3d35cfa, executor driver, partition 152, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.319+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=151, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.320+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=151),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/151] for update
[2025-07-19T18:30:21.320+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 152.0 in stage 1.0 (TID 568)
[2025-07-19T18:30:21.321+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.321+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 135.0 in stage 1.0 (TID 558) in 83 ms on 8b44f3d35cfa (executor driver) (158/200)
[2025-07-19T18:30:21.321+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.321+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.321+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/148/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/148/.1.delta.cf34ada8-9a23-4d13-9c01-e1a233caf75a.TID566.tmp
[2025-07-19T18:30:21.325+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c1fe9b5
[2025-07-19T18:30:21.325+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=152, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.325+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=152),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/152] for update
[2025-07-19T18:30:21.326+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.327+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/142/.1.delta.222822af-9021-4155-ac32-2bbf793c0f6a.TID562.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/142/1.delta
[2025-07-19T18:30:21.327+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=142),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/142] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/142/1.delta
[2025-07-19T18:30:21.327+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 142 (task 562, attempt 0, stage 1.0)
[2025-07-19T18:30:21.327+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/151/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/151/.1.delta.32a5046e-00d1-4c2a-9110-48a912f2e874.TID567.tmp
[2025-07-19T18:30:21.331+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/141/.1.delta.9e48a279-3067-4810-a362-05491d96853d.TID561.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/141/1.delta
[2025-07-19T18:30:21.331+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=141),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/141] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/141/1.delta
[2025-07-19T18:30:21.331+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 141 (task 561, attempt 0, stage 1.0)
[2025-07-19T18:30:21.332+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/146/.1.delta.fcd30a33-88bb-4a4d-abfd-fd3e60d4eb4d.TID564.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/146/1.delta
[2025-07-19T18:30:21.333+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=146),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/146] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/146/1.delta
[2025-07-19T18:30:21.334+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 146 (task 564, attempt 0, stage 1.0)
[2025-07-19T18:30:21.334+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 142 (task 562, attempt 0, stage 1.0)
[2025-07-19T18:30:21.336+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/152/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/152/.1.delta.0025c598-44a7-40d1-bc7d-90d10c149114.TID568.tmp
[2025-07-19T18:30:21.336+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 142.0 in stage 1.0 (TID 562). 6200 bytes result sent to driver
[2025-07-19T18:30:21.336+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 141 (task 561, attempt 0, stage 1.0)
[2025-07-19T18:30:21.336+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 154.0 in stage 1.0 (TID 569) (8b44f3d35cfa, executor driver, partition 154, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.336+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 141.0 in stage 1.0 (TID 561). 6200 bytes result sent to driver
[2025-07-19T18:30:21.336+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 154.0 in stage 1.0 (TID 569)
[2025-07-19T18:30:21.336+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 156.0 in stage 1.0 (TID 570) (8b44f3d35cfa, executor driver, partition 156, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.336+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 142.0 in stage 1.0 (TID 562) in 65 ms on 8b44f3d35cfa (executor driver) (159/200)
[2025-07-19T18:30:21.336+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 141.0 in stage 1.0 (TID 561) in 67 ms on 8b44f3d35cfa (executor driver) (160/200)
[2025-07-19T18:30:21.336+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 156.0 in stage 1.0 (TID 570)
[2025-07-19T18:30:21.337+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.337+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.338+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.339+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.339+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 146 (task 564, attempt 0, stage 1.0)
[2025-07-19T18:30:21.339+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 146.0 in stage 1.0 (TID 564). 6200 bytes result sent to driver
[2025-07-19T18:30:21.339+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 157.0 in stage 1.0 (TID 571) (8b44f3d35cfa, executor driver, partition 157, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.339+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 146.0 in stage 1.0 (TID 564) in 59 ms on 8b44f3d35cfa (executor driver) (161/200)
[2025-07-19T18:30:21.340+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 157.0 in stage 1.0 (TID 571)
[2025-07-19T18:30:21.340+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/143/.1.delta.032930c6-6074-4834-a7f2-e95eb207e1a2.TID563.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/143/1.delta
[2025-07-19T18:30:21.340+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=143),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/143] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/143/1.delta
[2025-07-19T18:30:21.340+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 143 (task 563, attempt 0, stage 1.0)
[2025-07-19T18:30:21.341+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.341+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.341+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c5b462c
[2025-07-19T18:30:21.341+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=154, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.341+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=154),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/154] for update
[2025-07-19T18:30:21.344+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.345+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 143 (task 563, attempt 0, stage 1.0)
[2025-07-19T18:30:21.345+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 143.0 in stage 1.0 (TID 563). 6200 bytes result sent to driver
[2025-07-19T18:30:21.346+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 159.0 in stage 1.0 (TID 572) (8b44f3d35cfa, executor driver, partition 159, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.347+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 159.0 in stage 1.0 (TID 572)
[2025-07-19T18:30:21.347+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 143.0 in stage 1.0 (TID 563) in 67 ms on 8b44f3d35cfa (executor driver) (162/200)
[2025-07-19T18:30:21.347+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.347+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.347+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/147/.1.delta.1c0c3a84-f652-4310-be44-9eb7297d457d.TID565.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/147/1.delta
[2025-07-19T18:30:21.348+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=147),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/147] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/147/1.delta
[2025-07-19T18:30:21.349+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 147 (task 565, attempt 0, stage 1.0)
[2025-07-19T18:30:21.349+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@449a9b1e
[2025-07-19T18:30:21.349+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=157, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.350+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/148/.1.delta.cf34ada8-9a23-4d13-9c01-e1a233caf75a.TID566.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/148/1.delta
[2025-07-19T18:30:21.350+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=157),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/157] for update
[2025-07-19T18:30:21.350+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=148),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/148] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/148/1.delta
[2025-07-19T18:30:21.352+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 147 (task 565, attempt 0, stage 1.0)
[2025-07-19T18:30:21.352+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 147.0 in stage 1.0 (TID 565). 6200 bytes result sent to driver
[2025-07-19T18:30:21.353+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 148 (task 566, attempt 0, stage 1.0)
[2025-07-19T18:30:21.353+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 162.0 in stage 1.0 (TID 573) (8b44f3d35cfa, executor driver, partition 162, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.353+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 162.0 in stage 1.0 (TID 573)
[2025-07-19T18:30:21.353+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 147.0 in stage 1.0 (TID 565) in 60 ms on 8b44f3d35cfa (executor driver) (163/200)
[2025-07-19T18:30:21.354+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/154/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/154/.1.delta.80bf1d7b-722d-477e-82d1-b7932ce91bf8.TID569.tmp
[2025-07-19T18:30:21.354+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/151/.1.delta.32a5046e-00d1-4c2a-9110-48a912f2e874.TID567.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/151/1.delta
[2025-07-19T18:30:21.354+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=151),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/151] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/151/1.delta
[2025-07-19T18:30:21.354+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.354+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 151 (task 567, attempt 0, stage 1.0)
[2025-07-19T18:30:21.355+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.355+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.356+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2491d22e
[2025-07-19T18:30:21.357+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 151 (task 567, attempt 0, stage 1.0)
[2025-07-19T18:30:21.358+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=156, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.359+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=156),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/156] for update
[2025-07-19T18:30:21.359+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 151.0 in stage 1.0 (TID 567). 6200 bytes result sent to driver
[2025-07-19T18:30:21.360+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 148 (task 566, attempt 0, stage 1.0)
[2025-07-19T18:30:21.361+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 148.0 in stage 1.0 (TID 566). 6200 bytes result sent to driver
[2025-07-19T18:30:21.361+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 164.0 in stage 1.0 (TID 574) (8b44f3d35cfa, executor driver, partition 164, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.361+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 165.0 in stage 1.0 (TID 575) (8b44f3d35cfa, executor driver, partition 165, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.361+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 165.0 in stage 1.0 (TID 575)
[2025-07-19T18:30:21.362+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 148.0 in stage 1.0 (TID 566) in 57 ms on 8b44f3d35cfa (executor driver) (164/200)
[2025-07-19T18:30:21.362+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.363+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 164.0 in stage 1.0 (TID 574)
[2025-07-19T18:30:21.363+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 151.0 in stage 1.0 (TID 567) in 53 ms on 8b44f3d35cfa (executor driver) (165/200)
[2025-07-19T18:30:21.363+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.363+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.363+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/157/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/157/.1.delta.5ae4c026-4fb0-4c73-836e-4980539c575f.TID571.tmp
[2025-07-19T18:30:21.363+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.364+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.364+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b49f8ee
[2025-07-19T18:30:21.364+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=162, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.365+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=162),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/162] for update
[2025-07-19T18:30:21.366+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.367+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/152/.1.delta.0025c598-44a7-40d1-bc7d-90d10c149114.TID568.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/152/1.delta
[2025-07-19T18:30:21.367+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=152),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/152] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/152/1.delta
[2025-07-19T18:30:21.367+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 152 (task 568, attempt 0, stage 1.0)
[2025-07-19T18:30:21.368+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/156/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/156/.1.delta.eb9192fe-ca60-4c9b-8e73-5f8ec8a17f89.TID570.tmp
[2025-07-19T18:30:21.368+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@10099b7
[2025-07-19T18:30:21.369+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 152 (task 568, attempt 0, stage 1.0)
[2025-07-19T18:30:21.370+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 152.0 in stage 1.0 (TID 568). 6200 bytes result sent to driver
[2025-07-19T18:30:21.371+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=159, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.372+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=159),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/159] for update
[2025-07-19T18:30:21.373+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.374+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 166.0 in stage 1.0 (TID 576) (8b44f3d35cfa, executor driver, partition 166, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.374+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 152.0 in stage 1.0 (TID 568) in 53 ms on 8b44f3d35cfa (executor driver) (166/200)
[2025-07-19T18:30:21.375+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 166.0 in stage 1.0 (TID 576)
[2025-07-19T18:30:21.375+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f83aee8
[2025-07-19T18:30:21.376+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/162/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/162/.1.delta.85ae6078-ee37-47bd-92b8-fc6b99a2203b.TID573.tmp
[2025-07-19T18:30:21.376+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.376+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.376+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=164, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.377+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=164),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/164] for update
[2025-07-19T18:30:21.377+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.377+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/159/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/159/.1.delta.22920c15-81f1-447b-abd8-5c83078d55fb.TID572.tmp
[2025-07-19T18:30:21.378+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/154/.1.delta.80bf1d7b-722d-477e-82d1-b7932ce91bf8.TID569.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/154/1.delta
[2025-07-19T18:30:21.379+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=154),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/154] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/154/1.delta
[2025-07-19T18:30:21.379+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 154 (task 569, attempt 0, stage 1.0)
[2025-07-19T18:30:21.380+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f4b0f0f
[2025-07-19T18:30:21.381+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=165, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.381+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=165),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/165] for update
[2025-07-19T18:30:21.384+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.385+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 154 (task 569, attempt 0, stage 1.0)
[2025-07-19T18:30:21.386+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 154.0 in stage 1.0 (TID 569). 6200 bytes result sent to driver
[2025-07-19T18:30:21.387+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@586bd661
[2025-07-19T18:30:21.388+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 167.0 in stage 1.0 (TID 577) (8b44f3d35cfa, executor driver, partition 167, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.389+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=166, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.389+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=166),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/166] for update
[2025-07-19T18:30:21.389+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 167.0 in stage 1.0 (TID 577)
[2025-07-19T18:30:21.390+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 154.0 in stage 1.0 (TID 569) in 50 ms on 8b44f3d35cfa (executor driver) (167/200)
[2025-07-19T18:30:21.391+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/157/.1.delta.5ae4c026-4fb0-4c73-836e-4980539c575f.TID571.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/157/1.delta
[2025-07-19T18:30:21.392+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=157),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/157] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/157/1.delta
[2025-07-19T18:30:21.393+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.393+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 157 (task 571, attempt 0, stage 1.0)
[2025-07-19T18:30:21.393+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/164/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/164/.1.delta.0315380f-b75a-4e69-863a-1ee7404600ae.TID574.tmp
[2025-07-19T18:30:21.393+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.394+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.394+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 157 (task 571, attempt 0, stage 1.0)
[2025-07-19T18:30:21.394+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 157.0 in stage 1.0 (TID 571). 6200 bytes result sent to driver
[2025-07-19T18:30:21.395+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/165/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/165/.1.delta.30e3753a-8151-428d-89bf-3c33040005dd.TID575.tmp
[2025-07-19T18:30:21.395+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 168.0 in stage 1.0 (TID 578) (8b44f3d35cfa, executor driver, partition 168, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.395+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 157.0 in stage 1.0 (TID 571) in 52 ms on 8b44f3d35cfa (executor driver) (168/200)
[2025-07-19T18:30:21.398+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 168.0 in stage 1.0 (TID 578)
[2025-07-19T18:30:21.399+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/156/.1.delta.eb9192fe-ca60-4c9b-8e73-5f8ec8a17f89.TID570.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/156/1.delta
[2025-07-19T18:30:21.399+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=156),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/156] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/156/1.delta
[2025-07-19T18:30:21.401+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59d68c94
[2025-07-19T18:30:21.401+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 156 (task 570, attempt 0, stage 1.0)
[2025-07-19T18:30:21.402+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/166/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/166/.1.delta.bdcf0d59-c45b-4020-a494-9206513721b4.TID576.tmp
[2025-07-19T18:30:21.403+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=167, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.404+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=167),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/167] for update
[2025-07-19T18:30:21.404+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.404+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.404+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.405+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 156 (task 570, attempt 0, stage 1.0)
[2025-07-19T18:30:21.405+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/162/.1.delta.85ae6078-ee37-47bd-92b8-fc6b99a2203b.TID573.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/162/1.delta
[2025-07-19T18:30:21.405+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=162),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/162] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/162/1.delta
[2025-07-19T18:30:21.406+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 162 (task 573, attempt 0, stage 1.0)
[2025-07-19T18:30:21.407+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 156.0 in stage 1.0 (TID 570). 6200 bytes result sent to driver
[2025-07-19T18:30:21.407+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 171.0 in stage 1.0 (TID 579) (8b44f3d35cfa, executor driver, partition 171, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.408+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 156.0 in stage 1.0 (TID 570) in 66 ms on 8b44f3d35cfa (executor driver) (169/200)
[2025-07-19T18:30:21.408+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 171.0 in stage 1.0 (TID 579)
[2025-07-19T18:30:21.408+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a2be666
[2025-07-19T18:30:21.409+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=168, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.409+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=168),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/168] for update
[2025-07-19T18:30:21.410+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 162 (task 573, attempt 0, stage 1.0)
[2025-07-19T18:30:21.410+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.411+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.411+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 162.0 in stage 1.0 (TID 573). 6200 bytes result sent to driver
[2025-07-19T18:30:21.412+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/167/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/167/.1.delta.9e7441ec-11c4-4a50-943b-a0ee1dab256e.TID577.tmp
[2025-07-19T18:30:21.412+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 172.0 in stage 1.0 (TID 580) (8b44f3d35cfa, executor driver, partition 172, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.413+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 172.0 in stage 1.0 (TID 580)
[2025-07-19T18:30:21.414+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 162.0 in stage 1.0 (TID 573) in 53 ms on 8b44f3d35cfa (executor driver) (170/200)
[2025-07-19T18:30:21.414+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.415+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.415+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.417+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@473fc0d3
[2025-07-19T18:30:21.417+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/159/.1.delta.22920c15-81f1-447b-abd8-5c83078d55fb.TID572.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/159/1.delta
[2025-07-19T18:30:21.417+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=159),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/159] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/159/1.delta
[2025-07-19T18:30:21.417+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 159 (task 572, attempt 0, stage 1.0)
[2025-07-19T18:30:21.418+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=171, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.418+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=171),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/171] for update
[2025-07-19T18:30:21.419+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.419+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/164/.1.delta.0315380f-b75a-4e69-863a-1ee7404600ae.TID574.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/164/1.delta
[2025-07-19T18:30:21.420+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=164),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/164] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/164/1.delta
[2025-07-19T18:30:21.421+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 159 (task 572, attempt 0, stage 1.0)
[2025-07-19T18:30:21.421+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 164 (task 574, attempt 0, stage 1.0)
[2025-07-19T18:30:21.422+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 159.0 in stage 1.0 (TID 572). 6200 bytes result sent to driver
[2025-07-19T18:30:21.422+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 173.0 in stage 1.0 (TID 581) (8b44f3d35cfa, executor driver, partition 173, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.422+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 159.0 in stage 1.0 (TID 572) in 71 ms on 8b44f3d35cfa (executor driver) (171/200)
[2025-07-19T18:30:21.423+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 173.0 in stage 1.0 (TID 581)
[2025-07-19T18:30:21.424+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/168/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/168/.1.delta.0ad30a6a-c303-401c-ba2c-e646a3be0891.TID578.tmp
[2025-07-19T18:30:21.424+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 164 (task 574, attempt 0, stage 1.0)
[2025-07-19T18:30:21.424+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/165/.1.delta.30e3753a-8151-428d-89bf-3c33040005dd.TID575.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/165/1.delta
[2025-07-19T18:30:21.425+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=165),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/165] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/165/1.delta
[2025-07-19T18:30:21.425+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 164.0 in stage 1.0 (TID 574). 6200 bytes result sent to driver
[2025-07-19T18:30:21.426+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1dc8255a
[2025-07-19T18:30:21.426+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.426+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.426+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=172, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.426+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=172),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/172] for update
[2025-07-19T18:30:21.427+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 165 (task 575, attempt 0, stage 1.0)
[2025-07-19T18:30:21.427+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 174.0 in stage 1.0 (TID 582) (8b44f3d35cfa, executor driver, partition 174, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.428+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 164.0 in stage 1.0 (TID 574) in 62 ms on 8b44f3d35cfa (executor driver) (172/200)
[2025-07-19T18:30:21.428+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/171/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/171/.1.delta.21ceed90-3163-4898-a95f-b51abe425e97.TID579.tmp
[2025-07-19T18:30:21.429+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 174.0 in stage 1.0 (TID 582)
[2025-07-19T18:30:21.429+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.430+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.430+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.430+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 165 (task 575, attempt 0, stage 1.0)
[2025-07-19T18:30:21.431+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 165.0 in stage 1.0 (TID 575). 6200 bytes result sent to driver
[2025-07-19T18:30:21.432+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 175.0 in stage 1.0 (TID 583) (8b44f3d35cfa, executor driver, partition 175, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.433+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@11f9cf20
[2025-07-19T18:30:21.434+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 175.0 in stage 1.0 (TID 583)
[2025-07-19T18:30:21.434+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 165.0 in stage 1.0 (TID 575) in 67 ms on 8b44f3d35cfa (executor driver) (173/200)
[2025-07-19T18:30:21.435+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=173, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.435+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=173),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/173] for update
[2025-07-19T18:30:21.436+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/166/.1.delta.bdcf0d59-c45b-4020-a494-9206513721b4.TID576.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/166/1.delta
[2025-07-19T18:30:21.436+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=166),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/166] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/166/1.delta
[2025-07-19T18:30:21.437+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 166 (task 576, attempt 0, stage 1.0)
[2025-07-19T18:30:21.437+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/172/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/172/.1.delta.1dd4e8ea-39fd-4e61-8a31-0708249fc1f2.TID580.tmp
[2025-07-19T18:30:21.437+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.437+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.439+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.441+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 166 (task 576, attempt 0, stage 1.0)
[2025-07-19T18:30:21.442+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 166.0 in stage 1.0 (TID 576). 6200 bytes result sent to driver
[2025-07-19T18:30:21.442+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 176.0 in stage 1.0 (TID 584) (8b44f3d35cfa, executor driver, partition 176, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.443+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 166.0 in stage 1.0 (TID 576) in 61 ms on 8b44f3d35cfa (executor driver) (174/200)
[2025-07-19T18:30:21.444+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 176.0 in stage 1.0 (TID 584)
[2025-07-19T18:30:21.444+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@263ba209
[2025-07-19T18:30:21.445+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=174, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.445+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=174),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/174] for update
[2025-07-19T18:30:21.445+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.446+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.447+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/167/.1.delta.9e7441ec-11c4-4a50-943b-a0ee1dab256e.TID577.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/167/1.delta
[2025-07-19T18:30:21.447+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=167),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/167] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/167/1.delta
[2025-07-19T18:30:21.448+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.448+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 167 (task 577, attempt 0, stage 1.0)
[2025-07-19T18:30:21.449+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/173/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/173/.1.delta.6cad4339-dba6-4699-9da2-1dd651bbc76f.TID581.tmp
[2025-07-19T18:30:21.450+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@30ac438b
[2025-07-19T18:30:21.451+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 167 (task 577, attempt 0, stage 1.0)
[2025-07-19T18:30:21.451+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 167.0 in stage 1.0 (TID 577). 6200 bytes result sent to driver
[2025-07-19T18:30:21.452+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=175, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.453+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 177.0 in stage 1.0 (TID 585) (8b44f3d35cfa, executor driver, partition 177, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.453+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=175),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/175] for update
[2025-07-19T18:30:21.454+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.455+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 167.0 in stage 1.0 (TID 577) in 59 ms on 8b44f3d35cfa (executor driver) (175/200)
[2025-07-19T18:30:21.456+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 177.0 in stage 1.0 (TID 585)
[2025-07-19T18:30:21.456+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.458+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@610458c9
[2025-07-19T18:30:21.459+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T18:30:21.460+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=176, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.461+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=176),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/176] for update
[2025-07-19T18:30:21.461+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.462+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/168/.1.delta.0ad30a6a-c303-401c-ba2c-e646a3be0891.TID578.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/168/1.delta
[2025-07-19T18:30:21.463+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/174/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/174/.1.delta.8da8389e-5362-42a5-b340-2038e9fc61dd.TID582.tmp
[2025-07-19T18:30:21.463+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=168),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/168] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/168/1.delta
[2025-07-19T18:30:21.464+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 168 (task 578, attempt 0, stage 1.0)
[2025-07-19T18:30:21.465+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/175/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/175/.1.delta.f09aef11-2431-45a1-8cf6-0f42c3a74510.TID583.tmp
[2025-07-19T18:30:21.466+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c029b35
[2025-07-19T18:30:21.466+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=177, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.466+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=177),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/177] for update
[2025-07-19T18:30:21.467+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.467+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/172/.1.delta.1dd4e8ea-39fd-4e61-8a31-0708249fc1f2.TID580.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/172/1.delta
[2025-07-19T18:30:21.468+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=172),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/172] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/172/1.delta
[2025-07-19T18:30:21.468+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 168 (task 578, attempt 0, stage 1.0)
[2025-07-19T18:30:21.469+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 168.0 in stage 1.0 (TID 578). 6200 bytes result sent to driver
[2025-07-19T18:30:21.469+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 178.0 in stage 1.0 (TID 586) (8b44f3d35cfa, executor driver, partition 178, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.470+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 172 (task 580, attempt 0, stage 1.0)
[2025-07-19T18:30:21.470+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 168.0 in stage 1.0 (TID 578) in 70 ms on 8b44f3d35cfa (executor driver) (176/200)
[2025-07-19T18:30:21.470+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 178.0 in stage 1.0 (TID 586)
[2025-07-19T18:30:21.470+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/171/.1.delta.21ceed90-3163-4898-a95f-b51abe425e97.TID579.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/171/1.delta
[2025-07-19T18:30:21.471+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=171),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/171] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/171/1.delta
[2025-07-19T18:30:21.471+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 171 (task 579, attempt 0, stage 1.0)
[2025-07-19T18:30:21.471+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.471+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.471+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 172 (task 580, attempt 0, stage 1.0)
[2025-07-19T18:30:21.472+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/176/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/176/.1.delta.cbf91346-2b10-4660-87a3-c81c27ac5f7d.TID584.tmp
[2025-07-19T18:30:21.472+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 172.0 in stage 1.0 (TID 580). 6200 bytes result sent to driver
[2025-07-19T18:30:21.472+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 180.0 in stage 1.0 (TID 587) (8b44f3d35cfa, executor driver, partition 180, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.472+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 180.0 in stage 1.0 (TID 587)
[2025-07-19T18:30:21.472+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 172.0 in stage 1.0 (TID 580) in 63 ms on 8b44f3d35cfa (executor driver) (177/200)
[2025-07-19T18:30:21.472+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 171 (task 579, attempt 0, stage 1.0)
[2025-07-19T18:30:21.473+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 171.0 in stage 1.0 (TID 579). 6200 bytes result sent to driver
[2025-07-19T18:30:21.473+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.473+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.473+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 182.0 in stage 1.0 (TID 588) (8b44f3d35cfa, executor driver, partition 182, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.474+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 182.0 in stage 1.0 (TID 588)
[2025-07-19T18:30:21.474+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 171.0 in stage 1.0 (TID 579) in 70 ms on 8b44f3d35cfa (executor driver) (178/200)
[2025-07-19T18:30:21.475+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/177/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/177/.1.delta.8704795d-830a-4c45-8ce2-b01cc35a06b0.TID585.tmp
[2025-07-19T18:30:21.475+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.475+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.475+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@15302831
[2025-07-19T18:30:21.475+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=178, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.475+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=178),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/178] for update
[2025-07-19T18:30:21.476+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.484+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@746482df
[2025-07-19T18:30:21.485+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=182, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.485+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=182),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/182] for update
[2025-07-19T18:30:21.486+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.486+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/173/.1.delta.6cad4339-dba6-4699-9da2-1dd651bbc76f.TID581.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/173/1.delta
[2025-07-19T18:30:21.486+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=173),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/173] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/173/1.delta
[2025-07-19T18:30:21.487+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 173 (task 581, attempt 0, stage 1.0)
[2025-07-19T18:30:21.487+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/178/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/178/.1.delta.77866ec6-b683-4fe4-a68a-5205db36fc35.TID586.tmp
[2025-07-19T18:30:21.490+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 173 (task 581, attempt 0, stage 1.0)
[2025-07-19T18:30:21.491+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 173.0 in stage 1.0 (TID 581). 6243 bytes result sent to driver
[2025-07-19T18:30:21.492+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 184.0 in stage 1.0 (TID 589) (8b44f3d35cfa, executor driver, partition 184, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.493+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 184.0 in stage 1.0 (TID 589)
[2025-07-19T18:30:21.494+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 173.0 in stage 1.0 (TID 581) in 77 ms on 8b44f3d35cfa (executor driver) (179/200)
[2025-07-19T18:30:21.495+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47044c94
[2025-07-19T18:30:21.495+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=180, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.496+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=180),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/180] for update
[2025-07-19T18:30:21.496+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.496+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.496+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.497+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/182/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/182/.1.delta.5ea63587-f0a1-4bf3-8a4b-0247c8677f7f.TID588.tmp
[2025-07-19T18:30:21.500+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/174/.1.delta.8da8389e-5362-42a5-b340-2038e9fc61dd.TID582.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/174/1.delta
[2025-07-19T18:30:21.502+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=174),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/174] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/174/1.delta
[2025-07-19T18:30:21.503+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/175/.1.delta.f09aef11-2431-45a1-8cf6-0f42c3a74510.TID583.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/175/1.delta
[2025-07-19T18:30:21.503+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=175),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/175] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/175/1.delta
[2025-07-19T18:30:21.504+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 174 (task 582, attempt 0, stage 1.0)
[2025-07-19T18:30:21.505+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d15b231
[2025-07-19T18:30:21.505+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=184, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.505+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 175 (task 583, attempt 0, stage 1.0)
[2025-07-19T18:30:21.506+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=184),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/184] for update
[2025-07-19T18:30:21.507+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.507+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 175 (task 583, attempt 0, stage 1.0)
[2025-07-19T18:30:21.508+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/180/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/180/.1.delta.c0d56eab-1776-4149-ab10-e39969f0a75f.TID587.tmp
[2025-07-19T18:30:21.509+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 174 (task 582, attempt 0, stage 1.0)
[2025-07-19T18:30:21.510+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 174.0 in stage 1.0 (TID 582). 6243 bytes result sent to driver
[2025-07-19T18:30:21.510+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 175.0 in stage 1.0 (TID 583). 6243 bytes result sent to driver
[2025-07-19T18:30:21.512+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 185.0 in stage 1.0 (TID 590) (8b44f3d35cfa, executor driver, partition 185, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.514+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 185.0 in stage 1.0 (TID 590)
[2025-07-19T18:30:21.514+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 186.0 in stage 1.0 (TID 591) (8b44f3d35cfa, executor driver, partition 186, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.515+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 175.0 in stage 1.0 (TID 583) in 84 ms on 8b44f3d35cfa (executor driver) (180/200)
[2025-07-19T18:30:21.516+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 186.0 in stage 1.0 (TID 591)
[2025-07-19T18:30:21.516+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/176/.1.delta.cbf91346-2b10-4660-87a3-c81c27ac5f7d.TID584.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/176/1.delta
[2025-07-19T18:30:21.517+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=176),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/176] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/176/1.delta
[2025-07-19T18:30:21.518+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 176 (task 584, attempt 0, stage 1.0)
[2025-07-19T18:30:21.519+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 174.0 in stage 1.0 (TID 582) in 88 ms on 8b44f3d35cfa (executor driver) (181/200)
[2025-07-19T18:30:21.521+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/184/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/184/.1.delta.b810abdf-3f86-49ba-8ae6-0be2d63e1d90.TID589.tmp
[2025-07-19T18:30:21.522+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 176 (task 584, attempt 0, stage 1.0)
[2025-07-19T18:30:21.522+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 176.0 in stage 1.0 (TID 584). 6243 bytes result sent to driver
[2025-07-19T18:30:21.523+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 187.0 in stage 1.0 (TID 592) (8b44f3d35cfa, executor driver, partition 187, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.523+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.524+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.524+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.525+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:21.526+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 176.0 in stage 1.0 (TID 584) in 88 ms on 8b44f3d35cfa (executor driver) (182/200)
[2025-07-19T18:30:21.527+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 187.0 in stage 1.0 (TID 592)
[2025-07-19T18:30:21.527+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/177/.1.delta.8704795d-830a-4c45-8ce2-b01cc35a06b0.TID585.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/177/1.delta
[2025-07-19T18:30:21.528+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=177),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/177] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/177/1.delta
[2025-07-19T18:30:21.528+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 177 (task 585, attempt 0, stage 1.0)
[2025-07-19T18:30:21.529+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c2b8fc6
[2025-07-19T18:30:21.529+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=186, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.529+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=186),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/186] for update
[2025-07-19T18:30:21.530+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.530+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.531+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.533+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 177 (task 585, attempt 0, stage 1.0)
[2025-07-19T18:30:21.534+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 177.0 in stage 1.0 (TID 585). 6243 bytes result sent to driver
[2025-07-19T18:30:21.535+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 177.0 in stage 1.0 (TID 585) in 94 ms on 8b44f3d35cfa (executor driver) (183/200)
[2025-07-19T18:30:21.536+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 188.0 in stage 1.0 (TID 593) (8b44f3d35cfa, executor driver, partition 188, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.536+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/178/.1.delta.77866ec6-b683-4fe4-a68a-5205db36fc35.TID586.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/178/1.delta
[2025-07-19T18:30:21.536+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=178),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/178] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/178/1.delta
[2025-07-19T18:30:21.537+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 188.0 in stage 1.0 (TID 593)
[2025-07-19T18:30:21.538+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/182/.1.delta.5ea63587-f0a1-4bf3-8a4b-0247c8677f7f.TID588.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/182/1.delta
[2025-07-19T18:30:21.539+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=182),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/182] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/182/1.delta
[2025-07-19T18:30:21.539+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.539+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.539+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 178 (task 586, attempt 0, stage 1.0)
[2025-07-19T18:30:21.539+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/186/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/186/.1.delta.ceaab544-152c-498f-9180-eff42cd2dc04.TID591.tmp
[2025-07-19T18:30:21.542+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 182 (task 588, attempt 0, stage 1.0)
[2025-07-19T18:30:21.543+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@78b1886c
[2025-07-19T18:30:21.543+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=185, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.544+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=185),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/185] for update
[2025-07-19T18:30:21.546+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 178 (task 586, attempt 0, stage 1.0)
[2025-07-19T18:30:21.546+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.547+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 178.0 in stage 1.0 (TID 586). 6243 bytes result sent to driver
[2025-07-19T18:30:21.547+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/180/.1.delta.c0d56eab-1776-4149-ab10-e39969f0a75f.TID587.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/180/1.delta
[2025-07-19T18:30:21.547+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=180),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/180] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/180/1.delta
[2025-07-19T18:30:21.547+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 189.0 in stage 1.0 (TID 594) (8b44f3d35cfa, executor driver, partition 189, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.548+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 182 (task 588, attempt 0, stage 1.0)
[2025-07-19T18:30:21.548+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 189.0 in stage 1.0 (TID 594)
[2025-07-19T18:30:21.549+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 182.0 in stage 1.0 (TID 588). 6243 bytes result sent to driver
[2025-07-19T18:30:21.552+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 180 (task 587, attempt 0, stage 1.0)
[2025-07-19T18:30:21.553+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 178.0 in stage 1.0 (TID 586) in 87 ms on 8b44f3d35cfa (executor driver) (184/200)
[2025-07-19T18:30:21.554+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 191.0 in stage 1.0 (TID 595) (8b44f3d35cfa, executor driver, partition 191, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.554+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 191.0 in stage 1.0 (TID 595)
[2025-07-19T18:30:21.555+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 182.0 in stage 1.0 (TID 588) in 84 ms on 8b44f3d35cfa (executor driver) (185/200)
[2025-07-19T18:30:21.555+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.556+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.557+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.557+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.558+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@62831139
[2025-07-19T18:30:21.558+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=188, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.559+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 180 (task 587, attempt 0, stage 1.0)
[2025-07-19T18:30:21.559+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=188),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/188] for update
[2025-07-19T18:30:21.559+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 180.0 in stage 1.0 (TID 587). 6243 bytes result sent to driver
[2025-07-19T18:30:21.560+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 193.0 in stage 1.0 (TID 596) (8b44f3d35cfa, executor driver, partition 193, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.561+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/184/.1.delta.b810abdf-3f86-49ba-8ae6-0be2d63e1d90.TID589.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/184/1.delta
[2025-07-19T18:30:21.561+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=184),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/184] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/184/1.delta
[2025-07-19T18:30:21.562+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 180.0 in stage 1.0 (TID 587) in 90 ms on 8b44f3d35cfa (executor driver) (186/200)
[2025-07-19T18:30:21.562+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 184 (task 589, attempt 0, stage 1.0)
[2025-07-19T18:30:21.562+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.563+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/185/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/185/.1.delta.5f42a914-59e8-4ba5-89d9-2eca47f7a032.TID590.tmp
[2025-07-19T18:30:21.563+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 193.0 in stage 1.0 (TID 596)
[2025-07-19T18:30:21.564+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@18aa2cc4
[2025-07-19T18:30:21.564+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=187, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.564+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=187),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/187] for update
[2025-07-19T18:30:21.565+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 184 (task 589, attempt 0, stage 1.0)
[2025-07-19T18:30:21.565+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 184.0 in stage 1.0 (TID 589). 6243 bytes result sent to driver
[2025-07-19T18:30:21.565+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 194.0 in stage 1.0 (TID 597) (8b44f3d35cfa, executor driver, partition 194, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.566+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 194.0 in stage 1.0 (TID 597)
[2025-07-19T18:30:21.566+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 184.0 in stage 1.0 (TID 589) in 71 ms on 8b44f3d35cfa (executor driver) (187/200)
[2025-07-19T18:30:21.566+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.567+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.567+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.567+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.567+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.568+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@17fd4283
[2025-07-19T18:30:21.568+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=191, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.568+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=191),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/191] for update
[2025-07-19T18:30:21.568+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/188/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/188/.1.delta.d0771cf8-c139-4fc7-87ac-a2235faa5d85.TID593.tmp
[2025-07-19T18:30:21.568+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.568+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/186/.1.delta.ceaab544-152c-498f-9180-eff42cd2dc04.TID591.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/186/1.delta
[2025-07-19T18:30:21.568+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=186),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/186] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/186/1.delta
[2025-07-19T18:30:21.569+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 186 (task 591, attempt 0, stage 1.0)
[2025-07-19T18:30:21.570+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33cfe1ac
[2025-07-19T18:30:21.570+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=189, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.570+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=189),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/189] for update
[2025-07-19T18:30:21.571+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.576+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/187/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/187/.1.delta.bc24cb01-e3d2-4104-90a5-a131fe6c765f.TID592.tmp
[2025-07-19T18:30:21.576+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/191/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/191/.1.delta.71542f2a-f755-45a3-b9f2-8920102bc043.TID595.tmp
[2025-07-19T18:30:21.577+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 186 (task 591, attempt 0, stage 1.0)
[2025-07-19T18:30:21.578+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 186.0 in stage 1.0 (TID 591). 6243 bytes result sent to driver
[2025-07-19T18:30:21.578+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2fba6b2e
[2025-07-19T18:30:21.578+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=194, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.578+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=194),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/194] for update
[2025-07-19T18:30:21.578+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 195.0 in stage 1.0 (TID 598) (8b44f3d35cfa, executor driver, partition 195, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.579+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 186.0 in stage 1.0 (TID 591) in 68 ms on 8b44f3d35cfa (executor driver) (188/200)
[2025-07-19T18:30:21.579+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 195.0 in stage 1.0 (TID 598)
[2025-07-19T18:30:21.579+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.579+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.579+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.579+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@edc4574
[2025-07-19T18:30:21.581+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/189/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/189/.1.delta.c7e019f2-bbde-4943-9368-3a5f1e0fe1f7.TID594.tmp
[2025-07-19T18:30:21.581+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=193, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.581+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=193),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/193] for update
[2025-07-19T18:30:21.581+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.583+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f368afa
[2025-07-19T18:30:21.584+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=195, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.584+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=195),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/195] for update
[2025-07-19T18:30:21.584+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/194/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/194/.1.delta.31ec540c-d7dd-4b64-8a0c-e75334444746.TID597.tmp
[2025-07-19T18:30:21.585+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.586+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/185/.1.delta.5f42a914-59e8-4ba5-89d9-2eca47f7a032.TID590.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/185/1.delta
[2025-07-19T18:30:21.586+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=185),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/185] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/185/1.delta
[2025-07-19T18:30:21.586+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 185 (task 590, attempt 0, stage 1.0)
[2025-07-19T18:30:21.590+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 185 (task 590, attempt 0, stage 1.0)
[2025-07-19T18:30:21.590+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 185.0 in stage 1.0 (TID 590). 6243 bytes result sent to driver
[2025-07-19T18:30:21.590+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/193/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/193/.1.delta.92d44bbc-be37-4e5d-b913-6691b1370994.TID596.tmp
[2025-07-19T18:30:21.591+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 196.0 in stage 1.0 (TID 599) (8b44f3d35cfa, executor driver, partition 196, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.592+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 196.0 in stage 1.0 (TID 599)
[2025-07-19T18:30:21.592+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 185.0 in stage 1.0 (TID 590) in 84 ms on 8b44f3d35cfa (executor driver) (189/200)
[2025-07-19T18:30:21.593+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/195/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/195/.1.delta.fa132549-0ef8-41c4-8c8e-cde0ebac636b.TID598.tmp
[2025-07-19T18:30:21.593+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.594+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.595+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/188/.1.delta.d0771cf8-c139-4fc7-87ac-a2235faa5d85.TID593.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/188/1.delta
[2025-07-19T18:30:21.595+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=188),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/188] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/188/1.delta
[2025-07-19T18:30:21.596+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/191/.1.delta.71542f2a-f755-45a3-b9f2-8920102bc043.TID595.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/191/1.delta
[2025-07-19T18:30:21.596+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=191),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/191] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/191/1.delta
[2025-07-19T18:30:21.597+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 188 (task 593, attempt 0, stage 1.0)
[2025-07-19T18:30:21.598+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 191 (task 595, attempt 0, stage 1.0)
[2025-07-19T18:30:21.599+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 191 (task 595, attempt 0, stage 1.0)
[2025-07-19T18:30:21.600+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 191.0 in stage 1.0 (TID 595). 6200 bytes result sent to driver
[2025-07-19T18:30:21.600+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 188 (task 593, attempt 0, stage 1.0)
[2025-07-19T18:30:21.600+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 197.0 in stage 1.0 (TID 600) (8b44f3d35cfa, executor driver, partition 197, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.601+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 188.0 in stage 1.0 (TID 593). 6243 bytes result sent to driver
[2025-07-19T18:30:21.602+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 198.0 in stage 1.0 (TID 601) (8b44f3d35cfa, executor driver, partition 198, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.602+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 191.0 in stage 1.0 (TID 595) in 46 ms on 8b44f3d35cfa (executor driver) (190/200)
[2025-07-19T18:30:21.603+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 198.0 in stage 1.0 (TID 601)
[2025-07-19T18:30:21.603+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 188.0 in stage 1.0 (TID 593) in 64 ms on 8b44f3d35cfa (executor driver) (191/200)
[2025-07-19T18:30:21.603+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 197.0 in stage 1.0 (TID 600)
[2025-07-19T18:30:21.603+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a9a69d3
[2025-07-19T18:30:21.604+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=196, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.604+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/187/.1.delta.bc24cb01-e3d2-4104-90a5-a131fe6c765f.TID592.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/187/1.delta
[2025-07-19T18:30:21.604+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=187),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/187] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/187/1.delta
[2025-07-19T18:30:21.604+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=196),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/196] for update
[2025-07-19T18:30:21.605+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 187 (task 592, attempt 0, stage 1.0)
[2025-07-19T18:30:21.605+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.606+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.607+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.607+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.607+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.607+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 187 (task 592, attempt 0, stage 1.0)
[2025-07-19T18:30:21.607+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 187.0 in stage 1.0 (TID 592). 6243 bytes result sent to driver
[2025-07-19T18:30:21.607+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 199.0 in stage 1.0 (TID 602) (8b44f3d35cfa, executor driver, partition 199, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.608+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 199.0 in stage 1.0 (TID 602)
[2025-07-19T18:30:21.608+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 187.0 in stage 1.0 (TID 592) in 89 ms on 8b44f3d35cfa (executor driver) (192/200)
[2025-07-19T18:30:21.608+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@60a240c4
[2025-07-19T18:30:21.609+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=198, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.609+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=198),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/198] for update
[2025-07-19T18:30:21.609+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.610+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.610+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.610+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/196/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/196/.1.delta.4f13529d-072f-4473-8772-abb932ce8459.TID599.tmp
[2025-07-19T18:30:21.611+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/189/.1.delta.c7e019f2-bbde-4943-9368-3a5f1e0fe1f7.TID594.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/189/1.delta
[2025-07-19T18:30:21.611+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=189),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/189] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/189/1.delta
[2025-07-19T18:30:21.612+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f5c5edb
[2025-07-19T18:30:21.613+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 189 (task 594, attempt 0, stage 1.0)
[2025-07-19T18:30:21.613+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/194/.1.delta.31ec540c-d7dd-4b64-8a0c-e75334444746.TID597.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/194/1.delta
[2025-07-19T18:30:21.614+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=194),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/194] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/194/1.delta
[2025-07-19T18:30:21.614+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=197, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.614+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=197),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/197] for update
[2025-07-19T18:30:21.614+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 194 (task 597, attempt 0, stage 1.0)
[2025-07-19T18:30:21.615+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.615+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/198/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/198/.1.delta.647c1b90-0216-46c0-b294-f48f92cd6e6d.TID601.tmp
[2025-07-19T18:30:21.616+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 189 (task 594, attempt 0, stage 1.0)
[2025-07-19T18:30:21.618+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 189.0 in stage 1.0 (TID 594). 6243 bytes result sent to driver
[2025-07-19T18:30:21.618+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2252611f
[2025-07-19T18:30:21.618+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/195/.1.delta.fa132549-0ef8-41c4-8c8e-cde0ebac636b.TID598.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/195/1.delta
[2025-07-19T18:30:21.619+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=195),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/195] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/195/1.delta
[2025-07-19T18:30:21.619+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 195 (task 598, attempt 0, stage 1.0)
[2025-07-19T18:30:21.620+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 194 (task 597, attempt 0, stage 1.0)
[2025-07-19T18:30:21.620+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=199, storeName=default ],b8eee2e2-0960-4f84-b369-9c0543e84c2b) is active
[2025-07-19T18:30:21.621+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=199),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/199] for update
[2025-07-19T18:30:21.622+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 194.0 in stage 1.0 (TID 597). 6200 bytes result sent to driver
[2025-07-19T18:30:21.622+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/193/.1.delta.92d44bbc-be37-4e5d-b913-6691b1370994.TID596.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/193/1.delta
[2025-07-19T18:30:21.622+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=193),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/193] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/193/1.delta
[2025-07-19T18:30:21.622+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 193 (task 596, attempt 0, stage 1.0)
[2025-07-19T18:30:21.622+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.622+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 195 (task 598, attempt 0, stage 1.0)
[2025-07-19T18:30:21.622+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 603) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.623+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 193 (task 596, attempt 0, stage 1.0)
[2025-07-19T18:30:21.623+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 195.0 in stage 1.0 (TID 598). 6200 bytes result sent to driver
[2025-07-19T18:30:21.623+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 193.0 in stage 1.0 (TID 596). 6200 bytes result sent to driver
[2025-07-19T18:30:21.623+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/197/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/197/.1.delta.56d71a72-e821-45e6-96f9-13a8cb89999f.TID600.tmp
[2025-07-19T18:30:21.623+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 189.0 in stage 1.0 (TID 594) in 77 ms on 8b44f3d35cfa (executor driver) (193/200)
[2025-07-19T18:30:21.625+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 0.0 in stage 7.0 (TID 603)
[2025-07-19T18:30:21.626+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/199/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/199/.1.delta.9b9f37ca-1338-4ef9-a773-601c921ed0d2.TID602.tmp
[2025-07-19T18:30:21.626+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 604) (8b44f3d35cfa, executor driver, partition 1, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.626+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 605) (8b44f3d35cfa, executor driver, partition 2, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.627+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 1.0 in stage 7.0 (TID 604)
[2025-07-19T18:30:21.627+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 606) (8b44f3d35cfa, executor driver, partition 3, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.627+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 3.0 in stage 7.0 (TID 606)
[2025-07-19T18:30:21.627+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 194.0 in stage 1.0 (TID 597) in 64 ms on 8b44f3d35cfa (executor driver) (194/200)
[2025-07-19T18:30:21.628+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 2.0 in stage 7.0 (TID 605)
[2025-07-19T18:30:21.628+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 195.0 in stage 1.0 (TID 598) in 51 ms on 8b44f3d35cfa (executor driver) (195/200)
[2025-07-19T18:30:21.628+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 193.0 in stage 1.0 (TID 596) in 70 ms on 8b44f3d35cfa (executor driver) (196/200)
[2025-07-19T18:30:21.628+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.629+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.629+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.630+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.630+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.630+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.630+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@970d3a6
[2025-07-19T18:30:21.631+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=3, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:21.632+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/3] for update
[2025-07-19T18:30:21.633+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.633+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.633+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ffa47a2
[2025-07-19T18:30:21.633+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=0, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:21.634+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/0] for update
[2025-07-19T18:30:21.635+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@db7606c
[2025-07-19T18:30:21.635+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=2, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:21.635+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/2] for update
[2025-07-19T18:30:21.636+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@57ab4084
[2025-07-19T18:30:21.636+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=1, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:21.636+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/1] for update
[2025-07-19T18:30:21.636+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.637+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/196/.1.delta.4f13529d-072f-4473-8772-abb932ce8459.TID599.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/196/1.delta
[2025-07-19T18:30:21.637+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=196),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/196] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/196/1.delta
[2025-07-19T18:30:21.637+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.638+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 196 (task 599, attempt 0, stage 1.0)
[2025-07-19T18:30:21.638+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.638+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.642+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 196 (task 599, attempt 0, stage 1.0)
[2025-07-19T18:30:21.642+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/198/.1.delta.647c1b90-0216-46c0-b294-f48f92cd6e6d.TID601.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/198/1.delta
[2025-07-19T18:30:21.643+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=198),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/198] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/198/1.delta
[2025-07-19T18:30:21.643+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 196.0 in stage 1.0 (TID 599). 6200 bytes result sent to driver
[2025-07-19T18:30:21.643+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 198 (task 601, attempt 0, stage 1.0)
[2025-07-19T18:30:21.643+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 607) (8b44f3d35cfa, executor driver, partition 4, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.643+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 4.0 in stage 7.0 (TID 607)
[2025-07-19T18:30:21.644+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 196.0 in stage 1.0 (TID 599) in 52 ms on 8b44f3d35cfa (executor driver) (197/200)
[2025-07-19T18:30:21.645+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.646+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.647+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a8f78b1
[2025-07-19T18:30:21.650+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=4, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:21.651+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/4] for update
[2025-07-19T18:30:21.651+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/197/.1.delta.56d71a72-e821-45e6-96f9-13a8cb89999f.TID600.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/197/1.delta
[2025-07-19T18:30:21.652+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=197),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/197] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/197/1.delta
[2025-07-19T18:30:21.652+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 198 (task 601, attempt 0, stage 1.0)
[2025-07-19T18:30:21.653+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 197 (task 600, attempt 0, stage 1.0)
[2025-07-19T18:30:21.653+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 198.0 in stage 1.0 (TID 601). 6200 bytes result sent to driver
[2025-07-19T18:30:21.654+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.654+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 608) (8b44f3d35cfa, executor driver, partition 5, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.654+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 5.0 in stage 7.0 (TID 608)
[2025-07-19T18:30:21.654+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 198.0 in stage 1.0 (TID 601) in 51 ms on 8b44f3d35cfa (executor driver) (198/200)
[2025-07-19T18:30:21.655+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/199/.1.delta.9b9f37ca-1338-4ef9-a773-601c921ed0d2.TID602.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/199/1.delta
[2025-07-19T18:30:21.656+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=199),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/199] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/state/0/199/1.delta
[2025-07-19T18:30:21.656+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 199 (task 602, attempt 0, stage 1.0)
[2025-07-19T18:30:21.657+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.657+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.658+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@78325fda
[2025-07-19T18:30:21.659+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=5, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:21.659+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/5] for update
[2025-07-19T18:30:21.659+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.659+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 199 (task 602, attempt 0, stage 1.0)
[2025-07-19T18:30:21.660+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 199.0 in stage 1.0 (TID 602). 6200 bytes result sent to driver
[2025-07-19T18:30:21.660+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 197 (task 600, attempt 0, stage 1.0)
[2025-07-19T18:30:21.660+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 197.0 in stage 1.0 (TID 600). 6200 bytes result sent to driver
[2025-07-19T18:30:21.661+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 609) (8b44f3d35cfa, executor driver, partition 6, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.661+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 610) (8b44f3d35cfa, executor driver, partition 7, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.661+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 6.0 in stage 7.0 (TID 609)
[2025-07-19T18:30:21.662+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 7.0 in stage 7.0 (TID 610)
[2025-07-19T18:30:21.662+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.662+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 199.0 in stage 1.0 (TID 602) in 49 ms on 8b44f3d35cfa (executor driver) (199/200)
[2025-07-19T18:30:21.663+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.663+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 197.0 in stage 1.0 (TID 600) in 58 ms on 8b44f3d35cfa (executor driver) (200/200)
[2025-07-19T18:30:21.663+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
[2025-07-19T18:30:21.664+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodeGenerator: Code generated in 18.50925 ms
[2025-07-19T18:30:21.664+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.664+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DAGScheduler: ResultStage 1 (start at <unknown>:0) finished in 8.461 s
[2025-07-19T18:30:21.665+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.665+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-19T18:30:21.666+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
[2025-07-19T18:30:21.667+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7ddf6942
[2025-07-19T18:30:21.668+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DAGScheduler: Job 2 finished: start at <unknown>:0, took 9.663563 s
[2025-07-19T18:30:21.669+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=6, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:21.669+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/6] for update
[2025-07-19T18:30:21.669+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Reservations_raw, format=PARQUET)] is committing.
[2025-07-19T18:30:21.669+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.670+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO SparkWrite: Committing epoch 0 for query 2a1d3ae4-6012-45da-96cc-6bbf43f14340 in append mode
[2025-07-19T18:30:21.670+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2896ed27
[2025-07-19T18:30:21.670+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=7, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:21.671+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/7] for update
[2025-07-19T18:30:21.671+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.671+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/5/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/5/.2.delta.8ed3509d-77ef-4f34-ad31-85e712e1bc33.TID608.tmp
[2025-07-19T18:30:21.671+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/3/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/3/.2.delta.f24bafe4-a137-4e7b-b750-a2bdadaf46bd.TID606.tmp
[2025-07-19T18:30:21.671+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/4/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/4/.2.delta.e3b2fc43-4901-4e5a-9030-34517d635a5c.TID607.tmp
[2025-07-19T18:30:21.671+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/6/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/6/.2.delta.76430a7c-3f39-436c-bb22-30127bef76bf.TID609.tmp
[2025-07-19T18:30:21.673+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/0/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/0/.2.delta.d6b1b8e8-90e0-41bf-96e9-83a1539264d6.TID603.tmp
[2025-07-19T18:30:21.674+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/2/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/2/.2.delta.c96fe7ac-aa87-425b-8553-8e963150b89e.TID605.tmp
[2025-07-19T18:30:21.674+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/1/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/1/.2.delta.cbd7c2ba-6cb9-4566-a4e8-0875a0d6bfdc.TID604.tmp
[2025-07-19T18:30:21.674+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/7/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/7/.2.delta.7230781d-2385-436c-a186-7ec2fa582f53.TID610.tmp
[2025-07-19T18:30:21.674+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO SparkWrite: Committing streaming append with 60 new data files to table my_catalog.bronze.Reservations_raw
[2025-07-19T18:30:21.691+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/4/.2.delta.e3b2fc43-4901-4e5a-9030-34517d635a5c.TID607.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/4/2.delta
[2025-07-19T18:30:21.692+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/4] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/4/2.delta
[2025-07-19T18:30:21.692+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 4 (task 607, attempt 0, stage 7.0)
[2025-07-19T18:30:21.692+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/6/.2.delta.76430a7c-3f39-436c-bb22-30127bef76bf.TID609.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/6/2.delta
[2025-07-19T18:30:21.693+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/6] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/6/2.delta
[2025-07-19T18:30:21.693+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 6 (task 609, attempt 0, stage 7.0)
[2025-07-19T18:30:21.695+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 4 (task 607, attempt 0, stage 7.0)
[2025-07-19T18:30:21.695+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 4.0 in stage 7.0 (TID 607). 5829 bytes result sent to driver
[2025-07-19T18:30:21.698+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 611) (8b44f3d35cfa, executor driver, partition 8, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.699+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 607) in 55 ms on 8b44f3d35cfa (executor driver) (1/200)
[2025-07-19T18:30:21.700+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 6 (task 609, attempt 0, stage 7.0)
[2025-07-19T18:30:21.701+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 8.0 in stage 7.0 (TID 611)
[2025-07-19T18:30:21.702+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/0/.2.delta.d6b1b8e8-90e0-41bf-96e9-83a1539264d6.TID603.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/0/2.delta
[2025-07-19T18:30:21.702+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/0] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/0/2.delta
[2025-07-19T18:30:21.703+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 6.0 in stage 7.0 (TID 609). 5829 bytes result sent to driver
[2025-07-19T18:30:21.703+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 603, attempt 0, stage 7.0)
[2025-07-19T18:30:21.706+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 612) (8b44f3d35cfa, executor driver, partition 9, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.707+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 609) in 45 ms on 8b44f3d35cfa (executor driver) (2/200)
[2025-07-19T18:30:21.708+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.708+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.709+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 9.0 in stage 7.0 (TID 612)
[2025-07-19T18:30:21.709+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@456bb15b
[2025-07-19T18:30:21.709+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/5/.2.delta.8ed3509d-77ef-4f34-ad31-85e712e1bc33.TID608.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/5/2.delta
[2025-07-19T18:30:21.710+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=8, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:21.711+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/8] for update
[2025-07-19T18:30:21.712+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/5] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/5/2.delta
[2025-07-19T18:30:21.712+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.713+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.713+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/3/.2.delta.f24bafe4-a137-4e7b-b750-a2bdadaf46bd.TID606.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/3/2.delta
[2025-07-19T18:30:21.713+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/3] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/3/2.delta
[2025-07-19T18:30:21.715+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 5 (task 608, attempt 0, stage 7.0)
[2025-07-19T18:30:21.717+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 3 (task 606, attempt 0, stage 7.0)
[2025-07-19T18:30:21.717+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.718+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/1/.2.delta.cbd7c2ba-6cb9-4566-a4e8-0875a0d6bfdc.TID604.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/1/2.delta
[2025-07-19T18:30:21.718+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/1] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/1/2.delta
[2025-07-19T18:30:21.719+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/7/.2.delta.7230781d-2385-436c-a186-7ec2fa582f53.TID610.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/7/2.delta
[2025-07-19T18:30:21.719+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/7] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/7/2.delta
[2025-07-19T18:30:21.720+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 7 (task 610, attempt 0, stage 7.0)
[2025-07-19T18:30:21.721+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 0 (task 603, attempt 0, stage 7.0)
[2025-07-19T18:30:21.721+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 0.0 in stage 7.0 (TID 603). 5829 bytes result sent to driver
[2025-07-19T18:30:21.721+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/2/.2.delta.c96fe7ac-aa87-425b-8553-8e963150b89e.TID605.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/2/2.delta
[2025-07-19T18:30:21.722+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 7 (task 610, attempt 0, stage 7.0)
[2025-07-19T18:30:21.723+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/2] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/2/2.delta
[2025-07-19T18:30:21.723+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 1 (task 604, attempt 0, stage 7.0)
[2025-07-19T18:30:21.725+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 2 (task 605, attempt 0, stage 7.0)
[2025-07-19T18:30:21.725+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 10.0 in stage 7.0 (TID 613) (8b44f3d35cfa, executor driver, partition 10, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.726+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3af70ed1
[2025-07-19T18:30:21.726+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 7.0 in stage 7.0 (TID 610). 5829 bytes result sent to driver
[2025-07-19T18:30:21.727+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 3 (task 606, attempt 0, stage 7.0)
[2025-07-19T18:30:21.728+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 3.0 in stage 7.0 (TID 606). 5786 bytes result sent to driver
[2025-07-19T18:30:21.728+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 5 (task 608, attempt 0, stage 7.0)
[2025-07-19T18:30:21.729+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 5.0 in stage 7.0 (TID 608). 5786 bytes result sent to driver
[2025-07-19T18:30:21.729+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=9, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:21.729+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 10.0 in stage 7.0 (TID 613)
[2025-07-19T18:30:21.729+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 11.0 in stage 7.0 (TID 614) (8b44f3d35cfa, executor driver, partition 11, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.730+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/9] for update
[2025-07-19T18:30:21.730+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 12.0 in stage 7.0 (TID 615) (8b44f3d35cfa, executor driver, partition 12, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.732+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 13.0 in stage 7.0 (TID 616) (8b44f3d35cfa, executor driver, partition 13, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.732+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 13.0 in stage 7.0 (TID 616)
[2025-07-19T18:30:21.733+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.733+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 603) in 94 ms on 8b44f3d35cfa (executor driver) (3/200)
[2025-07-19T18:30:21.733+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 610) in 60 ms on 8b44f3d35cfa (executor driver) (4/200)
[2025-07-19T18:30:21.734+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 606) in 89 ms on 8b44f3d35cfa (executor driver) (5/200)
[2025-07-19T18:30:21.734+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.734+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.734+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 608) in 66 ms on 8b44f3d35cfa (executor driver) (6/200)
[2025-07-19T18:30:21.735+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 12.0 in stage 7.0 (TID 615)
[2025-07-19T18:30:21.735+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3e65d06c
[2025-07-19T18:30:21.735+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 11.0 in stage 7.0 (TID 614)
[2025-07-19T18:30:21.736+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 1 (task 604, attempt 0, stage 7.0)
[2025-07-19T18:30:21.736+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 1.0 in stage 7.0 (TID 604). 5829 bytes result sent to driver
[2025-07-19T18:30:21.737+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 2 (task 605, attempt 0, stage 7.0)
[2025-07-19T18:30:21.738+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=10, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:21.738+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=10),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/10] for update
[2025-07-19T18:30:21.738+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.738+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.739+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 14.0 in stage 7.0 (TID 617) (8b44f3d35cfa, executor driver, partition 14, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.739+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 14.0 in stage 7.0 (TID 617)
[2025-07-19T18:30:21.739+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.740+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.741+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.741+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/8/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/8/.2.delta.73e8a91d-4862-4d1f-a4bf-02e59ea80b2e.TID611.tmp
[2025-07-19T18:30:21.741+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 2.0 in stage 7.0 (TID 605). 5829 bytes result sent to driver
[2025-07-19T18:30:21.741+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.742+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:21.742+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.743+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.743+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 15.0 in stage 7.0 (TID 618) (8b44f3d35cfa, executor driver, partition 15, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.744+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@16f3868c
[2025-07-19T18:30:21.744+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 15.0 in stage 7.0 (TID 618)
[2025-07-19T18:30:21.745+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=13, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:21.745+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=13),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/13] for update
[2025-07-19T18:30:21.746+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b5a98d2
[2025-07-19T18:30:21.746+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=14, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:21.746+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=14),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/14] for update
[2025-07-19T18:30:21.747+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.747+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59be314c
[2025-07-19T18:30:21.748+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.748+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.748+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=12, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:21.749+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=12),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/12] for update
[2025-07-19T18:30:21.751+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 604) in 97 ms on 8b44f3d35cfa (executor driver) (7/200)
[2025-07-19T18:30:21.751+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 605) in 97 ms on 8b44f3d35cfa (executor driver) (8/200)
[2025-07-19T18:30:21.752+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c74e203
[2025-07-19T18:30:21.752+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=11, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:21.752+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=11),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/11] for update
[2025-07-19T18:30:21.753+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.754+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.754+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.755+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2aed4d7d
[2025-07-19T18:30:21.755+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=15, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:21.755+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=15),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/15] for update
[2025-07-19T18:30:21.756+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/9/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/9/.2.delta.3308175c-f2d9-4754-9287-0cc7b7c9e332.TID612.tmp
[2025-07-19T18:30:21.756+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.756+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/10/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/10/.2.delta.1fc06cc9-03f5-4309-a838-e2125d54bf18.TID613.tmp
[2025-07-19T18:30:21.757+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/13/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/13/.2.delta.27f6e532-afd3-4cac-8822-7fe8e502a4a2.TID616.tmp
[2025-07-19T18:30:21.758+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/11/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/11/.2.delta.b327c1d5-5793-43fc-8544-6adca89c9877.TID614.tmp
[2025-07-19T18:30:21.758+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/15/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/15/.2.delta.e1ffce7e-d832-4ee5-8643-d320bf8441b5.TID618.tmp
[2025-07-19T18:30:21.758+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/14/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/14/.2.delta.90278d13-b13d-4ca1-9b44-d15f92195d27.TID617.tmp
[2025-07-19T18:30:21.758+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/12/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/12/.2.delta.b7996ef4-d14e-405d-8e70-12b5f26a563e.TID615.tmp
[2025-07-19T18:30:21.758+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/8/.2.delta.73e8a91d-4862-4d1f-a4bf-02e59ea80b2e.TID611.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/8/2.delta
[2025-07-19T18:30:21.758+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/8] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/8/2.delta
[2025-07-19T18:30:21.759+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 8 (task 611, attempt 0, stage 7.0)
[2025-07-19T18:30:21.760+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 8 (task 611, attempt 0, stage 7.0)
[2025-07-19T18:30:21.761+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 8.0 in stage 7.0 (TID 611). 5829 bytes result sent to driver
[2025-07-19T18:30:21.763+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 16.0 in stage 7.0 (TID 619) (8b44f3d35cfa, executor driver, partition 16, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.764+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 16.0 in stage 7.0 (TID 619)
[2025-07-19T18:30:21.764+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 611) in 62 ms on 8b44f3d35cfa (executor driver) (9/200)
[2025-07-19T18:30:21.765+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.765+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.766+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@61af63e9
[2025-07-19T18:30:21.767+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=16, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:21.767+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=16),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/16] for update
[2025-07-19T18:30:21.767+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.767+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/10/.2.delta.1fc06cc9-03f5-4309-a838-e2125d54bf18.TID613.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/10/2.delta
[2025-07-19T18:30:21.767+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=10),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/10] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/10/2.delta
[2025-07-19T18:30:21.768+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/9/.2.delta.3308175c-f2d9-4754-9287-0cc7b7c9e332.TID612.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/9/2.delta
[2025-07-19T18:30:21.768+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/9] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/9/2.delta
[2025-07-19T18:30:21.770+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 10 (task 613, attempt 0, stage 7.0)
[2025-07-19T18:30:21.771+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 9 (task 612, attempt 0, stage 7.0)
[2025-07-19T18:30:21.772+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/15/.2.delta.e1ffce7e-d832-4ee5-8643-d320bf8441b5.TID618.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/15/2.delta
[2025-07-19T18:30:21.772+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=15),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/15] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/15/2.delta
[2025-07-19T18:30:21.773+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 15 (task 618, attempt 0, stage 7.0)
[2025-07-19T18:30:21.775+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 10 (task 613, attempt 0, stage 7.0)
[2025-07-19T18:30:21.776+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 9 (task 612, attempt 0, stage 7.0)
[2025-07-19T18:30:21.777+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 10.0 in stage 7.0 (TID 613). 5829 bytes result sent to driver
[2025-07-19T18:30:21.777+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 9.0 in stage 7.0 (TID 612). 5829 bytes result sent to driver
[2025-07-19T18:30:21.778+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/13/.2.delta.27f6e532-afd3-4cac-8822-7fe8e502a4a2.TID616.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/13/2.delta
[2025-07-19T18:30:21.778+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=13),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/13] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/13/2.delta
[2025-07-19T18:30:21.781+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 17.0 in stage 7.0 (TID 620) (8b44f3d35cfa, executor driver, partition 17, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.782+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 13 (task 616, attempt 0, stage 7.0)
[2025-07-19T18:30:21.782+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 18.0 in stage 7.0 (TID 621) (8b44f3d35cfa, executor driver, partition 18, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.782+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/16/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/16/.2.delta.8d8ebbd6-c938-4dcd-a11f-16a1ef8e985a.TID619.tmp
[2025-07-19T18:30:21.783+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 17.0 in stage 7.0 (TID 620)
[2025-07-19T18:30:21.783+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/14/.2.delta.90278d13-b13d-4ca1-9b44-d15f92195d27.TID617.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/14/2.delta
[2025-07-19T18:30:21.783+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=14),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/14] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/14/2.delta
[2025-07-19T18:30:21.783+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 14 (task 617, attempt 0, stage 7.0)
[2025-07-19T18:30:21.783+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.783+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.783+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/11/.2.delta.b327c1d5-5793-43fc-8544-6adca89c9877.TID614.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/11/2.delta
[2025-07-19T18:30:21.784+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=11),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/11] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/11/2.delta
[2025-07-19T18:30:21.784+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 10.0 in stage 7.0 (TID 613) in 61 ms on 8b44f3d35cfa (executor driver) (10/200)
[2025-07-19T18:30:21.785+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 18.0 in stage 7.0 (TID 621)
[2025-07-19T18:30:21.785+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 11 (task 614, attempt 0, stage 7.0)
[2025-07-19T18:30:21.785+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 14 (task 617, attempt 0, stage 7.0)
[2025-07-19T18:30:21.785+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 14.0 in stage 7.0 (TID 617). 5829 bytes result sent to driver
[2025-07-19T18:30:21.785+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 612) in 74 ms on 8b44f3d35cfa (executor driver) (11/200)
[2025-07-19T18:30:21.785+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 19.0 in stage 7.0 (TID 622) (8b44f3d35cfa, executor driver, partition 19, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.786+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.786+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.786+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d4b4b35
[2025-07-19T18:30:21.787+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 14.0 in stage 7.0 (TID 617) in 58 ms on 8b44f3d35cfa (executor driver) (12/200)
[2025-07-19T18:30:21.787+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 19.0 in stage 7.0 (TID 622)
[2025-07-19T18:30:21.787+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=17, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:21.788+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=17),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/17] for update
[2025-07-19T18:30:21.788+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 13 (task 616, attempt 0, stage 7.0)
[2025-07-19T18:30:21.788+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 15 (task 618, attempt 0, stage 7.0)
[2025-07-19T18:30:21.788+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 15.0 in stage 7.0 (TID 618). 5829 bytes result sent to driver
[2025-07-19T18:30:21.788+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 13.0 in stage 7.0 (TID 616). 5829 bytes result sent to driver
[2025-07-19T18:30:21.788+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.788+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.789+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/12/.2.delta.b7996ef4-d14e-405d-8e70-12b5f26a563e.TID615.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/12/2.delta
[2025-07-19T18:30:21.789+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=12),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/12] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/12/2.delta
[2025-07-19T18:30:21.790+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 12 (task 615, attempt 0, stage 7.0)
[2025-07-19T18:30:21.790+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 20.0 in stage 7.0 (TID 623) (8b44f3d35cfa, executor driver, partition 20, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.790+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 20.0 in stage 7.0 (TID 623)
[2025-07-19T18:30:21.790+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 21.0 in stage 7.0 (TID 624) (8b44f3d35cfa, executor driver, partition 21, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.791+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 21.0 in stage 7.0 (TID 624)
[2025-07-19T18:30:21.792+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 15.0 in stage 7.0 (TID 618) in 60 ms on 8b44f3d35cfa (executor driver) (13/200)
[2025-07-19T18:30:21.793+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.794+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 13.0 in stage 7.0 (TID 616) in 66 ms on 8b44f3d35cfa (executor driver) (14/200)
[2025-07-19T18:30:21.795+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 11 (task 614, attempt 0, stage 7.0)
[2025-07-19T18:30:21.795+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 11.0 in stage 7.0 (TID 614). 5829 bytes result sent to driver
[2025-07-19T18:30:21.796+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.797+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.799+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 22.0 in stage 7.0 (TID 625) (8b44f3d35cfa, executor driver, partition 22, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.800+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 22.0 in stage 7.0 (TID 625)
[2025-07-19T18:30:21.800+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 11.0 in stage 7.0 (TID 614) in 68 ms on 8b44f3d35cfa (executor driver) (15/200)
[2025-07-19T18:30:21.800+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@abbacc
[2025-07-19T18:30:21.801+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=18, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:21.801+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=18),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/18] for update
[2025-07-19T18:30:21.802+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.802+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.802+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@373a222b
[2025-07-19T18:30:21.803+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.803+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.804+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=20, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:21.804+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=20),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/20] for update
[2025-07-19T18:30:21.804+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 12 (task 615, attempt 0, stage 7.0)
[2025-07-19T18:30:21.805+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d4a9cdb
[2025-07-19T18:30:21.805+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 12.0 in stage 7.0 (TID 615). 5915 bytes result sent to driver
[2025-07-19T18:30:21.806+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=19, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:21.806+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=19),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/19] for update
[2025-07-19T18:30:21.806+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.806+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.807+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.808+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@417f6bff
[2025-07-19T18:30:21.808+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 23.0 in stage 7.0 (TID 626) (8b44f3d35cfa, executor driver, partition 23, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.808+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=22, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:21.809+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=22),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/22] for update
[2025-07-19T18:30:21.809+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 23.0 in stage 7.0 (TID 626)
[2025-07-19T18:30:21.810+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/17/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/17/.2.delta.5971905d-0b01-4388-b4a9-56110122f9f5.TID620.tmp
[2025-07-19T18:30:21.812+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 12.0 in stage 7.0 (TID 615) in 82 ms on 8b44f3d35cfa (executor driver) (16/200)
[2025-07-19T18:30:21.813+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.815+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.816+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a9fc360
[2025-07-19T18:30:21.818+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.818+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=21, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:21.820+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=21),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/21] for update
[2025-07-19T18:30:21.821+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.822+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@252217a
[2025-07-19T18:30:21.823+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=23, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:21.824+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=23),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/23] for update
[2025-07-19T18:30:21.825+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.826+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/19/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/19/.2.delta.00096d52-422c-4fef-b966-69d4cd80c666.TID622.tmp
[2025-07-19T18:30:21.827+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/18/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/18/.2.delta.22b79286-443c-4fb2-b091-d2d3cd55b28d.TID621.tmp
[2025-07-19T18:30:21.827+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/20/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/20/.2.delta.8ea69b8a-dd13-4239-a854-930daf01f3c3.TID623.tmp
[2025-07-19T18:30:21.827+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/21/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/21/.2.delta.11ec2624-3f4e-4e49-b58d-5221d302ae94.TID624.tmp
[2025-07-19T18:30:21.828+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/16/.2.delta.8d8ebbd6-c938-4dcd-a11f-16a1ef8e985a.TID619.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/16/2.delta
[2025-07-19T18:30:21.828+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=16),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/16] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/16/2.delta
[2025-07-19T18:30:21.829+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 16 (task 619, attempt 0, stage 7.0)
[2025-07-19T18:30:21.830+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/22/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/22/.2.delta.8d6078e9-e32c-4cd8-b9e0-7267a4dd147d.TID625.tmp
[2025-07-19T18:30:21.831+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 16 (task 619, attempt 0, stage 7.0)
[2025-07-19T18:30:21.831+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 16.0 in stage 7.0 (TID 619). 5872 bytes result sent to driver
[2025-07-19T18:30:21.831+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 24.0 in stage 7.0 (TID 627) (8b44f3d35cfa, executor driver, partition 24, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.831+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 16.0 in stage 7.0 (TID 619) in 60 ms on 8b44f3d35cfa (executor driver) (17/200)
[2025-07-19T18:30:21.831+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 24.0 in stage 7.0 (TID 627)
[2025-07-19T18:30:21.832+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/23/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/23/.2.delta.5f49baa4-6ba3-4b3f-82a9-568e5b07e980.TID626.tmp
[2025-07-19T18:30:21.832+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.833+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.833+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@551a580d
[2025-07-19T18:30:21.833+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=24, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:21.834+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=24),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/24] for update
[2025-07-19T18:30:21.834+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.838+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/24/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/24/.2.delta.0bcd810c-eb06-42cb-844e-c7a72e4fbc79.TID627.tmp
[2025-07-19T18:30:21.845+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/17/.2.delta.5971905d-0b01-4388-b4a9-56110122f9f5.TID620.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/17/2.delta
[2025-07-19T18:30:21.846+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HadoopTableOperations: Committed a new metadata file s3a://warehouse/bronze/Reservations_raw/metadata/v10.metadata.json
[2025-07-19T18:30:21.847+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=17),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/17] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/17/2.delta
[2025-07-19T18:30:21.847+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 17 (task 620, attempt 0, stage 7.0)
[2025-07-19T18:30:21.848+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/18/.2.delta.22b79286-443c-4fb2-b091-d2d3cd55b28d.TID621.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/18/2.delta
[2025-07-19T18:30:21.849+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=18),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/18] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/18/2.delta
[2025-07-19T18:30:21.849+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 18 (task 621, attempt 0, stage 7.0)
[2025-07-19T18:30:21.851+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 17 (task 620, attempt 0, stage 7.0)
[2025-07-19T18:30:21.852+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 17.0 in stage 7.0 (TID 620). 5872 bytes result sent to driver
[2025-07-19T18:30:21.854+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 25.0 in stage 7.0 (TID 628) (8b44f3d35cfa, executor driver, partition 25, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.854+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 17.0 in stage 7.0 (TID 620) in 84 ms on 8b44f3d35cfa (executor driver) (18/200)
[2025-07-19T18:30:21.855+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 18 (task 621, attempt 0, stage 7.0)
[2025-07-19T18:30:21.858+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 18.0 in stage 7.0 (TID 621). 5872 bytes result sent to driver
[2025-07-19T18:30:21.858+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 25.0 in stage 7.0 (TID 628)
[2025-07-19T18:30:21.859+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/19/.2.delta.00096d52-422c-4fef-b966-69d4cd80c666.TID622.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/19/2.delta
[2025-07-19T18:30:21.860+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 26.0 in stage 7.0 (TID 629) (8b44f3d35cfa, executor driver, partition 26, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.861+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=19),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/19] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/19/2.delta
[2025-07-19T18:30:21.862+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 18.0 in stage 7.0 (TID 621) in 85 ms on 8b44f3d35cfa (executor driver) (19/200)
[2025-07-19T18:30:21.863+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 26.0 in stage 7.0 (TID 629)
[2025-07-19T18:30:21.865+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.866+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.867+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 19 (task 622, attempt 0, stage 7.0)
[2025-07-19T18:30:21.868+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@9e69eff
[2025-07-19T18:30:21.869+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.869+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.871+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=25, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:21.871+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=25),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/25] for update
[2025-07-19T18:30:21.871+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/20/.2.delta.8ea69b8a-dd13-4239-a854-930daf01f3c3.TID623.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/20/2.delta
[2025-07-19T18:30:21.872+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=20),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/20] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/20/2.delta
[2025-07-19T18:30:21.872+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@27fb4eb3
[2025-07-19T18:30:21.872+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 20 (task 623, attempt 0, stage 7.0)
[2025-07-19T18:30:21.873+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 19 (task 622, attempt 0, stage 7.0)
[2025-07-19T18:30:21.873+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/21/.2.delta.11ec2624-3f4e-4e49-b58d-5221d302ae94.TID624.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/21/2.delta
[2025-07-19T18:30:21.873+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=21),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/21] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/21/2.delta
[2025-07-19T18:30:21.873+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.873+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 21 (task 624, attempt 0, stage 7.0)
[2025-07-19T18:30:21.873+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=26, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:21.873+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=26),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/26] for update
[2025-07-19T18:30:21.874+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 19.0 in stage 7.0 (TID 622). 5872 bytes result sent to driver
[2025-07-19T18:30:21.874+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 27.0 in stage 7.0 (TID 630) (8b44f3d35cfa, executor driver, partition 27, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.874+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 19.0 in stage 7.0 (TID 622) in 90 ms on 8b44f3d35cfa (executor driver) (20/200)
[2025-07-19T18:30:21.874+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 27.0 in stage 7.0 (TID 630)
[2025-07-19T18:30:21.874+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.875+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 20 (task 623, attempt 0, stage 7.0)
[2025-07-19T18:30:21.875+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 20.0 in stage 7.0 (TID 623). 5872 bytes result sent to driver
[2025-07-19T18:30:21.875+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.875+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.876+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 28.0 in stage 7.0 (TID 631) (8b44f3d35cfa, executor driver, partition 28, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.876+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 20.0 in stage 7.0 (TID 623) in 92 ms on 8b44f3d35cfa (executor driver) (21/200)
[2025-07-19T18:30:21.876+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ed5e024
[2025-07-19T18:30:21.877+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=27, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:21.877+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=27),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/27] for update
[2025-07-19T18:30:21.877+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 28.0 in stage 7.0 (TID 631)
[2025-07-19T18:30:21.878+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 21 (task 624, attempt 0, stage 7.0)
[2025-07-19T18:30:21.878+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/22/.2.delta.8d6078e9-e32c-4cd8-b9e0-7267a4dd147d.TID625.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/22/2.delta
[2025-07-19T18:30:21.878+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=22),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/22] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/22/2.delta
[2025-07-19T18:30:21.879+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 21.0 in stage 7.0 (TID 624). 5872 bytes result sent to driver
[2025-07-19T18:30:21.879+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.879+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 22 (task 625, attempt 0, stage 7.0)
[2025-07-19T18:30:21.879+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 29.0 in stage 7.0 (TID 632) (8b44f3d35cfa, executor driver, partition 29, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.880+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 21.0 in stage 7.0 (TID 624) in 95 ms on 8b44f3d35cfa (executor driver) (22/200)
[2025-07-19T18:30:21.880+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 29.0 in stage 7.0 (TID 632)
[2025-07-19T18:30:21.883+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.885+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.885+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 22 (task 625, attempt 0, stage 7.0)
[2025-07-19T18:30:21.886+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@61198931
[2025-07-19T18:30:21.886+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/23/.2.delta.5f49baa4-6ba3-4b3f-82a9-568e5b07e980.TID626.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/23/2.delta
[2025-07-19T18:30:21.887+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=23),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/23] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/23/2.delta
[2025-07-19T18:30:21.888+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 22.0 in stage 7.0 (TID 625). 5872 bytes result sent to driver
[2025-07-19T18:30:21.888+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.888+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.889+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=28, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:21.890+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=28),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/28] for update
[2025-07-19T18:30:21.890+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 30.0 in stage 7.0 (TID 633) (8b44f3d35cfa, executor driver, partition 30, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.890+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 8b44f3d35cfa:40517 in memory (size: 19.6 KiB, free: 434.2 MiB)
[2025-07-19T18:30:21.891+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 22.0 in stage 7.0 (TID 625) in 105 ms on 8b44f3d35cfa (executor driver) (23/200)
[2025-07-19T18:30:21.892+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 30.0 in stage 7.0 (TID 633)
[2025-07-19T18:30:21.896+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 23 (task 626, attempt 0, stage 7.0)
[2025-07-19T18:30:21.896+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/26/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/26/.2.delta.0ed22c12-7c0b-486f-a663-3bd292868a54.TID629.tmp
[2025-07-19T18:30:21.899+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.900+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.901+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.902+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@64bbe13b
[2025-07-19T18:30:21.903+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/25/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/25/.2.delta.6cf691f0-9174-4766-af59-b716367f55ee.TID628.tmp
[2025-07-19T18:30:21.904+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=29, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:21.905+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=29),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/29] for update
[2025-07-19T18:30:21.905+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.905+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/27/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/27/.2.delta.d6507a18-6e81-4a67-8b56-69a3b008617a.TID630.tmp
[2025-07-19T18:30:21.906+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6b7263a7
[2025-07-19T18:30:21.906+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=30, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:21.907+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=30),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/30] for update
[2025-07-19T18:30:21.908+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 23 (task 626, attempt 0, stage 7.0)
[2025-07-19T18:30:21.908+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 23.0 in stage 7.0 (TID 626). 5829 bytes result sent to driver
[2025-07-19T18:30:21.909+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 31.0 in stage 7.0 (TID 634) (8b44f3d35cfa, executor driver, partition 31, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.909+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 23.0 in stage 7.0 (TID 626) in 101 ms on 8b44f3d35cfa (executor driver) (24/200)
[2025-07-19T18:30:21.909+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 31.0 in stage 7.0 (TID 634)
[2025-07-19T18:30:21.910+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO SnapshotProducer: Committed snapshot 6197000065785861206 (FastAppend)
[2025-07-19T18:30:21.911+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.911+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.911+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.911+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@255e8ee1
[2025-07-19T18:30:21.911+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=31, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:21.912+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=31),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/31] for update
[2025-07-19T18:30:21.913+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/24/.2.delta.0bcd810c-eb06-42cb-844e-c7a72e4fbc79.TID627.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/24/2.delta
[2025-07-19T18:30:21.914+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=24),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/24] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/24/2.delta
[2025-07-19T18:30:21.914+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 24 (task 627, attempt 0, stage 7.0)
[2025-07-19T18:30:21.915+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.915+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/29/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/29/.2.delta.fea7ed55-7125-4976-94f0-d474d4ad1d62.TID632.tmp
[2025-07-19T18:30:21.915+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 24 (task 627, attempt 0, stage 7.0)
[2025-07-19T18:30:21.915+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/28/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/28/.2.delta.362a5e95-4b84-48b7-9f21-442ba3fa83b5.TID631.tmp
[2025-07-19T18:30:21.916+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 24.0 in stage 7.0 (TID 627). 5829 bytes result sent to driver
[2025-07-19T18:30:21.916+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 24.0 in stage 7.0 (TID 627) in 88 ms on 8b44f3d35cfa (executor driver) (25/200)
[2025-07-19T18:30:21.916+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 32.0 in stage 7.0 (TID 635) (8b44f3d35cfa, executor driver, partition 32, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.919+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 32.0 in stage 7.0 (TID 635)
[2025-07-19T18:30:21.919+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.919+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.920+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2cf04bef
[2025-07-19T18:30:21.920+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/30/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/30/.2.delta.737e16de-3329-414a-b3d0-0e46c6c7b623.TID633.tmp
[2025-07-19T18:30:21.920+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=32, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:21.920+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=32),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/32] for update
[2025-07-19T18:30:21.921+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.921+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/31/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/31/.2.delta.84e77823-d288-4c82-aa46-8c76aadbb81e.TID634.tmp
[2025-07-19T18:30:21.926+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/27/.2.delta.d6507a18-6e81-4a67-8b56-69a3b008617a.TID630.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/27/2.delta
[2025-07-19T18:30:21.926+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=27),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/27] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/27/2.delta
[2025-07-19T18:30:21.927+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 27 (task 630, attempt 0, stage 7.0)
[2025-07-19T18:30:21.929+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/26/.2.delta.0ed22c12-7c0b-486f-a663-3bd292868a54.TID629.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/26/2.delta
[2025-07-19T18:30:21.933+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=26),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/26] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/26/2.delta
[2025-07-19T18:30:21.933+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 27 (task 630, attempt 0, stage 7.0)
[2025-07-19T18:30:21.934+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 26 (task 629, attempt 0, stage 7.0)
[2025-07-19T18:30:21.934+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/32/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/32/.2.delta.bd065fdf-128b-4822-a2f1-0660f0c287a8.TID635.tmp
[2025-07-19T18:30:21.934+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 27.0 in stage 7.0 (TID 630). 5829 bytes result sent to driver
[2025-07-19T18:30:21.937+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 33.0 in stage 7.0 (TID 636) (8b44f3d35cfa, executor driver, partition 33, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.937+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 27.0 in stage 7.0 (TID 630) in 68 ms on 8b44f3d35cfa (executor driver) (26/200)
[2025-07-19T18:30:21.938+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 26 (task 629, attempt 0, stage 7.0)
[2025-07-19T18:30:21.938+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 33.0 in stage 7.0 (TID 636)
[2025-07-19T18:30:21.938+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 26.0 in stage 7.0 (TID 629). 5829 bytes result sent to driver
[2025-07-19T18:30:21.940+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 34.0 in stage 7.0 (TID 637) (8b44f3d35cfa, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.942+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 34.0 in stage 7.0 (TID 637)
[2025-07-19T18:30:21.943+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/29/.2.delta.fea7ed55-7125-4976-94f0-d474d4ad1d62.TID632.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/29/2.delta
[2025-07-19T18:30:21.945+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=29),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/29] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/29/2.delta
[2025-07-19T18:30:21.947+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 29 (task 632, attempt 0, stage 7.0)
[2025-07-19T18:30:21.949+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 26.0 in stage 7.0 (TID 629) in 82 ms on 8b44f3d35cfa (executor driver) (27/200)
[2025-07-19T18:30:21.950+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/25/.2.delta.6cf691f0-9174-4766-af59-b716367f55ee.TID628.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/25/2.delta
[2025-07-19T18:30:21.950+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.951+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=25),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/25] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/25/2.delta
[2025-07-19T18:30:21.951+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.952+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 25 (task 628, attempt 0, stage 7.0)
[2025-07-19T18:30:21.952+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.952+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.953+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@421d524d
[2025-07-19T18:30:21.954+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=33, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:21.955+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 29 (task 632, attempt 0, stage 7.0)
[2025-07-19T18:30:21.955+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=33),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/33] for update
[2025-07-19T18:30:21.957+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 29.0 in stage 7.0 (TID 632). 5829 bytes result sent to driver
[2025-07-19T18:30:21.958+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@49d1332c
[2025-07-19T18:30:21.959+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.960+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=34, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:21.961+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=34),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/34] for update
[2025-07-19T18:30:21.961+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 35.0 in stage 7.0 (TID 638) (8b44f3d35cfa, executor driver, partition 35, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.964+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 35.0 in stage 7.0 (TID 638)
[2025-07-19T18:30:21.965+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 29.0 in stage 7.0 (TID 632) in 71 ms on 8b44f3d35cfa (executor driver) (28/200)
[2025-07-19T18:30:21.965+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.966+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 25 (task 628, attempt 0, stage 7.0)
[2025-07-19T18:30:21.966+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 25.0 in stage 7.0 (TID 628). 5829 bytes result sent to driver
[2025-07-19T18:30:21.967+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 36.0 in stage 7.0 (TID 639) (8b44f3d35cfa, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.967+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.968+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.970+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 36.0 in stage 7.0 (TID 639)
[2025-07-19T18:30:21.971+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 25.0 in stage 7.0 (TID 628) in 95 ms on 8b44f3d35cfa (executor driver) (29/200)
[2025-07-19T18:30:21.972+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/28/.2.delta.362a5e95-4b84-48b7-9f21-442ba3fa83b5.TID631.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/28/2.delta
[2025-07-19T18:30:21.972+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=28),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/28] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/28/2.delta
[2025-07-19T18:30:21.973+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 28 (task 631, attempt 0, stage 7.0)
[2025-07-19T18:30:21.974+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO LoggingMetricsReporter: Received metrics report: CommitReport{tableName=my_catalog.bronze.Reservations_raw, snapshotId=6197000065785861206, sequenceNumber=9, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.2732215S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=CounterResult{unit=COUNT, value=60}, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=457}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=CounterResult{unit=COUNT, value=68}, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=511}, addedFilesSizeInBytes=CounterResult{unit=BYTES, value=177725}, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=1352840}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}}, metadata={engine-version=3.5.6, app-id=local-1752949808869, engine-name=spark, iceberg-version=Apache Iceberg 1.4.0 (commit 10367c380098c2e06a49521a33681ac7f6c64b2c)}}
[2025-07-19T18:30:21.974+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO SparkWrite: Committed in 273 ms
[2025-07-19T18:30:21.976+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Reservations_raw, format=PARQUET)] committed.
[2025-07-19T18:30:21.976+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.977+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.977+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d815aaa
[2025-07-19T18:30:21.978+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=35, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:21.979+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=35),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/35] for update
[2025-07-19T18:30:21.979+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1103479c
[2025-07-19T18:30:21.979+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 28 (task 631, attempt 0, stage 7.0)
[2025-07-19T18:30:21.980+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.980+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/34/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/34/.2.delta.4dd75565-9e4d-486a-a8b8-959ff8456480.TID637.tmp
[2025-07-19T18:30:21.981+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 28.0 in stage 7.0 (TID 631). 5829 bytes result sent to driver
[2025-07-19T18:30:21.982+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=36, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:21.983+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=36),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/36] for update
[2025-07-19T18:30:21.983+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.983+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 37.0 in stage 7.0 (TID 640) (8b44f3d35cfa, executor driver, partition 37, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.984+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 28.0 in stage 7.0 (TID 631) in 87 ms on 8b44f3d35cfa (executor driver) (30/200)
[2025-07-19T18:30:21.984+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/30/.2.delta.737e16de-3329-414a-b3d0-0e46c6c7b623.TID633.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/30/2.delta
[2025-07-19T18:30:21.985+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=30),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/30] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/30/2.delta
[2025-07-19T18:30:21.986+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 37.0 in stage 7.0 (TID 640)
[2025-07-19T18:30:21.986+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 30 (task 633, attempt 0, stage 7.0)
[2025-07-19T18:30:21.986+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/33/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/33/.2.delta.034dd16a-d703-4110-a99b-c4a27725ba22.TID636.tmp
[2025-07-19T18:30:21.986+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.986+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.986+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/31/.2.delta.84e77823-d288-4c82-aa46-8c76aadbb81e.TID634.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/31/2.delta
[2025-07-19T18:30:21.987+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=31),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/31] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/31/2.delta
[2025-07-19T18:30:21.987+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@662ed407
[2025-07-19T18:30:21.987+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 31 (task 634, attempt 0, stage 7.0)
[2025-07-19T18:30:21.987+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/commits/0 using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/commits/.0.966fced5-f230-4bbe-bf70-fd262b0c3817.tmp
[2025-07-19T18:30:21.987+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=37, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:21.987+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=37),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/37] for update
[2025-07-19T18:30:21.987+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 30 (task 633, attempt 0, stage 7.0)
[2025-07-19T18:30:21.987+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.988+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/36/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/36/.2.delta.9ad0fbe6-4cd3-4ead-a5cf-ae12e49651ce.TID639.tmp
[2025-07-19T18:30:21.988+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 30.0 in stage 7.0 (TID 633). 5829 bytes result sent to driver
[2025-07-19T18:30:21.988+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 31 (task 634, attempt 0, stage 7.0)
[2025-07-19T18:30:21.988+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 31.0 in stage 7.0 (TID 634). 5829 bytes result sent to driver
[2025-07-19T18:30:21.989+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 38.0 in stage 7.0 (TID 641) (8b44f3d35cfa, executor driver, partition 38, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.989+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 39.0 in stage 7.0 (TID 642) (8b44f3d35cfa, executor driver, partition 39, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.989+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 30.0 in stage 7.0 (TID 633) in 81 ms on 8b44f3d35cfa (executor driver) (31/200)
[2025-07-19T18:30:21.989+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 39.0 in stage 7.0 (TID 642)
[2025-07-19T18:30:21.990+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 31.0 in stage 7.0 (TID 634) in 72 ms on 8b44f3d35cfa (executor driver) (32/200)
[2025-07-19T18:30:21.990+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/35/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/35/.2.delta.39ab1e64-2e0c-4d69-b31f-8540c7b39b9c.TID638.tmp
[2025-07-19T18:30:21.991+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 38.0 in stage 7.0 (TID 641)
[2025-07-19T18:30:21.991+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/32/.2.delta.bd065fdf-128b-4822-a2f1-0660f0c287a8.TID635.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/32/2.delta
[2025-07-19T18:30:21.992+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=32),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/32] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/32/2.delta
[2025-07-19T18:30:21.992+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.994+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.995+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25a174ac
[2025-07-19T18:30:21.996+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 32 (task 635, attempt 0, stage 7.0)
[2025-07-19T18:30:21.996+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=38, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:21.997+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=38),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/38] for update
[2025-07-19T18:30:21.997+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/37/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/37/.2.delta.64d4a230-f139-4169-9afc-66e546b24882.TID640.tmp
[2025-07-19T18:30:21.997+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:21.997+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:21.997+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:21.997+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 32 (task 635, attempt 0, stage 7.0)
[2025-07-19T18:30:21.997+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@17b798a5
[2025-07-19T18:30:21.997+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 32.0 in stage 7.0 (TID 635). 5829 bytes result sent to driver
[2025-07-19T18:30:21.998+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 40.0 in stage 7.0 (TID 643) (8b44f3d35cfa, executor driver, partition 40, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:21.998+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 40.0 in stage 7.0 (TID 643)
[2025-07-19T18:30:21.999+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 32.0 in stage 7.0 (TID 635) in 69 ms on 8b44f3d35cfa (executor driver) (33/200)
[2025-07-19T18:30:22.000+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=39, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.001+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=39),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/39] for update
[2025-07-19T18:30:22.001+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.001+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:22.002+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.006+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@163985be
[2025-07-19T18:30:22.006+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=40, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.007+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/38/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/38/.2.delta.6f33208e-a1c1-4958-b140-ba8d48da5aa7.TID641.tmp
[2025-07-19T18:30:22.008+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=40),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/40] for update
[2025-07-19T18:30:22.010+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.011+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/39/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/39/.2.delta.bd55c11e-2c26-4259-82fb-b2869987a58b.TID642.tmp
[2025-07-19T18:30:22.011+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/34/.2.delta.4dd75565-9e4d-486a-a8b8-959ff8456480.TID637.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/34/2.delta
[2025-07-19T18:30:22.012+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=34),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/34] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/34/2.delta
[2025-07-19T18:30:22.015+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 34 (task 637, attempt 0, stage 7.0)
[2025-07-19T18:30:22.020+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/40/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/40/.2.delta.48d74551-9528-4496-beee-1a3689534f45.TID643.tmp
[2025-07-19T18:30:22.024+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Committed partition 34 (task 637, attempt 0, stage 7.0)
[2025-07-19T18:30:22.027+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Finished task 34.0 in stage 7.0 (TID 637). 5829 bytes result sent to driver
[2025-07-19T18:30:22.027+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/33/.2.delta.034dd16a-d703-4110-a99b-c4a27725ba22.TID636.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/33/2.delta
[2025-07-19T18:30:22.029+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=33),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/33] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/33/2.delta
[2025-07-19T18:30:22.032+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO DataWritingSparkTask: Commit authorized for partition 33 (task 636, attempt 0, stage 7.0)
[2025-07-19T18:30:22.032+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Starting task 41.0 in stage 7.0 (TID 644) (8b44f3d35cfa, executor driver, partition 41, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.036+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO Executor: Running task 41.0 in stage 7.0 (TID 644)
[2025-07-19T18:30:22.039+0000] {subprocess.py:93} INFO - 25/07/19 18:30:21 INFO TaskSetManager: Finished task 34.0 in stage 7.0 (TID 637) in 67 ms on 8b44f3d35cfa (executor driver) (34/200)
[2025-07-19T18:30:22.043+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 33 (task 636, attempt 0, stage 7.0)
[2025-07-19T18:30:22.045+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.047+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.047+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6bdb8507
[2025-07-19T18:30:22.048+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 33.0 in stage 7.0 (TID 636). 5872 bytes result sent to driver
[2025-07-19T18:30:22.049+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=41, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.049+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=41),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/41] for update
[2025-07-19T18:30:22.049+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.050+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 42.0 in stage 7.0 (TID 645) (8b44f3d35cfa, executor driver, partition 42, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.050+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 42.0 in stage 7.0 (TID 645)
[2025-07-19T18:30:22.053+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/35/.2.delta.39ab1e64-2e0c-4d69-b31f-8540c7b39b9c.TID638.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/35/2.delta
[2025-07-19T18:30:22.054+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=35),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/35] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/35/2.delta
[2025-07-19T18:30:22.054+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 33.0 in stage 7.0 (TID 636) in 77 ms on 8b44f3d35cfa (executor driver) (35/200)
[2025-07-19T18:30:22.055+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 35 (task 638, attempt 0, stage 7.0)
[2025-07-19T18:30:22.056+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/commits/.0.966fced5-f230-4bbe-bf70-fd262b0c3817.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T18:28:00+00:00/commits/0
[2025-07-19T18:30:22.056+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 35 (task 638, attempt 0, stage 7.0)
[2025-07-19T18:30:22.057+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 35.0 in stage 7.0 (TID 638). 5829 bytes result sent to driver
[2025-07-19T18:30:22.057+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 43.0 in stage 7.0 (TID 646) (8b44f3d35cfa, executor driver, partition 43, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.061+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 43.0 in stage 7.0 (TID 646)
[2025-07-19T18:30:22.066+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 35.0 in stage 7.0 (TID 638) in 74 ms on 8b44f3d35cfa (executor driver) (36/200)
[2025-07-19T18:30:22.066+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/37/.2.delta.64d4a230-f139-4169-9afc-66e546b24882.TID640.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/37/2.delta
[2025-07-19T18:30:22.067+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=37),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/37] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/37/2.delta
[2025-07-19T18:30:22.068+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.069+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.070+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 37 (task 640, attempt 0, stage 7.0)
[2025-07-19T18:30:22.073+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO MicroBatchExecution: Streaming query made progress: {
[2025-07-19T18:30:22.074+0000] {subprocess.py:93} INFO -   "id" : "2a1d3ae4-6012-45da-96cc-6bbf43f14340",
[2025-07-19T18:30:22.075+0000] {subprocess.py:93} INFO -   "runId" : "b8eee2e2-0960-4f84-b369-9c0543e84c2b",
[2025-07-19T18:30:22.075+0000] {subprocess.py:93} INFO -   "name" : null,
[2025-07-19T18:30:22.075+0000] {subprocess.py:93} INFO -   "timestamp" : "2025-07-19T18:30:10.665Z",
[2025-07-19T18:30:22.076+0000] {subprocess.py:93} INFO -   "batchId" : 0,
[2025-07-19T18:30:22.076+0000] {subprocess.py:93} INFO -   "numInputRows" : 69,
[2025-07-19T18:30:22.077+0000] {subprocess.py:93} INFO -   "inputRowsPerSecond" : 0.0,
[2025-07-19T18:30:22.077+0000] {subprocess.py:93} INFO -   "processedRowsPerSecond" : 6.082510578279267,
[2025-07-19T18:30:22.078+0000] {subprocess.py:93} INFO -   "durationMs" : {
[2025-07-19T18:30:22.078+0000] {subprocess.py:93} INFO -     "addBatch" : 10456,
[2025-07-19T18:30:22.079+0000] {subprocess.py:93} INFO -     "commitOffsets" : 62,
[2025-07-19T18:30:22.079+0000] {subprocess.py:93} INFO -     "getBatch" : 8,
[2025-07-19T18:30:22.080+0000] {subprocess.py:93} INFO -     "latestOffset" : 406,
[2025-07-19T18:30:22.083+0000] {subprocess.py:93} INFO -     "queryPlanning" : 378,
[2025-07-19T18:30:22.083+0000] {subprocess.py:93} INFO -     "triggerExecution" : 11344,
[2025-07-19T18:30:22.085+0000] {subprocess.py:93} INFO -     "walCommit" : 23
[2025-07-19T18:30:22.087+0000] {subprocess.py:93} INFO -   },
[2025-07-19T18:30:22.087+0000] {subprocess.py:93} INFO -   "eventTime" : {
[2025-07-19T18:30:22.088+0000] {subprocess.py:93} INFO -     "avg" : "1970-01-01T00:00:00.000Z",
[2025-07-19T18:30:22.090+0000] {subprocess.py:93} INFO -     "max" : "1970-01-01T00:00:00.000Z",
[2025-07-19T18:30:22.091+0000] {subprocess.py:93} INFO -     "min" : "1970-01-01T00:00:00.000Z",
[2025-07-19T18:30:22.091+0000] {subprocess.py:93} INFO -     "watermark" : "1970-01-01T00:00:00.000Z"
[2025-07-19T18:30:22.093+0000] {subprocess.py:93} INFO -   },
[2025-07-19T18:30:22.094+0000] {subprocess.py:93} INFO -   "stateOperators" : [ {
[2025-07-19T18:30:22.094+0000] {subprocess.py:93} INFO -     "operatorName" : "dedupe",
[2025-07-19T18:30:22.095+0000] {subprocess.py:93} INFO -     "numRowsTotal" : 68,
[2025-07-19T18:30:22.096+0000] {subprocess.py:93} INFO -     "numRowsUpdated" : 68,
[2025-07-19T18:30:22.096+0000] {subprocess.py:93} INFO -     "allUpdatesTimeMs" : 2757,
[2025-07-19T18:30:22.097+0000] {subprocess.py:93} INFO -     "numRowsRemoved" : 0,
[2025-07-19T18:30:22.098+0000] {subprocess.py:93} INFO -     "allRemovalsTimeMs" : 103,
[2025-07-19T18:30:22.098+0000] {subprocess.py:93} INFO -     "commitTimeMs" : 8792,
[2025-07-19T18:30:22.099+0000] {subprocess.py:93} INFO -     "memoryUsedBytes" : 65312,
[2025-07-19T18:30:22.099+0000] {subprocess.py:93} INFO -     "numRowsDroppedByWatermark" : 0,
[2025-07-19T18:30:22.101+0000] {subprocess.py:93} INFO -     "numShufflePartitions" : 200,
[2025-07-19T18:30:22.101+0000] {subprocess.py:93} INFO -     "numStateStoreInstances" : 200,
[2025-07-19T18:30:22.101+0000] {subprocess.py:93} INFO -     "customMetrics" : {
[2025-07-19T18:30:22.102+0000] {subprocess.py:93} INFO -       "loadedMapCacheHitCount" : 0,
[2025-07-19T18:30:22.102+0000] {subprocess.py:93} INFO -       "loadedMapCacheMissCount" : 0,
[2025-07-19T18:30:22.102+0000] {subprocess.py:93} INFO -       "numDroppedDuplicateRows" : 1,
[2025-07-19T18:30:22.103+0000] {subprocess.py:93} INFO -       "stateOnCurrentVersionSizeBytes" : 36512
[2025-07-19T18:30:22.104+0000] {subprocess.py:93} INFO -     }
[2025-07-19T18:30:22.104+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T18:30:22.106+0000] {subprocess.py:93} INFO -   "sources" : [ {
[2025-07-19T18:30:22.107+0000] {subprocess.py:93} INFO -     "description" : "KafkaV2[Subscribe[reservations]]",
[2025-07-19T18:30:22.108+0000] {subprocess.py:93} INFO -     "startOffset" : null,
[2025-07-19T18:30:22.109+0000] {subprocess.py:93} INFO -     "endOffset" : {
[2025-07-19T18:30:22.109+0000] {subprocess.py:93} INFO -       "reservations" : {
[2025-07-19T18:30:22.109+0000] {subprocess.py:93} INFO -         "0" : 69
[2025-07-19T18:30:22.110+0000] {subprocess.py:93} INFO -       }
[2025-07-19T18:30:22.110+0000] {subprocess.py:93} INFO -     },
[2025-07-19T18:30:22.113+0000] {subprocess.py:93} INFO -     "latestOffset" : {
[2025-07-19T18:30:22.114+0000] {subprocess.py:93} INFO -       "reservations" : {
[2025-07-19T18:30:22.115+0000] {subprocess.py:93} INFO -         "0" : 69
[2025-07-19T18:30:22.116+0000] {subprocess.py:93} INFO -       }
[2025-07-19T18:30:22.116+0000] {subprocess.py:93} INFO -     },
[2025-07-19T18:30:22.117+0000] {subprocess.py:93} INFO -     "numInputRows" : 69,
[2025-07-19T18:30:22.117+0000] {subprocess.py:93} INFO -     "inputRowsPerSecond" : 0.0,
[2025-07-19T18:30:22.119+0000] {subprocess.py:93} INFO -     "processedRowsPerSecond" : 6.082510578279267,
[2025-07-19T18:30:22.119+0000] {subprocess.py:93} INFO -     "metrics" : {
[2025-07-19T18:30:22.120+0000] {subprocess.py:93} INFO -       "avgOffsetsBehindLatest" : "0.0",
[2025-07-19T18:30:22.123+0000] {subprocess.py:93} INFO -       "maxOffsetsBehindLatest" : "0",
[2025-07-19T18:30:22.127+0000] {subprocess.py:93} INFO -       "minOffsetsBehindLatest" : "0"
[2025-07-19T18:30:22.127+0000] {subprocess.py:93} INFO -     }
[2025-07-19T18:30:22.128+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T18:30:22.128+0000] {subprocess.py:93} INFO -   "sink" : {
[2025-07-19T18:30:22.128+0000] {subprocess.py:93} INFO -     "description" : "my_catalog.bronze.Reservations_raw",
[2025-07-19T18:30:22.129+0000] {subprocess.py:93} INFO -     "numOutputRows" : 68
[2025-07-19T18:30:22.130+0000] {subprocess.py:93} INFO -   }
[2025-07-19T18:30:22.131+0000] {subprocess.py:93} INFO - }
[2025-07-19T18:30:22.132+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7309b141
[2025-07-19T18:30:22.134+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/38/.2.delta.6f33208e-a1c1-4958-b140-ba8d48da5aa7.TID641.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/38/2.delta
[2025-07-19T18:30:22.134+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=38),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/38] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/38/2.delta
[2025-07-19T18:30:22.135+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.135+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.135+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 38 (task 641, attempt 0, stage 7.0)
[2025-07-19T18:30:22.136+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=42, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.136+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=42),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/42] for update
[2025-07-19T18:30:22.136+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.138+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 37 (task 640, attempt 0, stage 7.0)
[2025-07-19T18:30:22.138+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 38 (task 641, attempt 0, stage 7.0)
[2025-07-19T18:30:22.138+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f57f23b
[2025-07-19T18:30:22.138+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/41/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/41/.2.delta.f4fd1c28-9732-4ddc-bd01-b1b369684070.TID644.tmp
[2025-07-19T18:30:22.138+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 37.0 in stage 7.0 (TID 640). 5829 bytes result sent to driver
[2025-07-19T18:30:22.139+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=43, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.140+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=43),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/43] for update
[2025-07-19T18:30:22.142+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 38.0 in stage 7.0 (TID 641). 5829 bytes result sent to driver
[2025-07-19T18:30:22.143+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.143+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 44.0 in stage 7.0 (TID 647) (8b44f3d35cfa, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.144+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 45.0 in stage 7.0 (TID 648) (8b44f3d35cfa, executor driver, partition 45, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.144+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 45.0 in stage 7.0 (TID 648)
[2025-07-19T18:30:22.144+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 44.0 in stage 7.0 (TID 647)
[2025-07-19T18:30:22.144+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/36/.2.delta.9ad0fbe6-4cd3-4ead-a5cf-ae12e49651ce.TID639.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/36/2.delta
[2025-07-19T18:30:22.144+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=36),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/36] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/36/2.delta
[2025-07-19T18:30:22.144+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 38.0 in stage 7.0 (TID 641) in 62 ms on 8b44f3d35cfa (executor driver) (37/200)
[2025-07-19T18:30:22.144+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.144+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.144+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.144+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.145+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 36 (task 639, attempt 0, stage 7.0)
[2025-07-19T18:30:22.145+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 37.0 in stage 7.0 (TID 640) in 75 ms on 8b44f3d35cfa (executor driver) (38/200)
[2025-07-19T18:30:22.145+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6b18ccdf
[2025-07-19T18:30:22.145+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=44, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.145+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=44),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/44] for update
[2025-07-19T18:30:22.145+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7de32b54
[2025-07-19T18:30:22.145+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.145+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=45, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.145+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=45),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/45] for update
[2025-07-19T18:30:22.146+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/42/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/42/.2.delta.d379d86d-161f-41b4-bd7d-3072d82c76ab.TID645.tmp
[2025-07-19T18:30:22.147+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.149+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 36 (task 639, attempt 0, stage 7.0)
[2025-07-19T18:30:22.150+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 36.0 in stage 7.0 (TID 639). 5829 bytes result sent to driver
[2025-07-19T18:30:22.151+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 46.0 in stage 7.0 (TID 649) (8b44f3d35cfa, executor driver, partition 46, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.154+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 46.0 in stage 7.0 (TID 649)
[2025-07-19T18:30:22.155+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 36.0 in stage 7.0 (TID 639) in 93 ms on 8b44f3d35cfa (executor driver) (39/200)
[2025-07-19T18:30:22.156+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.156+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/44/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/44/.2.delta.5e04be50-29e2-40af-92be-c5b1798d26f2.TID647.tmp
[2025-07-19T18:30:22.156+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.158+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@46db9e1b
[2025-07-19T18:30:22.159+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=46, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.159+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=46),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/46] for update
[2025-07-19T18:30:22.159+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/43/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/43/.2.delta.7885b447-ef97-4b59-be22-b15ef071cba8.TID646.tmp
[2025-07-19T18:30:22.160+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.161+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/45/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/45/.2.delta.4da16144-5e8e-4a24-84ec-9912c40208e4.TID648.tmp
[2025-07-19T18:30:22.162+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/40/.2.delta.48d74551-9528-4496-beee-1a3689534f45.TID643.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/40/2.delta
[2025-07-19T18:30:22.162+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=40),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/40] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/40/2.delta
[2025-07-19T18:30:22.163+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 40 (task 643, attempt 0, stage 7.0)
[2025-07-19T18:30:22.163+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/46/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/46/.2.delta.4618f5df-d7bb-4079-970b-4322cac15e68.TID649.tmp
[2025-07-19T18:30:22.163+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/39/.2.delta.bd55c11e-2c26-4259-82fb-b2869987a58b.TID642.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/39/2.delta
[2025-07-19T18:30:22.164+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=39),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/39] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/39/2.delta
[2025-07-19T18:30:22.164+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 40 (task 643, attempt 0, stage 7.0)
[2025-07-19T18:30:22.164+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 39 (task 642, attempt 0, stage 7.0)
[2025-07-19T18:30:22.165+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/41/.2.delta.f4fd1c28-9732-4ddc-bd01-b1b369684070.TID644.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/41/2.delta
[2025-07-19T18:30:22.165+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=41),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/41] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/41/2.delta
[2025-07-19T18:30:22.165+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 41 (task 644, attempt 0, stage 7.0)
[2025-07-19T18:30:22.165+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 40.0 in stage 7.0 (TID 643). 5829 bytes result sent to driver
[2025-07-19T18:30:22.165+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 47.0 in stage 7.0 (TID 650) (8b44f3d35cfa, executor driver, partition 47, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.165+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 47.0 in stage 7.0 (TID 650)
[2025-07-19T18:30:22.165+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 40.0 in stage 7.0 (TID 643) in 91 ms on 8b44f3d35cfa (executor driver) (40/200)
[2025-07-19T18:30:22.166+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 41 (task 644, attempt 0, stage 7.0)
[2025-07-19T18:30:22.166+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 41.0 in stage 7.0 (TID 644). 5829 bytes result sent to driver
[2025-07-19T18:30:22.166+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 39 (task 642, attempt 0, stage 7.0)
[2025-07-19T18:30:22.166+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 39.0 in stage 7.0 (TID 642). 5829 bytes result sent to driver
[2025-07-19T18:30:22.166+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.166+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.166+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d132874
[2025-07-19T18:30:22.167+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 48.0 in stage 7.0 (TID 651) (8b44f3d35cfa, executor driver, partition 48, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.167+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=47, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.167+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=47),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/47] for update
[2025-07-19T18:30:22.168+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 39.0 in stage 7.0 (TID 642) in 107 ms on 8b44f3d35cfa (executor driver) (41/200)
[2025-07-19T18:30:22.168+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 41.0 in stage 7.0 (TID 644) in 73 ms on 8b44f3d35cfa (executor driver) (42/200)
[2025-07-19T18:30:22.169+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 49.0 in stage 7.0 (TID 652) (8b44f3d35cfa, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.169+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 49.0 in stage 7.0 (TID 652)
[2025-07-19T18:30:22.170+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 48.0 in stage 7.0 (TID 651)
[2025-07-19T18:30:22.170+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.170+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.173+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.173+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.176+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T18:30:22.176+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c861742
[2025-07-19T18:30:22.177+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=48, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.178+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=48),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/48] for update
[2025-07-19T18:30:22.178+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f7ee32b
[2025-07-19T18:30:22.181+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.182+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=49, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.183+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=49),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/49] for update
[2025-07-19T18:30:22.183+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.183+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/47/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/47/.2.delta.7dae5800-f1cb-4333-bd25-524e046c25b3.TID650.tmp
[2025-07-19T18:30:22.184+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/42/.2.delta.d379d86d-161f-41b4-bd7d-3072d82c76ab.TID645.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/42/2.delta
[2025-07-19T18:30:22.186+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=42),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/42] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/42/2.delta
[2025-07-19T18:30:22.186+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 42 (task 645, attempt 0, stage 7.0)
[2025-07-19T18:30:22.186+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/43/.2.delta.7885b447-ef97-4b59-be22-b15ef071cba8.TID646.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/43/2.delta
[2025-07-19T18:30:22.186+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=43),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/43] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/43/2.delta
[2025-07-19T18:30:22.187+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 43 (task 646, attempt 0, stage 7.0)
[2025-07-19T18:30:22.187+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/45/.2.delta.4da16144-5e8e-4a24-84ec-9912c40208e4.TID648.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/45/2.delta
[2025-07-19T18:30:22.187+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=45),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/45] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/45/2.delta
[2025-07-19T18:30:22.188+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 45 (task 648, attempt 0, stage 7.0)
[2025-07-19T18:30:22.188+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/44/.2.delta.5e04be50-29e2-40af-92be-c5b1798d26f2.TID647.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/44/2.delta
[2025-07-19T18:30:22.188+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=44),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/44] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/44/2.delta
[2025-07-19T18:30:22.189+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 44 (task 647, attempt 0, stage 7.0)
[2025-07-19T18:30:22.190+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 43 (task 646, attempt 0, stage 7.0)
[2025-07-19T18:30:22.191+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 43.0 in stage 7.0 (TID 646). 5829 bytes result sent to driver
[2025-07-19T18:30:22.191+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 50.0 in stage 7.0 (TID 653) (8b44f3d35cfa, executor driver, partition 50, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.192+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 43.0 in stage 7.0 (TID 646) in 77 ms on 8b44f3d35cfa (executor driver) (43/200)
[2025-07-19T18:30:22.193+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 42 (task 645, attempt 0, stage 7.0)
[2025-07-19T18:30:22.193+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 45 (task 648, attempt 0, stage 7.0)
[2025-07-19T18:30:22.193+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 42.0 in stage 7.0 (TID 645). 5829 bytes result sent to driver
[2025-07-19T18:30:22.193+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 51.0 in stage 7.0 (TID 654) (8b44f3d35cfa, executor driver, partition 51, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.194+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 50.0 in stage 7.0 (TID 653)
[2025-07-19T18:30:22.194+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 45.0 in stage 7.0 (TID 648). 5829 bytes result sent to driver
[2025-07-19T18:30:22.194+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 52.0 in stage 7.0 (TID 655) (8b44f3d35cfa, executor driver, partition 52, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.195+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 52.0 in stage 7.0 (TID 655)
[2025-07-19T18:30:22.196+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/49/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/49/.2.delta.8ff98b5b-912b-4769-894a-ce6ce1e3f132.TID652.tmp
[2025-07-19T18:30:22.196+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 51.0 in stage 7.0 (TID 654)
[2025-07-19T18:30:22.197+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 42.0 in stage 7.0 (TID 645) in 88 ms on 8b44f3d35cfa (executor driver) (44/200)
[2025-07-19T18:30:22.198+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/48/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/48/.2.delta.62c30a32-0dc4-44ca-92a7-88c132369f77.TID651.tmp
[2025-07-19T18:30:22.199+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 44 (task 647, attempt 0, stage 7.0)
[2025-07-19T18:30:22.199+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 45.0 in stage 7.0 (TID 648) in 69 ms on 8b44f3d35cfa (executor driver) (45/200)
[2025-07-19T18:30:22.199+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.199+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 44.0 in stage 7.0 (TID 647). 5829 bytes result sent to driver
[2025-07-19T18:30:22.199+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.199+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:22.199+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:22.200+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 53.0 in stage 7.0 (TID 656) (8b44f3d35cfa, executor driver, partition 53, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.200+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 53.0 in stage 7.0 (TID 656)
[2025-07-19T18:30:22.200+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 44.0 in stage 7.0 (TID 647) in 72 ms on 8b44f3d35cfa (executor driver) (46/200)
[2025-07-19T18:30:22.200+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.200+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.201+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@102f9f25
[2025-07-19T18:30:22.201+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.201+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.201+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=50, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.201+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=50),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/50] for update
[2025-07-19T18:30:22.201+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@284f7cec
[2025-07-19T18:30:22.201+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/46/.2.delta.4618f5df-d7bb-4079-970b-4322cac15e68.TID649.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/46/2.delta
[2025-07-19T18:30:22.202+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=46),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/46] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/46/2.delta
[2025-07-19T18:30:22.202+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 46 (task 649, attempt 0, stage 7.0)
[2025-07-19T18:30:22.202+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=53, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.202+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=53),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/53] for update
[2025-07-19T18:30:22.204+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.205+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.206+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@8e64441
[2025-07-19T18:30:22.206+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=51, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.207+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=51),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/51] for update
[2025-07-19T18:30:22.207+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 46 (task 649, attempt 0, stage 7.0)
[2025-07-19T18:30:22.209+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 46.0 in stage 7.0 (TID 649). 5829 bytes result sent to driver
[2025-07-19T18:30:22.210+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@66d5054b
[2025-07-19T18:30:22.211+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=52, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.212+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 54.0 in stage 7.0 (TID 657) (8b44f3d35cfa, executor driver, partition 54, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.213+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=52),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/52] for update
[2025-07-19T18:30:22.214+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 54.0 in stage 7.0 (TID 657)
[2025-07-19T18:30:22.214+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 46.0 in stage 7.0 (TID 649) in 73 ms on 8b44f3d35cfa (executor driver) (47/200)
[2025-07-19T18:30:22.214+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.214+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.215+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/50/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/50/.2.delta.76fa1079-1b06-45e6-8e5f-0a948dc54413.TID653.tmp
[2025-07-19T18:30:22.215+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.217+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.218+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4713ebee
[2025-07-19T18:30:22.218+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=54, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.218+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=54),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/54] for update
[2025-07-19T18:30:22.218+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.218+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/53/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/53/.2.delta.01572f22-78d0-4df0-bee0-2094440c8923.TID656.tmp
[2025-07-19T18:30:22.219+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/52/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/52/.2.delta.a61aa842-af5a-4a3e-a1b4-296348bce64d.TID655.tmp
[2025-07-19T18:30:22.219+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/51/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/51/.2.delta.5329c1ce-ba42-4b79-b3a9-7b597cc4260e.TID654.tmp
[2025-07-19T18:30:22.219+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/49/.2.delta.8ff98b5b-912b-4769-894a-ce6ce1e3f132.TID652.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/49/2.delta
[2025-07-19T18:30:22.219+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=49),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/49] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/49/2.delta
[2025-07-19T18:30:22.219+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 49 (task 652, attempt 0, stage 7.0)
[2025-07-19T18:30:22.219+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/47/.2.delta.7dae5800-f1cb-4333-bd25-524e046c25b3.TID650.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/47/2.delta
[2025-07-19T18:30:22.220+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=47),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/47] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/47/2.delta
[2025-07-19T18:30:22.220+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/48/.2.delta.62c30a32-0dc4-44ca-92a7-88c132369f77.TID651.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/48/2.delta
[2025-07-19T18:30:22.221+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=48),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/48] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/48/2.delta
[2025-07-19T18:30:22.223+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 47 (task 650, attempt 0, stage 7.0)
[2025-07-19T18:30:22.224+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 48 (task 651, attempt 0, stage 7.0)
[2025-07-19T18:30:22.224+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/54/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/54/.2.delta.c6ce030e-f940-4a79-af49-b7a4c7f32dff.TID657.tmp
[2025-07-19T18:30:22.224+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 47 (task 650, attempt 0, stage 7.0)
[2025-07-19T18:30:22.224+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 47.0 in stage 7.0 (TID 650). 5829 bytes result sent to driver
[2025-07-19T18:30:22.224+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 49 (task 652, attempt 0, stage 7.0)
[2025-07-19T18:30:22.225+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 49.0 in stage 7.0 (TID 652). 5829 bytes result sent to driver
[2025-07-19T18:30:22.225+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 55.0 in stage 7.0 (TID 658) (8b44f3d35cfa, executor driver, partition 55, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.226+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 48 (task 651, attempt 0, stage 7.0)
[2025-07-19T18:30:22.226+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 55.0 in stage 7.0 (TID 658)
[2025-07-19T18:30:22.227+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 48.0 in stage 7.0 (TID 651). 5829 bytes result sent to driver
[2025-07-19T18:30:22.228+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 56.0 in stage 7.0 (TID 659) (8b44f3d35cfa, executor driver, partition 56, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.229+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 47.0 in stage 7.0 (TID 650) in 90 ms on 8b44f3d35cfa (executor driver) (48/200)
[2025-07-19T18:30:22.229+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 49.0 in stage 7.0 (TID 652) in 81 ms on 8b44f3d35cfa (executor driver) (49/200)
[2025-07-19T18:30:22.229+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 56.0 in stage 7.0 (TID 659)
[2025-07-19T18:30:22.229+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 57.0 in stage 7.0 (TID 660) (8b44f3d35cfa, executor driver, partition 57, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.229+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 48.0 in stage 7.0 (TID 651) in 83 ms on 8b44f3d35cfa (executor driver) (50/200)
[2025-07-19T18:30:22.229+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 57.0 in stage 7.0 (TID 660)
[2025-07-19T18:30:22.229+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.230+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.230+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2efa009
[2025-07-19T18:30:22.231+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=55, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.231+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=55),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/55] for update
[2025-07-19T18:30:22.231+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.232+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.232+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.232+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.232+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@cc3d3dd
[2025-07-19T18:30:22.232+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.232+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=56, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.232+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=56),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/56] for update
[2025-07-19T18:30:22.233+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58c9528
[2025-07-19T18:30:22.233+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.233+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=57, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.234+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=57),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/57] for update
[2025-07-19T18:30:22.235+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.235+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/55/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/55/.2.delta.8b406572-2a8f-4014-83bc-c1ba9a0b6115.TID658.tmp
[2025-07-19T18:30:22.235+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/51/.2.delta.5329c1ce-ba42-4b79-b3a9-7b597cc4260e.TID654.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/51/2.delta
[2025-07-19T18:30:22.237+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=51),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/51] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/51/2.delta
[2025-07-19T18:30:22.237+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 51 (task 654, attempt 0, stage 7.0)
[2025-07-19T18:30:22.238+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/50/.2.delta.76fa1079-1b06-45e6-8e5f-0a948dc54413.TID653.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/50/2.delta
[2025-07-19T18:30:22.238+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=50),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/50] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/50/2.delta
[2025-07-19T18:30:22.238+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/53/.2.delta.01572f22-78d0-4df0-bee0-2094440c8923.TID656.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/53/2.delta
[2025-07-19T18:30:22.239+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=53),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/53] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/53/2.delta
[2025-07-19T18:30:22.239+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 53 (task 656, attempt 0, stage 7.0)
[2025-07-19T18:30:22.239+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 50 (task 653, attempt 0, stage 7.0)
[2025-07-19T18:30:22.240+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/56/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/56/.2.delta.9bab9af9-d623-41c5-a192-d3d7c9f81dad.TID659.tmp
[2025-07-19T18:30:22.241+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 53 (task 656, attempt 0, stage 7.0)
[2025-07-19T18:30:22.241+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 51 (task 654, attempt 0, stage 7.0)
[2025-07-19T18:30:22.242+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 50 (task 653, attempt 0, stage 7.0)
[2025-07-19T18:30:22.242+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/52/.2.delta.a61aa842-af5a-4a3e-a1b4-296348bce64d.TID655.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/52/2.delta
[2025-07-19T18:30:22.246+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=52),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/52] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/52/2.delta
[2025-07-19T18:30:22.247+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 52 (task 655, attempt 0, stage 7.0)
[2025-07-19T18:30:22.248+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 51.0 in stage 7.0 (TID 654). 5872 bytes result sent to driver
[2025-07-19T18:30:22.248+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/54/.2.delta.c6ce030e-f940-4a79-af49-b7a4c7f32dff.TID657.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/54/2.delta
[2025-07-19T18:30:22.249+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=54),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/54] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/54/2.delta
[2025-07-19T18:30:22.249+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 54 (task 657, attempt 0, stage 7.0)
[2025-07-19T18:30:22.249+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 52 (task 655, attempt 0, stage 7.0)
[2025-07-19T18:30:22.250+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 50.0 in stage 7.0 (TID 653). 5872 bytes result sent to driver
[2025-07-19T18:30:22.250+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 52.0 in stage 7.0 (TID 655). 5872 bytes result sent to driver
[2025-07-19T18:30:22.251+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/57/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/57/.2.delta.964f8524-a5c3-42ed-be5e-d584a5674545.TID660.tmp
[2025-07-19T18:30:22.251+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 58.0 in stage 7.0 (TID 661) (8b44f3d35cfa, executor driver, partition 58, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.251+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 59.0 in stage 7.0 (TID 662) (8b44f3d35cfa, executor driver, partition 59, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.251+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 60.0 in stage 7.0 (TID 663) (8b44f3d35cfa, executor driver, partition 60, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.252+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 53.0 in stage 7.0 (TID 656). 5872 bytes result sent to driver
[2025-07-19T18:30:22.252+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 59.0 in stage 7.0 (TID 662)
[2025-07-19T18:30:22.252+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 61.0 in stage 7.0 (TID 664) (8b44f3d35cfa, executor driver, partition 61, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.253+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 54 (task 657, attempt 0, stage 7.0)
[2025-07-19T18:30:22.253+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 58.0 in stage 7.0 (TID 661)
[2025-07-19T18:30:22.253+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 54.0 in stage 7.0 (TID 657). 5872 bytes result sent to driver
[2025-07-19T18:30:22.255+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.256+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.256+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 50.0 in stage 7.0 (TID 653) in 94 ms on 8b44f3d35cfa (executor driver) (51/200)
[2025-07-19T18:30:22.256+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 52.0 in stage 7.0 (TID 655) in 92 ms on 8b44f3d35cfa (executor driver) (52/200)
[2025-07-19T18:30:22.256+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 51.0 in stage 7.0 (TID 654) in 92 ms on 8b44f3d35cfa (executor driver) (53/200)
[2025-07-19T18:30:22.257+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 53.0 in stage 7.0 (TID 656) in 87 ms on 8b44f3d35cfa (executor driver) (54/200)
[2025-07-19T18:30:22.257+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 62.0 in stage 7.0 (TID 665) (8b44f3d35cfa, executor driver, partition 62, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.257+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 61.0 in stage 7.0 (TID 664)
[2025-07-19T18:30:22.257+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.258+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.258+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@76ced848
[2025-07-19T18:30:22.259+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 54.0 in stage 7.0 (TID 657) in 80 ms on 8b44f3d35cfa (executor driver) (55/200)
[2025-07-19T18:30:22.259+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 62.0 in stage 7.0 (TID 665)
[2025-07-19T18:30:22.260+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.260+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.260+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 60.0 in stage 7.0 (TID 663)
[2025-07-19T18:30:22.261+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=59, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.262+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=59),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/59] for update
[2025-07-19T18:30:22.262+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.262+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.263+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.264+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.264+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7dc59f44
[2025-07-19T18:30:22.264+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=61, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.265+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=61),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/61] for update
[2025-07-19T18:30:22.265+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.265+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.265+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@716784ff
[2025-07-19T18:30:22.265+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=58, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.265+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=58),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/58] for update
[2025-07-19T18:30:22.265+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53e7268b
[2025-07-19T18:30:22.265+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.266+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/55/.2.delta.8b406572-2a8f-4014-83bc-c1ba9a0b6115.TID658.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/55/2.delta
[2025-07-19T18:30:22.267+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=55),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/55] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/55/2.delta
[2025-07-19T18:30:22.268+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=62, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.270+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=62),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/62] for update
[2025-07-19T18:30:22.273+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.275+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/61/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/61/.2.delta.0921da2d-9743-43a6-8bfd-843c57c52d73.TID664.tmp
[2025-07-19T18:30:22.276+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 55 (task 658, attempt 0, stage 7.0)
[2025-07-19T18:30:22.278+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/59/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/59/.2.delta.fe15474c-7ef0-413f-be3f-88dff323d5c4.TID662.tmp
[2025-07-19T18:30:22.278+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@45fd6b80
[2025-07-19T18:30:22.279+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=60, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.279+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=60),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/60] for update
[2025-07-19T18:30:22.280+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 55 (task 658, attempt 0, stage 7.0)
[2025-07-19T18:30:22.280+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 55.0 in stage 7.0 (TID 658). 5872 bytes result sent to driver
[2025-07-19T18:30:22.281+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/56/.2.delta.9bab9af9-d623-41c5-a192-d3d7c9f81dad.TID659.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/56/2.delta
[2025-07-19T18:30:22.282+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=56),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/56] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/56/2.delta
[2025-07-19T18:30:22.282+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 63.0 in stage 7.0 (TID 666) (8b44f3d35cfa, executor driver, partition 63, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.282+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 63.0 in stage 7.0 (TID 666)
[2025-07-19T18:30:22.283+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.283+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 55.0 in stage 7.0 (TID 658) in 57 ms on 8b44f3d35cfa (executor driver) (56/200)
[2025-07-19T18:30:22.283+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 56 (task 659, attempt 0, stage 7.0)
[2025-07-19T18:30:22.285+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.285+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.286+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28a3ab7d
[2025-07-19T18:30:22.288+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=63, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.289+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=63),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/63] for update
[2025-07-19T18:30:22.289+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 56 (task 659, attempt 0, stage 7.0)
[2025-07-19T18:30:22.290+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 56.0 in stage 7.0 (TID 659). 5872 bytes result sent to driver
[2025-07-19T18:30:22.291+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 64.0 in stage 7.0 (TID 667) (8b44f3d35cfa, executor driver, partition 64, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.291+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 64.0 in stage 7.0 (TID 667)
[2025-07-19T18:30:22.292+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 56.0 in stage 7.0 (TID 659) in 60 ms on 8b44f3d35cfa (executor driver) (57/200)
[2025-07-19T18:30:22.293+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.294+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/60/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/60/.2.delta.7ef08586-bf94-4e4b-8905-9fe32bfaf29e.TID663.tmp
[2025-07-19T18:30:22.294+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.295+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.295+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@507d4fa
[2025-07-19T18:30:22.296+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=64, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.297+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=64),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/64] for update
[2025-07-19T18:30:22.297+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/58/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/58/.2.delta.616c317c-340e-4f1f-9100-c6f09a676ecc.TID661.tmp
[2025-07-19T18:30:22.298+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/57/.2.delta.964f8524-a5c3-42ed-be5e-d584a5674545.TID660.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/57/2.delta
[2025-07-19T18:30:22.298+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=57),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/57] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/57/2.delta
[2025-07-19T18:30:22.298+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.299+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 57 (task 660, attempt 0, stage 7.0)
[2025-07-19T18:30:22.299+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/62/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/62/.2.delta.69da3f57-e67b-4e73-a3f7-7908982bc746.TID665.tmp
[2025-07-19T18:30:22.300+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/63/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/63/.2.delta.91e7e8cc-a13d-4671-80b5-ac97acda76e3.TID666.tmp
[2025-07-19T18:30:22.300+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 57 (task 660, attempt 0, stage 7.0)
[2025-07-19T18:30:22.302+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 57.0 in stage 7.0 (TID 660). 5829 bytes result sent to driver
[2025-07-19T18:30:22.302+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 57.0 in stage 7.0 (TID 660) in 73 ms on 8b44f3d35cfa (executor driver) (58/200)
[2025-07-19T18:30:22.302+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 65.0 in stage 7.0 (TID 668) (8b44f3d35cfa, executor driver, partition 65, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.303+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 65.0 in stage 7.0 (TID 668)
[2025-07-19T18:30:22.303+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.303+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.303+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ebccfb6
[2025-07-19T18:30:22.303+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=65, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.303+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=65),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/65] for update
[2025-07-19T18:30:22.303+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.303+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/64/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/64/.2.delta.5fa56c85-8f10-46bc-a7c2-c5bc26f5389e.TID667.tmp
[2025-07-19T18:30:22.303+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/59/.2.delta.fe15474c-7ef0-413f-be3f-88dff323d5c4.TID662.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/59/2.delta
[2025-07-19T18:30:22.304+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=59),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/59] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/59/2.delta
[2025-07-19T18:30:22.304+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 59 (task 662, attempt 0, stage 7.0)
[2025-07-19T18:30:22.304+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/61/.2.delta.0921da2d-9743-43a6-8bfd-843c57c52d73.TID664.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/61/2.delta
[2025-07-19T18:30:22.304+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=61),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/61] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/61/2.delta
[2025-07-19T18:30:22.304+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 61 (task 664, attempt 0, stage 7.0)
[2025-07-19T18:30:22.305+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 59 (task 662, attempt 0, stage 7.0)
[2025-07-19T18:30:22.305+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 59.0 in stage 7.0 (TID 662). 5872 bytes result sent to driver
[2025-07-19T18:30:22.305+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 66.0 in stage 7.0 (TID 669) (8b44f3d35cfa, executor driver, partition 66, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.306+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/65/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/65/.2.delta.9dc36245-9027-4b93-99ee-615415610375.TID668.tmp
[2025-07-19T18:30:22.306+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 66.0 in stage 7.0 (TID 669)
[2025-07-19T18:30:22.307+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 59.0 in stage 7.0 (TID 662) in 61 ms on 8b44f3d35cfa (executor driver) (59/200)
[2025-07-19T18:30:22.307+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.307+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.307+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@292ab438
[2025-07-19T18:30:22.307+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=66, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.307+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=66),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/66] for update
[2025-07-19T18:30:22.307+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.307+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 61 (task 664, attempt 0, stage 7.0)
[2025-07-19T18:30:22.307+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 61.0 in stage 7.0 (TID 664). 5872 bytes result sent to driver
[2025-07-19T18:30:22.308+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/60/.2.delta.7ef08586-bf94-4e4b-8905-9fe32bfaf29e.TID663.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/60/2.delta
[2025-07-19T18:30:22.308+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=60),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/60] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/60/2.delta
[2025-07-19T18:30:22.308+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 67.0 in stage 7.0 (TID 670) (8b44f3d35cfa, executor driver, partition 67, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.308+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/66/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/66/.2.delta.349bd32c-6089-4354-8c51-2cef4c065b2f.TID669.tmp
[2025-07-19T18:30:22.308+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 60 (task 663, attempt 0, stage 7.0)
[2025-07-19T18:30:22.308+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 61.0 in stage 7.0 (TID 664) in 72 ms on 8b44f3d35cfa (executor driver) (60/200)
[2025-07-19T18:30:22.308+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 67.0 in stage 7.0 (TID 670)
[2025-07-19T18:30:22.309+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/62/.2.delta.69da3f57-e67b-4e73-a3f7-7908982bc746.TID665.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/62/2.delta
[2025-07-19T18:30:22.309+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=62),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/62] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/62/2.delta
[2025-07-19T18:30:22.309+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 62 (task 665, attempt 0, stage 7.0)
[2025-07-19T18:30:22.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/58/.2.delta.616c317c-340e-4f1f-9100-c6f09a676ecc.TID661.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/58/2.delta
[2025-07-19T18:30:22.311+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=58),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/58] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/58/2.delta
[2025-07-19T18:30:22.311+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/63/.2.delta.91e7e8cc-a13d-4671-80b5-ac97acda76e3.TID666.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/63/2.delta
[2025-07-19T18:30:22.311+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=63),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/63] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/63/2.delta
[2025-07-19T18:30:22.312+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 60 (task 663, attempt 0, stage 7.0)
[2025-07-19T18:30:22.312+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 62 (task 665, attempt 0, stage 7.0)
[2025-07-19T18:30:22.312+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 58 (task 661, attempt 0, stage 7.0)
[2025-07-19T18:30:22.313+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 60.0 in stage 7.0 (TID 663). 5872 bytes result sent to driver
[2025-07-19T18:30:22.313+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 63 (task 666, attempt 0, stage 7.0)
[2025-07-19T18:30:22.314+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 68.0 in stage 7.0 (TID 671) (8b44f3d35cfa, executor driver, partition 68, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.314+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2025-07-19T18:30:22.314+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 68.0 in stage 7.0 (TID 671)
[2025-07-19T18:30:22.314+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 58 (task 661, attempt 0, stage 7.0)
[2025-07-19T18:30:22.315+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 58.0 in stage 7.0 (TID 661). 5872 bytes result sent to driver
[2025-07-19T18:30:22.315+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 69.0 in stage 7.0 (TID 672) (8b44f3d35cfa, executor driver, partition 69, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.315+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 62.0 in stage 7.0 (TID 665). 5872 bytes result sent to driver
[2025-07-19T18:30:22.316+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 58.0 in stage 7.0 (TID 661) in 86 ms on 8b44f3d35cfa (executor driver) (61/200)
[2025-07-19T18:30:22.316+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.316+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.316+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/65/.2.delta.9dc36245-9027-4b93-99ee-615415610375.TID668.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/65/2.delta
[2025-07-19T18:30:22.317+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=65),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/65] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/65/2.delta
[2025-07-19T18:30:22.317+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@150d9aad
[2025-07-19T18:30:22.317+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 60.0 in stage 7.0 (TID 663) in 87 ms on 8b44f3d35cfa (executor driver) (62/200)
[2025-07-19T18:30:22.317+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=67, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.317+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=67),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/67] for update
[2025-07-19T18:30:22.317+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 69.0 in stage 7.0 (TID 672)
[2025-07-19T18:30:22.317+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 62.0 in stage 7.0 (TID 665) in 83 ms on 8b44f3d35cfa (executor driver) (63/200)
[2025-07-19T18:30:22.317+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 70.0 in stage 7.0 (TID 673) (8b44f3d35cfa, executor driver, partition 70, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.317+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 70.0 in stage 7.0 (TID 673)
[2025-07-19T18:30:22.318+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 65 (task 668, attempt 0, stage 7.0)
[2025-07-19T18:30:22.318+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.318+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/64/.2.delta.5fa56c85-8f10-46bc-a7c2-c5bc26f5389e.TID667.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/64/2.delta
[2025-07-19T18:30:22.319+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=64),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/64] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/64/2.delta
[2025-07-19T18:30:22.319+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.320+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.320+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 64 (task 667, attempt 0, stage 7.0)
[2025-07-19T18:30:22.321+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.321+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.321+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@26ccce9
[2025-07-19T18:30:22.322+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=70, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.322+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=70),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/70] for update
[2025-07-19T18:30:22.323+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 65 (task 668, attempt 0, stage 7.0)
[2025-07-19T18:30:22.324+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7e301aec
[2025-07-19T18:30:22.324+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 63 (task 666, attempt 0, stage 7.0)
[2025-07-19T18:30:22.325+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 64 (task 667, attempt 0, stage 7.0)
[2025-07-19T18:30:22.325+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=68, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.326+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=68),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/68] for update
[2025-07-19T18:30:22.326+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 65.0 in stage 7.0 (TID 668). 5829 bytes result sent to driver
[2025-07-19T18:30:22.327+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 63.0 in stage 7.0 (TID 666). 5872 bytes result sent to driver
[2025-07-19T18:30:22.327+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 64.0 in stage 7.0 (TID 667). 5872 bytes result sent to driver
[2025-07-19T18:30:22.327+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 71.0 in stage 7.0 (TID 674) (8b44f3d35cfa, executor driver, partition 71, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.328+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 72.0 in stage 7.0 (TID 675) (8b44f3d35cfa, executor driver, partition 72, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.328+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 73.0 in stage 7.0 (TID 676) (8b44f3d35cfa, executor driver, partition 73, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.328+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 65.0 in stage 7.0 (TID 668) in 47 ms on 8b44f3d35cfa (executor driver) (64/200)
[2025-07-19T18:30:22.329+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 63.0 in stage 7.0 (TID 666) in 70 ms on 8b44f3d35cfa (executor driver) (65/200)
[2025-07-19T18:30:22.329+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 64.0 in stage 7.0 (TID 667) in 66 ms on 8b44f3d35cfa (executor driver) (66/200)
[2025-07-19T18:30:22.329+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 72.0 in stage 7.0 (TID 675)
[2025-07-19T18:30:22.329+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 73.0 in stage 7.0 (TID 676)
[2025-07-19T18:30:22.329+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.329+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.330+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 71.0 in stage 7.0 (TID 674)
[2025-07-19T18:30:22.330+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.330+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.330+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.331+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.331+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.331+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@78b0e4dc
[2025-07-19T18:30:22.331+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.331+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/67/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/67/.2.delta.8c5bd7bc-f4e5-42ad-b158-3c52b2becc08.TID670.tmp
[2025-07-19T18:30:22.331+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=69, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.332+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=69),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/69] for update
[2025-07-19T18:30:22.332+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.332+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@650c1c40
[2025-07-19T18:30:22.333+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=72, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.334+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=72),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/72] for update
[2025-07-19T18:30:22.335+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1bdbb06e
[2025-07-19T18:30:22.335+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=73, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.335+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=73),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/73] for update
[2025-07-19T18:30:22.335+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.335+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@93f3b86
[2025-07-19T18:30:22.336+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=71, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.336+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=71),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/71] for update
[2025-07-19T18:30:22.336+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/66/.2.delta.349bd32c-6089-4354-8c51-2cef4c065b2f.TID669.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/66/2.delta
[2025-07-19T18:30:22.336+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=66),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/66] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/66/2.delta
[2025-07-19T18:30:22.336+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 66 (task 669, attempt 0, stage 7.0)
[2025-07-19T18:30:22.337+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.337+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/70/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/70/.2.delta.17a3ec0e-4348-42a3-b3e1-89db5ae81fdc.TID673.tmp
[2025-07-19T18:30:22.337+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/68/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/68/.2.delta.8f790ce3-e927-4124-89ca-9815f074b7ca.TID671.tmp
[2025-07-19T18:30:22.337+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.337+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 66 (task 669, attempt 0, stage 7.0)
[2025-07-19T18:30:22.337+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 66.0 in stage 7.0 (TID 669). 5829 bytes result sent to driver
[2025-07-19T18:30:22.337+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 74.0 in stage 7.0 (TID 677) (8b44f3d35cfa, executor driver, partition 74, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.338+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 74.0 in stage 7.0 (TID 677)
[2025-07-19T18:30:22.338+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/69/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/69/.2.delta.797afa27-edb3-48be-986d-948c165fde7f.TID672.tmp
[2025-07-19T18:30:22.338+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.338+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.338+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 66.0 in stage 7.0 (TID 669) in 52 ms on 8b44f3d35cfa (executor driver) (67/200)
[2025-07-19T18:30:22.338+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2cfbd747
[2025-07-19T18:30:22.338+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=74, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.339+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=74),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/74] for update
[2025-07-19T18:30:22.339+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.340+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/71/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/71/.2.delta.f2f749d9-fcea-4eb5-83aa-63fb75d2b53b.TID674.tmp
[2025-07-19T18:30:22.341+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/72/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/72/.2.delta.3db45a57-7b09-4649-b3c0-b25355de0e4b.TID675.tmp
[2025-07-19T18:30:22.342+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/73/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/73/.2.delta.af3fee64-804b-47c9-8a7f-da5faf15d40a.TID676.tmp
[2025-07-19T18:30:22.342+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/74/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/74/.2.delta.31e63ba4-0d4e-4f5d-abe3-59e463c0edca.TID677.tmp
[2025-07-19T18:30:22.343+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/70/.2.delta.17a3ec0e-4348-42a3-b3e1-89db5ae81fdc.TID673.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/70/2.delta
[2025-07-19T18:30:22.343+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=70),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/70] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/70/2.delta
[2025-07-19T18:30:22.344+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/67/.2.delta.8c5bd7bc-f4e5-42ad-b158-3c52b2becc08.TID670.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/67/2.delta
[2025-07-19T18:30:22.345+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=67),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/67] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/67/2.delta
[2025-07-19T18:30:22.346+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 70 (task 673, attempt 0, stage 7.0)
[2025-07-19T18:30:22.347+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 67 (task 670, attempt 0, stage 7.0)
[2025-07-19T18:30:22.348+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 70 (task 673, attempt 0, stage 7.0)
[2025-07-19T18:30:22.348+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 70.0 in stage 7.0 (TID 673). 5829 bytes result sent to driver
[2025-07-19T18:30:22.349+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/71/.2.delta.f2f749d9-fcea-4eb5-83aa-63fb75d2b53b.TID674.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/71/2.delta
[2025-07-19T18:30:22.350+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=71),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/71] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/71/2.delta
[2025-07-19T18:30:22.350+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 75.0 in stage 7.0 (TID 678) (8b44f3d35cfa, executor driver, partition 75, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.350+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 71 (task 674, attempt 0, stage 7.0)
[2025-07-19T18:30:22.350+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 70.0 in stage 7.0 (TID 673) in 58 ms on 8b44f3d35cfa (executor driver) (68/200)
[2025-07-19T18:30:22.350+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 75.0 in stage 7.0 (TID 678)
[2025-07-19T18:30:22.351+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/72/.2.delta.3db45a57-7b09-4649-b3c0-b25355de0e4b.TID675.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/72/2.delta
[2025-07-19T18:30:22.351+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=72),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/72] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/72/2.delta
[2025-07-19T18:30:22.351+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/68/.2.delta.8f790ce3-e927-4124-89ca-9815f074b7ca.TID671.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/68/2.delta
[2025-07-19T18:30:22.351+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=68),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/68] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/68/2.delta
[2025-07-19T18:30:22.351+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 72 (task 675, attempt 0, stage 7.0)
[2025-07-19T18:30:22.351+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 68 (task 671, attempt 0, stage 7.0)
[2025-07-19T18:30:22.351+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 67 (task 670, attempt 0, stage 7.0)
[2025-07-19T18:30:22.352+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.352+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:22.352+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 71 (task 674, attempt 0, stage 7.0)
[2025-07-19T18:30:22.353+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 71.0 in stage 7.0 (TID 674). 5786 bytes result sent to driver
[2025-07-19T18:30:22.353+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 67.0 in stage 7.0 (TID 670). 5829 bytes result sent to driver
[2025-07-19T18:30:22.353+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 76.0 in stage 7.0 (TID 679) (8b44f3d35cfa, executor driver, partition 76, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.354+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 77.0 in stage 7.0 (TID 680) (8b44f3d35cfa, executor driver, partition 77, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.354+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/73/.2.delta.af3fee64-804b-47c9-8a7f-da5faf15d40a.TID676.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/73/2.delta
[2025-07-19T18:30:22.355+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=73),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/73] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/73/2.delta
[2025-07-19T18:30:22.355+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 71.0 in stage 7.0 (TID 674) in 58 ms on 8b44f3d35cfa (executor driver) (69/200)
[2025-07-19T18:30:22.356+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d6f9f6f
[2025-07-19T18:30:22.356+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 73 (task 676, attempt 0, stage 7.0)
[2025-07-19T18:30:22.357+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 72 (task 675, attempt 0, stage 7.0)
[2025-07-19T18:30:22.357+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 72.0 in stage 7.0 (TID 675). 5829 bytes result sent to driver
[2025-07-19T18:30:22.357+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/74/.2.delta.31e63ba4-0d4e-4f5d-abe3-59e463c0edca.TID677.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/74/2.delta
[2025-07-19T18:30:22.357+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=74),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/74] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/74/2.delta
[2025-07-19T18:30:22.357+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 67.0 in stage 7.0 (TID 670) in 81 ms on 8b44f3d35cfa (executor driver) (70/200)
[2025-07-19T18:30:22.358+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 68 (task 671, attempt 0, stage 7.0)
[2025-07-19T18:30:22.358+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 68.0 in stage 7.0 (TID 671). 5829 bytes result sent to driver
[2025-07-19T18:30:22.358+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/69/.2.delta.797afa27-edb3-48be-986d-948c165fde7f.TID672.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/69/2.delta
[2025-07-19T18:30:22.358+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=69),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/69] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/69/2.delta
[2025-07-19T18:30:22.358+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=75, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.358+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=75),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/75] for update
[2025-07-19T18:30:22.358+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.358+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 74 (task 677, attempt 0, stage 7.0)
[2025-07-19T18:30:22.358+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 69 (task 672, attempt 0, stage 7.0)
[2025-07-19T18:30:22.359+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 78.0 in stage 7.0 (TID 681) (8b44f3d35cfa, executor driver, partition 78, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.359+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 79.0 in stage 7.0 (TID 682) (8b44f3d35cfa, executor driver, partition 79, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.359+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 78.0 in stage 7.0 (TID 681)
[2025-07-19T18:30:22.359+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 79.0 in stage 7.0 (TID 682)
[2025-07-19T18:30:22.359+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 76.0 in stage 7.0 (TID 679)
[2025-07-19T18:30:22.360+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.360+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.361+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.361+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 72.0 in stage 7.0 (TID 675) in 67 ms on 8b44f3d35cfa (executor driver) (71/200)
[2025-07-19T18:30:22.362+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 68.0 in stage 7.0 (TID 671) in 76 ms on 8b44f3d35cfa (executor driver) (72/200)
[2025-07-19T18:30:22.362+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.363+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 77.0 in stage 7.0 (TID 680)
[2025-07-19T18:30:22.363+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 69 (task 672, attempt 0, stage 7.0)
[2025-07-19T18:30:22.364+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 69.0 in stage 7.0 (TID 672). 5829 bytes result sent to driver
[2025-07-19T18:30:22.364+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 74 (task 677, attempt 0, stage 7.0)
[2025-07-19T18:30:22.364+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 74.0 in stage 7.0 (TID 677). 5829 bytes result sent to driver
[2025-07-19T18:30:22.364+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.364+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.364+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 80.0 in stage 7.0 (TID 683) (8b44f3d35cfa, executor driver, partition 80, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.365+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f3e0bae
[2025-07-19T18:30:22.365+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 81.0 in stage 7.0 (TID 684) (8b44f3d35cfa, executor driver, partition 81, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.365+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 80.0 in stage 7.0 (TID 683)
[2025-07-19T18:30:22.366+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 69.0 in stage 7.0 (TID 672) in 78 ms on 8b44f3d35cfa (executor driver) (73/200)
[2025-07-19T18:30:22.366+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=78, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.367+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=78),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/78] for update
[2025-07-19T18:30:22.367+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 74.0 in stage 7.0 (TID 677) in 53 ms on 8b44f3d35cfa (executor driver) (74/200)
[2025-07-19T18:30:22.367+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 81.0 in stage 7.0 (TID 684)
[2025-07-19T18:30:22.367+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 73 (task 676, attempt 0, stage 7.0)
[2025-07-19T18:30:22.367+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 73.0 in stage 7.0 (TID 676). 5829 bytes result sent to driver
[2025-07-19T18:30:22.367+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.367+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.367+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 82.0 in stage 7.0 (TID 685) (8b44f3d35cfa, executor driver, partition 82, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.368+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.368+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.368+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 73.0 in stage 7.0 (TID 676) in 72 ms on 8b44f3d35cfa (executor driver) (75/200)
[2025-07-19T18:30:22.369+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.369+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.369+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 82.0 in stage 7.0 (TID 685)
[2025-07-19T18:30:22.369+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.369+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2bf6892c
[2025-07-19T18:30:22.370+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=80, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.370+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=80),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/80] for update
[2025-07-19T18:30:22.370+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/75/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/75/.2.delta.6eabf191-7f79-4047-870b-e7ad8d0c64a8.TID678.tmp
[2025-07-19T18:30:22.371+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.372+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.373+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.373+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@184e8062
[2025-07-19T18:30:22.373+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=77, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.373+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=77),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/77] for update
[2025-07-19T18:30:22.373+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.374+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f134d68
[2025-07-19T18:30:22.374+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=79, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.375+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=79),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/79] for update
[2025-07-19T18:30:22.375+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/78/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/78/.2.delta.4e26f953-4c63-43e6-b85b-06f4cc3dc09c.TID681.tmp
[2025-07-19T18:30:22.376+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.376+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7ed82c3f
[2025-07-19T18:30:22.376+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=82, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.377+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d4a811
[2025-07-19T18:30:22.377+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=82),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/82] for update
[2025-07-19T18:30:22.378+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=76, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.378+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=76),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/76] for update
[2025-07-19T18:30:22.378+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a013e9c
[2025-07-19T18:30:22.379+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=81, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.380+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=81),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/81] for update
[2025-07-19T18:30:22.380+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/80/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/80/.2.delta.1add9fb4-373c-43da-a56b-2a8cb12fb782.TID683.tmp
[2025-07-19T18:30:22.381+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.381+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.381+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.382+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/79/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/79/.2.delta.5380175a-4984-4194-a739-515f76116ea5.TID682.tmp
[2025-07-19T18:30:22.382+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/77/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/77/.2.delta.4d419f82-8280-4f63-b1b2-192123cdccf3.TID680.tmp
[2025-07-19T18:30:22.383+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/82/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/82/.2.delta.22685b93-49a5-4342-b731-b55bc9c6c90b.TID685.tmp
[2025-07-19T18:30:22.383+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/81/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/81/.2.delta.cd6bd403-145f-40af-9f62-d20d084f0903.TID684.tmp
[2025-07-19T18:30:22.383+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/75/.2.delta.6eabf191-7f79-4047-870b-e7ad8d0c64a8.TID678.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/75/2.delta
[2025-07-19T18:30:22.384+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=75),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/75] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/75/2.delta
[2025-07-19T18:30:22.384+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 75 (task 678, attempt 0, stage 7.0)
[2025-07-19T18:30:22.387+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/76/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/76/.2.delta.8bb28735-e62c-4536-95d0-f606ccca0ce9.TID679.tmp
[2025-07-19T18:30:22.387+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 75 (task 678, attempt 0, stage 7.0)
[2025-07-19T18:30:22.388+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 75.0 in stage 7.0 (TID 678). 5829 bytes result sent to driver
[2025-07-19T18:30:22.388+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 83.0 in stage 7.0 (TID 686) (8b44f3d35cfa, executor driver, partition 83, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.392+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 83.0 in stage 7.0 (TID 686)
[2025-07-19T18:30:22.393+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 75.0 in stage 7.0 (TID 678) in 56 ms on 8b44f3d35cfa (executor driver) (76/200)
[2025-07-19T18:30:22.394+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.394+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.395+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d420b3f
[2025-07-19T18:30:22.395+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=83, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.395+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=83),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/83] for update
[2025-07-19T18:30:22.396+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.396+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/78/.2.delta.4e26f953-4c63-43e6-b85b-06f4cc3dc09c.TID681.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/78/2.delta
[2025-07-19T18:30:22.396+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=78),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/78] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/78/2.delta
[2025-07-19T18:30:22.399+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 78 (task 681, attempt 0, stage 7.0)
[2025-07-19T18:30:22.399+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 78 (task 681, attempt 0, stage 7.0)
[2025-07-19T18:30:22.400+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 78.0 in stage 7.0 (TID 681). 5829 bytes result sent to driver
[2025-07-19T18:30:22.400+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 84.0 in stage 7.0 (TID 687) (8b44f3d35cfa, executor driver, partition 84, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.401+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 84.0 in stage 7.0 (TID 687)
[2025-07-19T18:30:22.401+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 78.0 in stage 7.0 (TID 681) in 52 ms on 8b44f3d35cfa (executor driver) (77/200)
[2025-07-19T18:30:22.401+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.402+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.402+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ad496f4
[2025-07-19T18:30:22.402+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=84, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.402+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=84),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/84] for update
[2025-07-19T18:30:22.402+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.403+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/83/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/83/.2.delta.5cfd11e0-4b28-4e51-aa44-ed2653322b17.TID686.tmp
[2025-07-19T18:30:22.404+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/80/.2.delta.1add9fb4-373c-43da-a56b-2a8cb12fb782.TID683.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/80/2.delta
[2025-07-19T18:30:22.404+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=80),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/80] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/80/2.delta
[2025-07-19T18:30:22.405+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 80 (task 683, attempt 0, stage 7.0)
[2025-07-19T18:30:22.406+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 80 (task 683, attempt 0, stage 7.0)
[2025-07-19T18:30:22.406+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 80.0 in stage 7.0 (TID 683). 5829 bytes result sent to driver
[2025-07-19T18:30:22.408+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/79/.2.delta.5380175a-4984-4194-a739-515f76116ea5.TID682.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/79/2.delta
[2025-07-19T18:30:22.408+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=79),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/79] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/79/2.delta
[2025-07-19T18:30:22.408+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 79 (task 682, attempt 0, stage 7.0)
[2025-07-19T18:30:22.409+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 80.0 in stage 7.0 (TID 683) in 63 ms on 8b44f3d35cfa (executor driver) (78/200)
[2025-07-19T18:30:22.409+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/84/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/84/.2.delta.59666295-f0b1-40c4-b63a-5840ff70f0c5.TID687.tmp
[2025-07-19T18:30:22.409+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/82/.2.delta.22685b93-49a5-4342-b731-b55bc9c6c90b.TID685.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/82/2.delta
[2025-07-19T18:30:22.409+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=82),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/82] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/82/2.delta
[2025-07-19T18:30:22.409+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 85.0 in stage 7.0 (TID 688) (8b44f3d35cfa, executor driver, partition 85, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.409+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 82 (task 685, attempt 0, stage 7.0)
[2025-07-19T18:30:22.410+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/77/.2.delta.4d419f82-8280-4f63-b1b2-192123cdccf3.TID680.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/77/2.delta
[2025-07-19T18:30:22.410+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=77),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/77] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/77/2.delta
[2025-07-19T18:30:22.410+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 85.0 in stage 7.0 (TID 688)
[2025-07-19T18:30:22.410+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/81/.2.delta.cd6bd403-145f-40af-9f62-d20d084f0903.TID684.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/81/2.delta
[2025-07-19T18:30:22.410+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=81),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/81] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/81/2.delta
[2025-07-19T18:30:22.412+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 77 (task 680, attempt 0, stage 7.0)
[2025-07-19T18:30:22.418+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/76/.2.delta.8bb28735-e62c-4536-95d0-f606ccca0ce9.TID679.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/76/2.delta
[2025-07-19T18:30:22.419+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=76),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/76] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/76/2.delta
[2025-07-19T18:30:22.419+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 82 (task 685, attempt 0, stage 7.0)
[2025-07-19T18:30:22.420+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 76 (task 679, attempt 0, stage 7.0)
[2025-07-19T18:30:22.421+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 81 (task 684, attempt 0, stage 7.0)
[2025-07-19T18:30:22.421+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.422+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 79 (task 682, attempt 0, stage 7.0)
[2025-07-19T18:30:22.422+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 79.0 in stage 7.0 (TID 682). 5786 bytes result sent to driver
[2025-07-19T18:30:22.422+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 82.0 in stage 7.0 (TID 685). 5829 bytes result sent to driver
[2025-07-19T18:30:22.424+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 86.0 in stage 7.0 (TID 689) (8b44f3d35cfa, executor driver, partition 86, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.425+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 87.0 in stage 7.0 (TID 690) (8b44f3d35cfa, executor driver, partition 87, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.427+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:22.427+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 86.0 in stage 7.0 (TID 689)
[2025-07-19T18:30:22.428+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 87.0 in stage 7.0 (TID 690)
[2025-07-19T18:30:22.428+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 79.0 in stage 7.0 (TID 682) in 75 ms on 8b44f3d35cfa (executor driver) (79/200)
[2025-07-19T18:30:22.429+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@27041517
[2025-07-19T18:30:22.429+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 81 (task 684, attempt 0, stage 7.0)
[2025-07-19T18:30:22.430+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.432+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.434+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 81.0 in stage 7.0 (TID 684). 5829 bytes result sent to driver
[2025-07-19T18:30:22.434+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 88.0 in stage 7.0 (TID 691) (8b44f3d35cfa, executor driver, partition 88, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.436+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 82.0 in stage 7.0 (TID 685) in 70 ms on 8b44f3d35cfa (executor driver) (80/200)
[2025-07-19T18:30:22.437+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 81.0 in stage 7.0 (TID 684) in 72 ms on 8b44f3d35cfa (executor driver) (81/200)
[2025-07-19T18:30:22.438+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 88.0 in stage 7.0 (TID 691)
[2025-07-19T18:30:22.438+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 76 (task 679, attempt 0, stage 7.0)
[2025-07-19T18:30:22.438+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 76.0 in stage 7.0 (TID 679). 5829 bytes result sent to driver
[2025-07-19T18:30:22.439+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=85, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.439+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=85),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/85] for update
[2025-07-19T18:30:22.439+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 89.0 in stage 7.0 (TID 692) (8b44f3d35cfa, executor driver, partition 89, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.439+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 89.0 in stage 7.0 (TID 692)
[2025-07-19T18:30:22.439+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 76.0 in stage 7.0 (TID 679) in 85 ms on 8b44f3d35cfa (executor driver) (82/200)
[2025-07-19T18:30:22.439+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.439+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:22.440+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 77 (task 680, attempt 0, stage 7.0)
[2025-07-19T18:30:22.440+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.440+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.440+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T18:30:22.440+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5479e1da
[2025-07-19T18:30:22.440+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=86, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.440+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=86),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/86] for update
[2025-07-19T18:30:22.441+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.441+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.441+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.442+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 77.0 in stage 7.0 (TID 680). 5829 bytes result sent to driver
[2025-07-19T18:30:22.444+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 90.0 in stage 7.0 (TID 693) (8b44f3d35cfa, executor driver, partition 90, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.445+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 90.0 in stage 7.0 (TID 693)
[2025-07-19T18:30:22.446+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.446+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.447+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 77.0 in stage 7.0 (TID 680) in 93 ms on 8b44f3d35cfa (executor driver) (83/200)
[2025-07-19T18:30:22.447+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@70c0b7c
[2025-07-19T18:30:22.447+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=89, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.447+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=89),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/89] for update
[2025-07-19T18:30:22.447+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b226005
[2025-07-19T18:30:22.447+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.447+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=88, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.448+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=88),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/88] for update
[2025-07-19T18:30:22.448+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.448+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a943df1
[2025-07-19T18:30:22.449+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=87, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.450+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=87),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/87] for update
[2025-07-19T18:30:22.451+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.451+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6fbacda8
[2025-07-19T18:30:22.452+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=90, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.452+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=90),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/90] for update
[2025-07-19T18:30:22.453+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.453+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/86/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/86/.2.delta.26f8fbbb-8392-4af1-be59-5db2016ff62d.TID689.tmp
[2025-07-19T18:30:22.454+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/83/.2.delta.5cfd11e0-4b28-4e51-aa44-ed2653322b17.TID686.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/83/2.delta
[2025-07-19T18:30:22.454+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=83),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/83] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/83/2.delta
[2025-07-19T18:30:22.454+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 83 (task 686, attempt 0, stage 7.0)
[2025-07-19T18:30:22.455+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/85/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/85/.2.delta.c39749ad-b2c6-4794-a8cd-c1a16adaeaf8.TID688.tmp
[2025-07-19T18:30:22.455+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/89/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/89/.2.delta.305cedab-d494-4a1e-ac30-9e41718bffa2.TID692.tmp
[2025-07-19T18:30:22.456+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 83 (task 686, attempt 0, stage 7.0)
[2025-07-19T18:30:22.456+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 83.0 in stage 7.0 (TID 686). 5829 bytes result sent to driver
[2025-07-19T18:30:22.456+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 91.0 in stage 7.0 (TID 694) (8b44f3d35cfa, executor driver, partition 91, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.457+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 91.0 in stage 7.0 (TID 694)
[2025-07-19T18:30:22.457+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 83.0 in stage 7.0 (TID 686) in 67 ms on 8b44f3d35cfa (executor driver) (84/200)
[2025-07-19T18:30:22.457+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.457+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/88/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/88/.2.delta.c8a593ca-b932-4117-aa87-65901ae80f4e.TID691.tmp
[2025-07-19T18:30:22.457+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.457+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/90/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/90/.2.delta.5631a2e7-8212-4463-93a8-5acfd329fecf.TID693.tmp
[2025-07-19T18:30:22.457+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2881e879
[2025-07-19T18:30:22.457+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=91, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.457+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=91),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/91] for update
[2025-07-19T18:30:22.457+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.458+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/87/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/87/.2.delta.1518f561-768e-4b20-80c1-6dda3ec7893d.TID690.tmp
[2025-07-19T18:30:22.459+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/91/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/91/.2.delta.33097ae6-bad2-4d77-a132-2198eb0ba0ef.TID694.tmp
[2025-07-19T18:30:22.460+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/84/.2.delta.59666295-f0b1-40c4-b63a-5840ff70f0c5.TID687.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/84/2.delta
[2025-07-19T18:30:22.460+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=84),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/84] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/84/2.delta
[2025-07-19T18:30:22.460+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 84 (task 687, attempt 0, stage 7.0)
[2025-07-19T18:30:22.464+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 84 (task 687, attempt 0, stage 7.0)
[2025-07-19T18:30:22.466+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 84.0 in stage 7.0 (TID 687). 5829 bytes result sent to driver
[2025-07-19T18:30:22.466+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 84.0 in stage 7.0 (TID 687) in 75 ms on 8b44f3d35cfa (executor driver) (85/200)
[2025-07-19T18:30:22.467+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 92.0 in stage 7.0 (TID 695) (8b44f3d35cfa, executor driver, partition 92, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.467+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 92.0 in stage 7.0 (TID 695)
[2025-07-19T18:30:22.469+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.470+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.471+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7159e30f
[2025-07-19T18:30:22.471+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=92, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.471+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=92),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/92] for update
[2025-07-19T18:30:22.473+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.479+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/85/.2.delta.c39749ad-b2c6-4794-a8cd-c1a16adaeaf8.TID688.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/85/2.delta
[2025-07-19T18:30:22.480+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=85),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/85] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/85/2.delta
[2025-07-19T18:30:22.480+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/89/.2.delta.305cedab-d494-4a1e-ac30-9e41718bffa2.TID692.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/89/2.delta
[2025-07-19T18:30:22.480+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=89),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/89] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/89/2.delta
[2025-07-19T18:30:22.480+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 85 (task 688, attempt 0, stage 7.0)
[2025-07-19T18:30:22.481+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 89 (task 692, attempt 0, stage 7.0)
[2025-07-19T18:30:22.482+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/86/.2.delta.26f8fbbb-8392-4af1-be59-5db2016ff62d.TID689.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/86/2.delta
[2025-07-19T18:30:22.482+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=86),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/86] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/86/2.delta
[2025-07-19T18:30:22.482+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 86 (task 689, attempt 0, stage 7.0)
[2025-07-19T18:30:22.484+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/92/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/92/.2.delta.f10c6ddf-fbcc-4530-b98f-ffb38f0836c0.TID695.tmp
[2025-07-19T18:30:22.486+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/90/.2.delta.5631a2e7-8212-4463-93a8-5acfd329fecf.TID693.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/90/2.delta
[2025-07-19T18:30:22.486+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=90),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/90] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/90/2.delta
[2025-07-19T18:30:22.486+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 85 (task 688, attempt 0, stage 7.0)
[2025-07-19T18:30:22.487+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 89 (task 692, attempt 0, stage 7.0)
[2025-07-19T18:30:22.487+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 90 (task 693, attempt 0, stage 7.0)
[2025-07-19T18:30:22.488+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 86 (task 689, attempt 0, stage 7.0)
[2025-07-19T18:30:22.489+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 86.0 in stage 7.0 (TID 689). 5829 bytes result sent to driver
[2025-07-19T18:30:22.491+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 89.0 in stage 7.0 (TID 692). 5829 bytes result sent to driver
[2025-07-19T18:30:22.492+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 85.0 in stage 7.0 (TID 688). 5829 bytes result sent to driver
[2025-07-19T18:30:22.492+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 93.0 in stage 7.0 (TID 696) (8b44f3d35cfa, executor driver, partition 93, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.493+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 94.0 in stage 7.0 (TID 697) (8b44f3d35cfa, executor driver, partition 94, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.493+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 95.0 in stage 7.0 (TID 698) (8b44f3d35cfa, executor driver, partition 95, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.493+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 94.0 in stage 7.0 (TID 697)
[2025-07-19T18:30:22.494+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 86.0 in stage 7.0 (TID 689) in 74 ms on 8b44f3d35cfa (executor driver) (86/200)
[2025-07-19T18:30:22.495+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 85.0 in stage 7.0 (TID 688) in 79 ms on 8b44f3d35cfa (executor driver) (87/200)
[2025-07-19T18:30:22.496+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 95.0 in stage 7.0 (TID 698)
[2025-07-19T18:30:22.496+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 93.0 in stage 7.0 (TID 696)
[2025-07-19T18:30:22.496+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 89.0 in stage 7.0 (TID 692) in 70 ms on 8b44f3d35cfa (executor driver) (88/200)
[2025-07-19T18:30:22.497+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/88/.2.delta.c8a593ca-b932-4117-aa87-65901ae80f4e.TID691.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/88/2.delta
[2025-07-19T18:30:22.497+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=88),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/88] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/88/2.delta
[2025-07-19T18:30:22.497+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 90 (task 693, attempt 0, stage 7.0)
[2025-07-19T18:30:22.498+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/91/.2.delta.33097ae6-bad2-4d77-a132-2198eb0ba0ef.TID694.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/91/2.delta
[2025-07-19T18:30:22.498+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=91),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/91] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/91/2.delta
[2025-07-19T18:30:22.498+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.498+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.499+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 90.0 in stage 7.0 (TID 693). 5829 bytes result sent to driver
[2025-07-19T18:30:22.499+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.500+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.500+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 91 (task 694, attempt 0, stage 7.0)
[2025-07-19T18:30:22.500+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.500+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.500+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 88 (task 691, attempt 0, stage 7.0)
[2025-07-19T18:30:22.500+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 96.0 in stage 7.0 (TID 699) (8b44f3d35cfa, executor driver, partition 96, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.500+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 90.0 in stage 7.0 (TID 693) in 67 ms on 8b44f3d35cfa (executor driver) (89/200)
[2025-07-19T18:30:22.500+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 96.0 in stage 7.0 (TID 699)
[2025-07-19T18:30:22.500+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@758caf82
[2025-07-19T18:30:22.501+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/87/.2.delta.1518f561-768e-4b20-80c1-6dda3ec7893d.TID690.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/87/2.delta
[2025-07-19T18:30:22.501+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=87),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/87] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/87/2.delta
[2025-07-19T18:30:22.502+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.502+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.502+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=93, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.502+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=93),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/93] for update
[2025-07-19T18:30:22.502+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 87 (task 690, attempt 0, stage 7.0)
[2025-07-19T18:30:22.503+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 91 (task 694, attempt 0, stage 7.0)
[2025-07-19T18:30:22.504+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23b5563b
[2025-07-19T18:30:22.506+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.506+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=95, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.507+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=95),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/95] for update
[2025-07-19T18:30:22.507+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 88 (task 691, attempt 0, stage 7.0)
[2025-07-19T18:30:22.508+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@507e4cb0
[2025-07-19T18:30:22.509+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 91.0 in stage 7.0 (TID 694). 5915 bytes result sent to driver
[2025-07-19T18:30:22.511+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 88.0 in stage 7.0 (TID 691). 5915 bytes result sent to driver
[2025-07-19T18:30:22.511+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 91.0 in stage 7.0 (TID 694) in 58 ms on 8b44f3d35cfa (executor driver) (90/200)
[2025-07-19T18:30:22.511+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 87 (task 690, attempt 0, stage 7.0)
[2025-07-19T18:30:22.512+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.515+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 97.0 in stage 7.0 (TID 700) (8b44f3d35cfa, executor driver, partition 97, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.516+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 98.0 in stage 7.0 (TID 701) (8b44f3d35cfa, executor driver, partition 98, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.516+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 97.0 in stage 7.0 (TID 700)
[2025-07-19T18:30:22.517+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 88.0 in stage 7.0 (TID 691) in 91 ms on 8b44f3d35cfa (executor driver) (91/200)
[2025-07-19T18:30:22.518+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 98.0 in stage 7.0 (TID 701)
[2025-07-19T18:30:22.520+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=96, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.521+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=96),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/96] for update
[2025-07-19T18:30:22.521+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.522+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.522+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.522+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.523+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 87.0 in stage 7.0 (TID 690). 5872 bytes result sent to driver
[2025-07-19T18:30:22.523+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.523+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/93/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/93/.2.delta.b5cefdb2-d200-444e-a389-2db93abd65f2.TID696.tmp
[2025-07-19T18:30:22.524+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 99.0 in stage 7.0 (TID 702) (8b44f3d35cfa, executor driver, partition 99, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.525+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2a37538f
[2025-07-19T18:30:22.525+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 99.0 in stage 7.0 (TID 702)
[2025-07-19T18:30:22.526+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 87.0 in stage 7.0 (TID 690) in 99 ms on 8b44f3d35cfa (executor driver) (92/200)
[2025-07-19T18:30:22.527+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=97, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.527+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=97),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/97] for update
[2025-07-19T18:30:22.528+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.528+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58ea622e
[2025-07-19T18:30:22.529+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=94, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.531+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.532+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22507e2d
[2025-07-19T18:30:22.533+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.533+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=94),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/94] for update
[2025-07-19T18:30:22.534+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=98, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.534+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=98),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/98] for update
[2025-07-19T18:30:22.534+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.535+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.535+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1bcdae3b
[2025-07-19T18:30:22.535+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=99, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.536+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=99),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/99] for update
[2025-07-19T18:30:22.536+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/96/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/96/.2.delta.a4226cbb-79e0-42e9-b0c3-1cb8f67b49cd.TID699.tmp
[2025-07-19T18:30:22.537+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/95/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/95/.2.delta.e5947f98-9fa5-413d-9e8e-581d4d596270.TID698.tmp
[2025-07-19T18:30:22.537+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.538+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/94/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/94/.2.delta.cfc3c8eb-f82f-417d-9f89-f6022c563e27.TID697.tmp
[2025-07-19T18:30:22.538+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/92/.2.delta.f10c6ddf-fbcc-4530-b98f-ffb38f0836c0.TID695.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/92/2.delta
[2025-07-19T18:30:22.538+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=92),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/92] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/92/2.delta
[2025-07-19T18:30:22.540+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 92 (task 695, attempt 0, stage 7.0)
[2025-07-19T18:30:22.541+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/97/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/97/.2.delta.97336d87-4306-45aa-acbc-0ab742456e42.TID700.tmp
[2025-07-19T18:30:22.541+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 92 (task 695, attempt 0, stage 7.0)
[2025-07-19T18:30:22.542+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 92.0 in stage 7.0 (TID 695). 5872 bytes result sent to driver
[2025-07-19T18:30:22.543+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 100.0 in stage 7.0 (TID 703) (8b44f3d35cfa, executor driver, partition 100, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.544+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 100.0 in stage 7.0 (TID 703)
[2025-07-19T18:30:22.544+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 92.0 in stage 7.0 (TID 695) in 75 ms on 8b44f3d35cfa (executor driver) (93/200)
[2025-07-19T18:30:22.544+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.544+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.544+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@70501ba1
[2025-07-19T18:30:22.545+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=100, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.545+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=100),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/100] for update
[2025-07-19T18:30:22.545+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/98/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/98/.2.delta.2209367c-351e-419d-a898-d93512e9cc05.TID701.tmp
[2025-07-19T18:30:22.552+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/99/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/99/.2.delta.280d68a4-5f05-4560-93c8-20fd24fa1d94.TID702.tmp
[2025-07-19T18:30:22.555+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.560+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 8b44f3d35cfa:40517 in memory (size: 29.6 KiB, free: 434.2 MiB)
[2025-07-19T18:30:22.569+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/93/.2.delta.b5cefdb2-d200-444e-a389-2db93abd65f2.TID696.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/93/2.delta
[2025-07-19T18:30:22.570+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=93),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/93] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/93/2.delta
[2025-07-19T18:30:22.571+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 93 (task 696, attempt 0, stage 7.0)
[2025-07-19T18:30:22.571+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/100/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/100/.2.delta.792eb34f-3646-457c-853f-00e9d7221323.TID703.tmp
[2025-07-19T18:30:22.571+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 8b44f3d35cfa:40517 in memory (size: 35.4 KiB, free: 434.2 MiB)
[2025-07-19T18:30:22.577+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 93 (task 696, attempt 0, stage 7.0)
[2025-07-19T18:30:22.583+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 93.0 in stage 7.0 (TID 696). 5915 bytes result sent to driver
[2025-07-19T18:30:22.584+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 101.0 in stage 7.0 (TID 704) (8b44f3d35cfa, executor driver, partition 101, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.585+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 93.0 in stage 7.0 (TID 696) in 98 ms on 8b44f3d35cfa (executor driver) (94/200)
[2025-07-19T18:30:22.585+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 101.0 in stage 7.0 (TID 704)
[2025-07-19T18:30:22.587+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.587+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.588+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/95/.2.delta.e5947f98-9fa5-413d-9e8e-581d4d596270.TID698.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/95/2.delta
[2025-07-19T18:30:22.589+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=95),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/95] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/95/2.delta
[2025-07-19T18:30:22.589+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@617f1f6b
[2025-07-19T18:30:22.589+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=101, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.591+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 95 (task 698, attempt 0, stage 7.0)
[2025-07-19T18:30:22.592+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=101),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/101] for update
[2025-07-19T18:30:22.593+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/96/.2.delta.a4226cbb-79e0-42e9-b0c3-1cb8f67b49cd.TID699.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/96/2.delta
[2025-07-19T18:30:22.593+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=96),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/96] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/96/2.delta
[2025-07-19T18:30:22.593+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 96 (task 699, attempt 0, stage 7.0)
[2025-07-19T18:30:22.593+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 95 (task 698, attempt 0, stage 7.0)
[2025-07-19T18:30:22.594+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 95.0 in stage 7.0 (TID 698). 5872 bytes result sent to driver
[2025-07-19T18:30:22.594+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 102.0 in stage 7.0 (TID 705) (8b44f3d35cfa, executor driver, partition 102, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.595+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 102.0 in stage 7.0 (TID 705)
[2025-07-19T18:30:22.596+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 95.0 in stage 7.0 (TID 698) in 106 ms on 8b44f3d35cfa (executor driver) (95/200)
[2025-07-19T18:30:22.597+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.598+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 96 (task 699, attempt 0, stage 7.0)
[2025-07-19T18:30:22.599+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 96.0 in stage 7.0 (TID 699). 5829 bytes result sent to driver
[2025-07-19T18:30:22.600+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 103.0 in stage 7.0 (TID 706) (8b44f3d35cfa, executor driver, partition 103, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.600+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 96.0 in stage 7.0 (TID 699) in 105 ms on 8b44f3d35cfa (executor driver) (96/200)
[2025-07-19T18:30:22.601+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 103.0 in stage 7.0 (TID 706)
[2025-07-19T18:30:22.601+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/94/.2.delta.cfc3c8eb-f82f-417d-9f89-f6022c563e27.TID697.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/94/2.delta
[2025-07-19T18:30:22.601+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=94),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/94] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/94/2.delta
[2025-07-19T18:30:22.602+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 94 (task 697, attempt 0, stage 7.0)
[2025-07-19T18:30:22.602+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.604+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:22.605+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31ef83ef
[2025-07-19T18:30:22.605+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=102, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.605+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=102),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/102] for update
[2025-07-19T18:30:22.605+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/97/.2.delta.97336d87-4306-45aa-acbc-0ab742456e42.TID700.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/97/2.delta
[2025-07-19T18:30:22.606+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=97),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/97] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/97/2.delta
[2025-07-19T18:30:22.606+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 97 (task 700, attempt 0, stage 7.0)
[2025-07-19T18:30:22.606+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.607+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.607+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.607+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d9be5b6
[2025-07-19T18:30:22.607+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 94 (task 697, attempt 0, stage 7.0)
[2025-07-19T18:30:22.607+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 94.0 in stage 7.0 (TID 697). 5872 bytes result sent to driver
[2025-07-19T18:30:22.607+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/101/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/101/.2.delta.51dfb961-f56f-4f7e-8a22-143d223e539f.TID704.tmp
[2025-07-19T18:30:22.610+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/98/.2.delta.2209367c-351e-419d-a898-d93512e9cc05.TID701.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/98/2.delta
[2025-07-19T18:30:22.611+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=98),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/98] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/98/2.delta
[2025-07-19T18:30:22.611+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 97 (task 700, attempt 0, stage 7.0)
[2025-07-19T18:30:22.611+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 97.0 in stage 7.0 (TID 700). 5829 bytes result sent to driver
[2025-07-19T18:30:22.611+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 104.0 in stage 7.0 (TID 707) (8b44f3d35cfa, executor driver, partition 104, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.611+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=103, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.611+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 94.0 in stage 7.0 (TID 697) in 123 ms on 8b44f3d35cfa (executor driver) (97/200)
[2025-07-19T18:30:22.611+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=103),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/103] for update
[2025-07-19T18:30:22.612+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 105.0 in stage 7.0 (TID 708) (8b44f3d35cfa, executor driver, partition 105, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.612+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 97.0 in stage 7.0 (TID 700) in 104 ms on 8b44f3d35cfa (executor driver) (98/200)
[2025-07-19T18:30:22.612+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 105.0 in stage 7.0 (TID 708)
[2025-07-19T18:30:22.612+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 104.0 in stage 7.0 (TID 707)
[2025-07-19T18:30:22.612+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/99/.2.delta.280d68a4-5f05-4560-93c8-20fd24fa1d94.TID702.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/99/2.delta
[2025-07-19T18:30:22.613+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=99),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/99] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/99/2.delta
[2025-07-19T18:30:22.613+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 98 (task 701, attempt 0, stage 7.0)
[2025-07-19T18:30:22.613+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 99 (task 702, attempt 0, stage 7.0)
[2025-07-19T18:30:22.616+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.617+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.618+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.618+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.618+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.619+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/102/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/102/.2.delta.46ecb81a-48ba-49fa-8095-354e8e9a849d.TID705.tmp
[2025-07-19T18:30:22.620+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 99 (task 702, attempt 0, stage 7.0)
[2025-07-19T18:30:22.621+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 99.0 in stage 7.0 (TID 702). 5829 bytes result sent to driver
[2025-07-19T18:30:22.621+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 98 (task 701, attempt 0, stage 7.0)
[2025-07-19T18:30:22.622+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 106.0 in stage 7.0 (TID 709) (8b44f3d35cfa, executor driver, partition 106, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.622+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 98.0 in stage 7.0 (TID 701). 5786 bytes result sent to driver
[2025-07-19T18:30:22.624+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 106.0 in stage 7.0 (TID 709)
[2025-07-19T18:30:22.625+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 107.0 in stage 7.0 (TID 710) (8b44f3d35cfa, executor driver, partition 107, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.626+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 107.0 in stage 7.0 (TID 710)
[2025-07-19T18:30:22.628+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 99.0 in stage 7.0 (TID 702) in 105 ms on 8b44f3d35cfa (executor driver) (99/200)
[2025-07-19T18:30:22.629+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.630+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.631+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 98.0 in stage 7.0 (TID 701) in 112 ms on 8b44f3d35cfa (executor driver) (100/200)
[2025-07-19T18:30:22.632+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.633+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.634+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/100/.2.delta.792eb34f-3646-457c-853f-00e9d7221323.TID703.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/100/2.delta
[2025-07-19T18:30:22.634+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=100),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/100] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/100/2.delta
[2025-07-19T18:30:22.637+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 100 (task 703, attempt 0, stage 7.0)
[2025-07-19T18:30:22.639+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71cc3c4d
[2025-07-19T18:30:22.641+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/103/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/103/.2.delta.abbc1d15-d09a-4b94-900e-6fc56699a9ce.TID706.tmp
[2025-07-19T18:30:22.643+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 100 (task 703, attempt 0, stage 7.0)
[2025-07-19T18:30:22.648+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 100.0 in stage 7.0 (TID 703). 5829 bytes result sent to driver
[2025-07-19T18:30:22.652+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=105, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.653+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=105),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/105] for update
[2025-07-19T18:30:22.653+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 108.0 in stage 7.0 (TID 711) (8b44f3d35cfa, executor driver, partition 108, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.654+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 108.0 in stage 7.0 (TID 711)
[2025-07-19T18:30:22.655+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 100.0 in stage 7.0 (TID 703) in 84 ms on 8b44f3d35cfa (executor driver) (101/200)
[2025-07-19T18:30:22.656+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.657+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.657+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.658+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4bbbedcb
[2025-07-19T18:30:22.659+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=104, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.660+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=104),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/104] for update
[2025-07-19T18:30:22.661+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.662+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d396927
[2025-07-19T18:30:22.663+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=106, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.666+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=106),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/106] for update
[2025-07-19T18:30:22.669+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.670+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/105/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/105/.2.delta.99b8a920-c03f-43e2-9783-37550ca058e9.TID708.tmp
[2025-07-19T18:30:22.671+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7aeedbc6
[2025-07-19T18:30:22.672+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/104/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/104/.2.delta.b2e539f7-347d-412f-8412-cf8487a3e47d.TID707.tmp
[2025-07-19T18:30:22.673+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=107, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.674+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=107),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/107] for update
[2025-07-19T18:30:22.674+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.675+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3508af81
[2025-07-19T18:30:22.675+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=108, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.675+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=108),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/108] for update
[2025-07-19T18:30:22.676+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.676+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/107/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/107/.2.delta.5d08e7e2-a67e-4f48-984d-d47d928a18a1.TID710.tmp
[2025-07-19T18:30:22.677+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/106/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/106/.2.delta.44a5bb38-cda7-42c8-9afa-5add02b851bf.TID709.tmp
[2025-07-19T18:30:22.678+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/102/.2.delta.46ecb81a-48ba-49fa-8095-354e8e9a849d.TID705.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/102/2.delta
[2025-07-19T18:30:22.679+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=102),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/102] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/102/2.delta
[2025-07-19T18:30:22.679+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 102 (task 705, attempt 0, stage 7.0)
[2025-07-19T18:30:22.679+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/101/.2.delta.51dfb961-f56f-4f7e-8a22-143d223e539f.TID704.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/101/2.delta
[2025-07-19T18:30:22.679+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=101),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/101] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/101/2.delta
[2025-07-19T18:30:22.680+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 101 (task 704, attempt 0, stage 7.0)
[2025-07-19T18:30:22.680+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 102 (task 705, attempt 0, stage 7.0)
[2025-07-19T18:30:22.680+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 102.0 in stage 7.0 (TID 705). 5829 bytes result sent to driver
[2025-07-19T18:30:22.680+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 109.0 in stage 7.0 (TID 712) (8b44f3d35cfa, executor driver, partition 109, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.680+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/108/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/108/.2.delta.2fe53c25-5c2b-4319-988c-29825da2ce98.TID711.tmp
[2025-07-19T18:30:22.680+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 102.0 in stage 7.0 (TID 705) in 75 ms on 8b44f3d35cfa (executor driver) (102/200)
[2025-07-19T18:30:22.680+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 109.0 in stage 7.0 (TID 712)
[2025-07-19T18:30:22.680+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 101 (task 704, attempt 0, stage 7.0)
[2025-07-19T18:30:22.680+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 101.0 in stage 7.0 (TID 704). 5829 bytes result sent to driver
[2025-07-19T18:30:22.680+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 110.0 in stage 7.0 (TID 713) (8b44f3d35cfa, executor driver, partition 110, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.680+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.681+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.681+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f9c4ac0
[2025-07-19T18:30:22.681+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 101.0 in stage 7.0 (TID 704) in 90 ms on 8b44f3d35cfa (executor driver) (103/200)
[2025-07-19T18:30:22.681+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 110.0 in stage 7.0 (TID 713)
[2025-07-19T18:30:22.682+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=109, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.683+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=109),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/109] for update
[2025-07-19T18:30:22.684+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.684+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.685+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.685+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@655a6121
[2025-07-19T18:30:22.686+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=110, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.686+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=110),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/110] for update
[2025-07-19T18:30:22.686+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/103/.2.delta.abbc1d15-d09a-4b94-900e-6fc56699a9ce.TID706.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/103/2.delta
[2025-07-19T18:30:22.687+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=103),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/103] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/103/2.delta
[2025-07-19T18:30:22.688+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 103 (task 706, attempt 0, stage 7.0)
[2025-07-19T18:30:22.688+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.689+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 103 (task 706, attempt 0, stage 7.0)
[2025-07-19T18:30:22.689+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 103.0 in stage 7.0 (TID 706). 5829 bytes result sent to driver
[2025-07-19T18:30:22.689+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 111.0 in stage 7.0 (TID 714) (8b44f3d35cfa, executor driver, partition 111, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.689+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 111.0 in stage 7.0 (TID 714)
[2025-07-19T18:30:22.690+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 103.0 in stage 7.0 (TID 706) in 90 ms on 8b44f3d35cfa (executor driver) (104/200)
[2025-07-19T18:30:22.690+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.692+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.692+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/109/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/109/.2.delta.7e964bae-7f41-4450-a16d-573b58efd5a9.TID712.tmp
[2025-07-19T18:30:22.693+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@24a6d0ca
[2025-07-19T18:30:22.695+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=111, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.695+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=111),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/111] for update
[2025-07-19T18:30:22.696+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/110/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/110/.2.delta.4cee2bde-217c-4d30-8803-b05ac266a066.TID713.tmp
[2025-07-19T18:30:22.696+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.696+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/105/.2.delta.99b8a920-c03f-43e2-9783-37550ca058e9.TID708.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/105/2.delta
[2025-07-19T18:30:22.697+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=105),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/105] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/105/2.delta
[2025-07-19T18:30:22.698+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 105 (task 708, attempt 0, stage 7.0)
[2025-07-19T18:30:22.699+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 105 (task 708, attempt 0, stage 7.0)
[2025-07-19T18:30:22.700+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 105.0 in stage 7.0 (TID 708). 5829 bytes result sent to driver
[2025-07-19T18:30:22.700+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 112.0 in stage 7.0 (TID 715) (8b44f3d35cfa, executor driver, partition 112, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.703+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 112.0 in stage 7.0 (TID 715)
[2025-07-19T18:30:22.704+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 105.0 in stage 7.0 (TID 708) in 91 ms on 8b44f3d35cfa (executor driver) (105/200)
[2025-07-19T18:30:22.705+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/107/.2.delta.5d08e7e2-a67e-4f48-984d-d47d928a18a1.TID710.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/107/2.delta
[2025-07-19T18:30:22.705+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=107),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/107] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/107/2.delta
[2025-07-19T18:30:22.705+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 107 (task 710, attempt 0, stage 7.0)
[2025-07-19T18:30:22.705+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.706+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.706+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/111/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/111/.2.delta.e1add91b-e1d1-4c47-8e07-e5a7948ee69f.TID714.tmp
[2025-07-19T18:30:22.708+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/104/.2.delta.b2e539f7-347d-412f-8412-cf8487a3e47d.TID707.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/104/2.delta
[2025-07-19T18:30:22.710+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=104),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/104] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/104/2.delta
[2025-07-19T18:30:22.711+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@335b765f
[2025-07-19T18:30:22.712+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 104 (task 707, attempt 0, stage 7.0)
[2025-07-19T18:30:22.712+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/108/.2.delta.2fe53c25-5c2b-4319-988c-29825da2ce98.TID711.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/108/2.delta
[2025-07-19T18:30:22.712+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=108),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/108] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/108/2.delta
[2025-07-19T18:30:22.713+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 107 (task 710, attempt 0, stage 7.0)
[2025-07-19T18:30:22.714+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 107.0 in stage 7.0 (TID 710). 5829 bytes result sent to driver
[2025-07-19T18:30:22.715+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 113.0 in stage 7.0 (TID 716) (8b44f3d35cfa, executor driver, partition 113, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.717+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 107.0 in stage 7.0 (TID 710) in 91 ms on 8b44f3d35cfa (executor driver) (106/200)
[2025-07-19T18:30:22.718+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 108 (task 711, attempt 0, stage 7.0)
[2025-07-19T18:30:22.720+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/106/.2.delta.44a5bb38-cda7-42c8-9afa-5add02b851bf.TID709.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/106/2.delta
[2025-07-19T18:30:22.722+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=112, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.723+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=106),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/106] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/106/2.delta
[2025-07-19T18:30:22.724+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=112),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/112] for update
[2025-07-19T18:30:22.725+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 106 (task 709, attempt 0, stage 7.0)
[2025-07-19T18:30:22.727+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 113.0 in stage 7.0 (TID 716)
[2025-07-19T18:30:22.728+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.730+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 104 (task 707, attempt 0, stage 7.0)
[2025-07-19T18:30:22.730+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 104.0 in stage 7.0 (TID 707). 5829 bytes result sent to driver
[2025-07-19T18:30:22.730+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 114.0 in stage 7.0 (TID 717) (8b44f3d35cfa, executor driver, partition 114, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.730+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.731+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.731+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 106 (task 709, attempt 0, stage 7.0)
[2025-07-19T18:30:22.731+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 106.0 in stage 7.0 (TID 709). 5829 bytes result sent to driver
[2025-07-19T18:30:22.731+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 108 (task 711, attempt 0, stage 7.0)
[2025-07-19T18:30:22.731+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 108.0 in stage 7.0 (TID 711). 5829 bytes result sent to driver
[2025-07-19T18:30:22.731+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 114.0 in stage 7.0 (TID 717)
[2025-07-19T18:30:22.731+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28a9824e
[2025-07-19T18:30:22.731+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 115.0 in stage 7.0 (TID 718) (8b44f3d35cfa, executor driver, partition 115, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.731+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 104.0 in stage 7.0 (TID 707) in 107 ms on 8b44f3d35cfa (executor driver) (107/200)
[2025-07-19T18:30:22.732+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=113, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.732+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=113),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/113] for update
[2025-07-19T18:30:22.732+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 115.0 in stage 7.0 (TID 718)
[2025-07-19T18:30:22.732+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.733+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.733+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.733+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.733+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.733+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 116.0 in stage 7.0 (TID 719) (8b44f3d35cfa, executor driver, partition 116, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.733+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@698d4f2a
[2025-07-19T18:30:22.733+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 106.0 in stage 7.0 (TID 709) in 102 ms on 8b44f3d35cfa (executor driver) (108/200)
[2025-07-19T18:30:22.734+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=114, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.734+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=114),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/114] for update
[2025-07-19T18:30:22.734+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 116.0 in stage 7.0 (TID 719)
[2025-07-19T18:30:22.734+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 108.0 in stage 7.0 (TID 711) in 95 ms on 8b44f3d35cfa (executor driver) (109/200)
[2025-07-19T18:30:22.734+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/112/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/112/.2.delta.be9b5f31-d7f8-4329-89ae-bcb7bf80b92e.TID715.tmp
[2025-07-19T18:30:22.734+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.735+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@424f534c
[2025-07-19T18:30:22.736+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=115, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.737+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=115),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/115] for update
[2025-07-19T18:30:22.737+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.738+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.739+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.739+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/109/.2.delta.7e964bae-7f41-4450-a16d-573b58efd5a9.TID712.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/109/2.delta
[2025-07-19T18:30:22.739+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=109),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/109] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/109/2.delta
[2025-07-19T18:30:22.739+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@157acc58
[2025-07-19T18:30:22.740+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 109 (task 712, attempt 0, stage 7.0)
[2025-07-19T18:30:22.741+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/113/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/113/.2.delta.009acd68-7252-4e25-a2df-f66257dc00bf.TID716.tmp
[2025-07-19T18:30:22.742+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=116, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.744+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=116),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/116] for update
[2025-07-19T18:30:22.744+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.744+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 109 (task 712, attempt 0, stage 7.0)
[2025-07-19T18:30:22.744+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 109.0 in stage 7.0 (TID 712). 5829 bytes result sent to driver
[2025-07-19T18:30:22.744+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 109.0 in stage 7.0 (TID 712) in 64 ms on 8b44f3d35cfa (executor driver) (110/200)
[2025-07-19T18:30:22.745+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 117.0 in stage 7.0 (TID 720) (8b44f3d35cfa, executor driver, partition 117, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.745+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 117.0 in stage 7.0 (TID 720)
[2025-07-19T18:30:22.745+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.745+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.746+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/110/.2.delta.4cee2bde-217c-4d30-8803-b05ac266a066.TID713.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/110/2.delta
[2025-07-19T18:30:22.746+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=110),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/110] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/110/2.delta
[2025-07-19T18:30:22.746+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@50ad8743
[2025-07-19T18:30:22.746+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 110 (task 713, attempt 0, stage 7.0)
[2025-07-19T18:30:22.747+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=117, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.748+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=117),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/117] for update
[2025-07-19T18:30:22.748+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/115/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/115/.2.delta.dadd0f10-6f51-4512-9525-dc3f1abf803b.TID718.tmp
[2025-07-19T18:30:22.749+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.750+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 110 (task 713, attempt 0, stage 7.0)
[2025-07-19T18:30:22.750+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 110.0 in stage 7.0 (TID 713). 5829 bytes result sent to driver
[2025-07-19T18:30:22.750+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 118.0 in stage 7.0 (TID 721) (8b44f3d35cfa, executor driver, partition 118, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.751+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/116/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/116/.2.delta.508c1f24-cc53-4bf9-8d8b-f28bb1cf594c.TID719.tmp
[2025-07-19T18:30:22.752+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 110.0 in stage 7.0 (TID 713) in 72 ms on 8b44f3d35cfa (executor driver) (111/200)
[2025-07-19T18:30:22.753+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 118.0 in stage 7.0 (TID 721)
[2025-07-19T18:30:22.753+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/114/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/114/.2.delta.f76d3363-f35c-4715-96a7-97cb960b35e3.TID717.tmp
[2025-07-19T18:30:22.754+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.754+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.754+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ee762da
[2025-07-19T18:30:22.755+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=118, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.755+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=118),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/118] for update
[2025-07-19T18:30:22.755+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/117/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/117/.2.delta.7d4eb224-0937-4b78-8ef9-3b93944c7706.TID720.tmp
[2025-07-19T18:30:22.756+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/111/.2.delta.e1add91b-e1d1-4c47-8e07-e5a7948ee69f.TID714.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/111/2.delta
[2025-07-19T18:30:22.757+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=111),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/111] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/111/2.delta
[2025-07-19T18:30:22.757+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.757+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 111 (task 714, attempt 0, stage 7.0)
[2025-07-19T18:30:22.758+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 111 (task 714, attempt 0, stage 7.0)
[2025-07-19T18:30:22.759+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 111.0 in stage 7.0 (TID 714). 5829 bytes result sent to driver
[2025-07-19T18:30:22.760+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 119.0 in stage 7.0 (TID 722) (8b44f3d35cfa, executor driver, partition 119, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.760+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 111.0 in stage 7.0 (TID 714) in 73 ms on 8b44f3d35cfa (executor driver) (112/200)
[2025-07-19T18:30:22.761+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 119.0 in stage 7.0 (TID 722)
[2025-07-19T18:30:22.761+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.762+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.762+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@60d4d27f
[2025-07-19T18:30:22.762+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/118/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/118/.2.delta.386ea319-cd02-4756-8ba2-4453d43b8fe4.TID721.tmp
[2025-07-19T18:30:22.762+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=119, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.762+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=119),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/119] for update
[2025-07-19T18:30:22.762+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.763+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/112/.2.delta.be9b5f31-d7f8-4329-89ae-bcb7bf80b92e.TID715.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/112/2.delta
[2025-07-19T18:30:22.764+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=112),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/112] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/112/2.delta
[2025-07-19T18:30:22.766+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 112 (task 715, attempt 0, stage 7.0)
[2025-07-19T18:30:22.768+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/119/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/119/.2.delta.d57fa615-e882-489b-a496-5abb9962e574.TID722.tmp
[2025-07-19T18:30:22.770+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/113/.2.delta.009acd68-7252-4e25-a2df-f66257dc00bf.TID716.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/113/2.delta
[2025-07-19T18:30:22.771+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=113),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/113] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/113/2.delta
[2025-07-19T18:30:22.772+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 113 (task 716, attempt 0, stage 7.0)
[2025-07-19T18:30:22.772+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/115/.2.delta.dadd0f10-6f51-4512-9525-dc3f1abf803b.TID718.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/115/2.delta
[2025-07-19T18:30:22.773+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=115),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/115] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/115/2.delta
[2025-07-19T18:30:22.773+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 115 (task 718, attempt 0, stage 7.0)
[2025-07-19T18:30:22.774+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 113 (task 716, attempt 0, stage 7.0)
[2025-07-19T18:30:22.775+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 113.0 in stage 7.0 (TID 716). 5829 bytes result sent to driver
[2025-07-19T18:30:22.776+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 112 (task 715, attempt 0, stage 7.0)
[2025-07-19T18:30:22.776+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 120.0 in stage 7.0 (TID 723) (8b44f3d35cfa, executor driver, partition 120, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.776+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 112.0 in stage 7.0 (TID 715). 5829 bytes result sent to driver
[2025-07-19T18:30:22.776+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 113.0 in stage 7.0 (TID 716) in 69 ms on 8b44f3d35cfa (executor driver) (113/200)
[2025-07-19T18:30:22.776+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 115 (task 718, attempt 0, stage 7.0)
[2025-07-19T18:30:22.776+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/116/.2.delta.508c1f24-cc53-4bf9-8d8b-f28bb1cf594c.TID719.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/116/2.delta
[2025-07-19T18:30:22.777+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=116),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/116] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/116/2.delta
[2025-07-19T18:30:22.778+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 120.0 in stage 7.0 (TID 723)
[2025-07-19T18:30:22.780+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 115.0 in stage 7.0 (TID 718). 5829 bytes result sent to driver
[2025-07-19T18:30:22.780+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 121.0 in stage 7.0 (TID 724) (8b44f3d35cfa, executor driver, partition 121, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.781+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 116 (task 719, attempt 0, stage 7.0)
[2025-07-19T18:30:22.781+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 115.0 in stage 7.0 (TID 718) in 62 ms on 8b44f3d35cfa (executor driver) (114/200)
[2025-07-19T18:30:22.782+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 121.0 in stage 7.0 (TID 724)
[2025-07-19T18:30:22.782+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 122.0 in stage 7.0 (TID 725) (8b44f3d35cfa, executor driver, partition 122, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.784+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.784+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.785+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 122.0 in stage 7.0 (TID 725)
[2025-07-19T18:30:22.785+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/117/.2.delta.7d4eb224-0937-4b78-8ef9-3b93944c7706.TID720.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/117/2.delta
[2025-07-19T18:30:22.786+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=117),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/117] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/117/2.delta
[2025-07-19T18:30:22.786+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 117 (task 720, attempt 0, stage 7.0)
[2025-07-19T18:30:22.786+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.787+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.787+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 112.0 in stage 7.0 (TID 715) in 81 ms on 8b44f3d35cfa (executor driver) (115/200)
[2025-07-19T18:30:22.787+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.787+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T18:30:22.787+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/114/.2.delta.f76d3363-f35c-4715-96a7-97cb960b35e3.TID717.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/114/2.delta
[2025-07-19T18:30:22.787+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=114),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/114] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/114/2.delta
[2025-07-19T18:30:22.788+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 114 (task 717, attempt 0, stage 7.0)
[2025-07-19T18:30:22.788+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 114 (task 717, attempt 0, stage 7.0)
[2025-07-19T18:30:22.788+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 116 (task 719, attempt 0, stage 7.0)
[2025-07-19T18:30:22.791+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 117 (task 720, attempt 0, stage 7.0)
[2025-07-19T18:30:22.792+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 114.0 in stage 7.0 (TID 717). 5829 bytes result sent to driver
[2025-07-19T18:30:22.792+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 116.0 in stage 7.0 (TID 719). 5829 bytes result sent to driver
[2025-07-19T18:30:22.792+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 117.0 in stage 7.0 (TID 720). 5829 bytes result sent to driver
[2025-07-19T18:30:22.792+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 123.0 in stage 7.0 (TID 726) (8b44f3d35cfa, executor driver, partition 123, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.792+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 124.0 in stage 7.0 (TID 727) (8b44f3d35cfa, executor driver, partition 124, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.793+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 125.0 in stage 7.0 (TID 728) (8b44f3d35cfa, executor driver, partition 125, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.793+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 124.0 in stage 7.0 (TID 727)
[2025-07-19T18:30:22.793+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 123.0 in stage 7.0 (TID 726)
[2025-07-19T18:30:22.793+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 125.0 in stage 7.0 (TID 728)
[2025-07-19T18:30:22.793+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 114.0 in stage 7.0 (TID 717) in 75 ms on 8b44f3d35cfa (executor driver) (116/200)
[2025-07-19T18:30:22.793+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 117.0 in stage 7.0 (TID 720) in 56 ms on 8b44f3d35cfa (executor driver) (117/200)
[2025-07-19T18:30:22.793+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 116.0 in stage 7.0 (TID 719) in 71 ms on 8b44f3d35cfa (executor driver) (118/200)
[2025-07-19T18:30:22.793+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.793+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.794+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.795+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.796+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.796+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.796+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@14363d8c
[2025-07-19T18:30:22.796+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=122, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.796+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=122),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/122] for update
[2025-07-19T18:30:22.796+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.796+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a543d28
[2025-07-19T18:30:22.796+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=125, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.796+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=125),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/125] for update
[2025-07-19T18:30:22.797+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/119/.2.delta.d57fa615-e882-489b-a496-5abb9962e574.TID722.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/119/2.delta
[2025-07-19T18:30:22.797+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=119),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/119] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/119/2.delta
[2025-07-19T18:30:22.797+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/118/.2.delta.386ea319-cd02-4756-8ba2-4453d43b8fe4.TID721.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/118/2.delta
[2025-07-19T18:30:22.797+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=118),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/118] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/118/2.delta
[2025-07-19T18:30:22.797+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 119 (task 722, attempt 0, stage 7.0)
[2025-07-19T18:30:22.798+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.799+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3af40900
[2025-07-19T18:30:22.799+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 118 (task 721, attempt 0, stage 7.0)
[2025-07-19T18:30:22.800+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=124, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.800+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=124),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/124] for update
[2025-07-19T18:30:22.800+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d50e9ed
[2025-07-19T18:30:22.801+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.801+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=123, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.802+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=123),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/123] for update
[2025-07-19T18:30:22.803+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 118 (task 721, attempt 0, stage 7.0)
[2025-07-19T18:30:22.804+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 118.0 in stage 7.0 (TID 721). 5829 bytes result sent to driver
[2025-07-19T18:30:22.805+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/122/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/122/.2.delta.557063cc-71b4-4d79-be32-a5a54f4f95bc.TID725.tmp
[2025-07-19T18:30:22.807+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 126.0 in stage 7.0 (TID 729) (8b44f3d35cfa, executor driver, partition 126, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.808+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 118.0 in stage 7.0 (TID 721) in 62 ms on 8b44f3d35cfa (executor driver) (119/200)
[2025-07-19T18:30:22.809+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6baca699
[2025-07-19T18:30:22.809+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=120, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.809+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 126.0 in stage 7.0 (TID 729)
[2025-07-19T18:30:22.810+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.810+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=120),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/120] for update
[2025-07-19T18:30:22.810+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 119 (task 722, attempt 0, stage 7.0)
[2025-07-19T18:30:22.810+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 119.0 in stage 7.0 (TID 722). 5829 bytes result sent to driver
[2025-07-19T18:30:22.810+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.810+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 127.0 in stage 7.0 (TID 730) (8b44f3d35cfa, executor driver, partition 127, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.810+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 127.0 in stage 7.0 (TID 730)
[2025-07-19T18:30:22.810+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@60d75612
[2025-07-19T18:30:22.810+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.810+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 119.0 in stage 7.0 (TID 722) in 52 ms on 8b44f3d35cfa (executor driver) (120/200)
[2025-07-19T18:30:22.810+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:22.811+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=121, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.811+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=121),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/121] for update
[2025-07-19T18:30:22.811+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/125/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/125/.2.delta.21ae7e95-8a35-4cca-bc41-fa6d4adee458.TID728.tmp
[2025-07-19T18:30:22.812+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@76546cd
[2025-07-19T18:30:22.812+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.812+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.812+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T18:30:22.813+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=126, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.815+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=126),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/126] for update
[2025-07-19T18:30:22.816+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@50b497b4
[2025-07-19T18:30:22.816+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=127, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.816+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=127),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/127] for update
[2025-07-19T18:30:22.816+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/124/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/124/.2.delta.b27bb2f9-db21-44ed-bb3d-bb253f139952.TID727.tmp
[2025-07-19T18:30:22.816+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.817+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.819+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/120/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/120/.2.delta.68efc1a0-08fe-42e0-b854-4a5956f8207c.TID723.tmp
[2025-07-19T18:30:22.820+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/123/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/123/.2.delta.c52d9ca4-ad83-4890-ac10-ba8014e3045b.TID726.tmp
[2025-07-19T18:30:22.821+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/121/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/121/.2.delta.f478f5f9-8470-4322-8356-e29fb37a8d8d.TID724.tmp
[2025-07-19T18:30:22.826+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/126/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/126/.2.delta.4d1447d2-47ef-43f6-8906-d70908628b75.TID729.tmp
[2025-07-19T18:30:22.828+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/127/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/127/.2.delta.bbace0aa-8e1c-4083-bfbe-4aeb6d2dda69.TID730.tmp
[2025-07-19T18:30:22.843+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/122/.2.delta.557063cc-71b4-4d79-be32-a5a54f4f95bc.TID725.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/122/2.delta
[2025-07-19T18:30:22.844+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=122),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/122] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/122/2.delta
[2025-07-19T18:30:22.844+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 122 (task 725, attempt 0, stage 7.0)
[2025-07-19T18:30:22.844+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/124/.2.delta.b27bb2f9-db21-44ed-bb3d-bb253f139952.TID727.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/124/2.delta
[2025-07-19T18:30:22.845+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=124),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/124] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/124/2.delta
[2025-07-19T18:30:22.849+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 124 (task 727, attempt 0, stage 7.0)
[2025-07-19T18:30:22.852+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 124 (task 727, attempt 0, stage 7.0)
[2025-07-19T18:30:22.853+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 124.0 in stage 7.0 (TID 727). 5829 bytes result sent to driver
[2025-07-19T18:30:22.853+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 128.0 in stage 7.0 (TID 731) (8b44f3d35cfa, executor driver, partition 128, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.853+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 124.0 in stage 7.0 (TID 727) in 67 ms on 8b44f3d35cfa (executor driver) (121/200)
[2025-07-19T18:30:22.854+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 128.0 in stage 7.0 (TID 731)
[2025-07-19T18:30:22.856+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/125/.2.delta.21ae7e95-8a35-4cca-bc41-fa6d4adee458.TID728.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/125/2.delta
[2025-07-19T18:30:22.857+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=125),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/125] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/125/2.delta
[2025-07-19T18:30:22.857+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/123/.2.delta.c52d9ca4-ad83-4890-ac10-ba8014e3045b.TID726.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/123/2.delta
[2025-07-19T18:30:22.857+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=123),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/123] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/123/2.delta
[2025-07-19T18:30:22.857+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 123 (task 726, attempt 0, stage 7.0)
[2025-07-19T18:30:22.857+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 125 (task 728, attempt 0, stage 7.0)
[2025-07-19T18:30:22.857+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.857+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.861+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 122 (task 725, attempt 0, stage 7.0)
[2025-07-19T18:30:22.861+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/127/.2.delta.bbace0aa-8e1c-4083-bfbe-4aeb6d2dda69.TID730.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/127/2.delta
[2025-07-19T18:30:22.862+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=127),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/127] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/127/2.delta
[2025-07-19T18:30:22.862+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3af4fcbc
[2025-07-19T18:30:22.862+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=128, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.863+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=128),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/128] for update
[2025-07-19T18:30:22.863+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 122.0 in stage 7.0 (TID 725). 5829 bytes result sent to driver
[2025-07-19T18:30:22.863+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 127 (task 730, attempt 0, stage 7.0)
[2025-07-19T18:30:22.863+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 129.0 in stage 7.0 (TID 732) (8b44f3d35cfa, executor driver, partition 129, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.863+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.863+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 122.0 in stage 7.0 (TID 725) in 84 ms on 8b44f3d35cfa (executor driver) (122/200)
[2025-07-19T18:30:22.864+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 129.0 in stage 7.0 (TID 732)
[2025-07-19T18:30:22.864+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 123 (task 726, attempt 0, stage 7.0)
[2025-07-19T18:30:22.866+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 123.0 in stage 7.0 (TID 726). 5872 bytes result sent to driver
[2025-07-19T18:30:22.867+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 125 (task 728, attempt 0, stage 7.0)
[2025-07-19T18:30:22.871+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 130.0 in stage 7.0 (TID 733) (8b44f3d35cfa, executor driver, partition 130, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.873+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/126/.2.delta.4d1447d2-47ef-43f6-8906-d70908628b75.TID729.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/126/2.delta
[2025-07-19T18:30:22.874+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=126),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/126] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/126/2.delta
[2025-07-19T18:30:22.875+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 123.0 in stage 7.0 (TID 726) in 83 ms on 8b44f3d35cfa (executor driver) (123/200)
[2025-07-19T18:30:22.877+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/120/.2.delta.68efc1a0-08fe-42e0-b854-4a5956f8207c.TID723.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/120/2.delta
[2025-07-19T18:30:22.878+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=120),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/120] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/120/2.delta
[2025-07-19T18:30:22.879+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 125.0 in stage 7.0 (TID 728). 5786 bytes result sent to driver
[2025-07-19T18:30:22.879+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 120 (task 723, attempt 0, stage 7.0)
[2025-07-19T18:30:22.880+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.880+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T18:30:22.881+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 130.0 in stage 7.0 (TID 733)
[2025-07-19T18:30:22.881+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 131.0 in stage 7.0 (TID 734) (8b44f3d35cfa, executor driver, partition 131, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.881+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 126 (task 729, attempt 0, stage 7.0)
[2025-07-19T18:30:22.881+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 131.0 in stage 7.0 (TID 734)
[2025-07-19T18:30:22.881+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 125.0 in stage 7.0 (TID 728) in 85 ms on 8b44f3d35cfa (executor driver) (124/200)
[2025-07-19T18:30:22.881+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 127 (task 730, attempt 0, stage 7.0)
[2025-07-19T18:30:22.881+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 127.0 in stage 7.0 (TID 730). 5829 bytes result sent to driver
[2025-07-19T18:30:22.882+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 120 (task 723, attempt 0, stage 7.0)
[2025-07-19T18:30:22.882+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 120.0 in stage 7.0 (TID 723). 5829 bytes result sent to driver
[2025-07-19T18:30:22.882+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/121/.2.delta.f478f5f9-8470-4322-8356-e29fb37a8d8d.TID724.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/121/2.delta
[2025-07-19T18:30:22.882+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=121),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/121] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/121/2.delta
[2025-07-19T18:30:22.882+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.882+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.882+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d964437
[2025-07-19T18:30:22.883+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 132.0 in stage 7.0 (TID 735) (8b44f3d35cfa, executor driver, partition 132, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.883+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=129, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.883+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=129),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/129] for update
[2025-07-19T18:30:22.883+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 126 (task 729, attempt 0, stage 7.0)
[2025-07-19T18:30:22.883+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@129c0091
[2025-07-19T18:30:22.883+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 126.0 in stage 7.0 (TID 729). 5829 bytes result sent to driver
[2025-07-19T18:30:22.883+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=131, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.883+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=131),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/131] for update
[2025-07-19T18:30:22.883+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 121 (task 724, attempt 0, stage 7.0)
[2025-07-19T18:30:22.885+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.886+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 132.0 in stage 7.0 (TID 735)
[2025-07-19T18:30:22.887+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 133.0 in stage 7.0 (TID 736) (8b44f3d35cfa, executor driver, partition 133, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.887+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/128/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/128/.2.delta.f6a73e6f-98cd-4578-8e8d-60aca617c4a3.TID731.tmp
[2025-07-19T18:30:22.888+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 127.0 in stage 7.0 (TID 730) in 70 ms on 8b44f3d35cfa (executor driver) (125/200)
[2025-07-19T18:30:22.888+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 120.0 in stage 7.0 (TID 723) in 104 ms on 8b44f3d35cfa (executor driver) (126/200)
[2025-07-19T18:30:22.889+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 134.0 in stage 7.0 (TID 737) (8b44f3d35cfa, executor driver, partition 134, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.890+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 126.0 in stage 7.0 (TID 729) in 76 ms on 8b44f3d35cfa (executor driver) (127/200)
[2025-07-19T18:30:22.892+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.893+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 134.0 in stage 7.0 (TID 737)
[2025-07-19T18:30:22.893+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.894+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2025-07-19T18:30:22.895+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 133.0 in stage 7.0 (TID 736)
[2025-07-19T18:30:22.896+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.896+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.896+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 121 (task 724, attempt 0, stage 7.0)
[2025-07-19T18:30:22.898+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 121.0 in stage 7.0 (TID 724). 5829 bytes result sent to driver
[2025-07-19T18:30:22.899+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@79d6ab3e
[2025-07-19T18:30:22.899+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 135.0 in stage 7.0 (TID 738) (8b44f3d35cfa, executor driver, partition 135, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.899+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 135.0 in stage 7.0 (TID 738)
[2025-07-19T18:30:22.900+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=132, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.900+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=132),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/132] for update
[2025-07-19T18:30:22.900+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 121.0 in stage 7.0 (TID 724) in 115 ms on 8b44f3d35cfa (executor driver) (128/200)
[2025-07-19T18:30:22.901+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/129/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/129/.2.delta.c394d4ae-0b55-40cd-8667-4829b30d20cb.TID732.tmp
[2025-07-19T18:30:22.901+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.901+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.901+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3a4f98c
[2025-07-19T18:30:22.902+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=135, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.902+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=135),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/135] for update
[2025-07-19T18:30:22.902+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.903+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.903+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1cb56fa0
[2025-07-19T18:30:22.903+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=134, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.904+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=134),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/134] for update
[2025-07-19T18:30:22.904+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@45b09fd0
[2025-07-19T18:30:22.904+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.904+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.905+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.905+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=133, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.905+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=133),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/133] for update
[2025-07-19T18:30:22.906+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.906+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.906+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7641d46e
[2025-07-19T18:30:22.907+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=130, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.909+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.910+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/131/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/131/.2.delta.3a2ac6ea-6056-488c-895e-e684744a91f8.TID734.tmp
[2025-07-19T18:30:22.910+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=130),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/130] for update
[2025-07-19T18:30:22.910+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.910+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/134/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/134/.2.delta.ac00c463-109d-4579-bf76-478bd2bd7917.TID737.tmp
[2025-07-19T18:30:22.913+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/135/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/135/.2.delta.5595eb30-2380-4582-91ea-a2171cd4c331.TID738.tmp
[2025-07-19T18:30:22.917+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/133/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/133/.2.delta.c32af033-fb66-41bd-a821-57c97d7e77e5.TID736.tmp
[2025-07-19T18:30:22.919+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/132/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/132/.2.delta.0ccd8e17-fb12-44ca-99da-32478184cf92.TID735.tmp
[2025-07-19T18:30:22.929+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/130/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/130/.2.delta.681a4bab-2dcd-492e-9c54-b1b7cd137a31.TID733.tmp
[2025-07-19T18:30:22.940+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/128/.2.delta.f6a73e6f-98cd-4578-8e8d-60aca617c4a3.TID731.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/128/2.delta
[2025-07-19T18:30:22.941+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=128),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/128] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/128/2.delta
[2025-07-19T18:30:22.942+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 128 (task 731, attempt 0, stage 7.0)
[2025-07-19T18:30:22.946+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 128 (task 731, attempt 0, stage 7.0)
[2025-07-19T18:30:22.947+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 128.0 in stage 7.0 (TID 731). 5872 bytes result sent to driver
[2025-07-19T18:30:22.948+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 136.0 in stage 7.0 (TID 739) (8b44f3d35cfa, executor driver, partition 136, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.949+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 128.0 in stage 7.0 (TID 731) in 97 ms on 8b44f3d35cfa (executor driver) (129/200)
[2025-07-19T18:30:22.951+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 136.0 in stage 7.0 (TID 739)
[2025-07-19T18:30:22.954+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.959+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:22.962+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/129/.2.delta.c394d4ae-0b55-40cd-8667-4829b30d20cb.TID732.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/129/2.delta
[2025-07-19T18:30:22.963+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=129),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/129] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/129/2.delta
[2025-07-19T18:30:22.966+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@64a0b4a7
[2025-07-19T18:30:22.967+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 129 (task 732, attempt 0, stage 7.0)
[2025-07-19T18:30:22.967+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=136, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.967+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=136),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/136] for update
[2025-07-19T18:30:22.967+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:22.969+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/134/.2.delta.ac00c463-109d-4579-bf76-478bd2bd7917.TID737.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/134/2.delta
[2025-07-19T18:30:22.970+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=134),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/134] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/134/2.delta
[2025-07-19T18:30:22.970+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 129 (task 732, attempt 0, stage 7.0)
[2025-07-19T18:30:22.972+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 129.0 in stage 7.0 (TID 732). 5872 bytes result sent to driver
[2025-07-19T18:30:22.972+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/131/.2.delta.3a2ac6ea-6056-488c-895e-e684744a91f8.TID734.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/131/2.delta
[2025-07-19T18:30:22.972+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=131),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/131] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/131/2.delta
[2025-07-19T18:30:22.973+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 131 (task 734, attempt 0, stage 7.0)
[2025-07-19T18:30:22.974+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 134 (task 737, attempt 0, stage 7.0)
[2025-07-19T18:30:22.975+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 137.0 in stage 7.0 (TID 740) (8b44f3d35cfa, executor driver, partition 137, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.975+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 137.0 in stage 7.0 (TID 740)
[2025-07-19T18:30:22.975+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 129.0 in stage 7.0 (TID 732) in 105 ms on 8b44f3d35cfa (executor driver) (130/200)
[2025-07-19T18:30:22.975+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/135/.2.delta.5595eb30-2380-4582-91ea-a2171cd4c331.TID738.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/135/2.delta
[2025-07-19T18:30:22.975+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=135),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/135] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/135/2.delta
[2025-07-19T18:30:22.975+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 135 (task 738, attempt 0, stage 7.0)
[2025-07-19T18:30:22.975+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.976+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.976+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@519346c9
[2025-07-19T18:30:22.979+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 131 (task 734, attempt 0, stage 7.0)
[2025-07-19T18:30:22.979+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 131.0 in stage 7.0 (TID 734). 5872 bytes result sent to driver
[2025-07-19T18:30:22.979+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 134 (task 737, attempt 0, stage 7.0)
[2025-07-19T18:30:22.980+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=137, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:22.980+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 138.0 in stage 7.0 (TID 741) (8b44f3d35cfa, executor driver, partition 138, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.980+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 134.0 in stage 7.0 (TID 737). 5829 bytes result sent to driver
[2025-07-19T18:30:22.980+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=137),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/137] for update
[2025-07-19T18:30:22.984+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 138.0 in stage 7.0 (TID 741)
[2025-07-19T18:30:22.985+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 139.0 in stage 7.0 (TID 742) (8b44f3d35cfa, executor driver, partition 139, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.985+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 135 (task 738, attempt 0, stage 7.0)
[2025-07-19T18:30:22.987+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 139.0 in stage 7.0 (TID 742)
[2025-07-19T18:30:22.989+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 131.0 in stage 7.0 (TID 734) in 113 ms on 8b44f3d35cfa (executor driver) (131/200)
[2025-07-19T18:30:22.991+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/133/.2.delta.c32af033-fb66-41bd-a821-57c97d7e77e5.TID736.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/133/2.delta
[2025-07-19T18:30:22.992+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=133),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/133] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/133/2.delta
[2025-07-19T18:30:22.993+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/132/.2.delta.0ccd8e17-fb12-44ca-99da-32478184cf92.TID735.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/132/2.delta
[2025-07-19T18:30:22.993+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=132),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/132] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/132/2.delta
[2025-07-19T18:30:22.995+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:22.996+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:22.996+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 135.0 in stage 7.0 (TID 738). 5872 bytes result sent to driver
[2025-07-19T18:30:22.997+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 134.0 in stage 7.0 (TID 737) in 105 ms on 8b44f3d35cfa (executor driver) (132/200)
[2025-07-19T18:30:22.998+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 140.0 in stage 7.0 (TID 743) (8b44f3d35cfa, executor driver, partition 140, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:22.998+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 140.0 in stage 7.0 (TID 743)
[2025-07-19T18:30:22.999+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 135.0 in stage 7.0 (TID 738) in 94 ms on 8b44f3d35cfa (executor driver) (133/200)
[2025-07-19T18:30:22.999+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/136/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/136/.2.delta.2659ce2f-3bf0-43d6-a14d-4056b34ceda5.TID739.tmp
[2025-07-19T18:30:22.999+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.000+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.000+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 132 (task 735, attempt 0, stage 7.0)
[2025-07-19T18:30:23.001+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@66446450
[2025-07-19T18:30:23.001+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.002+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 133 (task 736, attempt 0, stage 7.0)
[2025-07-19T18:30:23.002+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=138, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.002+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=138),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/138] for update
[2025-07-19T18:30:23.003+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b6559e9
[2025-07-19T18:30:23.003+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 133 (task 736, attempt 0, stage 7.0)
[2025-07-19T18:30:23.004+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.004+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 133.0 in stage 7.0 (TID 736). 5872 bytes result sent to driver
[2025-07-19T18:30:23.004+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.006+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Committed partition 132 (task 735, attempt 0, stage 7.0)
[2025-07-19T18:30:23.007+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.007+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=139, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.008+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=139),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/139] for update
[2025-07-19T18:30:23.008+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/130/.2.delta.681a4bab-2dcd-492e-9c54-b1b7cd137a31.TID733.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/130/2.delta
[2025-07-19T18:30:23.009+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=130),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/130] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/130/2.delta
[2025-07-19T18:30:23.011+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Finished task 132.0 in stage 7.0 (TID 735). 5872 bytes result sent to driver
[2025-07-19T18:30:23.012+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO DataWritingSparkTask: Commit authorized for partition 130 (task 733, attempt 0, stage 7.0)
[2025-07-19T18:30:23.012+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.012+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 141.0 in stage 7.0 (TID 744) (8b44f3d35cfa, executor driver, partition 141, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.013+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 141.0 in stage 7.0 (TID 744)
[2025-07-19T18:30:23.015+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Starting task 142.0 in stage 7.0 (TID 745) (8b44f3d35cfa, executor driver, partition 142, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.015+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5374cfbd
[2025-07-19T18:30:23.016+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=140, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.016+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=140),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/140] for update
[2025-07-19T18:30:23.016+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 132.0 in stage 7.0 (TID 735) in 123 ms on 8b44f3d35cfa (executor driver) (134/200)
[2025-07-19T18:30:23.016+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO TaskSetManager: Finished task 133.0 in stage 7.0 (TID 736) in 120 ms on 8b44f3d35cfa (executor driver) (135/200)
[2025-07-19T18:30:23.016+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO Executor: Running task 142.0 in stage 7.0 (TID 745)
[2025-07-19T18:30:23.016+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.016+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.017+0000] {subprocess.py:93} INFO - 25/07/19 18:30:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.017+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.017+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.017+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 130 (task 733, attempt 0, stage 7.0)
[2025-07-19T18:30:23.017+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ab53416
[2025-07-19T18:30:23.018+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 130.0 in stage 7.0 (TID 733). 5872 bytes result sent to driver
[2025-07-19T18:30:23.018+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=142, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.019+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/137/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/137/.2.delta.66656be5-fe4b-41e3-93f0-f8ac4c49c0d6.TID740.tmp
[2025-07-19T18:30:23.019+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 143.0 in stage 7.0 (TID 746) (8b44f3d35cfa, executor driver, partition 143, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.019+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=142),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/142] for update
[2025-07-19T18:30:23.019+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 130.0 in stage 7.0 (TID 733) in 141 ms on 8b44f3d35cfa (executor driver) (136/200)
[2025-07-19T18:30:23.020+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 143.0 in stage 7.0 (TID 746)
[2025-07-19T18:30:23.020+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e1a68f2
[2025-07-19T18:30:23.020+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=141, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.021+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=141),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/141] for update
[2025-07-19T18:30:23.022+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.022+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/138/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/138/.2.delta.1c91f08f-a585-4056-ad4b-85140855eb64.TID741.tmp
[2025-07-19T18:30:23.022+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.023+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/139/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/139/.2.delta.aba60dee-d1d6-41be-b5ce-e6920e9e275d.TID742.tmp
[2025-07-19T18:30:23.024+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/140/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/140/.2.delta.7f111d04-649f-4b2f-9134-6a817c92359a.TID743.tmp
[2025-07-19T18:30:23.025+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.025+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.026+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4712b64e
[2025-07-19T18:30:23.027+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=143, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.028+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=143),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/143] for update
[2025-07-19T18:30:23.028+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.029+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/142/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/142/.2.delta.ca219913-8b51-4ef5-9711-3c1e810559d9.TID745.tmp
[2025-07-19T18:30:23.029+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/141/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/141/.2.delta.997afb86-1cc2-4fa1-a4d8-85870c7a667f.TID744.tmp
[2025-07-19T18:30:23.033+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/143/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/143/.2.delta.2fb898be-42d5-4196-9d9c-df51570d77b4.TID746.tmp
[2025-07-19T18:30:23.041+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/136/.2.delta.2659ce2f-3bf0-43d6-a14d-4056b34ceda5.TID739.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/136/2.delta
[2025-07-19T18:30:23.042+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=136),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/136] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/136/2.delta
[2025-07-19T18:30:23.042+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 136 (task 739, attempt 0, stage 7.0)
[2025-07-19T18:30:23.047+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 136 (task 739, attempt 0, stage 7.0)
[2025-07-19T18:30:23.049+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 136.0 in stage 7.0 (TID 739). 5872 bytes result sent to driver
[2025-07-19T18:30:23.050+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 144.0 in stage 7.0 (TID 747) (8b44f3d35cfa, executor driver, partition 144, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.050+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 136.0 in stage 7.0 (TID 739) in 101 ms on 8b44f3d35cfa (executor driver) (137/200)
[2025-07-19T18:30:23.050+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 144.0 in stage 7.0 (TID 747)
[2025-07-19T18:30:23.050+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.050+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.054+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68d5d885
[2025-07-19T18:30:23.055+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=144, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.055+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=144),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/144] for update
[2025-07-19T18:30:23.056+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.057+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/137/.2.delta.66656be5-fe4b-41e3-93f0-f8ac4c49c0d6.TID740.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/137/2.delta
[2025-07-19T18:30:23.057+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=137),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/137] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/137/2.delta
[2025-07-19T18:30:23.059+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 137 (task 740, attempt 0, stage 7.0)
[2025-07-19T18:30:23.063+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 137 (task 740, attempt 0, stage 7.0)
[2025-07-19T18:30:23.065+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 137.0 in stage 7.0 (TID 740). 5872 bytes result sent to driver
[2025-07-19T18:30:23.066+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/139/.2.delta.aba60dee-d1d6-41be-b5ce-e6920e9e275d.TID742.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/139/2.delta
[2025-07-19T18:30:23.067+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=139),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/139] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/139/2.delta
[2025-07-19T18:30:23.067+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 145.0 in stage 7.0 (TID 748) (8b44f3d35cfa, executor driver, partition 145, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.068+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/140/.2.delta.7f111d04-649f-4b2f-9134-6a817c92359a.TID743.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/140/2.delta
[2025-07-19T18:30:23.068+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=140),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/140] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/140/2.delta
[2025-07-19T18:30:23.070+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 139 (task 742, attempt 0, stage 7.0)
[2025-07-19T18:30:23.070+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 140 (task 743, attempt 0, stage 7.0)
[2025-07-19T18:30:23.071+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 145.0 in stage 7.0 (TID 748)
[2025-07-19T18:30:23.072+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 137.0 in stage 7.0 (TID 740) in 100 ms on 8b44f3d35cfa (executor driver) (138/200)
[2025-07-19T18:30:23.073+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/138/.2.delta.1c91f08f-a585-4056-ad4b-85140855eb64.TID741.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/138/2.delta
[2025-07-19T18:30:23.074+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=138),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/138] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/138/2.delta
[2025-07-19T18:30:23.075+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 138 (task 741, attempt 0, stage 7.0)
[2025-07-19T18:30:23.075+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 140 (task 743, attempt 0, stage 7.0)
[2025-07-19T18:30:23.076+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 139 (task 742, attempt 0, stage 7.0)
[2025-07-19T18:30:23.076+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 140.0 in stage 7.0 (TID 743). 5829 bytes result sent to driver
[2025-07-19T18:30:23.076+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 138 (task 741, attempt 0, stage 7.0)
[2025-07-19T18:30:23.077+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 146.0 in stage 7.0 (TID 749) (8b44f3d35cfa, executor driver, partition 146, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.077+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 139.0 in stage 7.0 (TID 742). 5829 bytes result sent to driver
[2025-07-19T18:30:23.077+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 138.0 in stage 7.0 (TID 741). 5872 bytes result sent to driver
[2025-07-19T18:30:23.077+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 140.0 in stage 7.0 (TID 743) in 88 ms on 8b44f3d35cfa (executor driver) (139/200)
[2025-07-19T18:30:23.078+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 146.0 in stage 7.0 (TID 749)
[2025-07-19T18:30:23.078+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 147.0 in stage 7.0 (TID 750) (8b44f3d35cfa, executor driver, partition 147, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.079+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 148.0 in stage 7.0 (TID 751) (8b44f3d35cfa, executor driver, partition 148, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.079+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 147.0 in stage 7.0 (TID 750)
[2025-07-19T18:30:23.080+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.080+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 148.0 in stage 7.0 (TID 751)
[2025-07-19T18:30:23.081+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 138.0 in stage 7.0 (TID 741) in 100 ms on 8b44f3d35cfa (executor driver) (140/200)
[2025-07-19T18:30:23.082+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T18:30:23.082+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 139.0 in stage 7.0 (TID 742) in 100 ms on 8b44f3d35cfa (executor driver) (141/200)
[2025-07-19T18:30:23.082+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c63a430
[2025-07-19T18:30:23.083+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=145, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.084+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.085+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=145),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/145] for update
[2025-07-19T18:30:23.085+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.086+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.086+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33c694ba
[2025-07-19T18:30:23.088+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=146, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.088+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=146),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/146] for update
[2025-07-19T18:30:23.089+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:23.089+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.090+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.091+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.091+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@61e0f297
[2025-07-19T18:30:23.092+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=147, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.092+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=147),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/147] for update
[2025-07-19T18:30:23.093+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.093+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@29df29a8
[2025-07-19T18:30:23.094+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=148, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.095+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=148),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/148] for update
[2025-07-19T18:30:23.096+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.097+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/144/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/144/.2.delta.2de1151a-71b8-47f9-bf17-52e95171bdbe.TID747.tmp
[2025-07-19T18:30:23.097+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/141/.2.delta.997afb86-1cc2-4fa1-a4d8-85870c7a667f.TID744.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/141/2.delta
[2025-07-19T18:30:23.098+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=141),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/141] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/141/2.delta
[2025-07-19T18:30:23.099+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.100+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 141 (task 744, attempt 0, stage 7.0)
[2025-07-19T18:30:23.101+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/142/.2.delta.ca219913-8b51-4ef5-9711-3c1e810559d9.TID745.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/142/2.delta
[2025-07-19T18:30:23.102+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=142),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/142] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/142/2.delta
[2025-07-19T18:30:23.102+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 141 (task 744, attempt 0, stage 7.0)
[2025-07-19T18:30:23.103+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/143/.2.delta.2fb898be-42d5-4196-9d9c-df51570d77b4.TID746.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/143/2.delta
[2025-07-19T18:30:23.104+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=143),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/143] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/143/2.delta
[2025-07-19T18:30:23.105+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/146/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/146/.2.delta.a419e5b2-99e5-4104-b688-ce1d4d87b659.TID749.tmp
[2025-07-19T18:30:23.106+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 142 (task 745, attempt 0, stage 7.0)
[2025-07-19T18:30:23.107+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 141.0 in stage 7.0 (TID 744). 5829 bytes result sent to driver
[2025-07-19T18:30:23.107+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/145/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/145/.2.delta.bcca3ec6-5748-4f71-b2b9-98699d6c903c.TID748.tmp
[2025-07-19T18:30:23.108+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 149.0 in stage 7.0 (TID 752) (8b44f3d35cfa, executor driver, partition 149, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.109+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 143 (task 746, attempt 0, stage 7.0)
[2025-07-19T18:30:23.109+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/148/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/148/.2.delta.8742767c-14a8-432f-8706-0953d593f148.TID751.tmp
[2025-07-19T18:30:23.110+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/147/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/147/.2.delta.a6c43841-6f75-4620-8bba-c39fc29692c7.TID750.tmp
[2025-07-19T18:30:23.110+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 149.0 in stage 7.0 (TID 752)
[2025-07-19T18:30:23.110+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 142 (task 745, attempt 0, stage 7.0)
[2025-07-19T18:30:23.110+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 142.0 in stage 7.0 (TID 745). 5829 bytes result sent to driver
[2025-07-19T18:30:23.111+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 141.0 in stage 7.0 (TID 744) in 100 ms on 8b44f3d35cfa (executor driver) (142/200)
[2025-07-19T18:30:23.111+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 150.0 in stage 7.0 (TID 753) (8b44f3d35cfa, executor driver, partition 150, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.112+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 150.0 in stage 7.0 (TID 753)
[2025-07-19T18:30:23.113+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 142.0 in stage 7.0 (TID 745) in 100 ms on 8b44f3d35cfa (executor driver) (143/200)
[2025-07-19T18:30:23.113+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 143 (task 746, attempt 0, stage 7.0)
[2025-07-19T18:30:23.114+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 143.0 in stage 7.0 (TID 746). 5829 bytes result sent to driver
[2025-07-19T18:30:23.114+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 151.0 in stage 7.0 (TID 754) (8b44f3d35cfa, executor driver, partition 151, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.114+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 143.0 in stage 7.0 (TID 746) in 92 ms on 8b44f3d35cfa (executor driver) (144/200)
[2025-07-19T18:30:23.114+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.114+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.114+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.114+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.115+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 151.0 in stage 7.0 (TID 754)
[2025-07-19T18:30:23.115+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6b520ffa
[2025-07-19T18:30:23.116+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=149, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.116+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=149),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/149] for update
[2025-07-19T18:30:23.117+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@296f41a6
[2025-07-19T18:30:23.117+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=150, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.117+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=150),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/150] for update
[2025-07-19T18:30:23.118+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.118+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.118+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@459368d8
[2025-07-19T18:30:23.118+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.118+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=151, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.119+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=151),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/151] for update
[2025-07-19T18:30:23.119+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.119+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.120+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/149/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/149/.2.delta.b11f8058-ee00-4746-be07-1e0e0eefb9e9.TID752.tmp
[2025-07-19T18:30:23.124+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/151/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/151/.2.delta.50d679a0-d134-45ab-95f1-ec36d2394bfc.TID754.tmp
[2025-07-19T18:30:23.124+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/150/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/150/.2.delta.e0fdd5af-c36b-4f18-87c0-e4f950b35b2f.TID753.tmp
[2025-07-19T18:30:23.124+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/144/.2.delta.2de1151a-71b8-47f9-bf17-52e95171bdbe.TID747.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/144/2.delta
[2025-07-19T18:30:23.124+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=144),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/144] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/144/2.delta
[2025-07-19T18:30:23.124+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 144 (task 747, attempt 0, stage 7.0)
[2025-07-19T18:30:23.129+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 144 (task 747, attempt 0, stage 7.0)
[2025-07-19T18:30:23.135+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 144.0 in stage 7.0 (TID 747). 5829 bytes result sent to driver
[2025-07-19T18:30:23.137+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 152.0 in stage 7.0 (TID 755) (8b44f3d35cfa, executor driver, partition 152, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.137+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 144.0 in stage 7.0 (TID 747) in 86 ms on 8b44f3d35cfa (executor driver) (145/200)
[2025-07-19T18:30:23.137+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 152.0 in stage 7.0 (TID 755)
[2025-07-19T18:30:23.138+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/145/.2.delta.bcca3ec6-5748-4f71-b2b9-98699d6c903c.TID748.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/145/2.delta
[2025-07-19T18:30:23.138+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=145),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/145] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/145/2.delta
[2025-07-19T18:30:23.139+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/147/.2.delta.a6c43841-6f75-4620-8bba-c39fc29692c7.TID750.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/147/2.delta
[2025-07-19T18:30:23.139+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=147),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/147] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/147/2.delta
[2025-07-19T18:30:23.140+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 147 (task 750, attempt 0, stage 7.0)
[2025-07-19T18:30:23.140+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 145 (task 748, attempt 0, stage 7.0)
[2025-07-19T18:30:23.142+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 145 (task 748, attempt 0, stage 7.0)
[2025-07-19T18:30:23.143+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 147 (task 750, attempt 0, stage 7.0)
[2025-07-19T18:30:23.143+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.144+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:23.145+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/146/.2.delta.a419e5b2-99e5-4104-b688-ce1d4d87b659.TID749.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/146/2.delta
[2025-07-19T18:30:23.145+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=146),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/146] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/146/2.delta
[2025-07-19T18:30:23.145+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 147.0 in stage 7.0 (TID 750). 5829 bytes result sent to driver
[2025-07-19T18:30:23.145+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 146 (task 749, attempt 0, stage 7.0)
[2025-07-19T18:30:23.145+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 145.0 in stage 7.0 (TID 748). 5829 bytes result sent to driver
[2025-07-19T18:30:23.146+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@152019d9
[2025-07-19T18:30:23.146+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=152, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.146+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=152),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/152] for update
[2025-07-19T18:30:23.146+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 153.0 in stage 7.0 (TID 756) (8b44f3d35cfa, executor driver, partition 153, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.146+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 145.0 in stage 7.0 (TID 748) in 80 ms on 8b44f3d35cfa (executor driver) (146/200)
[2025-07-19T18:30:23.147+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 153.0 in stage 7.0 (TID 756)
[2025-07-19T18:30:23.147+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.148+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 154.0 in stage 7.0 (TID 757) (8b44f3d35cfa, executor driver, partition 154, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.148+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/148/.2.delta.8742767c-14a8-432f-8706-0953d593f148.TID751.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/148/2.delta
[2025-07-19T18:30:23.148+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=148),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/148] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/148/2.delta
[2025-07-19T18:30:23.148+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 154.0 in stage 7.0 (TID 757)
[2025-07-19T18:30:23.148+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 147.0 in stage 7.0 (TID 750) in 76 ms on 8b44f3d35cfa (executor driver) (147/200)
[2025-07-19T18:30:23.149+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.150+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 148 (task 751, attempt 0, stage 7.0)
[2025-07-19T18:30:23.151+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.151+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T18:30:23.152+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T18:30:23.153+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d48ef8f
[2025-07-19T18:30:23.154+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=154, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.154+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=154),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/154] for update
[2025-07-19T18:30:23.155+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 146 (task 749, attempt 0, stage 7.0)
[2025-07-19T18:30:23.156+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.156+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 146.0 in stage 7.0 (TID 749). 5829 bytes result sent to driver
[2025-07-19T18:30:23.157+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 155.0 in stage 7.0 (TID 758) (8b44f3d35cfa, executor driver, partition 155, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.157+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/152/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/152/.2.delta.237200b7-b868-4603-9bd8-d8459434ba66.TID755.tmp
[2025-07-19T18:30:23.159+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a315ce0
[2025-07-19T18:30:23.160+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=153, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.161+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=153),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/153] for update
[2025-07-19T18:30:23.161+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 148 (task 751, attempt 0, stage 7.0)
[2025-07-19T18:30:23.162+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 148.0 in stage 7.0 (TID 751). 5829 bytes result sent to driver
[2025-07-19T18:30:23.162+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 146.0 in stage 7.0 (TID 749) in 88 ms on 8b44f3d35cfa (executor driver) (148/200)
[2025-07-19T18:30:23.162+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 156.0 in stage 7.0 (TID 759) (8b44f3d35cfa, executor driver, partition 156, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.162+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/149/.2.delta.b11f8058-ee00-4746-be07-1e0e0eefb9e9.TID752.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/149/2.delta
[2025-07-19T18:30:23.162+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=149),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/149] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/149/2.delta
[2025-07-19T18:30:23.162+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 155.0 in stage 7.0 (TID 758)
[2025-07-19T18:30:23.162+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 148.0 in stage 7.0 (TID 751) in 89 ms on 8b44f3d35cfa (executor driver) (149/200)
[2025-07-19T18:30:23.162+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 156.0 in stage 7.0 (TID 759)
[2025-07-19T18:30:23.163+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.163+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 149 (task 752, attempt 0, stage 7.0)
[2025-07-19T18:30:23.163+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.163+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.163+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/154/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/154/.2.delta.c55ff675-8e5d-40d2-ba5a-e4ce9995ee25.TID757.tmp
[2025-07-19T18:30:23.164+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.169+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73089f1
[2025-07-19T18:30:23.170+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 149 (task 752, attempt 0, stage 7.0)
[2025-07-19T18:30:23.171+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T18:30:23.171+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=155, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.171+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 149.0 in stage 7.0 (TID 752). 5829 bytes result sent to driver
[2025-07-19T18:30:23.172+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=155),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/155] for update
[2025-07-19T18:30:23.172+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 157.0 in stage 7.0 (TID 760) (8b44f3d35cfa, executor driver, partition 157, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.173+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 149.0 in stage 7.0 (TID 752) in 79 ms on 8b44f3d35cfa (executor driver) (150/200)
[2025-07-19T18:30:23.173+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 157.0 in stage 7.0 (TID 760)
[2025-07-19T18:30:23.174+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.174+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@496b8fee
[2025-07-19T18:30:23.174+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.175+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=156, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.175+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.176+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=156),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/156] for update
[2025-07-19T18:30:23.176+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@26383e41
[2025-07-19T18:30:23.177+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=157, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.178+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=157),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/157] for update
[2025-07-19T18:30:23.178+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/153/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/153/.2.delta.5972261e-71d2-4823-946f-78773c1362d8.TID756.tmp
[2025-07-19T18:30:23.179+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/150/.2.delta.e0fdd5af-c36b-4f18-87c0-e4f950b35b2f.TID753.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/150/2.delta
[2025-07-19T18:30:23.179+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=150),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/150] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/150/2.delta
[2025-07-19T18:30:23.180+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.181+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.181+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 150 (task 753, attempt 0, stage 7.0)
[2025-07-19T18:30:23.183+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 150 (task 753, attempt 0, stage 7.0)
[2025-07-19T18:30:23.185+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/155/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/155/.2.delta.b305ee97-1270-471f-abdf-23194913a3ac.TID758.tmp
[2025-07-19T18:30:23.187+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/151/.2.delta.50d679a0-d134-45ab-95f1-ec36d2394bfc.TID754.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/151/2.delta
[2025-07-19T18:30:23.187+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 150.0 in stage 7.0 (TID 753). 5829 bytes result sent to driver
[2025-07-19T18:30:23.188+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=151),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/151] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/151/2.delta
[2025-07-19T18:30:23.188+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 158.0 in stage 7.0 (TID 761) (8b44f3d35cfa, executor driver, partition 158, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.188+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 158.0 in stage 7.0 (TID 761)
[2025-07-19T18:30:23.188+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 150.0 in stage 7.0 (TID 753) in 91 ms on 8b44f3d35cfa (executor driver) (151/200)
[2025-07-19T18:30:23.188+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 151 (task 754, attempt 0, stage 7.0)
[2025-07-19T18:30:23.189+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.189+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.190+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b5f4d7a
[2025-07-19T18:30:23.191+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=158, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.191+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=158),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/158] for update
[2025-07-19T18:30:23.192+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/156/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/156/.2.delta.797f4709-7ece-4344-bbc1-e66a8507ad1e.TID759.tmp
[2025-07-19T18:30:23.194+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 151 (task 754, attempt 0, stage 7.0)
[2025-07-19T18:30:23.194+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.197+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/157/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/157/.2.delta.6cf2915d-8319-4bb4-8c0b-2173a7b285e2.TID760.tmp
[2025-07-19T18:30:23.198+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 151.0 in stage 7.0 (TID 754). 5829 bytes result sent to driver
[2025-07-19T18:30:23.198+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 159.0 in stage 7.0 (TID 762) (8b44f3d35cfa, executor driver, partition 159, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.198+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 151.0 in stage 7.0 (TID 754) in 97 ms on 8b44f3d35cfa (executor driver) (152/200)
[2025-07-19T18:30:23.198+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 159.0 in stage 7.0 (TID 762)
[2025-07-19T18:30:23.199+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.199+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.202+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35f574ca
[2025-07-19T18:30:23.202+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/154/.2.delta.c55ff675-8e5d-40d2-ba5a-e4ce9995ee25.TID757.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/154/2.delta
[2025-07-19T18:30:23.203+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=154),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/154] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/154/2.delta
[2025-07-19T18:30:23.203+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 154 (task 757, attempt 0, stage 7.0)
[2025-07-19T18:30:23.203+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=159, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.203+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=159),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/159] for update
[2025-07-19T18:30:23.206+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.209+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 154 (task 757, attempt 0, stage 7.0)
[2025-07-19T18:30:23.209+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 154.0 in stage 7.0 (TID 757). 5829 bytes result sent to driver
[2025-07-19T18:30:23.210+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 160.0 in stage 7.0 (TID 763) (8b44f3d35cfa, executor driver, partition 160, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.210+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 160.0 in stage 7.0 (TID 763)
[2025-07-19T18:30:23.210+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 154.0 in stage 7.0 (TID 757) in 64 ms on 8b44f3d35cfa (executor driver) (153/200)
[2025-07-19T18:30:23.214+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/152/.2.delta.237200b7-b868-4603-9bd8-d8459434ba66.TID755.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/152/2.delta
[2025-07-19T18:30:23.215+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=152),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/152] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/152/2.delta
[2025-07-19T18:30:23.215+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 152 (task 755, attempt 0, stage 7.0)
[2025-07-19T18:30:23.216+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.216+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.216+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@32035023
[2025-07-19T18:30:23.216+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=160, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.216+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=160),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/160] for update
[2025-07-19T18:30:23.216+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.217+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/158/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/158/.2.delta.374311f0-df2a-46a6-a1f3-dc2ef72a548f.TID761.tmp
[2025-07-19T18:30:23.218+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/159/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/159/.2.delta.c629a894-fefc-4a48-a385-6cd0ae68d6b0.TID762.tmp
[2025-07-19T18:30:23.219+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 152 (task 755, attempt 0, stage 7.0)
[2025-07-19T18:30:23.220+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/153/.2.delta.5972261e-71d2-4823-946f-78773c1362d8.TID756.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/153/2.delta
[2025-07-19T18:30:23.220+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=153),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/153] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/153/2.delta
[2025-07-19T18:30:23.220+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 152.0 in stage 7.0 (TID 755). 5829 bytes result sent to driver
[2025-07-19T18:30:23.220+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 153 (task 756, attempt 0, stage 7.0)
[2025-07-19T18:30:23.221+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 161.0 in stage 7.0 (TID 764) (8b44f3d35cfa, executor driver, partition 161, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.222+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 161.0 in stage 7.0 (TID 764)
[2025-07-19T18:30:23.225+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 153 (task 756, attempt 0, stage 7.0)
[2025-07-19T18:30:23.227+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 153.0 in stage 7.0 (TID 756). 5829 bytes result sent to driver
[2025-07-19T18:30:23.228+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 162.0 in stage 7.0 (TID 765) (8b44f3d35cfa, executor driver, partition 162, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.229+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 152.0 in stage 7.0 (TID 755) in 92 ms on 8b44f3d35cfa (executor driver) (154/200)
[2025-07-19T18:30:23.230+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 153.0 in stage 7.0 (TID 756) in 82 ms on 8b44f3d35cfa (executor driver) (155/200)
[2025-07-19T18:30:23.231+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 162.0 in stage 7.0 (TID 765)
[2025-07-19T18:30:23.231+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.231+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.232+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/155/.2.delta.b305ee97-1270-471f-abdf-23194913a3ac.TID758.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/155/2.delta
[2025-07-19T18:30:23.232+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=155),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/155] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/155/2.delta
[2025-07-19T18:30:23.233+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3e123def
[2025-07-19T18:30:23.234+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/160/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/160/.2.delta.9685b0e1-79d9-4014-89ae-abd008f3aed6.TID763.tmp
[2025-07-19T18:30:23.234+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=161, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.234+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=161),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/161] for update
[2025-07-19T18:30:23.235+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 155 (task 758, attempt 0, stage 7.0)
[2025-07-19T18:30:23.235+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.236+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.236+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a117cb6
[2025-07-19T18:30:23.236+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=162, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.237+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=162),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/162] for update
[2025-07-19T18:30:23.237+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.237+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.238+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 155 (task 758, attempt 0, stage 7.0)
[2025-07-19T18:30:23.238+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 155.0 in stage 7.0 (TID 758). 5829 bytes result sent to driver
[2025-07-19T18:30:23.238+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 163.0 in stage 7.0 (TID 766) (8b44f3d35cfa, executor driver, partition 163, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.238+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 155.0 in stage 7.0 (TID 758) in 80 ms on 8b44f3d35cfa (executor driver) (156/200)
[2025-07-19T18:30:23.239+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 163.0 in stage 7.0 (TID 766)
[2025-07-19T18:30:23.239+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.240+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.241+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/161/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/161/.2.delta.1990ba52-1869-4c56-b22d-a0117a1c7234.TID764.tmp
[2025-07-19T18:30:23.242+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/162/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/162/.2.delta.a31f21c0-4f0b-4cfa-89b4-7124bd1c6874.TID765.tmp
[2025-07-19T18:30:23.243+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@44334d29
[2025-07-19T18:30:23.244+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/156/.2.delta.797f4709-7ece-4344-bbc1-e66a8507ad1e.TID759.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/156/2.delta
[2025-07-19T18:30:23.245+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=156),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/156] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/156/2.delta
[2025-07-19T18:30:23.247+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=163, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.247+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=163),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/163] for update
[2025-07-19T18:30:23.248+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 156 (task 759, attempt 0, stage 7.0)
[2025-07-19T18:30:23.249+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.249+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/157/.2.delta.6cf2915d-8319-4bb4-8c0b-2173a7b285e2.TID760.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/157/2.delta
[2025-07-19T18:30:23.250+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=157),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/157] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/157/2.delta
[2025-07-19T18:30:23.250+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 157 (task 760, attempt 0, stage 7.0)
[2025-07-19T18:30:23.251+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 156 (task 759, attempt 0, stage 7.0)
[2025-07-19T18:30:23.251+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 156.0 in stage 7.0 (TID 759). 5829 bytes result sent to driver
[2025-07-19T18:30:23.251+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 164.0 in stage 7.0 (TID 767) (8b44f3d35cfa, executor driver, partition 164, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.252+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 164.0 in stage 7.0 (TID 767)
[2025-07-19T18:30:23.253+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 156.0 in stage 7.0 (TID 759) in 88 ms on 8b44f3d35cfa (executor driver) (157/200)
[2025-07-19T18:30:23.253+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/163/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/163/.2.delta.d6568b4f-48e1-460f-a743-f452ac20a0d1.TID766.tmp
[2025-07-19T18:30:23.254+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 157 (task 760, attempt 0, stage 7.0)
[2025-07-19T18:30:23.255+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.256+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.256+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 157.0 in stage 7.0 (TID 760). 5829 bytes result sent to driver
[2025-07-19T18:30:23.256+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@328df97d
[2025-07-19T18:30:23.256+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 165.0 in stage 7.0 (TID 768) (8b44f3d35cfa, executor driver, partition 165, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.256+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=164, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.256+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=164),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/164] for update
[2025-07-19T18:30:23.257+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 157.0 in stage 7.0 (TID 760) in 83 ms on 8b44f3d35cfa (executor driver) (158/200)
[2025-07-19T18:30:23.257+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 165.0 in stage 7.0 (TID 768)
[2025-07-19T18:30:23.257+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.258+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.259+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.259+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a863aa8
[2025-07-19T18:30:23.260+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=165, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.260+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=165),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/165] for update
[2025-07-19T18:30:23.262+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.263+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/158/.2.delta.374311f0-df2a-46a6-a1f3-dc2ef72a548f.TID761.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/158/2.delta
[2025-07-19T18:30:23.264+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=158),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/158] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/158/2.delta
[2025-07-19T18:30:23.264+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 158 (task 761, attempt 0, stage 7.0)
[2025-07-19T18:30:23.265+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/159/.2.delta.c629a894-fefc-4a48-a385-6cd0ae68d6b0.TID762.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/159/2.delta
[2025-07-19T18:30:23.266+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=159),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/159] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/159/2.delta
[2025-07-19T18:30:23.266+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 159 (task 762, attempt 0, stage 7.0)
[2025-07-19T18:30:23.266+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/164/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/164/.2.delta.247e3713-3213-4d68-a559-384b68ef9d02.TID767.tmp
[2025-07-19T18:30:23.267+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 158 (task 761, attempt 0, stage 7.0)
[2025-07-19T18:30:23.268+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 158.0 in stage 7.0 (TID 761). 5829 bytes result sent to driver
[2025-07-19T18:30:23.270+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 166.0 in stage 7.0 (TID 769) (8b44f3d35cfa, executor driver, partition 166, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.271+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 158.0 in stage 7.0 (TID 761) in 78 ms on 8b44f3d35cfa (executor driver) (159/200)
[2025-07-19T18:30:23.272+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 166.0 in stage 7.0 (TID 769)
[2025-07-19T18:30:23.274+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/165/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/165/.2.delta.f6bda0c9-661c-4a06-936a-f828c32289ad.TID768.tmp
[2025-07-19T18:30:23.275+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.276+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:23.277+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/160/.2.delta.9685b0e1-79d9-4014-89ae-abd008f3aed6.TID763.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/160/2.delta
[2025-07-19T18:30:23.277+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=160),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/160] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/160/2.delta
[2025-07-19T18:30:23.278+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 159 (task 762, attempt 0, stage 7.0)
[2025-07-19T18:30:23.278+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ab2ebda
[2025-07-19T18:30:23.279+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 159.0 in stage 7.0 (TID 762). 5829 bytes result sent to driver
[2025-07-19T18:30:23.281+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 160 (task 763, attempt 0, stage 7.0)
[2025-07-19T18:30:23.282+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=166, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.283+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=166),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/166] for update
[2025-07-19T18:30:23.283+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 167.0 in stage 7.0 (TID 770) (8b44f3d35cfa, executor driver, partition 167, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.283+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.284+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 159.0 in stage 7.0 (TID 762) in 74 ms on 8b44f3d35cfa (executor driver) (160/200)
[2025-07-19T18:30:23.284+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 167.0 in stage 7.0 (TID 770)
[2025-07-19T18:30:23.285+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 160 (task 763, attempt 0, stage 7.0)
[2025-07-19T18:30:23.286+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 160.0 in stage 7.0 (TID 763). 5829 bytes result sent to driver
[2025-07-19T18:30:23.287+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.287+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.288+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 168.0 in stage 7.0 (TID 771) (8b44f3d35cfa, executor driver, partition 168, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.288+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 160.0 in stage 7.0 (TID 763) in 64 ms on 8b44f3d35cfa (executor driver) (161/200)
[2025-07-19T18:30:23.290+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 168.0 in stage 7.0 (TID 771)
[2025-07-19T18:30:23.290+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@79a15c99
[2025-07-19T18:30:23.290+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=167, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.290+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=167),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/167] for update
[2025-07-19T18:30:23.290+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.290+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.291+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.291+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c3ecc9c
[2025-07-19T18:30:23.291+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/161/.2.delta.1990ba52-1869-4c56-b22d-a0117a1c7234.TID764.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/161/2.delta
[2025-07-19T18:30:23.291+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=161),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/161] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/161/2.delta
[2025-07-19T18:30:23.291+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=168, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.291+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=168),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/168] for update
[2025-07-19T18:30:23.291+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 161 (task 764, attempt 0, stage 7.0)
[2025-07-19T18:30:23.291+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.291+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/166/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/166/.2.delta.e1a08cde-61cf-4cd8-a005-4c147f37ec14.TID769.tmp
[2025-07-19T18:30:23.292+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 161 (task 764, attempt 0, stage 7.0)
[2025-07-19T18:30:23.292+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 161.0 in stage 7.0 (TID 764). 5829 bytes result sent to driver
[2025-07-19T18:30:23.292+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/162/.2.delta.a31f21c0-4f0b-4cfa-89b4-7124bd1c6874.TID765.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/162/2.delta
[2025-07-19T18:30:23.293+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=162),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/162] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/162/2.delta
[2025-07-19T18:30:23.293+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 162 (task 765, attempt 0, stage 7.0)
[2025-07-19T18:30:23.294+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 169.0 in stage 7.0 (TID 772) (8b44f3d35cfa, executor driver, partition 169, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.294+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 169.0 in stage 7.0 (TID 772)
[2025-07-19T18:30:23.295+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 161.0 in stage 7.0 (TID 764) in 63 ms on 8b44f3d35cfa (executor driver) (162/200)
[2025-07-19T18:30:23.296+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.296+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.296+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@326e74fd
[2025-07-19T18:30:23.296+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=169, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.296+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=169),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/169] for update
[2025-07-19T18:30:23.296+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.296+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/168/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/168/.2.delta.1e0b7689-1d09-4002-8098-c75b3d31157a.TID771.tmp
[2025-07-19T18:30:23.296+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/163/.2.delta.d6568b4f-48e1-460f-a743-f452ac20a0d1.TID766.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/163/2.delta
[2025-07-19T18:30:23.296+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=163),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/163] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/163/2.delta
[2025-07-19T18:30:23.297+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 163 (task 766, attempt 0, stage 7.0)
[2025-07-19T18:30:23.297+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/167/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/167/.2.delta.b4804058-fdfe-4d8d-9b8a-7923317d343e.TID770.tmp
[2025-07-19T18:30:23.297+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 163 (task 766, attempt 0, stage 7.0)
[2025-07-19T18:30:23.297+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 163.0 in stage 7.0 (TID 766). 5829 bytes result sent to driver
[2025-07-19T18:30:23.297+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 170.0 in stage 7.0 (TID 773) (8b44f3d35cfa, executor driver, partition 170, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.297+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 163.0 in stage 7.0 (TID 766) in 62 ms on 8b44f3d35cfa (executor driver) (163/200)
[2025-07-19T18:30:23.298+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 170.0 in stage 7.0 (TID 773)
[2025-07-19T18:30:23.299+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/164/.2.delta.247e3713-3213-4d68-a559-384b68ef9d02.TID767.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/164/2.delta
[2025-07-19T18:30:23.299+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=164),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/164] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/164/2.delta
[2025-07-19T18:30:23.300+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.301+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.301+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6bfa05f2
[2025-07-19T18:30:23.302+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=170, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.302+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=170),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/170] for update
[2025-07-19T18:30:23.302+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 164 (task 767, attempt 0, stage 7.0)
[2025-07-19T18:30:23.302+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.302+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/165/.2.delta.f6bda0c9-661c-4a06-936a-f828c32289ad.TID768.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/165/2.delta
[2025-07-19T18:30:23.302+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=165),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/165] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/165/2.delta
[2025-07-19T18:30:23.303+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 165 (task 768, attempt 0, stage 7.0)
[2025-07-19T18:30:23.303+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/169/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/169/.2.delta.20d0101d-5f16-44f6-9dfb-2e67993c3113.TID772.tmp
[2025-07-19T18:30:23.307+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 165 (task 768, attempt 0, stage 7.0)
[2025-07-19T18:30:23.308+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 165.0 in stage 7.0 (TID 768). 5829 bytes result sent to driver
[2025-07-19T18:30:23.308+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 164 (task 767, attempt 0, stage 7.0)
[2025-07-19T18:30:23.309+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 171.0 in stage 7.0 (TID 774) (8b44f3d35cfa, executor driver, partition 171, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.309+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 165.0 in stage 7.0 (TID 768) in 57 ms on 8b44f3d35cfa (executor driver) (164/200)
[2025-07-19T18:30:23.309+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 164.0 in stage 7.0 (TID 767). 5829 bytes result sent to driver
[2025-07-19T18:30:23.309+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/170/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/170/.2.delta.a2205a90-81eb-4ddd-8a9e-a817aa020fa7.TID773.tmp
[2025-07-19T18:30:23.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 171.0 in stage 7.0 (TID 774)
[2025-07-19T18:30:23.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 172.0 in stage 7.0 (TID 775) (8b44f3d35cfa, executor driver, partition 172, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 172.0 in stage 7.0 (TID 775)
[2025-07-19T18:30:23.312+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/166/.2.delta.e1a08cde-61cf-4cd8-a005-4c147f37ec14.TID769.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/166/2.delta
[2025-07-19T18:30:23.313+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=166),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/166] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/166/2.delta
[2025-07-19T18:30:23.314+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 162 (task 765, attempt 0, stage 7.0)
[2025-07-19T18:30:23.315+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 166 (task 769, attempt 0, stage 7.0)
[2025-07-19T18:30:23.315+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 164.0 in stage 7.0 (TID 767) in 67 ms on 8b44f3d35cfa (executor driver) (165/200)
[2025-07-19T18:30:23.316+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.316+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.316+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.317+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.317+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 162.0 in stage 7.0 (TID 765). 5829 bytes result sent to driver
[2025-07-19T18:30:23.318+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 166 (task 769, attempt 0, stage 7.0)
[2025-07-19T18:30:23.318+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@45e3d05f
[2025-07-19T18:30:23.319+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 166.0 in stage 7.0 (TID 769). 5829 bytes result sent to driver
[2025-07-19T18:30:23.319+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=172, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.319+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=172),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/172] for update
[2025-07-19T18:30:23.320+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 173.0 in stage 7.0 (TID 776) (8b44f3d35cfa, executor driver, partition 173, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.320+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 174.0 in stage 7.0 (TID 777) (8b44f3d35cfa, executor driver, partition 174, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.321+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 162.0 in stage 7.0 (TID 765) in 90 ms on 8b44f3d35cfa (executor driver) (166/200)
[2025-07-19T18:30:23.321+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 166.0 in stage 7.0 (TID 769) in 53 ms on 8b44f3d35cfa (executor driver) (167/200)
[2025-07-19T18:30:23.321+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7470ec7d
[2025-07-19T18:30:23.321+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 173.0 in stage 7.0 (TID 776)
[2025-07-19T18:30:23.321+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.322+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=171, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.322+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=171),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/171] for update
[2025-07-19T18:30:23.322+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.322+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 174.0 in stage 7.0 (TID 777)
[2025-07-19T18:30:23.323+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.324+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.324+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.325+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.326+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2fafe779
[2025-07-19T18:30:23.326+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=173, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.326+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=173),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/173] for update
[2025-07-19T18:30:23.326+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/172/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/172/.2.delta.dda0f2e6-c429-4740-8405-c7525d2a4a9b.TID775.tmp
[2025-07-19T18:30:23.327+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@274f4fe8
[2025-07-19T18:30:23.327+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=174, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.327+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=174),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/174] for update
[2025-07-19T18:30:23.327+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/167/.2.delta.b4804058-fdfe-4d8d-9b8a-7923317d343e.TID770.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/167/2.delta
[2025-07-19T18:30:23.328+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=167),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/167] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/167/2.delta
[2025-07-19T18:30:23.328+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.328+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 167 (task 770, attempt 0, stage 7.0)
[2025-07-19T18:30:23.329+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.333+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/171/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/171/.2.delta.c8910a3c-ab30-4b79-906e-4f77e9f70c0f.TID774.tmp
[2025-07-19T18:30:23.333+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 167 (task 770, attempt 0, stage 7.0)
[2025-07-19T18:30:23.341+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 167.0 in stage 7.0 (TID 770). 5915 bytes result sent to driver
[2025-07-19T18:30:23.342+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 175.0 in stage 7.0 (TID 778) (8b44f3d35cfa, executor driver, partition 175, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.342+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/168/.2.delta.1e0b7689-1d09-4002-8098-c75b3d31157a.TID771.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/168/2.delta
[2025-07-19T18:30:23.343+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=168),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/168] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/168/2.delta
[2025-07-19T18:30:23.343+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 175.0 in stage 7.0 (TID 778)
[2025-07-19T18:30:23.344+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 168 (task 771, attempt 0, stage 7.0)
[2025-07-19T18:30:23.346+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 167.0 in stage 7.0 (TID 770) in 72 ms on 8b44f3d35cfa (executor driver) (168/200)
[2025-07-19T18:30:23.346+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/173/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/173/.2.delta.2b8d69ba-2c8f-424c-9025-b0e35a857745.TID776.tmp
[2025-07-19T18:30:23.347+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.348+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.348+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 168 (task 771, attempt 0, stage 7.0)
[2025-07-19T18:30:23.349+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 168.0 in stage 7.0 (TID 771). 5872 bytes result sent to driver
[2025-07-19T18:30:23.349+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 176.0 in stage 7.0 (TID 779) (8b44f3d35cfa, executor driver, partition 176, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.350+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 168.0 in stage 7.0 (TID 771) in 73 ms on 8b44f3d35cfa (executor driver) (169/200)
[2025-07-19T18:30:23.351+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 176.0 in stage 7.0 (TID 779)
[2025-07-19T18:30:23.351+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4aec87
[2025-07-19T18:30:23.351+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/174/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/174/.2.delta.f81d0e7b-0692-44b5-9748-5740156b16c1.TID777.tmp
[2025-07-19T18:30:23.351+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.351+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.351+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=175, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.352+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=175),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/175] for update
[2025-07-19T18:30:23.352+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/169/.2.delta.20d0101d-5f16-44f6-9dfb-2e67993c3113.TID772.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/169/2.delta
[2025-07-19T18:30:23.352+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=169),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/169] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/169/2.delta
[2025-07-19T18:30:23.352+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 169 (task 772, attempt 0, stage 7.0)
[2025-07-19T18:30:23.352+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@653abcbc
[2025-07-19T18:30:23.352+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=176, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.354+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=176),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/176] for update
[2025-07-19T18:30:23.355+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.357+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 169 (task 772, attempt 0, stage 7.0)
[2025-07-19T18:30:23.357+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 169.0 in stage 7.0 (TID 772). 5872 bytes result sent to driver
[2025-07-19T18:30:23.357+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 177.0 in stage 7.0 (TID 780) (8b44f3d35cfa, executor driver, partition 177, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.358+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 177.0 in stage 7.0 (TID 780)
[2025-07-19T18:30:23.358+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 169.0 in stage 7.0 (TID 772) in 72 ms on 8b44f3d35cfa (executor driver) (170/200)
[2025-07-19T18:30:23.358+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.358+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.358+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.358+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63e6aca0
[2025-07-19T18:30:23.358+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=177, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.359+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=177),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/177] for update
[2025-07-19T18:30:23.361+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.363+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/170/.2.delta.a2205a90-81eb-4ddd-8a9e-a817aa020fa7.TID773.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/170/2.delta
[2025-07-19T18:30:23.364+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=170),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/170] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/170/2.delta
[2025-07-19T18:30:23.364+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 170 (task 773, attempt 0, stage 7.0)
[2025-07-19T18:30:23.365+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/172/.2.delta.dda0f2e6-c429-4740-8405-c7525d2a4a9b.TID775.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/172/2.delta
[2025-07-19T18:30:23.367+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=172),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/172] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/172/2.delta
[2025-07-19T18:30:23.368+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/176/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/176/.2.delta.47485f54-0e32-449a-a65c-62cba9390a3f.TID779.tmp
[2025-07-19T18:30:23.369+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 172 (task 775, attempt 0, stage 7.0)
[2025-07-19T18:30:23.370+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 170 (task 773, attempt 0, stage 7.0)
[2025-07-19T18:30:23.370+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 170.0 in stage 7.0 (TID 773). 5872 bytes result sent to driver
[2025-07-19T18:30:23.370+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 178.0 in stage 7.0 (TID 781) (8b44f3d35cfa, executor driver, partition 178, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.371+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 178.0 in stage 7.0 (TID 781)
[2025-07-19T18:30:23.371+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 170.0 in stage 7.0 (TID 773) in 73 ms on 8b44f3d35cfa (executor driver) (171/200)
[2025-07-19T18:30:23.372+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 172 (task 775, attempt 0, stage 7.0)
[2025-07-19T18:30:23.373+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 172.0 in stage 7.0 (TID 775). 5872 bytes result sent to driver
[2025-07-19T18:30:23.374+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 179.0 in stage 7.0 (TID 782) (8b44f3d35cfa, executor driver, partition 179, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.374+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 179.0 in stage 7.0 (TID 782)
[2025-07-19T18:30:23.375+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 172.0 in stage 7.0 (TID 775) in 66 ms on 8b44f3d35cfa (executor driver) (172/200)
[2025-07-19T18:30:23.376+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.378+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.378+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.380+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@21c0cf29
[2025-07-19T18:30:23.380+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=179, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.380+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=179),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/179] for update
[2025-07-19T18:30:23.381+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T18:30:23.381+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.381+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2cbd7f04
[2025-07-19T18:30:23.381+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=178, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.382+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=178),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/178] for update
[2025-07-19T18:30:23.382+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/175/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/175/.2.delta.dc63e2b9-dd6a-4bad-a76b-9d9e1e84d065.TID778.tmp
[2025-07-19T18:30:23.382+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.384+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/177/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/177/.2.delta.ba476a2a-9fc8-4d68-9909-87db15f8c6d1.TID780.tmp
[2025-07-19T18:30:23.389+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/179/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/179/.2.delta.836a4f1f-44b8-48d0-8482-80e95ec7ee3f.TID782.tmp
[2025-07-19T18:30:23.390+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/178/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/178/.2.delta.785e97d3-a4f8-4a92-9c9a-040c30b9488b.TID781.tmp
[2025-07-19T18:30:23.390+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/173/.2.delta.2b8d69ba-2c8f-424c-9025-b0e35a857745.TID776.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/173/2.delta
[2025-07-19T18:30:23.390+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=173),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/173] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/173/2.delta
[2025-07-19T18:30:23.392+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 173 (task 776, attempt 0, stage 7.0)
[2025-07-19T18:30:23.392+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/174/.2.delta.f81d0e7b-0692-44b5-9748-5740156b16c1.TID777.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/174/2.delta
[2025-07-19T18:30:23.393+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/171/.2.delta.c8910a3c-ab30-4b79-906e-4f77e9f70c0f.TID774.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/171/2.delta
[2025-07-19T18:30:23.393+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=171),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/171] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/171/2.delta
[2025-07-19T18:30:23.393+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=174),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/174] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/174/2.delta
[2025-07-19T18:30:23.393+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 171 (task 774, attempt 0, stage 7.0)
[2025-07-19T18:30:23.393+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 174 (task 777, attempt 0, stage 7.0)
[2025-07-19T18:30:23.402+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 173 (task 776, attempt 0, stage 7.0)
[2025-07-19T18:30:23.402+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 173.0 in stage 7.0 (TID 776). 5872 bytes result sent to driver
[2025-07-19T18:30:23.403+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 180.0 in stage 7.0 (TID 783) (8b44f3d35cfa, executor driver, partition 180, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.403+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 180.0 in stage 7.0 (TID 783)
[2025-07-19T18:30:23.406+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 173.0 in stage 7.0 (TID 776) in 89 ms on 8b44f3d35cfa (executor driver) (173/200)
[2025-07-19T18:30:23.407+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 171 (task 774, attempt 0, stage 7.0)
[2025-07-19T18:30:23.407+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 171.0 in stage 7.0 (TID 774). 5872 bytes result sent to driver
[2025-07-19T18:30:23.407+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 174 (task 777, attempt 0, stage 7.0)
[2025-07-19T18:30:23.408+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.409+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:23.409+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 174.0 in stage 7.0 (TID 777). 5872 bytes result sent to driver
[2025-07-19T18:30:23.410+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 181.0 in stage 7.0 (TID 784) (8b44f3d35cfa, executor driver, partition 181, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.410+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 181.0 in stage 7.0 (TID 784)
[2025-07-19T18:30:23.410+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 182.0 in stage 7.0 (TID 785) (8b44f3d35cfa, executor driver, partition 182, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.411+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 174.0 in stage 7.0 (TID 777) in 92 ms on 8b44f3d35cfa (executor driver) (174/200)
[2025-07-19T18:30:23.411+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 171.0 in stage 7.0 (TID 774) in 102 ms on 8b44f3d35cfa (executor driver) (175/200)
[2025-07-19T18:30:23.412+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e203806
[2025-07-19T18:30:23.413+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 182.0 in stage 7.0 (TID 785)
[2025-07-19T18:30:23.414+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=180, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.414+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=180),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/180] for update
[2025-07-19T18:30:23.414+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.414+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.415+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.416+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.418+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:23.419+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/176/.2.delta.47485f54-0e32-449a-a65c-62cba9390a3f.TID779.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/176/2.delta
[2025-07-19T18:30:23.419+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=176),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/176] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/176/2.delta
[2025-07-19T18:30:23.419+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@44a1bdfd
[2025-07-19T18:30:23.419+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=181, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.419+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=181),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/181] for update
[2025-07-19T18:30:23.419+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 176 (task 779, attempt 0, stage 7.0)
[2025-07-19T18:30:23.419+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.419+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@62bb20f9
[2025-07-19T18:30:23.424+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=182, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.426+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=182),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/182] for update
[2025-07-19T18:30:23.428+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 176 (task 779, attempt 0, stage 7.0)
[2025-07-19T18:30:23.428+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 176.0 in stage 7.0 (TID 779). 5829 bytes result sent to driver
[2025-07-19T18:30:23.428+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 183.0 in stage 7.0 (TID 786) (8b44f3d35cfa, executor driver, partition 183, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.428+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 176.0 in stage 7.0 (TID 779) in 80 ms on 8b44f3d35cfa (executor driver) (176/200)
[2025-07-19T18:30:23.428+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 183.0 in stage 7.0 (TID 786)
[2025-07-19T18:30:23.428+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.428+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/180/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/180/.2.delta.b88f06b3-e1b2-4328-926a-d8ce54b72988.TID783.tmp
[2025-07-19T18:30:23.429+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/175/.2.delta.dc63e2b9-dd6a-4bad-a76b-9d9e1e84d065.TID778.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/175/2.delta
[2025-07-19T18:30:23.429+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=175),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/175] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/175/2.delta
[2025-07-19T18:30:23.429+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/181/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/181/.2.delta.c5d44364-5370-4eff-8501-ad3291cf587c.TID784.tmp
[2025-07-19T18:30:23.432+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.432+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.434+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 175 (task 778, attempt 0, stage 7.0)
[2025-07-19T18:30:23.434+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@44068ad4
[2025-07-19T18:30:23.435+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/182/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/182/.2.delta.1bfd239c-8fd5-4edd-ae81-4d6d95dfa7b9.TID785.tmp
[2025-07-19T18:30:23.437+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/177/.2.delta.ba476a2a-9fc8-4d68-9909-87db15f8c6d1.TID780.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/177/2.delta
[2025-07-19T18:30:23.437+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=177),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/177] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/177/2.delta
[2025-07-19T18:30:23.438+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 177 (task 780, attempt 0, stage 7.0)
[2025-07-19T18:30:23.439+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=183, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.439+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=183),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/183] for update
[2025-07-19T18:30:23.440+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/179/.2.delta.836a4f1f-44b8-48d0-8482-80e95ec7ee3f.TID782.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/179/2.delta
[2025-07-19T18:30:23.440+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=179),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/179] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/179/2.delta
[2025-07-19T18:30:23.440+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.443+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/178/.2.delta.785e97d3-a4f8-4a92-9c9a-040c30b9488b.TID781.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/178/2.delta
[2025-07-19T18:30:23.447+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=178),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/178] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/178/2.delta
[2025-07-19T18:30:23.448+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 175 (task 778, attempt 0, stage 7.0)
[2025-07-19T18:30:23.448+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 175.0 in stage 7.0 (TID 778). 5829 bytes result sent to driver
[2025-07-19T18:30:23.449+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 179 (task 782, attempt 0, stage 7.0)
[2025-07-19T18:30:23.450+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 177 (task 780, attempt 0, stage 7.0)
[2025-07-19T18:30:23.450+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 184.0 in stage 7.0 (TID 787) (8b44f3d35cfa, executor driver, partition 184, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.450+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 184.0 in stage 7.0 (TID 787)
[2025-07-19T18:30:23.451+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 177.0 in stage 7.0 (TID 780). 5829 bytes result sent to driver
[2025-07-19T18:30:23.451+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.451+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.452+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 175.0 in stage 7.0 (TID 778) in 110 ms on 8b44f3d35cfa (executor driver) (177/200)
[2025-07-19T18:30:23.454+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5aa320f6
[2025-07-19T18:30:23.455+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=184, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.455+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=184),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/184] for update
[2025-07-19T18:30:23.456+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 178 (task 781, attempt 0, stage 7.0)
[2025-07-19T18:30:23.456+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 179 (task 782, attempt 0, stage 7.0)
[2025-07-19T18:30:23.457+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 179.0 in stage 7.0 (TID 782). 5786 bytes result sent to driver
[2025-07-19T18:30:23.457+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 185.0 in stage 7.0 (TID 788) (8b44f3d35cfa, executor driver, partition 185, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.458+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 186.0 in stage 7.0 (TID 789) (8b44f3d35cfa, executor driver, partition 186, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.458+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/183/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/183/.2.delta.237caff2-f24e-41fd-9c3c-437e3a9c85a8.TID786.tmp
[2025-07-19T18:30:23.458+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.459+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 179.0 in stage 7.0 (TID 782) in 83 ms on 8b44f3d35cfa (executor driver) (178/200)
[2025-07-19T18:30:23.461+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 177.0 in stage 7.0 (TID 780) in 102 ms on 8b44f3d35cfa (executor driver) (179/200)
[2025-07-19T18:30:23.461+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 186.0 in stage 7.0 (TID 789)
[2025-07-19T18:30:23.462+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.462+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.464+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 185.0 in stage 7.0 (TID 788)
[2025-07-19T18:30:23.464+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.465+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.465+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@49682a58
[2025-07-19T18:30:23.466+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 178 (task 781, attempt 0, stage 7.0)
[2025-07-19T18:30:23.466+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/181/.2.delta.c5d44364-5370-4eff-8501-ad3291cf587c.TID784.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/181/2.delta
[2025-07-19T18:30:23.467+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=181),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/181] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/181/2.delta
[2025-07-19T18:30:23.467+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 178.0 in stage 7.0 (TID 781). 5829 bytes result sent to driver
[2025-07-19T18:30:23.467+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 181 (task 784, attempt 0, stage 7.0)
[2025-07-19T18:30:23.468+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 187.0 in stage 7.0 (TID 790) (8b44f3d35cfa, executor driver, partition 187, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.469+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 187.0 in stage 7.0 (TID 790)
[2025-07-19T18:30:23.469+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=186, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.470+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 178.0 in stage 7.0 (TID 781) in 94 ms on 8b44f3d35cfa (executor driver) (180/200)
[2025-07-19T18:30:23.470+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=186),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/186] for update
[2025-07-19T18:30:23.471+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 181 (task 784, attempt 0, stage 7.0)
[2025-07-19T18:30:23.471+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 181.0 in stage 7.0 (TID 784). 5829 bytes result sent to driver
[2025-07-19T18:30:23.473+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.473+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:23.474+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 188.0 in stage 7.0 (TID 791) (8b44f3d35cfa, executor driver, partition 188, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.474+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ff7899b
[2025-07-19T18:30:23.474+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 181.0 in stage 7.0 (TID 784) in 58 ms on 8b44f3d35cfa (executor driver) (181/200)
[2025-07-19T18:30:23.475+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 188.0 in stage 7.0 (TID 791)
[2025-07-19T18:30:23.475+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=185, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.475+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=185),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/185] for update
[2025-07-19T18:30:23.475+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.476+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.476+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@302637f8
[2025-07-19T18:30:23.477+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.477+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.478+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=187, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.479+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=187),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/187] for update
[2025-07-19T18:30:23.480+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/180/.2.delta.b88f06b3-e1b2-4328-926a-d8ce54b72988.TID783.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/180/2.delta
[2025-07-19T18:30:23.480+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=180),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/180] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/180/2.delta
[2025-07-19T18:30:23.480+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 180 (task 783, attempt 0, stage 7.0)
[2025-07-19T18:30:23.480+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/184/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/184/.2.delta.bd6b7132-3dee-4dd4-af6f-195bb4f4d5dc.TID787.tmp
[2025-07-19T18:30:23.480+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@13c90fef
[2025-07-19T18:30:23.481+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=188, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.481+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=188),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/188] for update
[2025-07-19T18:30:23.482+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.482+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.482+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/182/.2.delta.1bfd239c-8fd5-4edd-ae81-4d6d95dfa7b9.TID785.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/182/2.delta
[2025-07-19T18:30:23.482+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=182),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/182] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/182/2.delta
[2025-07-19T18:30:23.483+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 182 (task 785, attempt 0, stage 7.0)
[2025-07-19T18:30:23.483+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 180 (task 783, attempt 0, stage 7.0)
[2025-07-19T18:30:23.484+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 180.0 in stage 7.0 (TID 783). 5829 bytes result sent to driver
[2025-07-19T18:30:23.484+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 189.0 in stage 7.0 (TID 792) (8b44f3d35cfa, executor driver, partition 189, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.484+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/185/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/185/.2.delta.34b71d4d-1c17-459d-8e69-0e9aaa72f759.TID788.tmp
[2025-07-19T18:30:23.485+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 180.0 in stage 7.0 (TID 783) in 78 ms on 8b44f3d35cfa (executor driver) (182/200)
[2025-07-19T18:30:23.485+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 189.0 in stage 7.0 (TID 792)
[2025-07-19T18:30:23.485+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/187/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/187/.2.delta.3d6356b7-8b94-4ebe-99a9-dba9658e18d8.TID790.tmp
[2025-07-19T18:30:23.485+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 182 (task 785, attempt 0, stage 7.0)
[2025-07-19T18:30:23.485+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.485+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.485+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/186/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/186/.2.delta.81960cde-c8d7-4520-9f4b-ef9b27d5e7c8.TID789.tmp
[2025-07-19T18:30:23.485+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/188/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/188/.2.delta.a14f796a-13cf-46fc-9b90-5c972be11603.TID791.tmp
[2025-07-19T18:30:23.485+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 182.0 in stage 7.0 (TID 785). 5829 bytes result sent to driver
[2025-07-19T18:30:23.486+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 190.0 in stage 7.0 (TID 793) (8b44f3d35cfa, executor driver, partition 190, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.486+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 182.0 in stage 7.0 (TID 785) in 76 ms on 8b44f3d35cfa (executor driver) (183/200)
[2025-07-19T18:30:23.486+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 190.0 in stage 7.0 (TID 793)
[2025-07-19T18:30:23.486+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.486+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52cab057
[2025-07-19T18:30:23.486+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:23.488+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=189, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.488+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=189),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/189] for update
[2025-07-19T18:30:23.490+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@396e5145
[2025-07-19T18:30:23.491+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=190, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.492+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=190),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/190] for update
[2025-07-19T18:30:23.492+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.494+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.497+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/183/.2.delta.237caff2-f24e-41fd-9c3c-437e3a9c85a8.TID786.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/183/2.delta
[2025-07-19T18:30:23.498+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=183),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/183] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/183/2.delta
[2025-07-19T18:30:23.498+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 183 (task 786, attempt 0, stage 7.0)
[2025-07-19T18:30:23.499+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/190/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/190/.2.delta.4475c35c-de92-4ad5-bed3-ee4efae17aef.TID793.tmp
[2025-07-19T18:30:23.500+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 183 (task 786, attempt 0, stage 7.0)
[2025-07-19T18:30:23.501+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/184/.2.delta.bd6b7132-3dee-4dd4-af6f-195bb4f4d5dc.TID787.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/184/2.delta
[2025-07-19T18:30:23.502+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/189/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/189/.2.delta.e93c8450-bdc8-49f1-950f-f89e6f9ddc50.TID792.tmp
[2025-07-19T18:30:23.503+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=184),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/184] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/184/2.delta
[2025-07-19T18:30:23.503+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 183.0 in stage 7.0 (TID 786). 5829 bytes result sent to driver
[2025-07-19T18:30:23.503+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 184 (task 787, attempt 0, stage 7.0)
[2025-07-19T18:30:23.504+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 191.0 in stage 7.0 (TID 794) (8b44f3d35cfa, executor driver, partition 191, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.504+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 183.0 in stage 7.0 (TID 786) in 78 ms on 8b44f3d35cfa (executor driver) (184/200)
[2025-07-19T18:30:23.504+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 191.0 in stage 7.0 (TID 794)
[2025-07-19T18:30:23.508+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 184 (task 787, attempt 0, stage 7.0)
[2025-07-19T18:30:23.509+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 184.0 in stage 7.0 (TID 787). 5786 bytes result sent to driver
[2025-07-19T18:30:23.509+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.509+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.510+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 192.0 in stage 7.0 (TID 795) (8b44f3d35cfa, executor driver, partition 192, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.510+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7fc353f6
[2025-07-19T18:30:23.510+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 192.0 in stage 7.0 (TID 795)
[2025-07-19T18:30:23.510+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 184.0 in stage 7.0 (TID 787) in 59 ms on 8b44f3d35cfa (executor driver) (185/200)
[2025-07-19T18:30:23.510+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=191, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.511+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=191),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/191] for update
[2025-07-19T18:30:23.511+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.511+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.511+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@79104059
[2025-07-19T18:30:23.511+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/186/.2.delta.81960cde-c8d7-4520-9f4b-ef9b27d5e7c8.TID789.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/186/2.delta
[2025-07-19T18:30:23.511+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=186),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/186] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/186/2.delta
[2025-07-19T18:30:23.511+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.512+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=192, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.512+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=192),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/192] for update
[2025-07-19T18:30:23.512+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 186 (task 789, attempt 0, stage 7.0)
[2025-07-19T18:30:23.513+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/188/.2.delta.a14f796a-13cf-46fc-9b90-5c972be11603.TID791.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/188/2.delta
[2025-07-19T18:30:23.514+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=188),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/188] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/188/2.delta
[2025-07-19T18:30:23.515+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.515+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 188 (task 791, attempt 0, stage 7.0)
[2025-07-19T18:30:23.516+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 186 (task 789, attempt 0, stage 7.0)
[2025-07-19T18:30:23.516+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 188 (task 791, attempt 0, stage 7.0)
[2025-07-19T18:30:23.517+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/187/.2.delta.3d6356b7-8b94-4ebe-99a9-dba9658e18d8.TID790.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/187/2.delta
[2025-07-19T18:30:23.518+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=187),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/187] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/187/2.delta
[2025-07-19T18:30:23.519+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/185/.2.delta.34b71d4d-1c17-459d-8e69-0e9aaa72f759.TID788.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/185/2.delta
[2025-07-19T18:30:23.520+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=185),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/185] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/185/2.delta
[2025-07-19T18:30:23.521+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 187 (task 790, attempt 0, stage 7.0)
[2025-07-19T18:30:23.521+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 185 (task 788, attempt 0, stage 7.0)
[2025-07-19T18:30:23.521+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 188.0 in stage 7.0 (TID 791). 5829 bytes result sent to driver
[2025-07-19T18:30:23.522+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 186.0 in stage 7.0 (TID 789). 5829 bytes result sent to driver
[2025-07-19T18:30:23.522+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 193.0 in stage 7.0 (TID 796) (8b44f3d35cfa, executor driver, partition 193, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.522+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 194.0 in stage 7.0 (TID 797) (8b44f3d35cfa, executor driver, partition 194, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.522+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 186.0 in stage 7.0 (TID 789) in 61 ms on 8b44f3d35cfa (executor driver) (186/200)
[2025-07-19T18:30:23.522+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 194.0 in stage 7.0 (TID 797)
[2025-07-19T18:30:23.522+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 193.0 in stage 7.0 (TID 796)
[2025-07-19T18:30:23.522+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 188.0 in stage 7.0 (TID 791) in 51 ms on 8b44f3d35cfa (executor driver) (187/200)
[2025-07-19T18:30:23.522+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.522+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.522+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@64329a27
[2025-07-19T18:30:23.522+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.523+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.523+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=194, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.523+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=194),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/194] for update
[2025-07-19T18:30:23.523+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/191/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/191/.2.delta.9213b067-2d0c-48fa-a09a-df98985e9bd4.TID794.tmp
[2025-07-19T18:30:23.523+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 187 (task 790, attempt 0, stage 7.0)
[2025-07-19T18:30:23.524+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@494a14e
[2025-07-19T18:30:23.524+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 185 (task 788, attempt 0, stage 7.0)
[2025-07-19T18:30:23.524+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=193, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.524+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 185.0 in stage 7.0 (TID 788). 5829 bytes result sent to driver
[2025-07-19T18:30:23.524+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=193),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/193] for update
[2025-07-19T18:30:23.525+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 187.0 in stage 7.0 (TID 790). 5829 bytes result sent to driver
[2025-07-19T18:30:23.525+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 195.0 in stage 7.0 (TID 798) (8b44f3d35cfa, executor driver, partition 195, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.525+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 195.0 in stage 7.0 (TID 798)
[2025-07-19T18:30:23.526+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/192/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/192/.2.delta.7314f4c9-5c40-4a12-a3d9-d201bcf2c7b9.TID795.tmp
[2025-07-19T18:30:23.526+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 196.0 in stage 7.0 (TID 799) (8b44f3d35cfa, executor driver, partition 196, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.527+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.527+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 187.0 in stage 7.0 (TID 790) in 61 ms on 8b44f3d35cfa (executor driver) (188/200)
[2025-07-19T18:30:23.527+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 185.0 in stage 7.0 (TID 788) in 69 ms on 8b44f3d35cfa (executor driver) (189/200)
[2025-07-19T18:30:23.527+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.527+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 196.0 in stage 7.0 (TID 799)
[2025-07-19T18:30:23.527+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.527+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.527+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.527+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.528+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@626d8cd0
[2025-07-19T18:30:23.528+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=196, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.529+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=196),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/196] for update
[2025-07-19T18:30:23.529+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/193/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/193/.2.delta.354ff955-f19a-4441-85ac-d7b8d203872c.TID796.tmp
[2025-07-19T18:30:23.530+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.530+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@10f6f169
[2025-07-19T18:30:23.531+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/194/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/194/.2.delta.9c557262-8c05-4b0c-af91-2d6801fa82f8.TID797.tmp
[2025-07-19T18:30:23.531+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=195, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.532+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=195),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/195] for update
[2025-07-19T18:30:23.532+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.532+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/189/.2.delta.e93c8450-bdc8-49f1-950f-f89e6f9ddc50.TID792.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/189/2.delta
[2025-07-19T18:30:23.533+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=189),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/189] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/189/2.delta
[2025-07-19T18:30:23.533+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 189 (task 792, attempt 0, stage 7.0)
[2025-07-19T18:30:23.535+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 189 (task 792, attempt 0, stage 7.0)
[2025-07-19T18:30:23.537+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 189.0 in stage 7.0 (TID 792). 5829 bytes result sent to driver
[2025-07-19T18:30:23.537+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 197.0 in stage 7.0 (TID 800) (8b44f3d35cfa, executor driver, partition 197, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.537+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 189.0 in stage 7.0 (TID 792) in 58 ms on 8b44f3d35cfa (executor driver) (190/200)
[2025-07-19T18:30:23.538+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 197.0 in stage 7.0 (TID 800)
[2025-07-19T18:30:23.541+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.543+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.544+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/196/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/196/.2.delta.7f6653f6-d6a1-4448-987c-d205726a717b.TID799.tmp
[2025-07-19T18:30:23.544+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@459503ae
[2025-07-19T18:30:23.544+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=197, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.544+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=197),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/197] for update
[2025-07-19T18:30:23.544+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.546+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/195/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/195/.2.delta.cdef77b6-fca5-4294-b154-8766107bad99.TID798.tmp
[2025-07-19T18:30:23.551+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/191/.2.delta.9213b067-2d0c-48fa-a09a-df98985e9bd4.TID794.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/191/2.delta
[2025-07-19T18:30:23.552+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=191),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/191] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/191/2.delta
[2025-07-19T18:30:23.552+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 191 (task 794, attempt 0, stage 7.0)
[2025-07-19T18:30:23.553+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/190/.2.delta.4475c35c-de92-4ad5-bed3-ee4efae17aef.TID793.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/190/2.delta
[2025-07-19T18:30:23.553+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=190),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/190] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/190/2.delta
[2025-07-19T18:30:23.555+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 191 (task 794, attempt 0, stage 7.0)
[2025-07-19T18:30:23.559+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 190 (task 793, attempt 0, stage 7.0)
[2025-07-19T18:30:23.560+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 191.0 in stage 7.0 (TID 794). 5829 bytes result sent to driver
[2025-07-19T18:30:23.560+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/197/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/197/.2.delta.e0435db6-adb0-43fa-bc65-2c28e95cfaf1.TID800.tmp
[2025-07-19T18:30:23.561+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 198.0 in stage 7.0 (TID 801) (8b44f3d35cfa, executor driver, partition 198, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.562+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 191.0 in stage 7.0 (TID 794) in 58 ms on 8b44f3d35cfa (executor driver) (191/200)
[2025-07-19T18:30:23.563+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 190 (task 793, attempt 0, stage 7.0)
[2025-07-19T18:30:23.563+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 198.0 in stage 7.0 (TID 801)
[2025-07-19T18:30:23.563+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 190.0 in stage 7.0 (TID 793). 5786 bytes result sent to driver
[2025-07-19T18:30:23.564+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 199.0 in stage 7.0 (TID 802) (8b44f3d35cfa, executor driver, partition 199, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.564+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 190.0 in stage 7.0 (TID 793) in 79 ms on 8b44f3d35cfa (executor driver) (192/200)
[2025-07-19T18:30:23.564+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 199.0 in stage 7.0 (TID 802)
[2025-07-19T18:30:23.565+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.566+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.567+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/192/.2.delta.7314f4c9-5c40-4a12-a3d9-d201bcf2c7b9.TID795.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/192/2.delta
[2025-07-19T18:30:23.568+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=192),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/192] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/192/2.delta
[2025-07-19T18:30:23.568+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 192 (task 795, attempt 0, stage 7.0)
[2025-07-19T18:30:23.570+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d5b0875
[2025-07-19T18:30:23.571+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=199, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.571+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=199),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/199] for update
[2025-07-19T18:30:23.571+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.571+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.571+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2025-07-19T18:30:23.571+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 192 (task 795, attempt 0, stage 7.0)
[2025-07-19T18:30:23.571+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35d76ed8
[2025-07-19T18:30:23.573+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 192.0 in stage 7.0 (TID 795). 5829 bytes result sent to driver
[2025-07-19T18:30:23.573+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=198, storeName=default ],e7c2576d-5139-486e-a3a4-0d60a8d676b4) is active
[2025-07-19T18:30:23.574+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=198),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/198] for update
[2025-07-19T18:30:23.574+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/193/.2.delta.354ff955-f19a-4441-85ac-d7b8d203872c.TID796.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/193/2.delta
[2025-07-19T18:30:23.574+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=193),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/193] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/193/2.delta
[2025-07-19T18:30:23.574+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.574+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 193 (task 796, attempt 0, stage 7.0)
[2025-07-19T18:30:23.575+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/194/.2.delta.9c557262-8c05-4b0c-af91-2d6801fa82f8.TID797.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/194/2.delta
[2025-07-19T18:30:23.575+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=194),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/194] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/194/2.delta
[2025-07-19T18:30:23.576+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/199/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/199/.2.delta.196c3787-7909-404d-800c-ac5fd54ea788.TID802.tmp
[2025-07-19T18:30:23.577+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 194 (task 797, attempt 0, stage 7.0)
[2025-07-19T18:30:23.577+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 193 (task 796, attempt 0, stage 7.0)
[2025-07-19T18:30:23.577+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 193.0 in stage 7.0 (TID 796). 5829 bytes result sent to driver
[2025-07-19T18:30:23.579+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 803) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.581+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 0.0 in stage 9.0 (TID 803)
[2025-07-19T18:30:23.581+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 804) (8b44f3d35cfa, executor driver, partition 1, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.582+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 193.0 in stage 7.0 (TID 796) in 64 ms on 8b44f3d35cfa (executor driver) (193/200)
[2025-07-19T18:30:23.582+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/198/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/198/.2.delta.1cf1a449-a1ad-4242-9c83-2c3893eec0a0.TID801.tmp
[2025-07-19T18:30:23.582+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 1.0 in stage 9.0 (TID 804)
[2025-07-19T18:30:23.583+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 192.0 in stage 7.0 (TID 795) in 75 ms on 8b44f3d35cfa (executor driver) (194/200)
[2025-07-19T18:30:23.583+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/196/.2.delta.7f6653f6-d6a1-4448-987c-d205726a717b.TID799.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/196/2.delta
[2025-07-19T18:30:23.584+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=196),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/196] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/196/2.delta
[2025-07-19T18:30:23.585+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 196 (task 799, attempt 0, stage 7.0)
[2025-07-19T18:30:23.586+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.586+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.586+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 194 (task 797, attempt 0, stage 7.0)
[2025-07-19T18:30:23.586+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@10e0ae48
[2025-07-19T18:30:23.586+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.586+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.586+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 194.0 in stage 7.0 (TID 797). 5829 bytes result sent to driver
[2025-07-19T18:30:23.587+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 805) (8b44f3d35cfa, executor driver, partition 2, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.587+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=0, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.587+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/0] for update
[2025-07-19T18:30:23.587+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 2.0 in stage 9.0 (TID 805)
[2025-07-19T18:30:23.587+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 196 (task 799, attempt 0, stage 7.0)
[2025-07-19T18:30:23.587+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 196.0 in stage 7.0 (TID 799). 5786 bytes result sent to driver
[2025-07-19T18:30:23.587+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 806) (8b44f3d35cfa, executor driver, partition 3, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.587+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 194.0 in stage 7.0 (TID 797) in 72 ms on 8b44f3d35cfa (executor driver) (195/200)
[2025-07-19T18:30:23.588+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 196.0 in stage 7.0 (TID 799) in 66 ms on 8b44f3d35cfa (executor driver) (196/200)
[2025-07-19T18:30:23.588+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@453358df
[2025-07-19T18:30:23.589+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 3.0 in stage 9.0 (TID 806)
[2025-07-19T18:30:23.590+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.590+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:23.591+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.591+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=1, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.591+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/1] for update
[2025-07-19T18:30:23.592+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.592+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.594+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7ac58838
[2025-07-19T18:30:23.594+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=2, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.595+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/2] for update
[2025-07-19T18:30:23.597+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T18:30:23.598+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@27bc86be
[2025-07-19T18:30:23.599+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=3, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.599+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/3] for update
[2025-07-19T18:30:23.600+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.600+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodeGenerator: Code generated in 7.769417 ms
[2025-07-19T18:30:23.600+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.602+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/195/.2.delta.cdef77b6-fca5-4294-b154-8766107bad99.TID798.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/195/2.delta
[2025-07-19T18:30:23.603+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=195),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/195] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/195/2.delta
[2025-07-19T18:30:23.603+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 195 (task 798, attempt 0, stage 7.0)
[2025-07-19T18:30:23.605+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 195 (task 798, attempt 0, stage 7.0)
[2025-07-19T18:30:23.605+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 195.0 in stage 7.0 (TID 798). 5829 bytes result sent to driver
[2025-07-19T18:30:23.607+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/197/.2.delta.e0435db6-adb0-43fa-bc65-2c28e95cfaf1.TID800.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/197/2.delta
[2025-07-19T18:30:23.608+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=197),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/197] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/197/2.delta
[2025-07-19T18:30:23.609+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/1/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/1/.2.delta.3af090db-ac23-4800-aeab-c39e3c715582.TID804.tmp
[2025-07-19T18:30:23.610+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/0/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/0/.2.delta.d96017b0-a380-40f4-998c-9905ece1745d.TID803.tmp
[2025-07-19T18:30:23.610+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 4.0 in stage 9.0 (TID 807) (8b44f3d35cfa, executor driver, partition 4, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.610+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 197 (task 800, attempt 0, stage 7.0)
[2025-07-19T18:30:23.611+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/199/.2.delta.196c3787-7909-404d-800c-ac5fd54ea788.TID802.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/199/2.delta
[2025-07-19T18:30:23.611+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=199),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/199] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/199/2.delta
[2025-07-19T18:30:23.611+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 199 (task 802, attempt 0, stage 7.0)
[2025-07-19T18:30:23.612+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 4.0 in stage 9.0 (TID 807)
[2025-07-19T18:30:23.612+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/3/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/3/.2.delta.8267263a-c1ba-4710-8ac5-cac24cf21a39.TID806.tmp
[2025-07-19T18:30:23.613+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 195.0 in stage 7.0 (TID 798) in 94 ms on 8b44f3d35cfa (executor driver) (197/200)
[2025-07-19T18:30:23.614+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.614+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.618+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/2/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/2/.2.delta.3d7cf607-0076-4d6f-b663-a443a76607c3.TID805.tmp
[2025-07-19T18:30:23.619+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 197 (task 800, attempt 0, stage 7.0)
[2025-07-19T18:30:23.621+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 199 (task 802, attempt 0, stage 7.0)
[2025-07-19T18:30:23.622+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40b2f9a6
[2025-07-19T18:30:23.623+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=4, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.623+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/4] for update
[2025-07-19T18:30:23.623+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 199.0 in stage 7.0 (TID 802). 5829 bytes result sent to driver
[2025-07-19T18:30:23.623+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 197.0 in stage 7.0 (TID 800). 5829 bytes result sent to driver
[2025-07-19T18:30:23.625+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 5.0 in stage 9.0 (TID 808) (8b44f3d35cfa, executor driver, partition 5, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.627+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 6.0 in stage 9.0 (TID 809) (8b44f3d35cfa, executor driver, partition 6, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.628+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 5.0 in stage 9.0 (TID 808)
[2025-07-19T18:30:23.629+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 6.0 in stage 9.0 (TID 809)
[2025-07-19T18:30:23.629+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.630+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.631+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.632+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.633+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.634+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 199.0 in stage 7.0 (TID 802) in 61 ms on 8b44f3d35cfa (executor driver) (198/200)
[2025-07-19T18:30:23.634+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 197.0 in stage 7.0 (TID 800) in 85 ms on 8b44f3d35cfa (executor driver) (199/200)
[2025-07-19T18:30:23.634+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c310a3c
[2025-07-19T18:30:23.635+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=6, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.635+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/6] for update
[2025-07-19T18:30:23.636+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.636+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56a5b2b6
[2025-07-19T18:30:23.637+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=5, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.637+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/5] for update
[2025-07-19T18:30:23.638+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.640+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/4/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/4/.2.delta.7a379130-baa3-4a1a-b05a-c09ee605f911.TID807.tmp
[2025-07-19T18:30:23.642+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/198/.2.delta.1cf1a449-a1ad-4242-9c83-2c3893eec0a0.TID801.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/198/2.delta
[2025-07-19T18:30:23.643+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=198),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/198] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/state/0/198/2.delta
[2025-07-19T18:30:23.645+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 198 (task 801, attempt 0, stage 7.0)
[2025-07-19T18:30:23.645+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/6/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/6/.2.delta.a2103563-3600-46c8-a6ec-319164d61e06.TID809.tmp
[2025-07-19T18:30:23.645+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 198 (task 801, attempt 0, stage 7.0)
[2025-07-19T18:30:23.645+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/5/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/5/.2.delta.2aa18f9e-7979-48bb-9d74-05cad8c3efd0.TID808.tmp
[2025-07-19T18:30:23.645+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 198.0 in stage 7.0 (TID 801). 5829 bytes result sent to driver
[2025-07-19T18:30:23.646+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 7.0 in stage 9.0 (TID 810) (8b44f3d35cfa, executor driver, partition 7, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.646+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 198.0 in stage 7.0 (TID 801) in 81 ms on 8b44f3d35cfa (executor driver) (200/200)
[2025-07-19T18:30:23.646+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool
[2025-07-19T18:30:23.646+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DAGScheduler: ResultStage 7 (start at <unknown>:0) finished in 5.271 s
[2025-07-19T18:30:23.646+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-19T18:30:23.646+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
[2025-07-19T18:30:23.646+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DAGScheduler: Job 3 finished: start at <unknown>:0, took 5.336266 s
[2025-07-19T18:30:23.646+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 1, writer: IcebergStreamingWrite(table=my_catalog.bronze.Checkins_raw, format=PARQUET)] is committing.
[2025-07-19T18:30:23.647+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO SparkWrite: Committing epoch 1 for query 987ca175-704b-42a6-8146-d1b15494abbf in append mode
[2025-07-19T18:30:23.648+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/1/.2.delta.3af090db-ac23-4800-aeab-c39e3c715582.TID804.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/1/2.delta
[2025-07-19T18:30:23.649+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/1] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/1/2.delta
[2025-07-19T18:30:23.650+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 7.0 in stage 9.0 (TID 810)
[2025-07-19T18:30:23.651+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 1 (task 804, attempt 0, stage 9.0)
[2025-07-19T18:30:23.651+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/0/.2.delta.d96017b0-a380-40f4-998c-9905ece1745d.TID803.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/0/2.delta
[2025-07-19T18:30:23.652+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/0] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/0/2.delta
[2025-07-19T18:30:23.653+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.654+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.655+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 1 (task 804, attempt 0, stage 9.0)
[2025-07-19T18:30:23.656+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 1.0 in stage 9.0 (TID 804). 5829 bytes result sent to driver
[2025-07-19T18:30:23.658+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 803, attempt 0, stage 9.0)
[2025-07-19T18:30:23.658+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35ae690b
[2025-07-19T18:30:23.659+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 8.0 in stage 9.0 (TID 811) (8b44f3d35cfa, executor driver, partition 8, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.660+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=7, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.660+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/7] for update
[2025-07-19T18:30:23.661+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 804) in 70 ms on 8b44f3d35cfa (executor driver) (1/200)
[2025-07-19T18:30:23.661+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 8.0 in stage 9.0 (TID 811)
[2025-07-19T18:30:23.663+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.664+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.664+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.665+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/3/.2.delta.8267263a-c1ba-4710-8ac5-cac24cf21a39.TID806.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/3/2.delta
[2025-07-19T18:30:23.666+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/3] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/3/2.delta
[2025-07-19T18:30:23.667+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/2/.2.delta.3d7cf607-0076-4d6f-b663-a443a76607c3.TID805.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/2/2.delta
[2025-07-19T18:30:23.667+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/2] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/2/2.delta
[2025-07-19T18:30:23.668+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 3 (task 806, attempt 0, stage 9.0)
[2025-07-19T18:30:23.668+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 2 (task 805, attempt 0, stage 9.0)
[2025-07-19T18:30:23.668+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 0 (task 803, attempt 0, stage 9.0)
[2025-07-19T18:30:23.669+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 0.0 in stage 9.0 (TID 803). 5829 bytes result sent to driver
[2025-07-19T18:30:23.669+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 9.0 in stage 9.0 (TID 812) (8b44f3d35cfa, executor driver, partition 9, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.670+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 803) in 82 ms on 8b44f3d35cfa (executor driver) (2/200)
[2025-07-19T18:30:23.671+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO SparkWrite: Committing streaming append with 0 new data files to table my_catalog.bronze.Checkins_raw
[2025-07-19T18:30:23.672+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 9.0 in stage 9.0 (TID 812)
[2025-07-19T18:30:23.672+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 2 (task 805, attempt 0, stage 9.0)
[2025-07-19T18:30:23.673+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 2.0 in stage 9.0 (TID 805). 5829 bytes result sent to driver
[2025-07-19T18:30:23.673+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 805) in 76 ms on 8b44f3d35cfa (executor driver) (3/200)
[2025-07-19T18:30:23.673+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@331f051a
[2025-07-19T18:30:23.673+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 10.0 in stage 9.0 (TID 813) (8b44f3d35cfa, executor driver, partition 10, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.673+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 3 (task 806, attempt 0, stage 9.0)
[2025-07-19T18:30:23.674+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 10.0 in stage 9.0 (TID 813)
[2025-07-19T18:30:23.674+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.674+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.674+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=8, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.674+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/8] for update
[2025-07-19T18:30:23.676+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 3.0 in stage 9.0 (TID 806). 5829 bytes result sent to driver
[2025-07-19T18:30:23.676+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 11.0 in stage 9.0 (TID 814) (8b44f3d35cfa, executor driver, partition 11, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.676+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 806) in 76 ms on 8b44f3d35cfa (executor driver) (4/200)
[2025-07-19T18:30:23.677+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 11.0 in stage 9.0 (TID 814)
[2025-07-19T18:30:23.677+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.677+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.677+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.677+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/7/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/7/.2.delta.7b35abb7-4488-4831-a2d7-a9946b06574e.TID810.tmp
[2025-07-19T18:30:23.677+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2526730b
[2025-07-19T18:30:23.677+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.678+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.678+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=10, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.680+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=10),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/10] for update
[2025-07-19T18:30:23.681+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@125deafb
[2025-07-19T18:30:23.684+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.686+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=9, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.687+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/9] for update
[2025-07-19T18:30:23.687+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/5/.2.delta.2aa18f9e-7979-48bb-9d74-05cad8c3efd0.TID808.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/5/2.delta
[2025-07-19T18:30:23.687+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/5] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/5/2.delta
[2025-07-19T18:30:23.687+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 5 (task 808, attempt 0, stage 9.0)
[2025-07-19T18:30:23.687+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@616dc34b
[2025-07-19T18:30:23.688+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.689+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/6/.2.delta.a2103563-3600-46c8-a6ec-319164d61e06.TID809.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/6/2.delta
[2025-07-19T18:30:23.690+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/6] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/6/2.delta
[2025-07-19T18:30:23.692+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=11, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.693+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=11),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/11] for update
[2025-07-19T18:30:23.694+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 6 (task 809, attempt 0, stage 9.0)
[2025-07-19T18:30:23.694+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/4/.2.delta.7a379130-baa3-4a1a-b05a-c09ee605f911.TID807.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/4/2.delta
[2025-07-19T18:30:23.695+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/4] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/4/2.delta
[2025-07-19T18:30:23.695+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 4 (task 807, attempt 0, stage 9.0)
[2025-07-19T18:30:23.697+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.699+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 5 (task 808, attempt 0, stage 9.0)
[2025-07-19T18:30:23.700+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 5.0 in stage 9.0 (TID 808). 5872 bytes result sent to driver
[2025-07-19T18:30:23.700+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 6 (task 809, attempt 0, stage 9.0)
[2025-07-19T18:30:23.700+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 4 (task 807, attempt 0, stage 9.0)
[2025-07-19T18:30:23.701+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 6.0 in stage 9.0 (TID 809). 5872 bytes result sent to driver
[2025-07-19T18:30:23.701+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 4.0 in stage 9.0 (TID 807). 5872 bytes result sent to driver
[2025-07-19T18:30:23.701+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 12.0 in stage 9.0 (TID 815) (8b44f3d35cfa, executor driver, partition 12, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.702+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 12.0 in stage 9.0 (TID 815)
[2025-07-19T18:30:23.702+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 13.0 in stage 9.0 (TID 816) (8b44f3d35cfa, executor driver, partition 13, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.702+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 14.0 in stage 9.0 (TID 817) (8b44f3d35cfa, executor driver, partition 14, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.703+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 14.0 in stage 9.0 (TID 817)
[2025-07-19T18:30:23.704+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 13.0 in stage 9.0 (TID 816)
[2025-07-19T18:30:23.705+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/8/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/8/.2.delta.da7e8e3c-9064-461a-91cc-cffa76997ae1.TID811.tmp
[2025-07-19T18:30:23.705+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 6.0 in stage 9.0 (TID 809) in 67 ms on 8b44f3d35cfa (executor driver) (5/200)
[2025-07-19T18:30:23.705+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 4.0 in stage 9.0 (TID 807) in 78 ms on 8b44f3d35cfa (executor driver) (6/200)
[2025-07-19T18:30:23.706+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 5.0 in stage 9.0 (TID 808) in 68 ms on 8b44f3d35cfa (executor driver) (7/200)
[2025-07-19T18:30:23.706+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.706+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.707+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.707+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.707+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@641c942a
[2025-07-19T18:30:23.708+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=12, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.709+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=12),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/12] for update
[2025-07-19T18:30:23.710+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.710+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.711+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/10/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/10/.2.delta.96990b79-92ad-4bea-8123-17fea8885a6e.TID813.tmp
[2025-07-19T18:30:23.711+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.713+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/9/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/9/.2.delta.3da86938-5fc3-4133-826d-4b59a0adc363.TID812.tmp
[2025-07-19T18:30:23.714+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@382534af
[2025-07-19T18:30:23.715+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=13, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.717+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=13),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/13] for update
[2025-07-19T18:30:23.717+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3299ac1a
[2025-07-19T18:30:23.719+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=14, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.720+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=14),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/14] for update
[2025-07-19T18:30:23.721+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.721+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/11/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/11/.2.delta.3843ebfd-ea39-4ce0-b3a4-be13ad40df3a.TID814.tmp
[2025-07-19T18:30:23.722+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.722+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/13/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/13/.2.delta.2ea32eb0-8b13-4ec1-9195-02e18f635fa4.TID816.tmp
[2025-07-19T18:30:23.722+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/12/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/12/.2.delta.0d11597b-3844-4bdb-91f5-92b599d2c96c.TID815.tmp
[2025-07-19T18:30:23.723+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/7/.2.delta.7b35abb7-4488-4831-a2d7-a9946b06574e.TID810.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/7/2.delta
[2025-07-19T18:30:23.723+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/7] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/7/2.delta
[2025-07-19T18:30:23.723+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 7 (task 810, attempt 0, stage 9.0)
[2025-07-19T18:30:23.723+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 7 (task 810, attempt 0, stage 9.0)
[2025-07-19T18:30:23.724+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 7.0 in stage 9.0 (TID 810). 5872 bytes result sent to driver
[2025-07-19T18:30:23.724+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 15.0 in stage 9.0 (TID 818) (8b44f3d35cfa, executor driver, partition 15, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.725+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 7.0 in stage 9.0 (TID 810) in 82 ms on 8b44f3d35cfa (executor driver) (8/200)
[2025-07-19T18:30:23.725+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 15.0 in stage 9.0 (TID 818)
[2025-07-19T18:30:23.729+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.730+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.733+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3033c23e
[2025-07-19T18:30:23.734+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/14/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/14/.2.delta.de261a3f-6b9f-4dfb-9efb-4e90aabd4e35.TID817.tmp
[2025-07-19T18:30:23.735+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=15, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.736+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=15),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/15] for update
[2025-07-19T18:30:23.736+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/11/.2.delta.3843ebfd-ea39-4ce0-b3a4-be13ad40df3a.TID814.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/11/2.delta
[2025-07-19T18:30:23.737+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=11),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/11] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/11/2.delta
[2025-07-19T18:30:23.737+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 11 (task 814, attempt 0, stage 9.0)
[2025-07-19T18:30:23.737+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/8/.2.delta.da7e8e3c-9064-461a-91cc-cffa76997ae1.TID811.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/8/2.delta
[2025-07-19T18:30:23.737+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/8] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/8/2.delta
[2025-07-19T18:30:23.738+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 8 (task 811, attempt 0, stage 9.0)
[2025-07-19T18:30:23.738+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.738+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/9/.2.delta.3da86938-5fc3-4133-826d-4b59a0adc363.TID812.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/9/2.delta
[2025-07-19T18:30:23.738+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/9] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/9/2.delta
[2025-07-19T18:30:23.738+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 9 (task 812, attempt 0, stage 9.0)
[2025-07-19T18:30:23.743+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/10/.2.delta.96990b79-92ad-4bea-8123-17fea8885a6e.TID813.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/10/2.delta
[2025-07-19T18:30:23.744+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=10),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/10] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/10/2.delta
[2025-07-19T18:30:23.745+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 10 (task 813, attempt 0, stage 9.0)
[2025-07-19T18:30:23.746+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 9 (task 812, attempt 0, stage 9.0)
[2025-07-19T18:30:23.748+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 9.0 in stage 9.0 (TID 812). 5872 bytes result sent to driver
[2025-07-19T18:30:23.748+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 8 (task 811, attempt 0, stage 9.0)
[2025-07-19T18:30:23.750+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 8.0 in stage 9.0 (TID 811). 5872 bytes result sent to driver
[2025-07-19T18:30:23.751+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 16.0 in stage 9.0 (TID 819) (8b44f3d35cfa, executor driver, partition 16, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.751+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 11 (task 814, attempt 0, stage 9.0)
[2025-07-19T18:30:23.752+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 11.0 in stage 9.0 (TID 814). 5872 bytes result sent to driver
[2025-07-19T18:30:23.753+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/13/.2.delta.2ea32eb0-8b13-4ec1-9195-02e18f635fa4.TID816.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/13/2.delta
[2025-07-19T18:30:23.753+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 9.0 in stage 9.0 (TID 812) in 92 ms on 8b44f3d35cfa (executor driver) (9/200)
[2025-07-19T18:30:23.754+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 8.0 in stage 9.0 (TID 811) in 100 ms on 8b44f3d35cfa (executor driver) (10/200)
[2025-07-19T18:30:23.755+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 16.0 in stage 9.0 (TID 819)
[2025-07-19T18:30:23.755+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=13),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/13] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/13/2.delta
[2025-07-19T18:30:23.755+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 10 (task 813, attempt 0, stage 9.0)
[2025-07-19T18:30:23.756+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 17.0 in stage 9.0 (TID 820) (8b44f3d35cfa, executor driver, partition 17, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.757+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 10.0 in stage 9.0 (TID 813). 5872 bytes result sent to driver
[2025-07-19T18:30:23.758+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 11.0 in stage 9.0 (TID 814) in 88 ms on 8b44f3d35cfa (executor driver) (11/200)
[2025-07-19T18:30:23.759+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 13 (task 816, attempt 0, stage 9.0)
[2025-07-19T18:30:23.759+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/15/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/15/.2.delta.deffeef5-a521-4cc6-90a9-417887b1a346.TID818.tmp
[2025-07-19T18:30:23.760+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 17.0 in stage 9.0 (TID 820)
[2025-07-19T18:30:23.760+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 18.0 in stage 9.0 (TID 821) (8b44f3d35cfa, executor driver, partition 18, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.761+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 19.0 in stage 9.0 (TID 822) (8b44f3d35cfa, executor driver, partition 19, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.762+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 10.0 in stage 9.0 (TID 813) in 90 ms on 8b44f3d35cfa (executor driver) (12/200)
[2025-07-19T18:30:23.763+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 18.0 in stage 9.0 (TID 821)
[2025-07-19T18:30:23.764+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 19.0 in stage 9.0 (TID 822)
[2025-07-19T18:30:23.764+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/12/.2.delta.0d11597b-3844-4bdb-91f5-92b599d2c96c.TID815.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/12/2.delta
[2025-07-19T18:30:23.765+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=12),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/12] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/12/2.delta
[2025-07-19T18:30:23.766+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 12 (task 815, attempt 0, stage 9.0)
[2025-07-19T18:30:23.766+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.766+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.767+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.767+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.768+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.769+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.770+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 13 (task 816, attempt 0, stage 9.0)
[2025-07-19T18:30:23.772+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.773+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T18:30:23.773+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 13.0 in stage 9.0 (TID 816). 5872 bytes result sent to driver
[2025-07-19T18:30:23.774+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HadoopTableOperations: Committed a new metadata file s3a://warehouse/bronze/Checkins_raw/metadata/v19.metadata.json
[2025-07-19T18:30:23.774+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 20.0 in stage 9.0 (TID 823) (8b44f3d35cfa, executor driver, partition 20, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.775+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 20.0 in stage 9.0 (TID 823)
[2025-07-19T18:30:23.776+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 13.0 in stage 9.0 (TID 816) in 72 ms on 8b44f3d35cfa (executor driver) (13/200)
[2025-07-19T18:30:23.777+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4393d7d3
[2025-07-19T18:30:23.778+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=18, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.778+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=18),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/18] for update
[2025-07-19T18:30:23.779+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.779+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.780+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.782+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 12 (task 815, attempt 0, stage 9.0)
[2025-07-19T18:30:23.783+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 12.0 in stage 9.0 (TID 815). 5872 bytes result sent to driver
[2025-07-19T18:30:23.784+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 21.0 in stage 9.0 (TID 824) (8b44f3d35cfa, executor driver, partition 21, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.785+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 21.0 in stage 9.0 (TID 824)
[2025-07-19T18:30:23.786+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 12.0 in stage 9.0 (TID 815) in 78 ms on 8b44f3d35cfa (executor driver) (14/200)
[2025-07-19T18:30:23.787+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4890e076
[2025-07-19T18:30:23.788+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=20, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.790+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3639e344
[2025-07-19T18:30:23.791+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=20),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/20] for update
[2025-07-19T18:30:23.792+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.792+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T18:30:23.792+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=16, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.793+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=16),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/16] for update
[2025-07-19T18:30:23.793+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.793+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.793+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@78fef0a2
[2025-07-19T18:30:23.793+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=19, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.793+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=19),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/19] for update
[2025-07-19T18:30:23.793+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/18/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/18/.2.delta.34b487b2-4bd3-4cc7-8374-938dbb89367e.TID821.tmp
[2025-07-19T18:30:23.794+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/14/.2.delta.de261a3f-6b9f-4dfb-9efb-4e90aabd4e35.TID817.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/14/2.delta
[2025-07-19T18:30:23.795+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=14),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/14] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/14/2.delta
[2025-07-19T18:30:23.795+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 14 (task 817, attempt 0, stage 9.0)
[2025-07-19T18:30:23.796+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.796+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2959e33c
[2025-07-19T18:30:23.797+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=17, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.797+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=17),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/17] for update
[2025-07-19T18:30:23.797+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@784da6c3
[2025-07-19T18:30:23.798+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=21, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.799+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=21),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/21] for update
[2025-07-19T18:30:23.799+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.800+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.801+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/16/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/16/.2.delta.8fbf6f06-e833-4e98-8a3c-14798c6133e0.TID819.tmp
[2025-07-19T18:30:23.801+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 14 (task 817, attempt 0, stage 9.0)
[2025-07-19T18:30:23.802+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/20/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/20/.2.delta.bba9aa9d-0a58-4250-bcd8-fd7a04edbbb7.TID823.tmp
[2025-07-19T18:30:23.803+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 14.0 in stage 9.0 (TID 817). 5872 bytes result sent to driver
[2025-07-19T18:30:23.803+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 22.0 in stage 9.0 (TID 825) (8b44f3d35cfa, executor driver, partition 22, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.803+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/15/.2.delta.deffeef5-a521-4cc6-90a9-417887b1a346.TID818.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/15/2.delta
[2025-07-19T18:30:23.804+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=15),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/15] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/15/2.delta
[2025-07-19T18:30:23.805+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 22.0 in stage 9.0 (TID 825)
[2025-07-19T18:30:23.806+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 14.0 in stage 9.0 (TID 817) in 101 ms on 8b44f3d35cfa (executor driver) (15/200)
[2025-07-19T18:30:23.807+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 15 (task 818, attempt 0, stage 9.0)
[2025-07-19T18:30:23.807+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 15 (task 818, attempt 0, stage 9.0)
[2025-07-19T18:30:23.807+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.808+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.809+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 15.0 in stage 9.0 (TID 818). 5872 bytes result sent to driver
[2025-07-19T18:30:23.809+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@64cb498a
[2025-07-19T18:30:23.810+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=22, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.810+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=22),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/22] for update
[2025-07-19T18:30:23.810+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 23.0 in stage 9.0 (TID 826) (8b44f3d35cfa, executor driver, partition 23, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.811+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.812+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 15.0 in stage 9.0 (TID 818) in 75 ms on 8b44f3d35cfa (executor driver) (16/200)
[2025-07-19T18:30:23.812+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/21/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/21/.2.delta.a14ef1f1-ae58-4035-accf-d364088dcb94.TID824.tmp
[2025-07-19T18:30:23.813+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/19/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/19/.2.delta.8305ad3a-6f63-4373-ae69-26b98c4fa9d8.TID822.tmp
[2025-07-19T18:30:23.813+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 23.0 in stage 9.0 (TID 826)
[2025-07-19T18:30:23.814+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.814+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.815+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/17/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/17/.2.delta.59ecbca5-1112-4f3c-acd2-b41b9eb0a2b6.TID820.tmp
[2025-07-19T18:30:23.815+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4904f91f
[2025-07-19T18:30:23.816+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=23, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.817+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=23),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/23] for update
[2025-07-19T18:30:23.817+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.817+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/22/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/22/.2.delta.2d768029-1c5e-4234-812b-10267262db01.TID825.tmp
[2025-07-19T18:30:23.817+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/23/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/23/.2.delta.e935684b-45c1-4d17-bb0b-a41023afaaad.TID826.tmp
[2025-07-19T18:30:23.818+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO SnapshotProducer: Committed snapshot 1459027961069767535 (FastAppend)
[2025-07-19T18:30:23.819+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/18/.2.delta.34b487b2-4bd3-4cc7-8374-938dbb89367e.TID821.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/18/2.delta
[2025-07-19T18:30:23.820+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=18),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/18] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/18/2.delta
[2025-07-19T18:30:23.820+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 18 (task 821, attempt 0, stage 9.0)
[2025-07-19T18:30:23.822+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 18 (task 821, attempt 0, stage 9.0)
[2025-07-19T18:30:23.824+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 18.0 in stage 9.0 (TID 821). 5829 bytes result sent to driver
[2025-07-19T18:30:23.826+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/20/.2.delta.bba9aa9d-0a58-4250-bcd8-fd7a04edbbb7.TID823.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/20/2.delta
[2025-07-19T18:30:23.827+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=20),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/20] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/20/2.delta
[2025-07-19T18:30:23.828+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 20 (task 823, attempt 0, stage 9.0)
[2025-07-19T18:30:23.828+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/16/.2.delta.8fbf6f06-e833-4e98-8a3c-14798c6133e0.TID819.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/16/2.delta
[2025-07-19T18:30:23.829+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=16),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/16] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/16/2.delta
[2025-07-19T18:30:23.830+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 24.0 in stage 9.0 (TID 827) (8b44f3d35cfa, executor driver, partition 24, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.830+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 16 (task 819, attempt 0, stage 9.0)
[2025-07-19T18:30:23.830+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 18.0 in stage 9.0 (TID 821) in 75 ms on 8b44f3d35cfa (executor driver) (17/200)
[2025-07-19T18:30:23.831+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 24.0 in stage 9.0 (TID 827)
[2025-07-19T18:30:23.831+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 16 (task 819, attempt 0, stage 9.0)
[2025-07-19T18:30:23.832+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/17/.2.delta.59ecbca5-1112-4f3c-acd2-b41b9eb0a2b6.TID820.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/17/2.delta
[2025-07-19T18:30:23.833+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=17),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/17] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/17/2.delta
[2025-07-19T18:30:23.834+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 20 (task 823, attempt 0, stage 9.0)
[2025-07-19T18:30:23.835+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 17 (task 820, attempt 0, stage 9.0)
[2025-07-19T18:30:23.836+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 16.0 in stage 9.0 (TID 819). 5872 bytes result sent to driver
[2025-07-19T18:30:23.837+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 25.0 in stage 9.0 (TID 828) (8b44f3d35cfa, executor driver, partition 25, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.838+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 16.0 in stage 9.0 (TID 819) in 88 ms on 8b44f3d35cfa (executor driver) (18/200)
[2025-07-19T18:30:23.838+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 25.0 in stage 9.0 (TID 828)
[2025-07-19T18:30:23.840+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 20.0 in stage 9.0 (TID 823). 5829 bytes result sent to driver
[2025-07-19T18:30:23.841+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 26.0 in stage 9.0 (TID 829) (8b44f3d35cfa, executor driver, partition 26, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.843+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 20.0 in stage 9.0 (TID 823) in 76 ms on 8b44f3d35cfa (executor driver) (19/200)
[2025-07-19T18:30:23.847+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/21/.2.delta.a14ef1f1-ae58-4035-accf-d364088dcb94.TID824.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/21/2.delta
[2025-07-19T18:30:23.849+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=21),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/21] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/21/2.delta
[2025-07-19T18:30:23.849+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 21 (task 824, attempt 0, stage 9.0)
[2025-07-19T18:30:23.850+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.850+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.850+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 26.0 in stage 9.0 (TID 829)
[2025-07-19T18:30:23.851+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@13dc8d63
[2025-07-19T18:30:23.851+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=25, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.852+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=25),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/25] for update
[2025-07-19T18:30:23.853+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.853+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.854+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T18:30:23.854+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 21 (task 824, attempt 0, stage 9.0)
[2025-07-19T18:30:23.854+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 21.0 in stage 9.0 (TID 824). 5829 bytes result sent to driver
[2025-07-19T18:30:23.854+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 17 (task 820, attempt 0, stage 9.0)
[2025-07-19T18:30:23.855+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 27.0 in stage 9.0 (TID 830) (8b44f3d35cfa, executor driver, partition 27, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.856+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 27.0 in stage 9.0 (TID 830)
[2025-07-19T18:30:23.857+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 17.0 in stage 9.0 (TID 820). 5829 bytes result sent to driver
[2025-07-19T18:30:23.857+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 28.0 in stage 9.0 (TID 831) (8b44f3d35cfa, executor driver, partition 28, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.858+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 28.0 in stage 9.0 (TID 831)
[2025-07-19T18:30:23.859+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c29683e
[2025-07-19T18:30:23.860+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/19/.2.delta.8305ad3a-6f63-4373-ae69-26b98c4fa9d8.TID822.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/19/2.delta
[2025-07-19T18:30:23.860+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=19),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/19] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/19/2.delta
[2025-07-19T18:30:23.860+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.861+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.862+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 19 (task 822, attempt 0, stage 9.0)
[2025-07-19T18:30:23.863+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 21.0 in stage 9.0 (TID 824) in 77 ms on 8b44f3d35cfa (executor driver) (20/200)
[2025-07-19T18:30:23.865+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 17.0 in stage 9.0 (TID 820) in 93 ms on 8b44f3d35cfa (executor driver) (21/200)
[2025-07-19T18:30:23.865+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=24, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.866+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=24),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/24] for update
[2025-07-19T18:30:23.866+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/25/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/25/.2.delta.2c222e08-e5cd-4364-8416-32cd71eb7efe.TID828.tmp
[2025-07-19T18:30:23.867+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1291c273
[2025-07-19T18:30:23.868+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.868+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T18:30:23.868+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.868+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 19 (task 822, attempt 0, stage 9.0)
[2025-07-19T18:30:23.869+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.869+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.870+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 19.0 in stage 9.0 (TID 822). 5829 bytes result sent to driver
[2025-07-19T18:30:23.870+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=27, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.870+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=27),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/27] for update
[2025-07-19T18:30:23.870+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 29.0 in stage 9.0 (TID 832) (8b44f3d35cfa, executor driver, partition 29, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.870+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 29.0 in stage 9.0 (TID 832)
[2025-07-19T18:30:23.870+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 19.0 in stage 9.0 (TID 822) in 97 ms on 8b44f3d35cfa (executor driver) (22/200)
[2025-07-19T18:30:23.870+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65590833
[2025-07-19T18:30:23.870+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.871+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=28, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.871+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=28),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/28] for update
[2025-07-19T18:30:23.871+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.871+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.871+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.872+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6cf93a07
[2025-07-19T18:30:23.872+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=26, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.872+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=26),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/26] for update
[2025-07-19T18:30:23.873+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/22/.2.delta.2d768029-1c5e-4234-812b-10267262db01.TID825.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/22/2.delta
[2025-07-19T18:30:23.873+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=22),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/22] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/22/2.delta
[2025-07-19T18:30:23.874+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.874+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@37c2cae3
[2025-07-19T18:30:23.874+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=29, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.874+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=29),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/29] for update
[2025-07-19T18:30:23.874+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.874+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/23/.2.delta.e935684b-45c1-4d17-bb0b-a41023afaaad.TID826.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/23/2.delta
[2025-07-19T18:30:23.874+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=23),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/23] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/23/2.delta
[2025-07-19T18:30:23.874+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 23 (task 826, attempt 0, stage 9.0)
[2025-07-19T18:30:23.874+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/27/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/27/.2.delta.d4eb6b2b-6682-4ec0-85e4-d7efce8cf3b3.TID830.tmp
[2025-07-19T18:30:23.875+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/24/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/24/.2.delta.41384c3f-cb00-475f-9367-9e5bd1a7c881.TID827.tmp
[2025-07-19T18:30:23.876+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 23 (task 826, attempt 0, stage 9.0)
[2025-07-19T18:30:23.877+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 23.0 in stage 9.0 (TID 826). 5829 bytes result sent to driver
[2025-07-19T18:30:23.878+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/28/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/28/.2.delta.92b42fe5-cdc4-417d-bb30-ae7247aa541e.TID831.tmp
[2025-07-19T18:30:23.878+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/26/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/26/.2.delta.38b202e4-0e3a-417d-8a90-a688b493135a.TID829.tmp
[2025-07-19T18:30:23.878+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 30.0 in stage 9.0 (TID 833) (8b44f3d35cfa, executor driver, partition 30, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.878+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 22 (task 825, attempt 0, stage 9.0)
[2025-07-19T18:30:23.879+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 23.0 in stage 9.0 (TID 826) in 67 ms on 8b44f3d35cfa (executor driver) (23/200)
[2025-07-19T18:30:23.879+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 30.0 in stage 9.0 (TID 833)
[2025-07-19T18:30:23.879+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.879+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.879+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6401c272
[2025-07-19T18:30:23.879+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 22 (task 825, attempt 0, stage 9.0)
[2025-07-19T18:30:23.879+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 22.0 in stage 9.0 (TID 825). 5829 bytes result sent to driver
[2025-07-19T18:30:23.879+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=30, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.879+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=30),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/30] for update
[2025-07-19T18:30:23.879+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 31.0 in stage 9.0 (TID 834) (8b44f3d35cfa, executor driver, partition 31, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.880+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 31.0 in stage 9.0 (TID 834)
[2025-07-19T18:30:23.880+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 22.0 in stage 9.0 (TID 825) in 83 ms on 8b44f3d35cfa (executor driver) (24/200)
[2025-07-19T18:30:23.880+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.880+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.880+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.880+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/29/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/29/.2.delta.6cf233e0-7628-4b33-bf8f-a980f25accdf.TID832.tmp
[2025-07-19T18:30:23.880+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22ed20e7
[2025-07-19T18:30:23.880+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO LoggingMetricsReporter: Received metrics report: CommitReport{tableName=my_catalog.bronze.Checkins_raw, snapshotId=1459027961069767535, sequenceNumber=18, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.217739875S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=null, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=463}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=null, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=513}, addedFilesSizeInBytes=null, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=1490806}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}}, metadata={engine-version=3.5.6, app-id=local-1752949808869, engine-name=spark, iceberg-version=Apache Iceberg 1.4.0 (commit 10367c380098c2e06a49521a33681ac7f6c64b2c)}}
[2025-07-19T18:30:23.880+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO SparkWrite: Committed in 218 ms
[2025-07-19T18:30:23.881+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 1, writer: IcebergStreamingWrite(table=my_catalog.bronze.Checkins_raw, format=PARQUET)] committed.
[2025-07-19T18:30:23.881+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=31, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.881+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=31),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/31] for update
[2025-07-19T18:30:23.881+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.882+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/30/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/30/.2.delta.d5282373-6d6b-49c9-b8c3-b9201ca778cc.TID833.tmp
[2025-07-19T18:30:23.884+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/31/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/31/.2.delta.48ebcf10-2d38-43a2-afbc-35f378f1f271.TID834.tmp
[2025-07-19T18:30:23.886+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/25/.2.delta.2c222e08-e5cd-4364-8416-32cd71eb7efe.TID828.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/25/2.delta
[2025-07-19T18:30:23.886+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=25),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/25] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/25/2.delta
[2025-07-19T18:30:23.887+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 25 (task 828, attempt 0, stage 9.0)
[2025-07-19T18:30:23.888+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/commits/1 using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/commits/.1.721e4036-9634-4c7b-912d-fa3024da4192.tmp
[2025-07-19T18:30:23.890+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 25 (task 828, attempt 0, stage 9.0)
[2025-07-19T18:30:23.890+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 25.0 in stage 9.0 (TID 828). 5829 bytes result sent to driver
[2025-07-19T18:30:23.892+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 32.0 in stage 9.0 (TID 835) (8b44f3d35cfa, executor driver, partition 32, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.893+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 25.0 in stage 9.0 (TID 828) in 60 ms on 8b44f3d35cfa (executor driver) (25/200)
[2025-07-19T18:30:23.893+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 32.0 in stage 9.0 (TID 835)
[2025-07-19T18:30:23.893+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/24/.2.delta.41384c3f-cb00-475f-9367-9e5bd1a7c881.TID827.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/24/2.delta
[2025-07-19T18:30:23.894+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=24),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/24] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/24/2.delta
[2025-07-19T18:30:23.894+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/27/.2.delta.d4eb6b2b-6682-4ec0-85e4-d7efce8cf3b3.TID830.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/27/2.delta
[2025-07-19T18:30:23.895+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=27),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/27] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/27/2.delta
[2025-07-19T18:30:23.895+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 27 (task 830, attempt 0, stage 9.0)
[2025-07-19T18:30:23.895+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 24 (task 827, attempt 0, stage 9.0)
[2025-07-19T18:30:23.896+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.896+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:23.897+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@611e62df
[2025-07-19T18:30:23.902+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=32, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.903+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=32),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/32] for update
[2025-07-19T18:30:23.904+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.905+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/26/.2.delta.38b202e4-0e3a-417d-8a90-a688b493135a.TID829.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/26/2.delta
[2025-07-19T18:30:23.905+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=26),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/26] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/26/2.delta
[2025-07-19T18:30:23.905+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 26 (task 829, attempt 0, stage 9.0)
[2025-07-19T18:30:23.906+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 24 (task 827, attempt 0, stage 9.0)
[2025-07-19T18:30:23.906+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 24.0 in stage 9.0 (TID 827). 5829 bytes result sent to driver
[2025-07-19T18:30:23.906+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 27 (task 830, attempt 0, stage 9.0)
[2025-07-19T18:30:23.906+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 33.0 in stage 9.0 (TID 836) (8b44f3d35cfa, executor driver, partition 33, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.907+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 33.0 in stage 9.0 (TID 836)
[2025-07-19T18:30:23.908+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 24.0 in stage 9.0 (TID 827) in 77 ms on 8b44f3d35cfa (executor driver) (26/200)
[2025-07-19T18:30:23.909+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 27.0 in stage 9.0 (TID 830). 5829 bytes result sent to driver
[2025-07-19T18:30:23.909+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 34.0 in stage 9.0 (TID 837) (8b44f3d35cfa, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.910+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 27.0 in stage 9.0 (TID 830) in 64 ms on 8b44f3d35cfa (executor driver) (27/200)
[2025-07-19T18:30:23.910+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 34.0 in stage 9.0 (TID 837)
[2025-07-19T18:30:23.911+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/29/.2.delta.6cf233e0-7628-4b33-bf8f-a980f25accdf.TID832.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/29/2.delta
[2025-07-19T18:30:23.912+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=29),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/29] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/29/2.delta
[2025-07-19T18:30:23.912+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 26 (task 829, attempt 0, stage 9.0)
[2025-07-19T18:30:23.912+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 29 (task 832, attempt 0, stage 9.0)
[2025-07-19T18:30:23.912+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 26.0 in stage 9.0 (TID 829). 5829 bytes result sent to driver
[2025-07-19T18:30:23.912+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.912+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.912+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 35.0 in stage 9.0 (TID 838) (8b44f3d35cfa, executor driver, partition 35, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.913+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 26.0 in stage 9.0 (TID 829) in 73 ms on 8b44f3d35cfa (executor driver) (28/200)
[2025-07-19T18:30:23.913+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 35.0 in stage 9.0 (TID 838)
[2025-07-19T18:30:23.913+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2514c01d
[2025-07-19T18:30:23.913+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.913+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.913+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=33, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.913+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=33),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/33] for update
[2025-07-19T18:30:23.913+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/28/.2.delta.92b42fe5-cdc4-417d-bb30-ae7247aa541e.TID831.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/28/2.delta
[2025-07-19T18:30:23.913+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=28),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/28] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/28/2.delta
[2025-07-19T18:30:23.913+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 28 (task 831, attempt 0, stage 9.0)
[2025-07-19T18:30:23.914+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.914+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 29 (task 832, attempt 0, stage 9.0)
[2025-07-19T18:30:23.914+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7cfbf504
[2025-07-19T18:30:23.914+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 29.0 in stage 9.0 (TID 832). 5829 bytes result sent to driver
[2025-07-19T18:30:23.914+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=34, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.914+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=34),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/34] for update
[2025-07-19T18:30:23.914+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 28 (task 831, attempt 0, stage 9.0)
[2025-07-19T18:30:23.914+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 36.0 in stage 9.0 (TID 839) (8b44f3d35cfa, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.915+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 28.0 in stage 9.0 (TID 831). 5829 bytes result sent to driver
[2025-07-19T18:30:23.915+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 29.0 in stage 9.0 (TID 832) in 66 ms on 8b44f3d35cfa (executor driver) (29/200)
[2025-07-19T18:30:23.915+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 36.0 in stage 9.0 (TID 839)
[2025-07-19T18:30:23.915+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.915+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/32/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/32/.2.delta.4184bf79-27d0-468f-92fb-d72b23eb1fc0.TID835.tmp
[2025-07-19T18:30:23.915+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.924+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T18:30:23.925+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 37.0 in stage 9.0 (TID 840) (8b44f3d35cfa, executor driver, partition 37, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.925+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 37.0 in stage 9.0 (TID 840)
[2025-07-19T18:30:23.926+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 28.0 in stage 9.0 (TID 831) in 76 ms on 8b44f3d35cfa (executor driver) (30/200)
[2025-07-19T18:30:23.926+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@480ec9cb
[2025-07-19T18:30:23.926+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=35, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.926+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=35),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/35] for update
[2025-07-19T18:30:23.926+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.926+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.926+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:23.926+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.926+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.927+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40c09e71
[2025-07-19T18:30:23.927+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=37, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.927+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=37),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/37] for update
[2025-07-19T18:30:23.927+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/33/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/33/.2.delta.afbc7553-210d-40e6-a66e-211bf6f94dca.TID836.tmp
[2025-07-19T18:30:23.927+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.927+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4213338b
[2025-07-19T18:30:23.927+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=36, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.927+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=36),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/36] for update
[2025-07-19T18:30:23.927+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.928+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/34/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/34/.2.delta.7afa6f14-7baf-415d-82ca-3c04c007a384.TID837.tmp
[2025-07-19T18:30:23.930+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/30/.2.delta.d5282373-6d6b-49c9-b8c3-b9201ca778cc.TID833.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/30/2.delta
[2025-07-19T18:30:23.930+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=30),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/30] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/30/2.delta
[2025-07-19T18:30:23.932+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 30 (task 833, attempt 0, stage 9.0)
[2025-07-19T18:30:23.936+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 30 (task 833, attempt 0, stage 9.0)
[2025-07-19T18:30:23.937+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 30.0 in stage 9.0 (TID 833). 5829 bytes result sent to driver
[2025-07-19T18:30:23.938+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 38.0 in stage 9.0 (TID 841) (8b44f3d35cfa, executor driver, partition 38, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.938+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 30.0 in stage 9.0 (TID 833) in 75 ms on 8b44f3d35cfa (executor driver) (31/200)
[2025-07-19T18:30:23.938+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 38.0 in stage 9.0 (TID 841)
[2025-07-19T18:30:23.939+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/35/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/35/.2.delta.85f9a721-9c6f-4d68-8ecd-595f3a23474f.TID838.tmp
[2025-07-19T18:30:23.939+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/commits/.1.721e4036-9634-4c7b-912d-fa3024da4192.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T18:28:00+00:00/commits/1
[2025-07-19T18:30:23.939+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.939+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.939+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d7c873e
[2025-07-19T18:30:23.939+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=38, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.939+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=38),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/38] for update
[2025-07-19T18:30:23.941+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/31/.2.delta.48ebcf10-2d38-43a2-afbc-35f378f1f271.TID834.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/31/2.delta
[2025-07-19T18:30:23.942+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=31),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/31] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/31/2.delta
[2025-07-19T18:30:23.942+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 31 (task 834, attempt 0, stage 9.0)
[2025-07-19T18:30:23.943+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.943+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/37/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/37/.2.delta.7cd5f868-c756-48ec-a77c-e76bcd716fd6.TID840.tmp
[2025-07-19T18:30:23.944+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/36/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/36/.2.delta.cc6cc2bd-52ab-46a6-9244-f1f9385b3bec.TID839.tmp
[2025-07-19T18:30:23.945+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 31 (task 834, attempt 0, stage 9.0)
[2025-07-19T18:30:23.945+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 31.0 in stage 9.0 (TID 834). 5829 bytes result sent to driver
[2025-07-19T18:30:23.946+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO MicroBatchExecution: Streaming query made progress: {
[2025-07-19T18:30:23.947+0000] {subprocess.py:93} INFO -   "id" : "987ca175-704b-42a6-8146-d1b15494abbf",
[2025-07-19T18:30:23.948+0000] {subprocess.py:93} INFO -   "runId" : "e7c2576d-5139-486e-a3a4-0d60a8d676b4",
[2025-07-19T18:30:23.948+0000] {subprocess.py:93} INFO -   "name" : null,
[2025-07-19T18:30:23.949+0000] {subprocess.py:93} INFO -   "timestamp" : "2025-07-19T18:30:18.090Z",
[2025-07-19T18:30:23.949+0000] {subprocess.py:93} INFO -   "batchId" : 1,
[2025-07-19T18:30:23.949+0000] {subprocess.py:93} INFO -   "numInputRows" : 0,
[2025-07-19T18:30:23.949+0000] {subprocess.py:93} INFO -   "inputRowsPerSecond" : 0.0,
[2025-07-19T18:30:23.950+0000] {subprocess.py:93} INFO -   "processedRowsPerSecond" : 0.0,
[2025-07-19T18:30:23.950+0000] {subprocess.py:93} INFO -   "durationMs" : {
[2025-07-19T18:30:23.950+0000] {subprocess.py:93} INFO -     "addBatch" : 5647,
[2025-07-19T18:30:23.950+0000] {subprocess.py:93} INFO -     "commitOffsets" : 59,
[2025-07-19T18:30:23.950+0000] {subprocess.py:93} INFO -     "getBatch" : 0,
[2025-07-19T18:30:23.950+0000] {subprocess.py:93} INFO -     "latestOffset" : 10,
[2025-07-19T18:30:23.950+0000] {subprocess.py:93} INFO -     "queryPlanning" : 65,
[2025-07-19T18:30:23.950+0000] {subprocess.py:93} INFO -     "triggerExecution" : 5846,
[2025-07-19T18:30:23.950+0000] {subprocess.py:93} INFO -     "walCommit" : 56
[2025-07-19T18:30:23.950+0000] {subprocess.py:93} INFO -   },
[2025-07-19T18:30:23.951+0000] {subprocess.py:93} INFO -   "eventTime" : {
[2025-07-19T18:30:23.951+0000] {subprocess.py:93} INFO -     "watermark" : "2025-07-17T18:13:00.000Z"
[2025-07-19T18:30:23.951+0000] {subprocess.py:93} INFO -   },
[2025-07-19T18:30:23.951+0000] {subprocess.py:93} INFO -   "stateOperators" : [ {
[2025-07-19T18:30:23.953+0000] {subprocess.py:93} INFO -     "operatorName" : "dedupe",
[2025-07-19T18:30:23.954+0000] {subprocess.py:93} INFO -     "numRowsTotal" : 69,
[2025-07-19T18:30:23.955+0000] {subprocess.py:93} INFO -     "numRowsUpdated" : 0,
[2025-07-19T18:30:23.956+0000] {subprocess.py:93} INFO -     "allUpdatesTimeMs" : 163,
[2025-07-19T18:30:23.956+0000] {subprocess.py:93} INFO -     "numRowsRemoved" : 0,
[2025-07-19T18:30:23.957+0000] {subprocess.py:93} INFO -     "allRemovalsTimeMs" : 146,
[2025-07-19T18:30:23.957+0000] {subprocess.py:93} INFO -     "commitTimeMs" : 11113,
[2025-07-19T18:30:23.957+0000] {subprocess.py:93} INFO -     "memoryUsedBytes" : 104680,
[2025-07-19T18:30:23.958+0000] {subprocess.py:93} INFO -     "numRowsDroppedByWatermark" : 0,
[2025-07-19T18:30:23.959+0000] {subprocess.py:93} INFO -     "numShufflePartitions" : 200,
[2025-07-19T18:30:23.960+0000] {subprocess.py:93} INFO -     "numStateStoreInstances" : 200,
[2025-07-19T18:30:23.960+0000] {subprocess.py:93} INFO -     "customMetrics" : {
[2025-07-19T18:30:23.960+0000] {subprocess.py:93} INFO -       "loadedMapCacheHitCount" : 200,
[2025-07-19T18:30:23.960+0000] {subprocess.py:93} INFO -       "loadedMapCacheMissCount" : 0,
[2025-07-19T18:30:23.960+0000] {subprocess.py:93} INFO -       "numDroppedDuplicateRows" : 0,
[2025-07-19T18:30:23.960+0000] {subprocess.py:93} INFO -       "stateOnCurrentVersionSizeBytes" : 36952
[2025-07-19T18:30:23.961+0000] {subprocess.py:93} INFO -     }
[2025-07-19T18:30:23.961+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T18:30:23.961+0000] {subprocess.py:93} INFO -   "sources" : [ {
[2025-07-19T18:30:23.961+0000] {subprocess.py:93} INFO -     "description" : "KafkaV2[Subscribe[checkins]]",
[2025-07-19T18:30:23.961+0000] {subprocess.py:93} INFO -     "startOffset" : {
[2025-07-19T18:30:23.961+0000] {subprocess.py:93} INFO -       "checkins" : {
[2025-07-19T18:30:23.961+0000] {subprocess.py:93} INFO -         "0" : 69
[2025-07-19T18:30:23.961+0000] {subprocess.py:93} INFO -       }
[2025-07-19T18:30:23.962+0000] {subprocess.py:93} INFO -     },
[2025-07-19T18:30:23.963+0000] {subprocess.py:93} INFO -     "endOffset" : {
[2025-07-19T18:30:23.964+0000] {subprocess.py:93} INFO -       "checkins" : {
[2025-07-19T18:30:23.965+0000] {subprocess.py:93} INFO -         "0" : 69
[2025-07-19T18:30:23.965+0000] {subprocess.py:93} INFO -       }
[2025-07-19T18:30:23.967+0000] {subprocess.py:93} INFO -     },
[2025-07-19T18:30:23.968+0000] {subprocess.py:93} INFO -     "latestOffset" : {
[2025-07-19T18:30:23.969+0000] {subprocess.py:93} INFO -       "checkins" : {
[2025-07-19T18:30:23.969+0000] {subprocess.py:93} INFO -         "0" : 69
[2025-07-19T18:30:23.969+0000] {subprocess.py:93} INFO -       }
[2025-07-19T18:30:23.969+0000] {subprocess.py:93} INFO -     },
[2025-07-19T18:30:23.969+0000] {subprocess.py:93} INFO -     "numInputRows" : 0,
[2025-07-19T18:30:23.969+0000] {subprocess.py:93} INFO -     "inputRowsPerSecond" : 0.0,
[2025-07-19T18:30:23.970+0000] {subprocess.py:93} INFO -     "processedRowsPerSecond" : 0.0,
[2025-07-19T18:30:23.970+0000] {subprocess.py:93} INFO -     "metrics" : {
[2025-07-19T18:30:23.970+0000] {subprocess.py:93} INFO -       "avgOffsetsBehindLatest" : "0.0",
[2025-07-19T18:30:23.970+0000] {subprocess.py:93} INFO -       "maxOffsetsBehindLatest" : "0",
[2025-07-19T18:30:23.970+0000] {subprocess.py:93} INFO -       "minOffsetsBehindLatest" : "0"
[2025-07-19T18:30:23.970+0000] {subprocess.py:93} INFO -     }
[2025-07-19T18:30:23.971+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T18:30:23.971+0000] {subprocess.py:93} INFO -   "sink" : {
[2025-07-19T18:30:23.971+0000] {subprocess.py:93} INFO -     "description" : "my_catalog.bronze.Checkins_raw",
[2025-07-19T18:30:23.971+0000] {subprocess.py:93} INFO -     "numOutputRows" : 0
[2025-07-19T18:30:23.971+0000] {subprocess.py:93} INFO -   }
[2025-07-19T18:30:23.971+0000] {subprocess.py:93} INFO - }
[2025-07-19T18:30:23.971+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 39.0 in stage 9.0 (TID 842) (8b44f3d35cfa, executor driver, partition 39, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.971+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 31.0 in stage 9.0 (TID 834) in 77 ms on 8b44f3d35cfa (executor driver) (32/200)
[2025-07-19T18:30:23.971+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 39.0 in stage 9.0 (TID 842)
[2025-07-19T18:30:23.971+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.971+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.972+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1dfa6590
[2025-07-19T18:30:23.972+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=39, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.972+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=39),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/39] for update
[2025-07-19T18:30:23.972+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.973+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/38/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/38/.2.delta.3afcbdff-5282-49ca-b58a-427061a16763.TID841.tmp
[2025-07-19T18:30:23.973+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/32/.2.delta.4184bf79-27d0-468f-92fb-d72b23eb1fc0.TID835.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/32/2.delta
[2025-07-19T18:30:23.974+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=32),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/32] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/32/2.delta
[2025-07-19T18:30:23.974+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 32 (task 835, attempt 0, stage 9.0)
[2025-07-19T18:30:23.975+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/39/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/39/.2.delta.9ebec1bf-9cd1-4435-8916-736f1a3da102.TID842.tmp
[2025-07-19T18:30:23.976+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 32 (task 835, attempt 0, stage 9.0)
[2025-07-19T18:30:23.976+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 32.0 in stage 9.0 (TID 835). 5829 bytes result sent to driver
[2025-07-19T18:30:23.977+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 40.0 in stage 9.0 (TID 843) (8b44f3d35cfa, executor driver, partition 40, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.978+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 40.0 in stage 9.0 (TID 843)
[2025-07-19T18:30:23.978+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 32.0 in stage 9.0 (TID 835) in 73 ms on 8b44f3d35cfa (executor driver) (33/200)
[2025-07-19T18:30:23.979+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.979+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.980+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7bec19c
[2025-07-19T18:30:23.980+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=40, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.981+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=40),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/40] for update
[2025-07-19T18:30:23.983+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.984+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/34/.2.delta.7afa6f14-7baf-415d-82ca-3c04c007a384.TID837.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/34/2.delta
[2025-07-19T18:30:23.984+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=34),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/34] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/34/2.delta
[2025-07-19T18:30:23.984+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 34 (task 837, attempt 0, stage 9.0)
[2025-07-19T18:30:23.984+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/35/.2.delta.85f9a721-9c6f-4d68-8ecd-595f3a23474f.TID838.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/35/2.delta
[2025-07-19T18:30:23.984+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=35),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/35] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/35/2.delta
[2025-07-19T18:30:23.984+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 35 (task 838, attempt 0, stage 9.0)
[2025-07-19T18:30:23.984+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/33/.2.delta.afbc7553-210d-40e6-a66e-211bf6f94dca.TID836.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/33/2.delta
[2025-07-19T18:30:23.984+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=33),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/33] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/33/2.delta
[2025-07-19T18:30:23.984+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 33 (task 836, attempt 0, stage 9.0)
[2025-07-19T18:30:23.985+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 34 (task 837, attempt 0, stage 9.0)
[2025-07-19T18:30:23.985+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/37/.2.delta.7cd5f868-c756-48ec-a77c-e76bcd716fd6.TID840.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/37/2.delta
[2025-07-19T18:30:23.985+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=37),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/37] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/37/2.delta
[2025-07-19T18:30:23.985+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/40/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/40/.2.delta.8573d21d-134a-4e3b-9a31-c49b73f0070f.TID843.tmp
[2025-07-19T18:30:23.986+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 34.0 in stage 9.0 (TID 837). 5829 bytes result sent to driver
[2025-07-19T18:30:23.986+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 35 (task 838, attempt 0, stage 9.0)
[2025-07-19T18:30:23.986+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 41.0 in stage 9.0 (TID 844) (8b44f3d35cfa, executor driver, partition 41, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.986+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 35.0 in stage 9.0 (TID 838). 5829 bytes result sent to driver
[2025-07-19T18:30:23.986+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 37 (task 840, attempt 0, stage 9.0)
[2025-07-19T18:30:23.986+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 33 (task 836, attempt 0, stage 9.0)
[2025-07-19T18:30:23.987+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 33.0 in stage 9.0 (TID 836). 5829 bytes result sent to driver
[2025-07-19T18:30:23.987+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 42.0 in stage 9.0 (TID 845) (8b44f3d35cfa, executor driver, partition 42, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.987+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 43.0 in stage 9.0 (TID 846) (8b44f3d35cfa, executor driver, partition 43, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:23.987+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 33.0 in stage 9.0 (TID 836) in 82 ms on 8b44f3d35cfa (executor driver) (34/200)
[2025-07-19T18:30:23.987+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 34.0 in stage 9.0 (TID 837) in 81 ms on 8b44f3d35cfa (executor driver) (35/200)
[2025-07-19T18:30:23.987+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 43.0 in stage 9.0 (TID 846)
[2025-07-19T18:30:23.987+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/36/.2.delta.cc6cc2bd-52ab-46a6-9244-f1f9385b3bec.TID839.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/36/2.delta
[2025-07-19T18:30:23.987+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=36),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/36] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/36/2.delta
[2025-07-19T18:30:23.987+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 41.0 in stage 9.0 (TID 844)
[2025-07-19T18:30:23.987+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 42.0 in stage 9.0 (TID 845)
[2025-07-19T18:30:23.988+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 35.0 in stage 9.0 (TID 838) in 78 ms on 8b44f3d35cfa (executor driver) (36/200)
[2025-07-19T18:30:23.988+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.988+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.988+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.988+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:23.988+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 36 (task 839, attempt 0, stage 9.0)
[2025-07-19T18:30:23.991+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@30996a79
[2025-07-19T18:30:23.993+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=43, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:23.994+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=43),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/43] for update
[2025-07-19T18:30:23.994+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:23.995+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 36 (task 839, attempt 0, stage 9.0)
[2025-07-19T18:30:23.996+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 36.0 in stage 9.0 (TID 839). 5829 bytes result sent to driver
[2025-07-19T18:30:23.997+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:23.998+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T18:30:23.998+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Committed partition 37 (task 840, attempt 0, stage 9.0)
[2025-07-19T18:30:23.998+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Finished task 37.0 in stage 9.0 (TID 840). 5829 bytes result sent to driver
[2025-07-19T18:30:23.999+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 44.0 in stage 9.0 (TID 847) (8b44f3d35cfa, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.001+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Starting task 45.0 in stage 9.0 (TID 848) (8b44f3d35cfa, executor driver, partition 45, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.002+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 44.0 in stage 9.0 (TID 847)
[2025-07-19T18:30:24.002+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 36.0 in stage 9.0 (TID 839) in 83 ms on 8b44f3d35cfa (executor driver) (37/200)
[2025-07-19T18:30:24.003+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47277cee
[2025-07-19T18:30:24.005+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO Executor: Running task 45.0 in stage 9.0 (TID 848)
[2025-07-19T18:30:24.005+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO TaskSetManager: Finished task 37.0 in stage 9.0 (TID 840) in 81 ms on 8b44f3d35cfa (executor driver) (38/200)
[2025-07-19T18:30:24.006+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=42, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.008+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=42),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/42] for update
[2025-07-19T18:30:24.009+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5cbf53ce
[2025-07-19T18:30:24.009+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=41, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.010+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=41),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/41] for update
[2025-07-19T18:30:24.010+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/38/.2.delta.3afcbdff-5282-49ca-b58a-427061a16763.TID841.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/38/2.delta
[2025-07-19T18:30:24.010+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=38),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/38] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/38/2.delta
[2025-07-19T18:30:24.010+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO DataWritingSparkTask: Commit authorized for partition 38 (task 841, attempt 0, stage 9.0)
[2025-07-19T18:30:24.010+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.010+0000] {subprocess.py:93} INFO - 25/07/19 18:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.010+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.010+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.011+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.012+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7bf1149f
[2025-07-19T18:30:24.012+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=44, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.014+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=44),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/44] for update
[2025-07-19T18:30:24.014+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.014+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/43/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/43/.2.delta.c8126d4c-d480-45a3-926b-31e9c9b0e7db.TID846.tmp
[2025-07-19T18:30:24.015+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@578d7023
[2025-07-19T18:30:24.016+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=45, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.017+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=45),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/45] for update
[2025-07-19T18:30:24.019+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.020+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 38 (task 841, attempt 0, stage 9.0)
[2025-07-19T18:30:24.021+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.021+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 38.0 in stage 9.0 (TID 841). 5829 bytes result sent to driver
[2025-07-19T18:30:24.021+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 46.0 in stage 9.0 (TID 849) (8b44f3d35cfa, executor driver, partition 46, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.021+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 38.0 in stage 9.0 (TID 841) in 75 ms on 8b44f3d35cfa (executor driver) (39/200)
[2025-07-19T18:30:24.021+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 46.0 in stage 9.0 (TID 849)
[2025-07-19T18:30:24.021+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.022+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.022+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/44/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/44/.2.delta.8790da2e-b7ea-4da7-a5d5-bab8fd555bc9.TID847.tmp
[2025-07-19T18:30:24.022+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/39/.2.delta.9ebec1bf-9cd1-4435-8916-736f1a3da102.TID842.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/39/2.delta
[2025-07-19T18:30:24.023+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=39),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/39] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/39/2.delta
[2025-07-19T18:30:24.023+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 39 (task 842, attempt 0, stage 9.0)
[2025-07-19T18:30:24.025+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/42/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/42/.2.delta.5640c8aa-803a-4cdb-a6bb-c7be7893881e.TID845.tmp
[2025-07-19T18:30:24.028+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/41/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/41/.2.delta.f2903a8e-0aab-4826-b2ea-31f15af5cc80.TID844.tmp
[2025-07-19T18:30:24.029+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/45/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/45/.2.delta.7921be1f-bd5e-4408-bd85-0d93ea2d4990.TID848.tmp
[2025-07-19T18:30:24.029+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 39 (task 842, attempt 0, stage 9.0)
[2025-07-19T18:30:24.029+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@79d7cc43
[2025-07-19T18:30:24.030+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 39.0 in stage 9.0 (TID 842). 5829 bytes result sent to driver
[2025-07-19T18:30:24.031+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 47.0 in stage 9.0 (TID 850) (8b44f3d35cfa, executor driver, partition 47, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.031+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=46, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.031+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=46),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/46] for update
[2025-07-19T18:30:24.032+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 47.0 in stage 9.0 (TID 850)
[2025-07-19T18:30:24.032+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 39.0 in stage 9.0 (TID 842) in 78 ms on 8b44f3d35cfa (executor driver) (40/200)
[2025-07-19T18:30:24.032+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.033+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.033+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.033+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58d3435a
[2025-07-19T18:30:24.033+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=47, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.034+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=47),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/47] for update
[2025-07-19T18:30:24.034+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.035+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/46/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/46/.2.delta.5f17462c-81c2-4407-a0b2-0b9f194514aa.TID849.tmp
[2025-07-19T18:30:24.037+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/40/.2.delta.8573d21d-134a-4e3b-9a31-c49b73f0070f.TID843.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/40/2.delta
[2025-07-19T18:30:24.037+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=40),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/40] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/40/2.delta
[2025-07-19T18:30:24.038+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 40 (task 843, attempt 0, stage 9.0)
[2025-07-19T18:30:24.041+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/47/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/47/.2.delta.7cf6737f-fa33-44d9-8b82-019cd1f9a956.TID850.tmp
[2025-07-19T18:30:24.042+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 40 (task 843, attempt 0, stage 9.0)
[2025-07-19T18:30:24.043+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 40.0 in stage 9.0 (TID 843). 5829 bytes result sent to driver
[2025-07-19T18:30:24.044+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 48.0 in stage 9.0 (TID 851) (8b44f3d35cfa, executor driver, partition 48, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.046+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 40.0 in stage 9.0 (TID 843) in 81 ms on 8b44f3d35cfa (executor driver) (41/200)
[2025-07-19T18:30:24.046+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 48.0 in stage 9.0 (TID 851)
[2025-07-19T18:30:24.047+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.048+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.054+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3bf1e586
[2025-07-19T18:30:24.055+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=48, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.055+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=48),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/48] for update
[2025-07-19T18:30:24.056+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.056+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/41/.2.delta.f2903a8e-0aab-4826-b2ea-31f15af5cc80.TID844.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/41/2.delta
[2025-07-19T18:30:24.057+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=41),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/41] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/41/2.delta
[2025-07-19T18:30:24.057+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/43/.2.delta.c8126d4c-d480-45a3-926b-31e9c9b0e7db.TID846.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/43/2.delta
[2025-07-19T18:30:24.058+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=43),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/43] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/43/2.delta
[2025-07-19T18:30:24.058+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 41 (task 844, attempt 0, stage 9.0)
[2025-07-19T18:30:24.059+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/42/.2.delta.5640c8aa-803a-4cdb-a6bb-c7be7893881e.TID845.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/42/2.delta
[2025-07-19T18:30:24.059+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=42),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/42] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/42/2.delta
[2025-07-19T18:30:24.060+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 43 (task 846, attempt 0, stage 9.0)
[2025-07-19T18:30:24.061+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 41 (task 844, attempt 0, stage 9.0)
[2025-07-19T18:30:24.062+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 41.0 in stage 9.0 (TID 844). 5829 bytes result sent to driver
[2025-07-19T18:30:24.062+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/48/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/48/.2.delta.716f7ae7-960c-408b-bce6-cbf1e97a13ba.TID851.tmp
[2025-07-19T18:30:24.063+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 42 (task 845, attempt 0, stage 9.0)
[2025-07-19T18:30:24.065+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 49.0 in stage 9.0 (TID 852) (8b44f3d35cfa, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.067+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/44/.2.delta.8790da2e-b7ea-4da7-a5d5-bab8fd555bc9.TID847.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/44/2.delta
[2025-07-19T18:30:24.068+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=44),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/44] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/44/2.delta
[2025-07-19T18:30:24.069+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 49.0 in stage 9.0 (TID 852)
[2025-07-19T18:30:24.069+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 43 (task 846, attempt 0, stage 9.0)
[2025-07-19T18:30:24.070+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 43.0 in stage 9.0 (TID 846). 5829 bytes result sent to driver
[2025-07-19T18:30:24.070+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/45/.2.delta.7921be1f-bd5e-4408-bd85-0d93ea2d4990.TID848.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/45/2.delta
[2025-07-19T18:30:24.070+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=45),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/45] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/45/2.delta
[2025-07-19T18:30:24.070+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 41.0 in stage 9.0 (TID 844) in 87 ms on 8b44f3d35cfa (executor driver) (42/200)
[2025-07-19T18:30:24.070+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 44 (task 847, attempt 0, stage 9.0)
[2025-07-19T18:30:24.071+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 50.0 in stage 9.0 (TID 853) (8b44f3d35cfa, executor driver, partition 50, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.071+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.073+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.073+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 45 (task 848, attempt 0, stage 9.0)
[2025-07-19T18:30:24.073+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 43.0 in stage 9.0 (TID 846) in 85 ms on 8b44f3d35cfa (executor driver) (43/200)
[2025-07-19T18:30:24.073+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4531daad
[2025-07-19T18:30:24.073+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 42 (task 845, attempt 0, stage 9.0)
[2025-07-19T18:30:24.073+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=49, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.074+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=49),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/49] for update
[2025-07-19T18:30:24.074+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 42.0 in stage 9.0 (TID 845). 5829 bytes result sent to driver
[2025-07-19T18:30:24.074+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 51.0 in stage 9.0 (TID 854) (8b44f3d35cfa, executor driver, partition 51, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.074+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 51.0 in stage 9.0 (TID 854)
[2025-07-19T18:30:24.074+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 42.0 in stage 9.0 (TID 845) in 87 ms on 8b44f3d35cfa (executor driver) (44/200)
[2025-07-19T18:30:24.074+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.079+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 45 (task 848, attempt 0, stage 9.0)
[2025-07-19T18:30:24.079+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 50.0 in stage 9.0 (TID 853)
[2025-07-19T18:30:24.081+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 45.0 in stage 9.0 (TID 848). 5872 bytes result sent to driver
[2025-07-19T18:30:24.083+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.084+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.084+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.084+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.085+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 44 (task 847, attempt 0, stage 9.0)
[2025-07-19T18:30:24.088+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 44.0 in stage 9.0 (TID 847). 5915 bytes result sent to driver
[2025-07-19T18:30:24.089+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1afb63d1
[2025-07-19T18:30:24.090+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 52.0 in stage 9.0 (TID 855) (8b44f3d35cfa, executor driver, partition 52, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.092+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 45.0 in stage 9.0 (TID 848) in 93 ms on 8b44f3d35cfa (executor driver) (45/200)
[2025-07-19T18:30:24.092+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 52.0 in stage 9.0 (TID 855)
[2025-07-19T18:30:24.092+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=51, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.093+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/46/.2.delta.5f17462c-81c2-4407-a0b2-0b9f194514aa.TID849.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/46/2.delta
[2025-07-19T18:30:24.093+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=46),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/46] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/46/2.delta
[2025-07-19T18:30:24.093+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 44.0 in stage 9.0 (TID 847) in 95 ms on 8b44f3d35cfa (executor driver) (46/200)
[2025-07-19T18:30:24.093+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@498a71e2
[2025-07-19T18:30:24.093+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=51),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/51] for update
[2025-07-19T18:30:24.093+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 46 (task 849, attempt 0, stage 9.0)
[2025-07-19T18:30:24.094+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=50, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.094+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=50),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/50] for update
[2025-07-19T18:30:24.094+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 53.0 in stage 9.0 (TID 856) (8b44f3d35cfa, executor driver, partition 53, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.095+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 53.0 in stage 9.0 (TID 856)
[2025-07-19T18:30:24.095+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.096+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.097+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.098+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/47/.2.delta.7cf6737f-fa33-44d9-8b82-019cd1f9a956.TID850.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/47/2.delta
[2025-07-19T18:30:24.098+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=47),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/47] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/47/2.delta
[2025-07-19T18:30:24.099+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.099+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.100+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.100+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 46 (task 849, attempt 0, stage 9.0)
[2025-07-19T18:30:24.101+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 46.0 in stage 9.0 (TID 849). 5872 bytes result sent to driver
[2025-07-19T18:30:24.101+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 47 (task 850, attempt 0, stage 9.0)
[2025-07-19T18:30:24.102+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/49/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/49/.2.delta.defeba16-bbf9-4ed4-9b3d-c224970f0499.TID852.tmp
[2025-07-19T18:30:24.103+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 54.0 in stage 9.0 (TID 857) (8b44f3d35cfa, executor driver, partition 54, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.104+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 46.0 in stage 9.0 (TID 849) in 90 ms on 8b44f3d35cfa (executor driver) (47/200)
[2025-07-19T18:30:24.106+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 54.0 in stage 9.0 (TID 857)
[2025-07-19T18:30:24.107+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@66a663da
[2025-07-19T18:30:24.108+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/51/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/51/.2.delta.f4288136-6c7b-4f87-826b-5dea4b51c36a.TID854.tmp
[2025-07-19T18:30:24.108+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=52, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.108+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=52),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/52] for update
[2025-07-19T18:30:24.109+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 47 (task 850, attempt 0, stage 9.0)
[2025-07-19T18:30:24.110+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 47.0 in stage 9.0 (TID 850). 5872 bytes result sent to driver
[2025-07-19T18:30:24.111+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.111+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.112+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 55.0 in stage 9.0 (TID 858) (8b44f3d35cfa, executor driver, partition 55, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.112+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 47.0 in stage 9.0 (TID 850) in 83 ms on 8b44f3d35cfa (executor driver) (48/200)
[2025-07-19T18:30:24.112+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 55.0 in stage 9.0 (TID 858)
[2025-07-19T18:30:24.112+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.113+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/50/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/50/.2.delta.69b941ea-173d-4b4f-a271-75dcf51cc9de.TID853.tmp
[2025-07-19T18:30:24.113+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b100abe
[2025-07-19T18:30:24.114+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.114+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.115+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=53, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.115+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=53),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/53] for update
[2025-07-19T18:30:24.115+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.115+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@637897b9
[2025-07-19T18:30:24.116+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=55, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.117+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=55),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/55] for update
[2025-07-19T18:30:24.118+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.119+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/48/.2.delta.716f7ae7-960c-408b-bce6-cbf1e97a13ba.TID851.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/48/2.delta
[2025-07-19T18:30:24.122+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=48),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/48] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/48/2.delta
[2025-07-19T18:30:24.123+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/53/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/53/.2.delta.aab2abe6-add0-4c94-b511-870e0c760ed5.TID856.tmp
[2025-07-19T18:30:24.124+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 48 (task 851, attempt 0, stage 9.0)
[2025-07-19T18:30:24.124+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7e059ac5
[2025-07-19T18:30:24.124+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/55/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/55/.2.delta.0e679dd0-0344-410b-9284-5baf5c385662.TID858.tmp
[2025-07-19T18:30:24.125+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 48 (task 851, attempt 0, stage 9.0)
[2025-07-19T18:30:24.125+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 48.0 in stage 9.0 (TID 851). 5872 bytes result sent to driver
[2025-07-19T18:30:24.126+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/52/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/52/.2.delta.ad3af1af-add0-4b56-8bba-61dc51d15920.TID855.tmp
[2025-07-19T18:30:24.127+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=54, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.127+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 56.0 in stage 9.0 (TID 859) (8b44f3d35cfa, executor driver, partition 56, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.128+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 56.0 in stage 9.0 (TID 859)
[2025-07-19T18:30:24.128+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 48.0 in stage 9.0 (TID 851) in 79 ms on 8b44f3d35cfa (executor driver) (49/200)
[2025-07-19T18:30:24.128+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=54),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/54] for update
[2025-07-19T18:30:24.128+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.128+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:24.131+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.133+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73bd8ed5
[2025-07-19T18:30:24.133+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=56, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.133+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=56),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/56] for update
[2025-07-19T18:30:24.134+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.134+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/49/.2.delta.defeba16-bbf9-4ed4-9b3d-c224970f0499.TID852.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/49/2.delta
[2025-07-19T18:30:24.134+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=49),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/49] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/49/2.delta
[2025-07-19T18:30:24.134+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 49 (task 852, attempt 0, stage 9.0)
[2025-07-19T18:30:24.137+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/54/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/54/.2.delta.ddc62e6d-666e-4f20-8697-d343358783c8.TID857.tmp
[2025-07-19T18:30:24.139+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 49 (task 852, attempt 0, stage 9.0)
[2025-07-19T18:30:24.140+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 49.0 in stage 9.0 (TID 852). 5872 bytes result sent to driver
[2025-07-19T18:30:24.141+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 57.0 in stage 9.0 (TID 860) (8b44f3d35cfa, executor driver, partition 57, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.142+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 49.0 in stage 9.0 (TID 852) in 78 ms on 8b44f3d35cfa (executor driver) (50/200)
[2025-07-19T18:30:24.142+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 57.0 in stage 9.0 (TID 860)
[2025-07-19T18:30:24.143+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/51/.2.delta.f4288136-6c7b-4f87-826b-5dea4b51c36a.TID854.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/51/2.delta
[2025-07-19T18:30:24.144+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=51),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/51] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/51/2.delta
[2025-07-19T18:30:24.144+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.145+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.146+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 51 (task 854, attempt 0, stage 9.0)
[2025-07-19T18:30:24.147+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/56/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/56/.2.delta.c989b6f5-0d7d-403b-9b12-944cb0d7f649.TID859.tmp
[2025-07-19T18:30:24.148+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1f5fe45b
[2025-07-19T18:30:24.150+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 51 (task 854, attempt 0, stage 9.0)
[2025-07-19T18:30:24.150+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=57, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.151+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=57),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/57] for update
[2025-07-19T18:30:24.151+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 51.0 in stage 9.0 (TID 854). 5872 bytes result sent to driver
[2025-07-19T18:30:24.153+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/50/.2.delta.69b941ea-173d-4b4f-a271-75dcf51cc9de.TID853.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/50/2.delta
[2025-07-19T18:30:24.154+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=50),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/50] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/50/2.delta
[2025-07-19T18:30:24.155+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 58.0 in stage 9.0 (TID 861) (8b44f3d35cfa, executor driver, partition 58, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.156+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 50 (task 853, attempt 0, stage 9.0)
[2025-07-19T18:30:24.157+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 51.0 in stage 9.0 (TID 854) in 81 ms on 8b44f3d35cfa (executor driver) (51/200)
[2025-07-19T18:30:24.157+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 58.0 in stage 9.0 (TID 861)
[2025-07-19T18:30:24.158+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.159+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 50 (task 853, attempt 0, stage 9.0)
[2025-07-19T18:30:24.160+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 50.0 in stage 9.0 (TID 853). 5872 bytes result sent to driver
[2025-07-19T18:30:24.160+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 59.0 in stage 9.0 (TID 862) (8b44f3d35cfa, executor driver, partition 59, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.161+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 59.0 in stage 9.0 (TID 862)
[2025-07-19T18:30:24.164+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.164+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:24.165+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 50.0 in stage 9.0 (TID 853) in 91 ms on 8b44f3d35cfa (executor driver) (52/200)
[2025-07-19T18:30:24.166+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@32b374ac
[2025-07-19T18:30:24.167+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=58, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.168+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=58),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/58] for update
[2025-07-19T18:30:24.169+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.171+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.171+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.171+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/57/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/57/.2.delta.aa45abe6-8f85-4890-ae29-60cf0ef198cc.TID860.tmp
[2025-07-19T18:30:24.171+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/55/.2.delta.0e679dd0-0344-410b-9284-5baf5c385662.TID858.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/55/2.delta
[2025-07-19T18:30:24.172+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=55),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/55] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/55/2.delta
[2025-07-19T18:30:24.172+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65eb26c6
[2025-07-19T18:30:24.173+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 55 (task 858, attempt 0, stage 9.0)
[2025-07-19T18:30:24.174+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=59, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.174+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=59),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/59] for update
[2025-07-19T18:30:24.175+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/53/.2.delta.aab2abe6-add0-4c94-b511-870e0c760ed5.TID856.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/53/2.delta
[2025-07-19T18:30:24.176+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=53),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/53] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/53/2.delta
[2025-07-19T18:30:24.176+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 53 (task 856, attempt 0, stage 9.0)
[2025-07-19T18:30:24.176+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/52/.2.delta.ad3af1af-add0-4b56-8bba-61dc51d15920.TID855.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/52/2.delta
[2025-07-19T18:30:24.178+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=52),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/52] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/52/2.delta
[2025-07-19T18:30:24.179+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 52 (task 855, attempt 0, stage 9.0)
[2025-07-19T18:30:24.179+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.179+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/58/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/58/.2.delta.948b3673-85c8-4092-b944-f1b6309269b1.TID861.tmp
[2025-07-19T18:30:24.179+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 55 (task 858, attempt 0, stage 9.0)
[2025-07-19T18:30:24.179+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 55.0 in stage 9.0 (TID 858). 5829 bytes result sent to driver
[2025-07-19T18:30:24.179+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 60.0 in stage 9.0 (TID 863) (8b44f3d35cfa, executor driver, partition 60, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.180+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 60.0 in stage 9.0 (TID 863)
[2025-07-19T18:30:24.182+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 55.0 in stage 9.0 (TID 858) in 64 ms on 8b44f3d35cfa (executor driver) (53/200)
[2025-07-19T18:30:24.183+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/54/.2.delta.ddc62e6d-666e-4f20-8697-d343358783c8.TID857.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/54/2.delta
[2025-07-19T18:30:24.183+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.183+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.183+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=54),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/54] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/54/2.delta
[2025-07-19T18:30:24.184+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 53 (task 856, attempt 0, stage 9.0)
[2025-07-19T18:30:24.184+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 52 (task 855, attempt 0, stage 9.0)
[2025-07-19T18:30:24.185+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 54 (task 857, attempt 0, stage 9.0)
[2025-07-19T18:30:24.187+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 53.0 in stage 9.0 (TID 856). 5829 bytes result sent to driver
[2025-07-19T18:30:24.188+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 61.0 in stage 9.0 (TID 864) (8b44f3d35cfa, executor driver, partition 61, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.188+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 52.0 in stage 9.0 (TID 855). 5829 bytes result sent to driver
[2025-07-19T18:30:24.189+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 53.0 in stage 9.0 (TID 856) in 84 ms on 8b44f3d35cfa (executor driver) (54/200)
[2025-07-19T18:30:24.189+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 61.0 in stage 9.0 (TID 864)
[2025-07-19T18:30:24.190+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 54 (task 857, attempt 0, stage 9.0)
[2025-07-19T18:30:24.191+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 54.0 in stage 9.0 (TID 857). 5829 bytes result sent to driver
[2025-07-19T18:30:24.191+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@587c1d7f
[2025-07-19T18:30:24.191+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 62.0 in stage 9.0 (TID 865) (8b44f3d35cfa, executor driver, partition 62, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.191+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 63.0 in stage 9.0 (TID 866) (8b44f3d35cfa, executor driver, partition 63, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.192+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.193+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.193+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=60, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.193+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 52.0 in stage 9.0 (TID 855) in 91 ms on 8b44f3d35cfa (executor driver) (55/200)
[2025-07-19T18:30:24.193+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 54.0 in stage 9.0 (TID 857) in 81 ms on 8b44f3d35cfa (executor driver) (56/200)
[2025-07-19T18:30:24.194+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 62.0 in stage 9.0 (TID 865)
[2025-07-19T18:30:24.194+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=60),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/60] for update
[2025-07-19T18:30:24.194+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@422892da
[2025-07-19T18:30:24.195+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=61, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.195+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=61),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/61] for update
[2025-07-19T18:30:24.195+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 63.0 in stage 9.0 (TID 866)
[2025-07-19T18:30:24.195+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/56/.2.delta.c989b6f5-0d7d-403b-9b12-944cb0d7f649.TID859.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/56/2.delta
[2025-07-19T18:30:24.196+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=56),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/56] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/56/2.delta
[2025-07-19T18:30:24.196+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/59/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/59/.2.delta.e4b7cdd1-a1e9-430f-aefc-97190cc271f4.TID862.tmp
[2025-07-19T18:30:24.196+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 56 (task 859, attempt 0, stage 9.0)
[2025-07-19T18:30:24.196+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.197+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2025-07-19T18:30:24.197+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.201+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.202+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
[2025-07-19T18:30:24.203+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.203+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 56 (task 859, attempt 0, stage 9.0)
[2025-07-19T18:30:24.203+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 56.0 in stage 9.0 (TID 859). 5829 bytes result sent to driver
[2025-07-19T18:30:24.203+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 64.0 in stage 9.0 (TID 867) (8b44f3d35cfa, executor driver, partition 64, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.204+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 8b44f3d35cfa:40517 in memory (size: 35.4 KiB, free: 434.3 MiB)
[2025-07-19T18:30:24.206+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/60/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/60/.2.delta.38a71fe7-cf79-4364-9940-17445189cd36.TID863.tmp
[2025-07-19T18:30:24.208+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@64b2ec73
[2025-07-19T18:30:24.208+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/61/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/61/.2.delta.d1724454-e166-48ae-a69b-361397bdad33.TID864.tmp
[2025-07-19T18:30:24.208+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/57/.2.delta.aa45abe6-8f85-4890-ae29-60cf0ef198cc.TID860.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/57/2.delta
[2025-07-19T18:30:24.208+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=57),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/57] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/57/2.delta
[2025-07-19T18:30:24.209+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 56.0 in stage 9.0 (TID 859) in 86 ms on 8b44f3d35cfa (executor driver) (57/200)
[2025-07-19T18:30:24.209+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 64.0 in stage 9.0 (TID 867)
[2025-07-19T18:30:24.210+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 8b44f3d35cfa:40517 in memory (size: 15.9 KiB, free: 434.3 MiB)
[2025-07-19T18:30:24.216+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.217+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T18:30:24.219+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=62, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.220+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=62),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/62] for update
[2025-07-19T18:30:24.221+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 57 (task 860, attempt 0, stage 9.0)
[2025-07-19T18:30:24.221+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 8b44f3d35cfa:40517 in memory (size: 29.5 KiB, free: 434.3 MiB)
[2025-07-19T18:30:24.223+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.224+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 57 (task 860, attempt 0, stage 9.0)
[2025-07-19T18:30:24.224+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 57.0 in stage 9.0 (TID 860). 5829 bytes result sent to driver
[2025-07-19T18:30:24.225+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/58/.2.delta.948b3673-85c8-4092-b944-f1b6309269b1.TID861.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/58/2.delta
[2025-07-19T18:30:24.226+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=58),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/58] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/58/2.delta
[2025-07-19T18:30:24.227+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 58 (task 861, attempt 0, stage 9.0)
[2025-07-19T18:30:24.228+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 65.0 in stage 9.0 (TID 868) (8b44f3d35cfa, executor driver, partition 65, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.232+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/59/.2.delta.e4b7cdd1-a1e9-430f-aefc-97190cc271f4.TID862.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/59/2.delta
[2025-07-19T18:30:24.234+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6478c714
[2025-07-19T18:30:24.237+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 58 (task 861, attempt 0, stage 9.0)
[2025-07-19T18:30:24.238+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=64, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.238+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=64),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/64] for update
[2025-07-19T18:30:24.240+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 57.0 in stage 9.0 (TID 860) in 91 ms on 8b44f3d35cfa (executor driver) (58/200)
[2025-07-19T18:30:24.242+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 58.0 in stage 9.0 (TID 861). 5829 bytes result sent to driver
[2025-07-19T18:30:24.242+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=59),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/59] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/59/2.delta
[2025-07-19T18:30:24.243+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@387742a6
[2025-07-19T18:30:24.244+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.245+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=63, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.245+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 59 (task 862, attempt 0, stage 9.0)
[2025-07-19T18:30:24.245+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=63),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/63] for update
[2025-07-19T18:30:24.245+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 66.0 in stage 9.0 (TID 869) (8b44f3d35cfa, executor driver, partition 66, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.245+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 66.0 in stage 9.0 (TID 869)
[2025-07-19T18:30:24.246+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.246+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 58.0 in stage 9.0 (TID 861) in 85 ms on 8b44f3d35cfa (executor driver) (59/200)
[2025-07-19T18:30:24.246+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 65.0 in stage 9.0 (TID 868)
[2025-07-19T18:30:24.247+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 59 (task 862, attempt 0, stage 9.0)
[2025-07-19T18:30:24.247+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 59.0 in stage 9.0 (TID 862). 5829 bytes result sent to driver
[2025-07-19T18:30:24.247+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 67.0 in stage 9.0 (TID 870) (8b44f3d35cfa, executor driver, partition 67, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.248+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 59.0 in stage 9.0 (TID 862) in 84 ms on 8b44f3d35cfa (executor driver) (60/200)
[2025-07-19T18:30:24.248+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.249+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.249+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 67.0 in stage 9.0 (TID 870)
[2025-07-19T18:30:24.251+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@394775df
[2025-07-19T18:30:24.251+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=65, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.251+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=65),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/65] for update
[2025-07-19T18:30:24.252+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.253+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.254+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:24.254+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d01ebdf
[2025-07-19T18:30:24.255+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=66, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.257+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=66),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/66] for update
[2025-07-19T18:30:24.258+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.259+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.259+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1be78d92
[2025-07-19T18:30:24.260+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.260+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=67, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.260+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=67),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/67] for update
[2025-07-19T18:30:24.260+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/64/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/64/.2.delta.fc162537-3b97-4c2e-bbee-411b3955ad2c.TID867.tmp
[2025-07-19T18:30:24.260+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.261+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/62/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/62/.2.delta.eec53b41-d28f-4018-83bd-39c5afb0d733.TID865.tmp
[2025-07-19T18:30:24.262+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/63/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/63/.2.delta.0ec3d6b3-4b47-4ee4-98d0-aa8202c75ffb.TID866.tmp
[2025-07-19T18:30:24.262+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/61/.2.delta.d1724454-e166-48ae-a69b-361397bdad33.TID864.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/61/2.delta
[2025-07-19T18:30:24.262+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=61),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/61] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/61/2.delta
[2025-07-19T18:30:24.263+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 61 (task 864, attempt 0, stage 9.0)
[2025-07-19T18:30:24.263+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 61 (task 864, attempt 0, stage 9.0)
[2025-07-19T18:30:24.263+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/60/.2.delta.38a71fe7-cf79-4364-9940-17445189cd36.TID863.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/60/2.delta
[2025-07-19T18:30:24.263+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=60),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/60] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/60/2.delta
[2025-07-19T18:30:24.263+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 61.0 in stage 9.0 (TID 864). 5829 bytes result sent to driver
[2025-07-19T18:30:24.263+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 60 (task 863, attempt 0, stage 9.0)
[2025-07-19T18:30:24.263+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 68.0 in stage 9.0 (TID 871) (8b44f3d35cfa, executor driver, partition 68, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.263+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 61.0 in stage 9.0 (TID 864) in 82 ms on 8b44f3d35cfa (executor driver) (61/200)
[2025-07-19T18:30:24.263+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 68.0 in stage 9.0 (TID 871)
[2025-07-19T18:30:24.263+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/66/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/66/.2.delta.af85943c-1f8b-483b-9c37-e63ca4976608.TID869.tmp
[2025-07-19T18:30:24.263+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/65/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/65/.2.delta.f42b18ae-6e90-4833-b743-cc5d6e669b3e.TID868.tmp
[2025-07-19T18:30:24.265+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 60 (task 863, attempt 0, stage 9.0)
[2025-07-19T18:30:24.265+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 60.0 in stage 9.0 (TID 863). 5829 bytes result sent to driver
[2025-07-19T18:30:24.265+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.266+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.268+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 69.0 in stage 9.0 (TID 872) (8b44f3d35cfa, executor driver, partition 69, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.268+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 60.0 in stage 9.0 (TID 863) in 94 ms on 8b44f3d35cfa (executor driver) (62/200)
[2025-07-19T18:30:24.268+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 69.0 in stage 9.0 (TID 872)
[2025-07-19T18:30:24.269+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@b546a4
[2025-07-19T18:30:24.270+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.270+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.271+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=68, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.271+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=68),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/68] for update
[2025-07-19T18:30:24.272+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@388a6ec8
[2025-07-19T18:30:24.272+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=69, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.272+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=69),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/69] for update
[2025-07-19T18:30:24.272+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.273+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/67/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/67/.2.delta.1fc034c8-42a2-4be8-9e5c-554ebd5dcbc0.TID870.tmp
[2025-07-19T18:30:24.273+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.276+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/68/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/68/.2.delta.c2b2727c-3ced-4717-9a08-b315de99ba8c.TID871.tmp
[2025-07-19T18:30:24.280+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/69/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/69/.2.delta.4e69cb46-6e32-4322-9be4-310593812efe.TID872.tmp
[2025-07-19T18:30:24.291+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/64/.2.delta.fc162537-3b97-4c2e-bbee-411b3955ad2c.TID867.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/64/2.delta
[2025-07-19T18:30:24.291+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=64),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/64] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/64/2.delta
[2025-07-19T18:30:24.292+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 64 (task 867, attempt 0, stage 9.0)
[2025-07-19T18:30:24.296+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/65/.2.delta.f42b18ae-6e90-4833-b743-cc5d6e669b3e.TID868.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/65/2.delta
[2025-07-19T18:30:24.297+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=65),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/65] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/65/2.delta
[2025-07-19T18:30:24.297+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 64 (task 867, attempt 0, stage 9.0)
[2025-07-19T18:30:24.297+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 64.0 in stage 9.0 (TID 867). 5829 bytes result sent to driver
[2025-07-19T18:30:24.297+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 70.0 in stage 9.0 (TID 873) (8b44f3d35cfa, executor driver, partition 70, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.297+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/62/.2.delta.eec53b41-d28f-4018-83bd-39c5afb0d733.TID865.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/62/2.delta
[2025-07-19T18:30:24.297+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 65 (task 868, attempt 0, stage 9.0)
[2025-07-19T18:30:24.297+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=62),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/62] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/62/2.delta
[2025-07-19T18:30:24.297+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 62 (task 865, attempt 0, stage 9.0)
[2025-07-19T18:30:24.299+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 64.0 in stage 9.0 (TID 867) in 96 ms on 8b44f3d35cfa (executor driver) (63/200)
[2025-07-19T18:30:24.301+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 70.0 in stage 9.0 (TID 873)
[2025-07-19T18:30:24.302+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 65 (task 868, attempt 0, stage 9.0)
[2025-07-19T18:30:24.303+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 65.0 in stage 9.0 (TID 868). 5829 bytes result sent to driver
[2025-07-19T18:30:24.303+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 71.0 in stage 9.0 (TID 874) (8b44f3d35cfa, executor driver, partition 71, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.304+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 65.0 in stage 9.0 (TID 868) in 76 ms on 8b44f3d35cfa (executor driver) (64/200)
[2025-07-19T18:30:24.305+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 71.0 in stage 9.0 (TID 874)
[2025-07-19T18:30:24.306+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/63/.2.delta.0ec3d6b3-4b47-4ee4-98d0-aa8202c75ffb.TID866.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/63/2.delta
[2025-07-19T18:30:24.306+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=63),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/63] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/63/2.delta
[2025-07-19T18:30:24.307+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 63 (task 866, attempt 0, stage 9.0)
[2025-07-19T18:30:24.307+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.308+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.308+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ca57e5
[2025-07-19T18:30:24.308+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=71, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.308+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=71),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/71] for update
[2025-07-19T18:30:24.308+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 62 (task 865, attempt 0, stage 9.0)
[2025-07-19T18:30:24.309+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 62.0 in stage 9.0 (TID 865). 5829 bytes result sent to driver
[2025-07-19T18:30:24.309+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/67/.2.delta.1fc034c8-42a2-4be8-9e5c-554ebd5dcbc0.TID870.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/67/2.delta
[2025-07-19T18:30:24.309+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=67),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/67] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/67/2.delta
[2025-07-19T18:30:24.309+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 67 (task 870, attempt 0, stage 9.0)
[2025-07-19T18:30:24.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 62.0 in stage 9.0 (TID 865) in 128 ms on 8b44f3d35cfa (executor driver) (65/200)
[2025-07-19T18:30:24.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 72.0 in stage 9.0 (TID 875) (8b44f3d35cfa, executor driver, partition 72, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 72.0 in stage 9.0 (TID 875)
[2025-07-19T18:30:24.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ec2b12e
[2025-07-19T18:30:24.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=72, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=72),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/72] for update
[2025-07-19T18:30:24.311+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.311+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T18:30:24.311+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.312+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74476d84
[2025-07-19T18:30:24.314+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=70, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.314+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=70),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/70] for update
[2025-07-19T18:30:24.314+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.314+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 67 (task 870, attempt 0, stage 9.0)
[2025-07-19T18:30:24.314+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 67.0 in stage 9.0 (TID 870). 5829 bytes result sent to driver
[2025-07-19T18:30:24.314+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 73.0 in stage 9.0 (TID 876) (8b44f3d35cfa, executor driver, partition 73, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.314+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 67.0 in stage 9.0 (TID 870) in 78 ms on 8b44f3d35cfa (executor driver) (66/200)
[2025-07-19T18:30:24.315+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 73.0 in stage 9.0 (TID 876)
[2025-07-19T18:30:24.318+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/66/.2.delta.af85943c-1f8b-483b-9c37-e63ca4976608.TID869.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/66/2.delta
[2025-07-19T18:30:24.319+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 63 (task 866, attempt 0, stage 9.0)
[2025-07-19T18:30:24.320+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=66),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/66] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/66/2.delta
[2025-07-19T18:30:24.320+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/69/.2.delta.4e69cb46-6e32-4322-9be4-310593812efe.TID872.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/69/2.delta
[2025-07-19T18:30:24.320+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=69),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/69] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/69/2.delta
[2025-07-19T18:30:24.321+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 69 (task 872, attempt 0, stage 9.0)
[2025-07-19T18:30:24.321+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 66 (task 869, attempt 0, stage 9.0)
[2025-07-19T18:30:24.322+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 63.0 in stage 9.0 (TID 866). 5829 bytes result sent to driver
[2025-07-19T18:30:24.322+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 74.0 in stage 9.0 (TID 877) (8b44f3d35cfa, executor driver, partition 74, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.323+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.323+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.323+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 74.0 in stage 9.0 (TID 877)
[2025-07-19T18:30:24.323+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 63.0 in stage 9.0 (TID 866) in 143 ms on 8b44f3d35cfa (executor driver) (67/200)
[2025-07-19T18:30:24.324+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.326+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.326+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/68/.2.delta.c2b2727c-3ced-4717-9a08-b315de99ba8c.TID871.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/68/2.delta
[2025-07-19T18:30:24.326+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=68),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/68] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/68/2.delta
[2025-07-19T18:30:24.327+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 69 (task 872, attempt 0, stage 9.0)
[2025-07-19T18:30:24.327+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 69.0 in stage 9.0 (TID 872). 5829 bytes result sent to driver
[2025-07-19T18:30:24.328+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 66 (task 869, attempt 0, stage 9.0)
[2025-07-19T18:30:24.329+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6aa39b45
[2025-07-19T18:30:24.330+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 68 (task 871, attempt 0, stage 9.0)
[2025-07-19T18:30:24.330+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 66.0 in stage 9.0 (TID 869). 5829 bytes result sent to driver
[2025-07-19T18:30:24.331+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 75.0 in stage 9.0 (TID 878) (8b44f3d35cfa, executor driver, partition 75, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.332+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 76.0 in stage 9.0 (TID 879) (8b44f3d35cfa, executor driver, partition 76, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.335+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=73, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.335+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=73),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/73] for update
[2025-07-19T18:30:24.336+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 75.0 in stage 9.0 (TID 878)
[2025-07-19T18:30:24.337+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 76.0 in stage 9.0 (TID 879)
[2025-07-19T18:30:24.337+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/71/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/71/.2.delta.fcfc2052-2c92-45a0-9a95-911561dafe7e.TID874.tmp
[2025-07-19T18:30:24.337+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 69.0 in stage 9.0 (TID 872) in 64 ms on 8b44f3d35cfa (executor driver) (68/200)
[2025-07-19T18:30:24.338+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@639838e7
[2025-07-19T18:30:24.338+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/72/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/72/.2.delta.d0fdb6d9-d1e1-4210-a160-9ad846d0f30a.TID875.tmp
[2025-07-19T18:30:24.338+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=74, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.338+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=74),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/74] for update
[2025-07-19T18:30:24.339+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.339+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.339+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 66.0 in stage 9.0 (TID 869) in 98 ms on 8b44f3d35cfa (executor driver) (69/200)
[2025-07-19T18:30:24.340+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.340+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.340+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.340+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 68 (task 871, attempt 0, stage 9.0)
[2025-07-19T18:30:24.340+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 68.0 in stage 9.0 (TID 871). 5829 bytes result sent to driver
[2025-07-19T18:30:24.340+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 77.0 in stage 9.0 (TID 880) (8b44f3d35cfa, executor driver, partition 77, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.340+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 68.0 in stage 9.0 (TID 871) in 75 ms on 8b44f3d35cfa (executor driver) (70/200)
[2025-07-19T18:30:24.340+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 77.0 in stage 9.0 (TID 880)
[2025-07-19T18:30:24.340+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/70/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/70/.2.delta.5560a165-5f9e-490b-8840-f784f56038b0.TID873.tmp
[2025-07-19T18:30:24.341+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.341+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.341+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.341+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7146c8a3
[2025-07-19T18:30:24.341+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=75, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.341+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=75),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/75] for update
[2025-07-19T18:30:24.341+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.342+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@75525e9f
[2025-07-19T18:30:24.344+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=77, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.345+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=77),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/77] for update
[2025-07-19T18:30:24.346+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.346+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@13039c80
[2025-07-19T18:30:24.346+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=76, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.346+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=76),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/76] for update
[2025-07-19T18:30:24.346+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.346+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/73/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/73/.2.delta.31d43db5-e039-404f-9dac-086d7c43a5e3.TID876.tmp
[2025-07-19T18:30:24.346+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/75/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/75/.2.delta.042853a1-dc8d-4de3-adab-1bdfba95e2f3.TID878.tmp
[2025-07-19T18:30:24.347+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/74/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/74/.2.delta.75aa26e0-1431-4225-9f7c-d24ad8f35480.TID877.tmp
[2025-07-19T18:30:24.351+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/77/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/77/.2.delta.9d49fe35-3f4f-48ef-9899-7faf96c3b604.TID880.tmp
[2025-07-19T18:30:24.356+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/76/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/76/.2.delta.e675e955-40e9-4605-9c12-0537cbb7cb9d.TID879.tmp
[2025-07-19T18:30:24.370+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/71/.2.delta.fcfc2052-2c92-45a0-9a95-911561dafe7e.TID874.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/71/2.delta
[2025-07-19T18:30:24.370+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=71),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/71] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/71/2.delta
[2025-07-19T18:30:24.370+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 71 (task 874, attempt 0, stage 9.0)
[2025-07-19T18:30:24.374+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/70/.2.delta.5560a165-5f9e-490b-8840-f784f56038b0.TID873.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/70/2.delta
[2025-07-19T18:30:24.375+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=70),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/70] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/70/2.delta
[2025-07-19T18:30:24.376+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 70 (task 873, attempt 0, stage 9.0)
[2025-07-19T18:30:24.381+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/72/.2.delta.d0fdb6d9-d1e1-4210-a160-9ad846d0f30a.TID875.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/72/2.delta
[2025-07-19T18:30:24.383+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=72),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/72] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/72/2.delta
[2025-07-19T18:30:24.383+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 72 (task 875, attempt 0, stage 9.0)
[2025-07-19T18:30:24.385+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 71 (task 874, attempt 0, stage 9.0)
[2025-07-19T18:30:24.386+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 71.0 in stage 9.0 (TID 874). 5829 bytes result sent to driver
[2025-07-19T18:30:24.387+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 78.0 in stage 9.0 (TID 881) (8b44f3d35cfa, executor driver, partition 78, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.387+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 71.0 in stage 9.0 (TID 874) in 75 ms on 8b44f3d35cfa (executor driver) (71/200)
[2025-07-19T18:30:24.388+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 78.0 in stage 9.0 (TID 881)
[2025-07-19T18:30:24.388+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 70 (task 873, attempt 0, stage 9.0)
[2025-07-19T18:30:24.389+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.390+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.391+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 70.0 in stage 9.0 (TID 873). 5829 bytes result sent to driver
[2025-07-19T18:30:24.394+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 72 (task 875, attempt 0, stage 9.0)
[2025-07-19T18:30:24.395+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 79.0 in stage 9.0 (TID 882) (8b44f3d35cfa, executor driver, partition 79, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.396+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 79.0 in stage 9.0 (TID 882)
[2025-07-19T18:30:24.397+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 72.0 in stage 9.0 (TID 875). 5829 bytes result sent to driver
[2025-07-19T18:30:24.398+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 70.0 in stage 9.0 (TID 873) in 85 ms on 8b44f3d35cfa (executor driver) (72/200)
[2025-07-19T18:30:24.399+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 72.0 in stage 9.0 (TID 875) in 74 ms on 8b44f3d35cfa (executor driver) (73/200)
[2025-07-19T18:30:24.399+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 80.0 in stage 9.0 (TID 883) (8b44f3d35cfa, executor driver, partition 80, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.400+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@539b65ff
[2025-07-19T18:30:24.401+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 80.0 in stage 9.0 (TID 883)
[2025-07-19T18:30:24.402+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=78, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.402+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=78),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/78] for update
[2025-07-19T18:30:24.402+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/77/.2.delta.9d49fe35-3f4f-48ef-9899-7faf96c3b604.TID880.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/77/2.delta
[2025-07-19T18:30:24.402+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=77),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/77] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/77/2.delta
[2025-07-19T18:30:24.402+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/73/.2.delta.31d43db5-e039-404f-9dac-086d7c43a5e3.TID876.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/73/2.delta
[2025-07-19T18:30:24.402+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=73),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/73] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/73/2.delta
[2025-07-19T18:30:24.403+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/75/.2.delta.042853a1-dc8d-4de3-adab-1bdfba95e2f3.TID878.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/75/2.delta
[2025-07-19T18:30:24.403+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=75),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/75] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/75/2.delta
[2025-07-19T18:30:24.403+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.403+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.403+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 73 (task 876, attempt 0, stage 9.0)
[2025-07-19T18:30:24.404+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 77 (task 880, attempt 0, stage 9.0)
[2025-07-19T18:30:24.405+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/74/.2.delta.75aa26e0-1431-4225-9f7c-d24ad8f35480.TID877.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/74/2.delta
[2025-07-19T18:30:24.406+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=74),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/74] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/74/2.delta
[2025-07-19T18:30:24.406+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.407+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.409+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7bc7e801
[2025-07-19T18:30:24.410+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 74 (task 877, attempt 0, stage 9.0)
[2025-07-19T18:30:24.411+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.412+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/76/.2.delta.e675e955-40e9-4605-9c12-0537cbb7cb9d.TID879.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/76/2.delta
[2025-07-19T18:30:24.413+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 75 (task 878, attempt 0, stage 9.0)
[2025-07-19T18:30:24.413+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=76),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/76] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/76/2.delta
[2025-07-19T18:30:24.414+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 73 (task 876, attempt 0, stage 9.0)
[2025-07-19T18:30:24.416+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 73.0 in stage 9.0 (TID 876). 5829 bytes result sent to driver
[2025-07-19T18:30:24.417+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 74 (task 877, attempt 0, stage 9.0)
[2025-07-19T18:30:24.417+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 74.0 in stage 9.0 (TID 877). 5829 bytes result sent to driver
[2025-07-19T18:30:24.419+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 76 (task 879, attempt 0, stage 9.0)
[2025-07-19T18:30:24.419+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=79, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.420+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 75 (task 878, attempt 0, stage 9.0)
[2025-07-19T18:30:24.420+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=79),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/79] for update
[2025-07-19T18:30:24.421+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 75.0 in stage 9.0 (TID 878). 5829 bytes result sent to driver
[2025-07-19T18:30:24.422+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 81.0 in stage 9.0 (TID 884) (8b44f3d35cfa, executor driver, partition 81, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.422+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 82.0 in stage 9.0 (TID 885) (8b44f3d35cfa, executor driver, partition 82, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.422+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 83.0 in stage 9.0 (TID 886) (8b44f3d35cfa, executor driver, partition 83, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.423+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 77 (task 880, attempt 0, stage 9.0)
[2025-07-19T18:30:24.423+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 83.0 in stage 9.0 (TID 886)
[2025-07-19T18:30:24.424+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 74.0 in stage 9.0 (TID 877) in 75 ms on 8b44f3d35cfa (executor driver) (74/200)
[2025-07-19T18:30:24.424+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 81.0 in stage 9.0 (TID 884)
[2025-07-19T18:30:24.424+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 77.0 in stage 9.0 (TID 880). 5829 bytes result sent to driver
[2025-07-19T18:30:24.424+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 73.0 in stage 9.0 (TID 876) in 79 ms on 8b44f3d35cfa (executor driver) (75/200)
[2025-07-19T18:30:24.425+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 75.0 in stage 9.0 (TID 878) in 68 ms on 8b44f3d35cfa (executor driver) (76/200)
[2025-07-19T18:30:24.425+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 84.0 in stage 9.0 (TID 887) (8b44f3d35cfa, executor driver, partition 84, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.426+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 77.0 in stage 9.0 (TID 880) in 63 ms on 8b44f3d35cfa (executor driver) (77/200)
[2025-07-19T18:30:24.426+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 82.0 in stage 9.0 (TID 885)
[2025-07-19T18:30:24.427+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5faca9b
[2025-07-19T18:30:24.429+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 84.0 in stage 9.0 (TID 887)
[2025-07-19T18:30:24.429+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.429+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 76 (task 879, attempt 0, stage 9.0)
[2025-07-19T18:30:24.430+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 76.0 in stage 9.0 (TID 879). 5829 bytes result sent to driver
[2025-07-19T18:30:24.430+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.430+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.430+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.431+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.431+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 85.0 in stage 9.0 (TID 888) (8b44f3d35cfa, executor driver, partition 85, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.432+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.432+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=80, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.433+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=80),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/80] for update
[2025-07-19T18:30:24.434+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 85.0 in stage 9.0 (TID 888)
[2025-07-19T18:30:24.434+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.434+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.435+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.435+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.436+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.436+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.436+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35cf6514
[2025-07-19T18:30:24.437+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/78/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/78/.2.delta.e75a23f9-7489-4d90-b4b1-ae9ac2183294.TID881.tmp
[2025-07-19T18:30:24.437+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/79/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/79/.2.delta.8e601780-2a9a-4a58-9f21-bd8e34d39873.TID882.tmp
[2025-07-19T18:30:24.437+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 76.0 in stage 9.0 (TID 879) in 75 ms on 8b44f3d35cfa (executor driver) (78/200)
[2025-07-19T18:30:24.438+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=81, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.439+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@588c3023
[2025-07-19T18:30:24.440+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=81),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/81] for update
[2025-07-19T18:30:24.440+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=82, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.441+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.441+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6cf9f5f6
[2025-07-19T18:30:24.441+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=82),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/82] for update
[2025-07-19T18:30:24.441+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=83, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.442+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=83),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/83] for update
[2025-07-19T18:30:24.442+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.442+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39a5bb8f
[2025-07-19T18:30:24.442+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.443+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=85, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.443+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=85),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/85] for update
[2025-07-19T18:30:24.444+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.445+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7af48759
[2025-07-19T18:30:24.445+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=84, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.447+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=84),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/84] for update
[2025-07-19T18:30:24.447+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.448+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/80/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/80/.2.delta.2512eede-e5f8-4613-a9b5-d9e0fd38651a.TID883.tmp
[2025-07-19T18:30:24.448+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/83/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/83/.2.delta.362954f7-38cb-49e5-b673-158ae93c4b27.TID886.tmp
[2025-07-19T18:30:24.449+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/81/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/81/.2.delta.11a99e2f-9af4-4c25-aff1-42c296245d31.TID884.tmp
[2025-07-19T18:30:24.450+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/85/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/85/.2.delta.600ed8f9-5f5b-45ac-bac0-c49114524914.TID888.tmp
[2025-07-19T18:30:24.450+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/84/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/84/.2.delta.6a626780-f2be-4e5a-903a-de8c86733ed5.TID887.tmp
[2025-07-19T18:30:24.450+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/82/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/82/.2.delta.ecd87fa3-cc29-43e2-8e04-aa40ad168b4b.TID885.tmp
[2025-07-19T18:30:24.450+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/78/.2.delta.e75a23f9-7489-4d90-b4b1-ae9ac2183294.TID881.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/78/2.delta
[2025-07-19T18:30:24.451+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=78),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/78] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/78/2.delta
[2025-07-19T18:30:24.452+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 78 (task 881, attempt 0, stage 9.0)
[2025-07-19T18:30:24.453+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 78 (task 881, attempt 0, stage 9.0)
[2025-07-19T18:30:24.453+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 78.0 in stage 9.0 (TID 881). 5829 bytes result sent to driver
[2025-07-19T18:30:24.455+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 86.0 in stage 9.0 (TID 889) (8b44f3d35cfa, executor driver, partition 86, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.456+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 78.0 in stage 9.0 (TID 881) in 76 ms on 8b44f3d35cfa (executor driver) (79/200)
[2025-07-19T18:30:24.456+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 86.0 in stage 9.0 (TID 889)
[2025-07-19T18:30:24.456+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/79/.2.delta.8e601780-2a9a-4a58-9f21-bd8e34d39873.TID882.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/79/2.delta
[2025-07-19T18:30:24.457+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=79),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/79] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/79/2.delta
[2025-07-19T18:30:24.457+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.458+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 79 (task 882, attempt 0, stage 9.0)
[2025-07-19T18:30:24.458+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.458+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ee83760
[2025-07-19T18:30:24.459+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=86, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.459+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=86),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/86] for update
[2025-07-19T18:30:24.461+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/80/.2.delta.2512eede-e5f8-4613-a9b5-d9e0fd38651a.TID883.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/80/2.delta
[2025-07-19T18:30:24.461+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=80),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/80] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/80/2.delta
[2025-07-19T18:30:24.462+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 80 (task 883, attempt 0, stage 9.0)
[2025-07-19T18:30:24.463+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.465+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 79 (task 882, attempt 0, stage 9.0)
[2025-07-19T18:30:24.469+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 79.0 in stage 9.0 (TID 882). 5829 bytes result sent to driver
[2025-07-19T18:30:24.470+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 87.0 in stage 9.0 (TID 890) (8b44f3d35cfa, executor driver, partition 87, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.471+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/81/.2.delta.11a99e2f-9af4-4c25-aff1-42c296245d31.TID884.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/81/2.delta
[2025-07-19T18:30:24.471+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=81),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/81] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/81/2.delta
[2025-07-19T18:30:24.472+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 80 (task 883, attempt 0, stage 9.0)
[2025-07-19T18:30:24.472+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 81 (task 884, attempt 0, stage 9.0)
[2025-07-19T18:30:24.473+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 79.0 in stage 9.0 (TID 882) in 85 ms on 8b44f3d35cfa (executor driver) (80/200)
[2025-07-19T18:30:24.473+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 80.0 in stage 9.0 (TID 883). 5829 bytes result sent to driver
[2025-07-19T18:30:24.474+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 87.0 in stage 9.0 (TID 890)
[2025-07-19T18:30:24.474+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/83/.2.delta.362954f7-38cb-49e5-b673-158ae93c4b27.TID886.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/83/2.delta
[2025-07-19T18:30:24.475+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=83),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/83] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/83/2.delta
[2025-07-19T18:30:24.476+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 81 (task 884, attempt 0, stage 9.0)
[2025-07-19T18:30:24.476+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 88.0 in stage 9.0 (TID 891) (8b44f3d35cfa, executor driver, partition 88, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.476+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 81.0 in stage 9.0 (TID 884). 5829 bytes result sent to driver
[2025-07-19T18:30:24.477+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 83 (task 886, attempt 0, stage 9.0)
[2025-07-19T18:30:24.477+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 88.0 in stage 9.0 (TID 891)
[2025-07-19T18:30:24.478+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 89.0 in stage 9.0 (TID 892) (8b44f3d35cfa, executor driver, partition 89, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.478+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.478+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 89.0 in stage 9.0 (TID 892)
[2025-07-19T18:30:24.479+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 80.0 in stage 9.0 (TID 883) in 91 ms on 8b44f3d35cfa (executor driver) (81/200)
[2025-07-19T18:30:24.479+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 81.0 in stage 9.0 (TID 884) in 80 ms on 8b44f3d35cfa (executor driver) (82/200)
[2025-07-19T18:30:24.479+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:24.479+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.479+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.479+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.479+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.479+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@323a1d7
[2025-07-19T18:30:24.479+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=87, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.479+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=87),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/87] for update
[2025-07-19T18:30:24.479+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@77edb652
[2025-07-19T18:30:24.479+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=89, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.480+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=89),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/89] for update
[2025-07-19T18:30:24.480+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/84/.2.delta.6a626780-f2be-4e5a-903a-de8c86733ed5.TID887.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/84/2.delta
[2025-07-19T18:30:24.480+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=84),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/84] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/84/2.delta
[2025-07-19T18:30:24.480+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@362a2be0
[2025-07-19T18:30:24.480+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=88, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.480+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=88),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/88] for update
[2025-07-19T18:30:24.481+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.488+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 84 (task 887, attempt 0, stage 9.0)
[2025-07-19T18:30:24.489+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.489+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.490+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/86/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/86/.2.delta.99fbbf82-c3d3-4249-9edf-34413551661d.TID889.tmp
[2025-07-19T18:30:24.490+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/85/.2.delta.600ed8f9-5f5b-45ac-bac0-c49114524914.TID888.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/85/2.delta
[2025-07-19T18:30:24.490+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=85),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/85] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/85/2.delta
[2025-07-19T18:30:24.491+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 85 (task 888, attempt 0, stage 9.0)
[2025-07-19T18:30:24.497+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 83 (task 886, attempt 0, stage 9.0)
[2025-07-19T18:30:24.498+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/82/.2.delta.ecd87fa3-cc29-43e2-8e04-aa40ad168b4b.TID885.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/82/2.delta
[2025-07-19T18:30:24.498+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=82),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/82] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/82/2.delta
[2025-07-19T18:30:24.498+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 83.0 in stage 9.0 (TID 886). 5872 bytes result sent to driver
[2025-07-19T18:30:24.498+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 90.0 in stage 9.0 (TID 893) (8b44f3d35cfa, executor driver, partition 90, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.499+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 85 (task 888, attempt 0, stage 9.0)
[2025-07-19T18:30:24.499+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 90.0 in stage 9.0 (TID 893)
[2025-07-19T18:30:24.499+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 83.0 in stage 9.0 (TID 886) in 102 ms on 8b44f3d35cfa (executor driver) (83/200)
[2025-07-19T18:30:24.500+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 84 (task 887, attempt 0, stage 9.0)
[2025-07-19T18:30:24.501+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 85.0 in stage 9.0 (TID 888). 5872 bytes result sent to driver
[2025-07-19T18:30:24.501+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 84.0 in stage 9.0 (TID 887). 5872 bytes result sent to driver
[2025-07-19T18:30:24.502+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 82 (task 885, attempt 0, stage 9.0)
[2025-07-19T18:30:24.502+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 91.0 in stage 9.0 (TID 894) (8b44f3d35cfa, executor driver, partition 91, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.502+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/87/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/87/.2.delta.2be0faf3-6a0a-4750-9630-d55ebc6b5ec4.TID890.tmp
[2025-07-19T18:30:24.502+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 91.0 in stage 9.0 (TID 894)
[2025-07-19T18:30:24.502+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 92.0 in stage 9.0 (TID 895) (8b44f3d35cfa, executor driver, partition 92, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.502+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.504+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 92.0 in stage 9.0 (TID 895)
[2025-07-19T18:30:24.505+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.505+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 85.0 in stage 9.0 (TID 888) in 99 ms on 8b44f3d35cfa (executor driver) (84/200)
[2025-07-19T18:30:24.505+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 84.0 in stage 9.0 (TID 887) in 102 ms on 8b44f3d35cfa (executor driver) (85/200)
[2025-07-19T18:30:24.506+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@107bfb3f
[2025-07-19T18:30:24.506+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.506+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.506+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.506+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.507+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=90, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.509+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=90),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/90] for update
[2025-07-19T18:30:24.509+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@79d823c0
[2025-07-19T18:30:24.510+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 82 (task 885, attempt 0, stage 9.0)
[2025-07-19T18:30:24.512+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 82.0 in stage 9.0 (TID 885). 5872 bytes result sent to driver
[2025-07-19T18:30:24.512+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=91, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.513+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=91),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/91] for update
[2025-07-19T18:30:24.514+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 93.0 in stage 9.0 (TID 896) (8b44f3d35cfa, executor driver, partition 93, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.515+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 93.0 in stage 9.0 (TID 896)
[2025-07-19T18:30:24.515+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.515+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.516+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 82.0 in stage 9.0 (TID 885) in 112 ms on 8b44f3d35cfa (executor driver) (86/200)
[2025-07-19T18:30:24.517+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/89/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/89/.2.delta.def6ce92-2152-4047-a40f-9a524331dd8c.TID892.tmp
[2025-07-19T18:30:24.517+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/88/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/88/.2.delta.e39f5fc1-1fe2-4d2c-8330-82095a2c7d5a.TID891.tmp
[2025-07-19T18:30:24.519+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@18d78b
[2025-07-19T18:30:24.519+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=92, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.520+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=92),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/92] for update
[2025-07-19T18:30:24.520+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.521+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.521+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.521+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e0867a4
[2025-07-19T18:30:24.522+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/90/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/90/.2.delta.412e2ecf-1950-43c1-afab-d69decb50ee8.TID893.tmp
[2025-07-19T18:30:24.522+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=93, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.523+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=93),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/93] for update
[2025-07-19T18:30:24.524+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.524+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/91/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/91/.2.delta.bb7bf809-2a7c-421c-a831-81ff2b03d6e0.TID894.tmp
[2025-07-19T18:30:24.524+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/92/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/92/.2.delta.ee42dc1f-141a-42c4-bb66-56cdc40316b6.TID895.tmp
[2025-07-19T18:30:24.531+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/86/.2.delta.99fbbf82-c3d3-4249-9edf-34413551661d.TID889.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/86/2.delta
[2025-07-19T18:30:24.531+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=86),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/86] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/86/2.delta
[2025-07-19T18:30:24.532+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 86 (task 889, attempt 0, stage 9.0)
[2025-07-19T18:30:24.536+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/87/.2.delta.2be0faf3-6a0a-4750-9630-d55ebc6b5ec4.TID890.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/87/2.delta
[2025-07-19T18:30:24.537+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=87),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/87] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/87/2.delta
[2025-07-19T18:30:24.537+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 87 (task 890, attempt 0, stage 9.0)
[2025-07-19T18:30:24.539+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 86 (task 889, attempt 0, stage 9.0)
[2025-07-19T18:30:24.539+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/89/.2.delta.def6ce92-2152-4047-a40f-9a524331dd8c.TID892.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/89/2.delta
[2025-07-19T18:30:24.539+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=89),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/89] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/89/2.delta
[2025-07-19T18:30:24.540+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/93/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/93/.2.delta.2fb4f20c-41b9-4a6d-81d0-d6602d2366a8.TID896.tmp
[2025-07-19T18:30:24.540+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 86.0 in stage 9.0 (TID 889). 5872 bytes result sent to driver
[2025-07-19T18:30:24.541+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 89 (task 892, attempt 0, stage 9.0)
[2025-07-19T18:30:24.543+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 87 (task 890, attempt 0, stage 9.0)
[2025-07-19T18:30:24.543+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 87.0 in stage 9.0 (TID 890). 5872 bytes result sent to driver
[2025-07-19T18:30:24.544+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 94.0 in stage 9.0 (TID 897) (8b44f3d35cfa, executor driver, partition 94, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.546+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 95.0 in stage 9.0 (TID 898) (8b44f3d35cfa, executor driver, partition 95, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.547+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 94.0 in stage 9.0 (TID 897)
[2025-07-19T18:30:24.548+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 86.0 in stage 9.0 (TID 889) in 90 ms on 8b44f3d35cfa (executor driver) (87/200)
[2025-07-19T18:30:24.548+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 87.0 in stage 9.0 (TID 890) in 80 ms on 8b44f3d35cfa (executor driver) (88/200)
[2025-07-19T18:30:24.548+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 89 (task 892, attempt 0, stage 9.0)
[2025-07-19T18:30:24.548+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 89.0 in stage 9.0 (TID 892). 5872 bytes result sent to driver
[2025-07-19T18:30:24.548+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 95.0 in stage 9.0 (TID 898)
[2025-07-19T18:30:24.548+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 96.0 in stage 9.0 (TID 899) (8b44f3d35cfa, executor driver, partition 96, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.548+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 89.0 in stage 9.0 (TID 892) in 76 ms on 8b44f3d35cfa (executor driver) (89/200)
[2025-07-19T18:30:24.549+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 96.0 in stage 9.0 (TID 899)
[2025-07-19T18:30:24.549+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.549+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.549+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@21d27b01
[2025-07-19T18:30:24.549+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.549+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.550+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=94, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.550+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=94),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/94] for update
[2025-07-19T18:30:24.551+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/88/.2.delta.e39f5fc1-1fe2-4d2c-8330-82095a2c7d5a.TID891.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/88/2.delta
[2025-07-19T18:30:24.551+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=88),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/88] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/88/2.delta
[2025-07-19T18:30:24.551+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 88 (task 891, attempt 0, stage 9.0)
[2025-07-19T18:30:24.551+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@45eac691
[2025-07-19T18:30:24.560+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.561+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.561+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.562+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 88 (task 891, attempt 0, stage 9.0)
[2025-07-19T18:30:24.562+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 88.0 in stage 9.0 (TID 891). 5872 bytes result sent to driver
[2025-07-19T18:30:24.562+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=96, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.562+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=96),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/96] for update
[2025-07-19T18:30:24.563+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/91/.2.delta.bb7bf809-2a7c-421c-a831-81ff2b03d6e0.TID894.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/91/2.delta
[2025-07-19T18:30:24.563+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=91),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/91] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/91/2.delta
[2025-07-19T18:30:24.563+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 91 (task 894, attempt 0, stage 9.0)
[2025-07-19T18:30:24.564+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 97.0 in stage 9.0 (TID 900) (8b44f3d35cfa, executor driver, partition 97, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.564+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 88.0 in stage 9.0 (TID 891) in 95 ms on 8b44f3d35cfa (executor driver) (90/200)
[2025-07-19T18:30:24.564+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2eef6fd9
[2025-07-19T18:30:24.567+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 97.0 in stage 9.0 (TID 900)
[2025-07-19T18:30:24.569+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=95, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.569+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=95),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/95] for update
[2025-07-19T18:30:24.570+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.570+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.570+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.570+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d9db855
[2025-07-19T18:30:24.571+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=97, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.571+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=97),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/97] for update
[2025-07-19T18:30:24.571+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.571+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.572+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/90/.2.delta.412e2ecf-1950-43c1-afab-d69decb50ee8.TID893.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/90/2.delta
[2025-07-19T18:30:24.572+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=90),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/90] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/90/2.delta
[2025-07-19T18:30:24.573+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 90 (task 893, attempt 0, stage 9.0)
[2025-07-19T18:30:24.577+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 91 (task 894, attempt 0, stage 9.0)
[2025-07-19T18:30:24.577+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 91.0 in stage 9.0 (TID 894). 5829 bytes result sent to driver
[2025-07-19T18:30:24.578+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/92/.2.delta.ee42dc1f-141a-42c4-bb66-56cdc40316b6.TID895.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/92/2.delta
[2025-07-19T18:30:24.578+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=92),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/92] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/92/2.delta
[2025-07-19T18:30:24.578+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 98.0 in stage 9.0 (TID 901) (8b44f3d35cfa, executor driver, partition 98, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.579+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 91.0 in stage 9.0 (TID 894) in 81 ms on 8b44f3d35cfa (executor driver) (91/200)
[2025-07-19T18:30:24.580+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 90 (task 893, attempt 0, stage 9.0)
[2025-07-19T18:30:24.581+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/97/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/97/.2.delta.80b7949f-ce39-4443-b603-630744424e2a.TID900.tmp
[2025-07-19T18:30:24.582+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 92 (task 895, attempt 0, stage 9.0)
[2025-07-19T18:30:24.582+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 90.0 in stage 9.0 (TID 893). 5872 bytes result sent to driver
[2025-07-19T18:30:24.582+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 98.0 in stage 9.0 (TID 901)
[2025-07-19T18:30:24.582+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/95/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/95/.2.delta.bd8bac79-f316-44cc-b99d-32fd012e0b20.TID898.tmp
[2025-07-19T18:30:24.582+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 99.0 in stage 9.0 (TID 902) (8b44f3d35cfa, executor driver, partition 99, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.584+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 90.0 in stage 9.0 (TID 893) in 84 ms on 8b44f3d35cfa (executor driver) (92/200)
[2025-07-19T18:30:24.584+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/94/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/94/.2.delta.32fa3bb9-ffc5-4001-ab13-cd8f370f26cb.TID897.tmp
[2025-07-19T18:30:24.585+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.586+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 99.0 in stage 9.0 (TID 902)
[2025-07-19T18:30:24.586+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.586+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@60c602ee
[2025-07-19T18:30:24.587+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/96/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/96/.2.delta.c65c4a7b-c0ce-4b62-8a2f-4aa8dfbb9647.TID899.tmp
[2025-07-19T18:30:24.587+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=98, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.587+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=98),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/98] for update
[2025-07-19T18:30:24.587+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.587+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.587+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:24.587+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e1ea8a8
[2025-07-19T18:30:24.587+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=99, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.587+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=99),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/99] for update
[2025-07-19T18:30:24.587+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 92 (task 895, attempt 0, stage 9.0)
[2025-07-19T18:30:24.587+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 92.0 in stage 9.0 (TID 895). 5872 bytes result sent to driver
[2025-07-19T18:30:24.588+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 100.0 in stage 9.0 (TID 903) (8b44f3d35cfa, executor driver, partition 100, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.588+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.589+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 92.0 in stage 9.0 (TID 895) in 91 ms on 8b44f3d35cfa (executor driver) (93/200)
[2025-07-19T18:30:24.590+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 100.0 in stage 9.0 (TID 903)
[2025-07-19T18:30:24.590+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.591+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.591+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a7efb2b
[2025-07-19T18:30:24.593+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=100, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.593+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=100),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/100] for update
[2025-07-19T18:30:24.594+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.597+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/93/.2.delta.2fb4f20c-41b9-4a6d-81d0-d6602d2366a8.TID896.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/93/2.delta
[2025-07-19T18:30:24.597+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=93),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/93] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/93/2.delta
[2025-07-19T18:30:24.598+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 93 (task 896, attempt 0, stage 9.0)
[2025-07-19T18:30:24.598+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/98/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/98/.2.delta.f0b0a152-43c2-43d5-8f19-6d9be0d0efb8.TID901.tmp
[2025-07-19T18:30:24.601+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/99/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/99/.2.delta.db6856c1-92db-43d6-88d9-843996348136.TID902.tmp
[2025-07-19T18:30:24.603+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/100/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/100/.2.delta.10936ca3-b81f-4b0f-abb4-7c951c2da989.TID903.tmp
[2025-07-19T18:30:24.605+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 93 (task 896, attempt 0, stage 9.0)
[2025-07-19T18:30:24.606+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 93.0 in stage 9.0 (TID 896). 5872 bytes result sent to driver
[2025-07-19T18:30:24.607+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 101.0 in stage 9.0 (TID 904) (8b44f3d35cfa, executor driver, partition 101, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.608+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 101.0 in stage 9.0 (TID 904)
[2025-07-19T18:30:24.609+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 93.0 in stage 9.0 (TID 896) in 104 ms on 8b44f3d35cfa (executor driver) (94/200)
[2025-07-19T18:30:24.610+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.610+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.611+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c1ea8f9
[2025-07-19T18:30:24.612+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=101, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.612+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=101),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/101] for update
[2025-07-19T18:30:24.613+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/97/.2.delta.80b7949f-ce39-4443-b603-630744424e2a.TID900.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/97/2.delta
[2025-07-19T18:30:24.613+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=97),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/97] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/97/2.delta
[2025-07-19T18:30:24.613+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/95/.2.delta.bd8bac79-f316-44cc-b99d-32fd012e0b20.TID898.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/95/2.delta
[2025-07-19T18:30:24.613+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=95),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/95] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/95/2.delta
[2025-07-19T18:30:24.613+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 95 (task 898, attempt 0, stage 9.0)
[2025-07-19T18:30:24.613+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 97 (task 900, attempt 0, stage 9.0)
[2025-07-19T18:30:24.613+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.615+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 97 (task 900, attempt 0, stage 9.0)
[2025-07-19T18:30:24.615+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 97.0 in stage 9.0 (TID 900). 5829 bytes result sent to driver
[2025-07-19T18:30:24.616+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 95 (task 898, attempt 0, stage 9.0)
[2025-07-19T18:30:24.617+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 102.0 in stage 9.0 (TID 905) (8b44f3d35cfa, executor driver, partition 102, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.617+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 95.0 in stage 9.0 (TID 898). 5872 bytes result sent to driver
[2025-07-19T18:30:24.617+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 103.0 in stage 9.0 (TID 906) (8b44f3d35cfa, executor driver, partition 103, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.618+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 103.0 in stage 9.0 (TID 906)
[2025-07-19T18:30:24.620+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 97.0 in stage 9.0 (TID 900) in 51 ms on 8b44f3d35cfa (executor driver) (95/200)
[2025-07-19T18:30:24.621+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 95.0 in stage 9.0 (TID 898) in 73 ms on 8b44f3d35cfa (executor driver) (96/200)
[2025-07-19T18:30:24.622+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 102.0 in stage 9.0 (TID 905)
[2025-07-19T18:30:24.622+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.622+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.622+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@602f5be2
[2025-07-19T18:30:24.622+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=102, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.622+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=102),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/102] for update
[2025-07-19T18:30:24.622+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/96/.2.delta.c65c4a7b-c0ce-4b62-8a2f-4aa8dfbb9647.TID899.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/96/2.delta
[2025-07-19T18:30:24.623+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=96),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/96] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/96/2.delta
[2025-07-19T18:30:24.623+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/94/.2.delta.32fa3bb9-ffc5-4001-ab13-cd8f370f26cb.TID897.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/94/2.delta
[2025-07-19T18:30:24.623+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=94),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/94] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/94/2.delta
[2025-07-19T18:30:24.624+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 94 (task 897, attempt 0, stage 9.0)
[2025-07-19T18:30:24.625+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 96 (task 899, attempt 0, stage 9.0)
[2025-07-19T18:30:24.625+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.625+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.626+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.627+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e5f95b5
[2025-07-19T18:30:24.627+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=103, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.627+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=103),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/103] for update
[2025-07-19T18:30:24.628+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 96 (task 899, attempt 0, stage 9.0)
[2025-07-19T18:30:24.629+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.629+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/101/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/101/.2.delta.3960e907-ae4c-4977-a38d-4d99a72b3ad4.TID904.tmp
[2025-07-19T18:30:24.629+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 96.0 in stage 9.0 (TID 899). 5872 bytes result sent to driver
[2025-07-19T18:30:24.629+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 94 (task 897, attempt 0, stage 9.0)
[2025-07-19T18:30:24.629+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 104.0 in stage 9.0 (TID 907) (8b44f3d35cfa, executor driver, partition 104, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.630+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 94.0 in stage 9.0 (TID 897). 5872 bytes result sent to driver
[2025-07-19T18:30:24.630+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 104.0 in stage 9.0 (TID 907)
[2025-07-19T18:30:24.631+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/98/.2.delta.f0b0a152-43c2-43d5-8f19-6d9be0d0efb8.TID901.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/98/2.delta
[2025-07-19T18:30:24.632+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=98),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/98] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/98/2.delta
[2025-07-19T18:30:24.632+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 105.0 in stage 9.0 (TID 908) (8b44f3d35cfa, executor driver, partition 105, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.633+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 98 (task 901, attempt 0, stage 9.0)
[2025-07-19T18:30:24.633+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 105.0 in stage 9.0 (TID 908)
[2025-07-19T18:30:24.634+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 96.0 in stage 9.0 (TID 899) in 80 ms on 8b44f3d35cfa (executor driver) (97/200)
[2025-07-19T18:30:24.634+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 94.0 in stage 9.0 (TID 897) in 86 ms on 8b44f3d35cfa (executor driver) (98/200)
[2025-07-19T18:30:24.635+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.638+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.638+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2fc0dbfd
[2025-07-19T18:30:24.639+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=104, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.640+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.641+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.641+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=104),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/104] for update
[2025-07-19T18:30:24.641+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/102/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/102/.2.delta.ca7606f9-4f24-4cfe-954e-e9be95f20771.TID905.tmp
[2025-07-19T18:30:24.642+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53f0edcd
[2025-07-19T18:30:24.642+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=105, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.644+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=105),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/105] for update
[2025-07-19T18:30:24.644+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.645+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.645+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 98 (task 901, attempt 0, stage 9.0)
[2025-07-19T18:30:24.645+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 98.0 in stage 9.0 (TID 901). 5829 bytes result sent to driver
[2025-07-19T18:30:24.646+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 106.0 in stage 9.0 (TID 909) (8b44f3d35cfa, executor driver, partition 106, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.646+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 106.0 in stage 9.0 (TID 909)
[2025-07-19T18:30:24.646+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 98.0 in stage 9.0 (TID 901) in 60 ms on 8b44f3d35cfa (executor driver) (99/200)
[2025-07-19T18:30:24.647+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/99/.2.delta.db6856c1-92db-43d6-88d9-843996348136.TID902.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/99/2.delta
[2025-07-19T18:30:24.648+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=99),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/99] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/99/2.delta
[2025-07-19T18:30:24.648+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.649+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.649+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/103/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/103/.2.delta.9e498742-43e7-434e-8f36-26e737fcf428.TID906.tmp
[2025-07-19T18:30:24.650+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 99 (task 902, attempt 0, stage 9.0)
[2025-07-19T18:30:24.651+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/105/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/105/.2.delta.a2959105-dd08-4482-a4e3-af39fb0334e0.TID908.tmp
[2025-07-19T18:30:24.651+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4262d3f9
[2025-07-19T18:30:24.652+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=106, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.652+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=106),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/106] for update
[2025-07-19T18:30:24.653+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/104/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/104/.2.delta.18760c2f-4c74-476f-a24f-3c2a4ebb16d6.TID907.tmp
[2025-07-19T18:30:24.653+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.653+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/100/.2.delta.10936ca3-b81f-4b0f-abb4-7c951c2da989.TID903.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/100/2.delta
[2025-07-19T18:30:24.654+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=100),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/100] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/100/2.delta
[2025-07-19T18:30:24.654+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 100 (task 903, attempt 0, stage 9.0)
[2025-07-19T18:30:24.655+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 99 (task 902, attempt 0, stage 9.0)
[2025-07-19T18:30:24.655+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 99.0 in stage 9.0 (TID 902). 5829 bytes result sent to driver
[2025-07-19T18:30:24.656+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 107.0 in stage 9.0 (TID 910) (8b44f3d35cfa, executor driver, partition 107, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.656+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 99.0 in stage 9.0 (TID 902) in 69 ms on 8b44f3d35cfa (executor driver) (100/200)
[2025-07-19T18:30:24.657+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 107.0 in stage 9.0 (TID 910)
[2025-07-19T18:30:24.657+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.658+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.658+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 100 (task 903, attempt 0, stage 9.0)
[2025-07-19T18:30:24.659+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 100.0 in stage 9.0 (TID 903). 5829 bytes result sent to driver
[2025-07-19T18:30:24.660+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1fee1285
[2025-07-19T18:30:24.661+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 108.0 in stage 9.0 (TID 911) (8b44f3d35cfa, executor driver, partition 108, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.661+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 100.0 in stage 9.0 (TID 903) in 63 ms on 8b44f3d35cfa (executor driver) (101/200)
[2025-07-19T18:30:24.662+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=107, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.663+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=107),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/107] for update
[2025-07-19T18:30:24.664+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/106/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/106/.2.delta.90633ccf-9ac7-4578-81ce-81f13835af8e.TID909.tmp
[2025-07-19T18:30:24.664+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.665+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 108.0 in stage 9.0 (TID 911)
[2025-07-19T18:30:24.665+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.666+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.667+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59768bbd
[2025-07-19T18:30:24.668+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=108, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.670+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=108),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/108] for update
[2025-07-19T18:30:24.670+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.670+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/101/.2.delta.3960e907-ae4c-4977-a38d-4d99a72b3ad4.TID904.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/101/2.delta
[2025-07-19T18:30:24.671+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=101),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/101] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/101/2.delta
[2025-07-19T18:30:24.671+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/107/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/107/.2.delta.a647a3dc-361d-4efa-abab-22b5e3e04f99.TID910.tmp
[2025-07-19T18:30:24.671+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 101 (task 904, attempt 0, stage 9.0)
[2025-07-19T18:30:24.672+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/102/.2.delta.ca7606f9-4f24-4cfe-954e-e9be95f20771.TID905.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/102/2.delta
[2025-07-19T18:30:24.674+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=102),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/102] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/102/2.delta
[2025-07-19T18:30:24.675+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 102 (task 905, attempt 0, stage 9.0)
[2025-07-19T18:30:24.676+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 102 (task 905, attempt 0, stage 9.0)
[2025-07-19T18:30:24.677+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 102.0 in stage 9.0 (TID 905). 5829 bytes result sent to driver
[2025-07-19T18:30:24.677+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 109.0 in stage 9.0 (TID 912) (8b44f3d35cfa, executor driver, partition 109, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.678+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 102.0 in stage 9.0 (TID 905) in 54 ms on 8b44f3d35cfa (executor driver) (102/200)
[2025-07-19T18:30:24.679+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 109.0 in stage 9.0 (TID 912)
[2025-07-19T18:30:24.680+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 101 (task 904, attempt 0, stage 9.0)
[2025-07-19T18:30:24.680+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/103/.2.delta.9e498742-43e7-434e-8f36-26e737fcf428.TID906.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/103/2.delta
[2025-07-19T18:30:24.682+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=103),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/103] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/103/2.delta
[2025-07-19T18:30:24.683+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 103 (task 906, attempt 0, stage 9.0)
[2025-07-19T18:30:24.684+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/108/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/108/.2.delta.1766aa60-289b-4d3c-808b-1884c76bffe8.TID911.tmp
[2025-07-19T18:30:24.685+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 101.0 in stage 9.0 (TID 904). 5829 bytes result sent to driver
[2025-07-19T18:30:24.688+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/104/.2.delta.18760c2f-4c74-476f-a24f-3c2a4ebb16d6.TID907.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/104/2.delta
[2025-07-19T18:30:24.691+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=104),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/104] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/104/2.delta
[2025-07-19T18:30:24.693+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 110.0 in stage 9.0 (TID 913) (8b44f3d35cfa, executor driver, partition 110, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.695+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 110.0 in stage 9.0 (TID 913)
[2025-07-19T18:30:24.698+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 101.0 in stage 9.0 (TID 904) in 67 ms on 8b44f3d35cfa (executor driver) (103/200)
[2025-07-19T18:30:24.701+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 104 (task 907, attempt 0, stage 9.0)
[2025-07-19T18:30:24.703+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.703+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T18:30:24.704+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71f2070b
[2025-07-19T18:30:24.704+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=109, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.705+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=109),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/109] for update
[2025-07-19T18:30:24.705+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.706+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.706+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71301cec
[2025-07-19T18:30:24.708+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=110, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.708+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=110),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/110] for update
[2025-07-19T18:30:24.708+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 103 (task 906, attempt 0, stage 9.0)
[2025-07-19T18:30:24.708+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/105/.2.delta.a2959105-dd08-4482-a4e3-af39fb0334e0.TID908.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/105/2.delta
[2025-07-19T18:30:24.709+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=105),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/105] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/105/2.delta
[2025-07-19T18:30:24.709+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 104 (task 907, attempt 0, stage 9.0)
[2025-07-19T18:30:24.709+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 105 (task 908, attempt 0, stage 9.0)
[2025-07-19T18:30:24.709+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 104.0 in stage 9.0 (TID 907). 5829 bytes result sent to driver
[2025-07-19T18:30:24.709+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.709+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 103.0 in stage 9.0 (TID 906). 5829 bytes result sent to driver
[2025-07-19T18:30:24.710+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 111.0 in stage 9.0 (TID 914) (8b44f3d35cfa, executor driver, partition 111, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.711+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 104.0 in stage 9.0 (TID 907) in 53 ms on 8b44f3d35cfa (executor driver) (104/200)
[2025-07-19T18:30:24.713+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 112.0 in stage 9.0 (TID 915) (8b44f3d35cfa, executor driver, partition 112, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.714+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.714+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 103.0 in stage 9.0 (TID 906) in 64 ms on 8b44f3d35cfa (executor driver) (105/200)
[2025-07-19T18:30:24.715+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 111.0 in stage 9.0 (TID 914)
[2025-07-19T18:30:24.715+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 112.0 in stage 9.0 (TID 915)
[2025-07-19T18:30:24.716+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.716+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.716+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.719+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.719+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 105 (task 908, attempt 0, stage 9.0)
[2025-07-19T18:30:24.727+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 105.0 in stage 9.0 (TID 908). 5829 bytes result sent to driver
[2025-07-19T18:30:24.727+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f90a222
[2025-07-19T18:30:24.728+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=112, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.728+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=112),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/112] for update
[2025-07-19T18:30:24.728+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 113.0 in stage 9.0 (TID 916) (8b44f3d35cfa, executor driver, partition 113, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.728+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.729+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 105.0 in stage 9.0 (TID 908) in 62 ms on 8b44f3d35cfa (executor driver) (106/200)
[2025-07-19T18:30:24.729+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/106/.2.delta.90633ccf-9ac7-4578-81ce-81f13835af8e.TID909.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/106/2.delta
[2025-07-19T18:30:24.730+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=106),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/106] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/106/2.delta
[2025-07-19T18:30:24.730+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 106 (task 909, attempt 0, stage 9.0)
[2025-07-19T18:30:24.731+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2fb3b286
[2025-07-19T18:30:24.731+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=111, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.732+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=111),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/111] for update
[2025-07-19T18:30:24.732+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 113.0 in stage 9.0 (TID 916)
[2025-07-19T18:30:24.733+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/109/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/109/.2.delta.4881d3b5-a3c6-4352-860d-33d4c9d1929d.TID912.tmp
[2025-07-19T18:30:24.733+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.734+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.735+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.736+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 106 (task 909, attempt 0, stage 9.0)
[2025-07-19T18:30:24.736+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 106.0 in stage 9.0 (TID 909). 5829 bytes result sent to driver
[2025-07-19T18:30:24.736+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1908bd57
[2025-07-19T18:30:24.736+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 114.0 in stage 9.0 (TID 917) (8b44f3d35cfa, executor driver, partition 114, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.737+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=113, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.737+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=113),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/113] for update
[2025-07-19T18:30:24.738+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 114.0 in stage 9.0 (TID 917)
[2025-07-19T18:30:24.738+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 106.0 in stage 9.0 (TID 909) in 60 ms on 8b44f3d35cfa (executor driver) (107/200)
[2025-07-19T18:30:24.739+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/110/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/110/.2.delta.4074eee0-7f22-4321-b72b-b85f7a847ad7.TID913.tmp
[2025-07-19T18:30:24.740+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.741+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.741+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.742+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@24a32692
[2025-07-19T18:30:24.742+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/111/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/111/.2.delta.0bd4566d-4e04-4f06-a1dd-939afe8d4631.TID914.tmp
[2025-07-19T18:30:24.743+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=114, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.743+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=114),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/114] for update
[2025-07-19T18:30:24.744+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.744+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/112/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/112/.2.delta.114fde9b-f423-4d75-a4c4-2548317e9e8f.TID915.tmp
[2025-07-19T18:30:24.745+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/113/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/113/.2.delta.e0bd8519-e478-472e-a2a6-1d0ed03aee7d.TID916.tmp
[2025-07-19T18:30:24.746+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/107/.2.delta.a647a3dc-361d-4efa-abab-22b5e3e04f99.TID910.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/107/2.delta
[2025-07-19T18:30:24.747+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=107),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/107] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/107/2.delta
[2025-07-19T18:30:24.748+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 107 (task 910, attempt 0, stage 9.0)
[2025-07-19T18:30:24.748+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 107 (task 910, attempt 0, stage 9.0)
[2025-07-19T18:30:24.748+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 107.0 in stage 9.0 (TID 910). 5829 bytes result sent to driver
[2025-07-19T18:30:24.749+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 115.0 in stage 9.0 (TID 918) (8b44f3d35cfa, executor driver, partition 115, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.750+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/108/.2.delta.1766aa60-289b-4d3c-808b-1884c76bffe8.TID911.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/108/2.delta
[2025-07-19T18:30:24.750+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=108),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/108] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/108/2.delta
[2025-07-19T18:30:24.750+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 108 (task 911, attempt 0, stage 9.0)
[2025-07-19T18:30:24.752+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 107.0 in stage 9.0 (TID 910) in 72 ms on 8b44f3d35cfa (executor driver) (108/200)
[2025-07-19T18:30:24.753+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 115.0 in stage 9.0 (TID 918)
[2025-07-19T18:30:24.754+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.754+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.756+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@26f81bca
[2025-07-19T18:30:24.757+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 108 (task 911, attempt 0, stage 9.0)
[2025-07-19T18:30:24.759+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 108.0 in stage 9.0 (TID 911). 5829 bytes result sent to driver
[2025-07-19T18:30:24.759+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 116.0 in stage 9.0 (TID 919) (8b44f3d35cfa, executor driver, partition 116, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.759+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 116.0 in stage 9.0 (TID 919)
[2025-07-19T18:30:24.759+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 108.0 in stage 9.0 (TID 911) in 73 ms on 8b44f3d35cfa (executor driver) (109/200)
[2025-07-19T18:30:24.760+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=115, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.760+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=115),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/115] for update
[2025-07-19T18:30:24.760+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/114/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/114/.2.delta.1571ea17-115f-4e35-a426-56b99a675b63.TID917.tmp
[2025-07-19T18:30:24.761+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.762+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.763+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@738707ba
[2025-07-19T18:30:24.764+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.765+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=116, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.765+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=116),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/116] for update
[2025-07-19T18:30:24.765+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/109/.2.delta.4881d3b5-a3c6-4352-860d-33d4c9d1929d.TID912.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/109/2.delta
[2025-07-19T18:30:24.766+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=109),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/109] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/109/2.delta
[2025-07-19T18:30:24.766+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.767+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 109 (task 912, attempt 0, stage 9.0)
[2025-07-19T18:30:24.767+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/111/.2.delta.0bd4566d-4e04-4f06-a1dd-939afe8d4631.TID914.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/111/2.delta
[2025-07-19T18:30:24.767+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=111),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/111] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/111/2.delta
[2025-07-19T18:30:24.768+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 111 (task 914, attempt 0, stage 9.0)
[2025-07-19T18:30:24.769+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 109 (task 912, attempt 0, stage 9.0)
[2025-07-19T18:30:24.769+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 109.0 in stage 9.0 (TID 912). 5829 bytes result sent to driver
[2025-07-19T18:30:24.769+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 117.0 in stage 9.0 (TID 920) (8b44f3d35cfa, executor driver, partition 117, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.770+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 117.0 in stage 9.0 (TID 920)
[2025-07-19T18:30:24.770+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 111 (task 914, attempt 0, stage 9.0)
[2025-07-19T18:30:24.770+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 109.0 in stage 9.0 (TID 912) in 66 ms on 8b44f3d35cfa (executor driver) (110/200)
[2025-07-19T18:30:24.771+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 111.0 in stage 9.0 (TID 914). 5829 bytes result sent to driver
[2025-07-19T18:30:24.772+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 118.0 in stage 9.0 (TID 921) (8b44f3d35cfa, executor driver, partition 118, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.772+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/115/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/115/.2.delta.4583efe4-b53a-4441-991b-804ea9a61acc.TID918.tmp
[2025-07-19T18:30:24.772+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 111.0 in stage 9.0 (TID 914) in 58 ms on 8b44f3d35cfa (executor driver) (111/200)
[2025-07-19T18:30:24.773+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.773+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.775+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 118.0 in stage 9.0 (TID 921)
[2025-07-19T18:30:24.776+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@234b5dda
[2025-07-19T18:30:24.777+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/112/.2.delta.114fde9b-f423-4d75-a4c4-2548317e9e8f.TID915.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/112/2.delta
[2025-07-19T18:30:24.778+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=112),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/112] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/112/2.delta
[2025-07-19T18:30:24.779+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=117, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.779+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=117),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/117] for update
[2025-07-19T18:30:24.779+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.780+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.780+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 112 (task 915, attempt 0, stage 9.0)
[2025-07-19T18:30:24.781+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1023445f
[2025-07-19T18:30:24.782+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=118, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.783+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=118),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/118] for update
[2025-07-19T18:30:24.784+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.785+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/110/.2.delta.4074eee0-7f22-4321-b72b-b85f7a847ad7.TID913.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/110/2.delta
[2025-07-19T18:30:24.785+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=110),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/110] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/110/2.delta
[2025-07-19T18:30:24.785+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.786+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 110 (task 913, attempt 0, stage 9.0)
[2025-07-19T18:30:24.786+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/116/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/116/.2.delta.4ff04685-3e31-4726-bf82-e94cdd2038ca.TID919.tmp
[2025-07-19T18:30:24.786+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/113/.2.delta.e0bd8519-e478-472e-a2a6-1d0ed03aee7d.TID916.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/113/2.delta
[2025-07-19T18:30:24.787+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=113),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/113] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/113/2.delta
[2025-07-19T18:30:24.787+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 112 (task 915, attempt 0, stage 9.0)
[2025-07-19T18:30:24.788+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 113 (task 916, attempt 0, stage 9.0)
[2025-07-19T18:30:24.789+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 112.0 in stage 9.0 (TID 915). 5829 bytes result sent to driver
[2025-07-19T18:30:24.789+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 119.0 in stage 9.0 (TID 922) (8b44f3d35cfa, executor driver, partition 119, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.789+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 110 (task 913, attempt 0, stage 9.0)
[2025-07-19T18:30:24.789+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 110.0 in stage 9.0 (TID 913). 5829 bytes result sent to driver
[2025-07-19T18:30:24.790+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 112.0 in stage 9.0 (TID 915) in 68 ms on 8b44f3d35cfa (executor driver) (112/200)
[2025-07-19T18:30:24.791+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 120.0 in stage 9.0 (TID 923) (8b44f3d35cfa, executor driver, partition 120, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.792+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 120.0 in stage 9.0 (TID 923)
[2025-07-19T18:30:24.792+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 110.0 in stage 9.0 (TID 913) in 78 ms on 8b44f3d35cfa (executor driver) (113/200)
[2025-07-19T18:30:24.793+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 119.0 in stage 9.0 (TID 922)
[2025-07-19T18:30:24.794+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 113 (task 916, attempt 0, stage 9.0)
[2025-07-19T18:30:24.795+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.795+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.796+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 113.0 in stage 9.0 (TID 916). 5829 bytes result sent to driver
[2025-07-19T18:30:24.796+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6fc14f0b
[2025-07-19T18:30:24.797+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 121.0 in stage 9.0 (TID 924) (8b44f3d35cfa, executor driver, partition 121, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.797+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 113.0 in stage 9.0 (TID 916) in 65 ms on 8b44f3d35cfa (executor driver) (114/200)
[2025-07-19T18:30:24.798+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=119, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.799+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/118/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/118/.2.delta.c90ebc9f-715d-4b1e-8952-6f11f2a57031.TID921.tmp
[2025-07-19T18:30:24.799+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=119),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/119] for update
[2025-07-19T18:30:24.801+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 121.0 in stage 9.0 (TID 924)
[2025-07-19T18:30:24.802+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.802+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.803+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/117/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/117/.2.delta.74e03938-d968-4d6e-901e-b177e39bbfb4.TID920.tmp
[2025-07-19T18:30:24.803+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7fc2ee04
[2025-07-19T18:30:24.804+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.804+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/114/.2.delta.1571ea17-115f-4e35-a426-56b99a675b63.TID917.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/114/2.delta
[2025-07-19T18:30:24.805+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=114),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/114] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/114/2.delta
[2025-07-19T18:30:24.806+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.806+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.806+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=120, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.807+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 114 (task 917, attempt 0, stage 9.0)
[2025-07-19T18:30:24.807+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=120),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/120] for update
[2025-07-19T18:30:24.807+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.808+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3b5b698b
[2025-07-19T18:30:24.809+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=121, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.810+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=121),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/121] for update
[2025-07-19T18:30:24.811+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.811+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 114 (task 917, attempt 0, stage 9.0)
[2025-07-19T18:30:24.811+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 114.0 in stage 9.0 (TID 917). 5829 bytes result sent to driver
[2025-07-19T18:30:24.812+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 122.0 in stage 9.0 (TID 925) (8b44f3d35cfa, executor driver, partition 122, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.812+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 114.0 in stage 9.0 (TID 917) in 65 ms on 8b44f3d35cfa (executor driver) (115/200)
[2025-07-19T18:30:24.813+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 122.0 in stage 9.0 (TID 925)
[2025-07-19T18:30:24.813+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.813+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.814+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56013d19
[2025-07-19T18:30:24.815+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=122, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.815+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=122),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/122] for update
[2025-07-19T18:30:24.816+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/119/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/119/.2.delta.102a678b-cb44-42db-ac99-b76bfc30c703.TID922.tmp
[2025-07-19T18:30:24.816+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.817+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/120/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/120/.2.delta.10fc5452-3ec8-4018-b58c-ffb335327b7d.TID923.tmp
[2025-07-19T18:30:24.817+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/121/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/121/.2.delta.08d4f85f-294b-4b06-aad8-4885c27f1774.TID924.tmp
[2025-07-19T18:30:24.817+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/115/.2.delta.4583efe4-b53a-4441-991b-804ea9a61acc.TID918.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/115/2.delta
[2025-07-19T18:30:24.818+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=115),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/115] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/115/2.delta
[2025-07-19T18:30:24.818+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/122/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/122/.2.delta.74aca400-87ca-4c79-adff-d00546f49d47.TID925.tmp
[2025-07-19T18:30:24.819+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 115 (task 918, attempt 0, stage 9.0)
[2025-07-19T18:30:24.819+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 115 (task 918, attempt 0, stage 9.0)
[2025-07-19T18:30:24.819+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 115.0 in stage 9.0 (TID 918). 5829 bytes result sent to driver
[2025-07-19T18:30:24.819+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 123.0 in stage 9.0 (TID 926) (8b44f3d35cfa, executor driver, partition 123, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.822+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/117/.2.delta.74e03938-d968-4d6e-901e-b177e39bbfb4.TID920.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/117/2.delta
[2025-07-19T18:30:24.824+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=117),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/117] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/117/2.delta
[2025-07-19T18:30:24.826+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 117 (task 920, attempt 0, stage 9.0)
[2025-07-19T18:30:24.826+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 123.0 in stage 9.0 (TID 926)
[2025-07-19T18:30:24.827+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 115.0 in stage 9.0 (TID 918) in 61 ms on 8b44f3d35cfa (executor driver) (116/200)
[2025-07-19T18:30:24.828+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/116/.2.delta.4ff04685-3e31-4726-bf82-e94cdd2038ca.TID919.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/116/2.delta
[2025-07-19T18:30:24.828+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=116),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/116] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/116/2.delta
[2025-07-19T18:30:24.828+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.829+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.829+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3126fb77
[2025-07-19T18:30:24.829+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 116 (task 919, attempt 0, stage 9.0)
[2025-07-19T18:30:24.830+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=123, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.830+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=123),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/123] for update
[2025-07-19T18:30:24.831+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 117 (task 920, attempt 0, stage 9.0)
[2025-07-19T18:30:24.832+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 117.0 in stage 9.0 (TID 920). 5829 bytes result sent to driver
[2025-07-19T18:30:24.832+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.832+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 116 (task 919, attempt 0, stage 9.0)
[2025-07-19T18:30:24.833+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 116.0 in stage 9.0 (TID 919). 5829 bytes result sent to driver
[2025-07-19T18:30:24.833+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 124.0 in stage 9.0 (TID 927) (8b44f3d35cfa, executor driver, partition 124, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.833+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 117.0 in stage 9.0 (TID 920) in 49 ms on 8b44f3d35cfa (executor driver) (117/200)
[2025-07-19T18:30:24.833+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 125.0 in stage 9.0 (TID 928) (8b44f3d35cfa, executor driver, partition 125, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.834+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 125.0 in stage 9.0 (TID 928)
[2025-07-19T18:30:24.834+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 124.0 in stage 9.0 (TID 927)
[2025-07-19T18:30:24.835+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 116.0 in stage 9.0 (TID 919) in 63 ms on 8b44f3d35cfa (executor driver) (118/200)
[2025-07-19T18:30:24.835+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.835+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.836+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.836+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.836+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@79adcef1
[2025-07-19T18:30:24.837+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=125, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.837+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=125),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/125] for update
[2025-07-19T18:30:24.837+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/118/.2.delta.c90ebc9f-715d-4b1e-8952-6f11f2a57031.TID921.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/118/2.delta
[2025-07-19T18:30:24.838+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=118),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/118] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/118/2.delta
[2025-07-19T18:30:24.839+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 118 (task 921, attempt 0, stage 9.0)
[2025-07-19T18:30:24.839+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@44f976a1
[2025-07-19T18:30:24.840+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=124, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.840+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=124),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/124] for update
[2025-07-19T18:30:24.841+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.841+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/120/.2.delta.10fc5452-3ec8-4018-b58c-ffb335327b7d.TID923.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/120/2.delta
[2025-07-19T18:30:24.841+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=120),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/120] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/120/2.delta
[2025-07-19T18:30:24.842+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 118 (task 921, attempt 0, stage 9.0)
[2025-07-19T18:30:24.842+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 120 (task 923, attempt 0, stage 9.0)
[2025-07-19T18:30:24.843+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.844+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/123/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/123/.2.delta.b6f8180d-541c-432c-a74e-5f3279783de8.TID926.tmp
[2025-07-19T18:30:24.844+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 118.0 in stage 9.0 (TID 921). 5829 bytes result sent to driver
[2025-07-19T18:30:24.845+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 126.0 in stage 9.0 (TID 929) (8b44f3d35cfa, executor driver, partition 126, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.845+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 126.0 in stage 9.0 (TID 929)
[2025-07-19T18:30:24.845+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/119/.2.delta.102a678b-cb44-42db-ac99-b76bfc30c703.TID922.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/119/2.delta
[2025-07-19T18:30:24.845+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=119),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/119] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/119/2.delta
[2025-07-19T18:30:24.845+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 119 (task 922, attempt 0, stage 9.0)
[2025-07-19T18:30:24.845+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 118.0 in stage 9.0 (TID 921) in 57 ms on 8b44f3d35cfa (executor driver) (119/200)
[2025-07-19T18:30:24.845+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.845+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 120 (task 923, attempt 0, stage 9.0)
[2025-07-19T18:30:24.845+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 119 (task 922, attempt 0, stage 9.0)
[2025-07-19T18:30:24.846+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.846+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 119.0 in stage 9.0 (TID 922). 5786 bytes result sent to driver
[2025-07-19T18:30:24.846+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 127.0 in stage 9.0 (TID 930) (8b44f3d35cfa, executor driver, partition 127, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.846+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 127.0 in stage 9.0 (TID 930)
[2025-07-19T18:30:24.846+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 120.0 in stage 9.0 (TID 923). 5829 bytes result sent to driver
[2025-07-19T18:30:24.846+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@153bd82
[2025-07-19T18:30:24.847+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 128.0 in stage 9.0 (TID 931) (8b44f3d35cfa, executor driver, partition 128, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.847+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=126, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.847+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=126),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/126] for update
[2025-07-19T18:30:24.847+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 120.0 in stage 9.0 (TID 923) in 50 ms on 8b44f3d35cfa (executor driver) (120/200)
[2025-07-19T18:30:24.847+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 128.0 in stage 9.0 (TID 931)
[2025-07-19T18:30:24.847+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 119.0 in stage 9.0 (TID 922) in 53 ms on 8b44f3d35cfa (executor driver) (121/200)
[2025-07-19T18:30:24.848+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.848+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.849+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.849+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.849+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.849+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/125/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/125/.2.delta.b0eb16e0-343c-4c2e-9cc1-15dd1841d88b.TID928.tmp
[2025-07-19T18:30:24.849+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e2cde60
[2025-07-19T18:30:24.849+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=127, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.849+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=127),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/127] for update
[2025-07-19T18:30:24.850+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ae4eb97
[2025-07-19T18:30:24.850+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=128, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.850+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=128),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/128] for update
[2025-07-19T18:30:24.850+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/124/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/124/.2.delta.36d76dd8-f2a0-467a-b632-a826c48c0d61.TID927.tmp
[2025-07-19T18:30:24.850+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.850+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.851+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/122/.2.delta.74aca400-87ca-4c79-adff-d00546f49d47.TID925.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/122/2.delta
[2025-07-19T18:30:24.851+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=122),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/122] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/122/2.delta
[2025-07-19T18:30:24.854+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/121/.2.delta.08d4f85f-294b-4b06-aad8-4885c27f1774.TID924.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/121/2.delta
[2025-07-19T18:30:24.854+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=121),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/121] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/121/2.delta
[2025-07-19T18:30:24.854+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 122 (task 925, attempt 0, stage 9.0)
[2025-07-19T18:30:24.854+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 121 (task 924, attempt 0, stage 9.0)
[2025-07-19T18:30:24.855+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/127/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/127/.2.delta.5ecd428c-463c-493b-a73d-2d16a0935061.TID930.tmp
[2025-07-19T18:30:24.855+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 121 (task 924, attempt 0, stage 9.0)
[2025-07-19T18:30:24.855+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/126/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/126/.2.delta.a946d8df-c6d8-4132-9c73-f6ac613e5580.TID929.tmp
[2025-07-19T18:30:24.856+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 121.0 in stage 9.0 (TID 924). 5829 bytes result sent to driver
[2025-07-19T18:30:24.856+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 122 (task 925, attempt 0, stage 9.0)
[2025-07-19T18:30:24.856+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 122.0 in stage 9.0 (TID 925). 5829 bytes result sent to driver
[2025-07-19T18:30:24.856+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 129.0 in stage 9.0 (TID 932) (8b44f3d35cfa, executor driver, partition 129, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.856+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 130.0 in stage 9.0 (TID 933) (8b44f3d35cfa, executor driver, partition 130, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.857+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 121.0 in stage 9.0 (TID 924) in 61 ms on 8b44f3d35cfa (executor driver) (122/200)
[2025-07-19T18:30:24.857+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 122.0 in stage 9.0 (TID 925) in 54 ms on 8b44f3d35cfa (executor driver) (123/200)
[2025-07-19T18:30:24.857+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/128/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/128/.2.delta.d5dd6f73-e24b-46bf-ad3b-fccc1fca8c79.TID931.tmp
[2025-07-19T18:30:24.857+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 129.0 in stage 9.0 (TID 932)
[2025-07-19T18:30:24.857+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.857+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.858+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 130.0 in stage 9.0 (TID 933)
[2025-07-19T18:30:24.858+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.858+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.858+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@434a2a65
[2025-07-19T18:30:24.859+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=129, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.861+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=129),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/129] for update
[2025-07-19T18:30:24.861+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/123/.2.delta.b6f8180d-541c-432c-a74e-5f3279783de8.TID926.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/123/2.delta
[2025-07-19T18:30:24.862+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=123),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/123] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/123/2.delta
[2025-07-19T18:30:24.863+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 123 (task 926, attempt 0, stage 9.0)
[2025-07-19T18:30:24.863+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.863+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@245524e2
[2025-07-19T18:30:24.866+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=130, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.869+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=130),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/130] for update
[2025-07-19T18:30:24.870+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.871+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 123 (task 926, attempt 0, stage 9.0)
[2025-07-19T18:30:24.871+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 123.0 in stage 9.0 (TID 926). 5829 bytes result sent to driver
[2025-07-19T18:30:24.872+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 131.0 in stage 9.0 (TID 934) (8b44f3d35cfa, executor driver, partition 131, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.872+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 123.0 in stage 9.0 (TID 926) in 51 ms on 8b44f3d35cfa (executor driver) (124/200)
[2025-07-19T18:30:24.873+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 131.0 in stage 9.0 (TID 934)
[2025-07-19T18:30:24.874+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.875+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.877+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/124/.2.delta.36d76dd8-f2a0-467a-b632-a826c48c0d61.TID927.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/124/2.delta
[2025-07-19T18:30:24.878+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=124),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/124] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/124/2.delta
[2025-07-19T18:30:24.879+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 124 (task 927, attempt 0, stage 9.0)
[2025-07-19T18:30:24.880+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d86374d
[2025-07-19T18:30:24.881+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/130/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/130/.2.delta.c76adbeb-8a5f-4d03-b336-e196c736be03.TID933.tmp
[2025-07-19T18:30:24.881+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=131, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.881+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/129/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/129/.2.delta.c82d161e-d0ed-44fc-9d31-f008bc64861f.TID932.tmp
[2025-07-19T18:30:24.882+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=131),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/131] for update
[2025-07-19T18:30:24.882+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.883+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/125/.2.delta.b0eb16e0-343c-4c2e-9cc1-15dd1841d88b.TID928.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/125/2.delta
[2025-07-19T18:30:24.883+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=125),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/125] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/125/2.delta
[2025-07-19T18:30:24.884+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 125 (task 928, attempt 0, stage 9.0)
[2025-07-19T18:30:24.884+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/127/.2.delta.5ecd428c-463c-493b-a73d-2d16a0935061.TID930.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/127/2.delta
[2025-07-19T18:30:24.887+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=127),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/127] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/127/2.delta
[2025-07-19T18:30:24.887+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 125 (task 928, attempt 0, stage 9.0)
[2025-07-19T18:30:24.888+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 125.0 in stage 9.0 (TID 928). 5829 bytes result sent to driver
[2025-07-19T18:30:24.888+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 132.0 in stage 9.0 (TID 935) (8b44f3d35cfa, executor driver, partition 132, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.889+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 127 (task 930, attempt 0, stage 9.0)
[2025-07-19T18:30:24.889+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 132.0 in stage 9.0 (TID 935)
[2025-07-19T18:30:24.889+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/126/.2.delta.a946d8df-c6d8-4132-9c73-f6ac613e5580.TID929.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/126/2.delta
[2025-07-19T18:30:24.890+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 125.0 in stage 9.0 (TID 928) in 56 ms on 8b44f3d35cfa (executor driver) (125/200)
[2025-07-19T18:30:24.891+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=126),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/126] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/126/2.delta
[2025-07-19T18:30:24.892+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 126 (task 929, attempt 0, stage 9.0)
[2025-07-19T18:30:24.893+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/131/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/131/.2.delta.8307a5e4-29e3-4746-a962-8a0a032948ed.TID934.tmp
[2025-07-19T18:30:24.894+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 127 (task 930, attempt 0, stage 9.0)
[2025-07-19T18:30:24.895+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 127.0 in stage 9.0 (TID 930). 5829 bytes result sent to driver
[2025-07-19T18:30:24.895+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.898+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 133.0 in stage 9.0 (TID 936) (8b44f3d35cfa, executor driver, partition 133, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.898+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 124 (task 927, attempt 0, stage 9.0)
[2025-07-19T18:30:24.899+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T18:30:24.899+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 126 (task 929, attempt 0, stage 9.0)
[2025-07-19T18:30:24.899+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 127.0 in stage 9.0 (TID 930) in 50 ms on 8b44f3d35cfa (executor driver) (126/200)
[2025-07-19T18:30:24.900+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 133.0 in stage 9.0 (TID 936)
[2025-07-19T18:30:24.900+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 126.0 in stage 9.0 (TID 929). 5915 bytes result sent to driver
[2025-07-19T18:30:24.901+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 124.0 in stage 9.0 (TID 927). 5786 bytes result sent to driver
[2025-07-19T18:30:24.901+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 134.0 in stage 9.0 (TID 937) (8b44f3d35cfa, executor driver, partition 134, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.902+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@75fb255e
[2025-07-19T18:30:24.902+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 134.0 in stage 9.0 (TID 937)
[2025-07-19T18:30:24.902+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 135.0 in stage 9.0 (TID 938) (8b44f3d35cfa, executor driver, partition 135, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.903+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 135.0 in stage 9.0 (TID 938)
[2025-07-19T18:30:24.903+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 126.0 in stage 9.0 (TID 929) in 60 ms on 8b44f3d35cfa (executor driver) (127/200)
[2025-07-19T18:30:24.904+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=132, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.904+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=132),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/132] for update
[2025-07-19T18:30:24.904+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 124.0 in stage 9.0 (TID 927) in 70 ms on 8b44f3d35cfa (executor driver) (128/200)
[2025-07-19T18:30:24.904+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.904+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.904+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.904+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/128/.2.delta.d5dd6f73-e24b-46bf-ad3b-fccc1fca8c79.TID931.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/128/2.delta
[2025-07-19T18:30:24.904+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=128),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/128] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/128/2.delta
[2025-07-19T18:30:24.904+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.905+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T18:30:24.905+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@962ab7a
[2025-07-19T18:30:24.905+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=135, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.909+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=135),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/135] for update
[2025-07-19T18:30:24.910+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.910+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 128 (task 931, attempt 0, stage 9.0)
[2025-07-19T18:30:24.910+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.911+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.911+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@588fe510
[2025-07-19T18:30:24.912+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=133, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.914+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=133),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/133] for update
[2025-07-19T18:30:24.918+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d1662fb
[2025-07-19T18:30:24.919+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=134, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.919+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=134),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/134] for update
[2025-07-19T18:30:24.919+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 128 (task 931, attempt 0, stage 9.0)
[2025-07-19T18:30:24.920+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 128.0 in stage 9.0 (TID 931). 5829 bytes result sent to driver
[2025-07-19T18:30:24.921+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.922+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 136.0 in stage 9.0 (TID 939) (8b44f3d35cfa, executor driver, partition 136, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.924+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 136.0 in stage 9.0 (TID 939)
[2025-07-19T18:30:24.925+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 128.0 in stage 9.0 (TID 931) in 72 ms on 8b44f3d35cfa (executor driver) (129/200)
[2025-07-19T18:30:24.925+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.926+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.926+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54a76a71
[2025-07-19T18:30:24.927+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.929+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=136, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.930+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=136),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/136] for update
[2025-07-19T18:30:24.930+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.930+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/132/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/132/.2.delta.e2978f6e-d0a4-4ce4-9598-3114e253e09c.TID935.tmp
[2025-07-19T18:30:24.930+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/135/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/135/.2.delta.0d1872ef-666a-4a26-b9df-1dabae1feb03.TID938.tmp
[2025-07-19T18:30:24.930+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/130/.2.delta.c76adbeb-8a5f-4d03-b336-e196c736be03.TID933.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/130/2.delta
[2025-07-19T18:30:24.931+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=130),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/130] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/130/2.delta
[2025-07-19T18:30:24.932+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 130 (task 933, attempt 0, stage 9.0)
[2025-07-19T18:30:24.933+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 130 (task 933, attempt 0, stage 9.0)
[2025-07-19T18:30:24.936+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/134/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/134/.2.delta.1a56b453-4fae-4aad-a4a3-76338a751164.TID937.tmp
[2025-07-19T18:30:24.936+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 130.0 in stage 9.0 (TID 933). 5872 bytes result sent to driver
[2025-07-19T18:30:24.936+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/133/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/133/.2.delta.9305cea6-6448-49fa-8fa9-7d1256523369.TID936.tmp
[2025-07-19T18:30:24.937+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 137.0 in stage 9.0 (TID 940) (8b44f3d35cfa, executor driver, partition 137, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.937+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 130.0 in stage 9.0 (TID 933) in 83 ms on 8b44f3d35cfa (executor driver) (130/200)
[2025-07-19T18:30:24.937+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 137.0 in stage 9.0 (TID 940)
[2025-07-19T18:30:24.937+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/136/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/136/.2.delta.d69993f8-5253-4de8-a787-48433d8f583d.TID939.tmp
[2025-07-19T18:30:24.937+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.937+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.937+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2765aa40
[2025-07-19T18:30:24.937+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/129/.2.delta.c82d161e-d0ed-44fc-9d31-f008bc64861f.TID932.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/129/2.delta
[2025-07-19T18:30:24.938+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=129),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/129] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/129/2.delta
[2025-07-19T18:30:24.939+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=137, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.941+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=137),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/137] for update
[2025-07-19T18:30:24.942+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 129 (task 932, attempt 0, stage 9.0)
[2025-07-19T18:30:24.943+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.943+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 129 (task 932, attempt 0, stage 9.0)
[2025-07-19T18:30:24.943+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 129.0 in stage 9.0 (TID 932). 5872 bytes result sent to driver
[2025-07-19T18:30:24.944+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/131/.2.delta.8307a5e4-29e3-4746-a962-8a0a032948ed.TID934.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/131/2.delta
[2025-07-19T18:30:24.944+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=131),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/131] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/131/2.delta
[2025-07-19T18:30:24.945+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 138.0 in stage 9.0 (TID 941) (8b44f3d35cfa, executor driver, partition 138, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.945+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 129.0 in stage 9.0 (TID 932) in 105 ms on 8b44f3d35cfa (executor driver) (131/200)
[2025-07-19T18:30:24.947+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 131 (task 934, attempt 0, stage 9.0)
[2025-07-19T18:30:24.947+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 138.0 in stage 9.0 (TID 941)
[2025-07-19T18:30:24.947+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/137/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/137/.2.delta.58afe9a2-6eb8-4b10-a605-f1ff81636fa7.TID940.tmp
[2025-07-19T18:30:24.948+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/132/.2.delta.e2978f6e-d0a4-4ce4-9598-3114e253e09c.TID935.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/132/2.delta
[2025-07-19T18:30:24.948+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=132),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/132] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/132/2.delta
[2025-07-19T18:30:24.949+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.950+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:24.950+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 131 (task 934, attempt 0, stage 9.0)
[2025-07-19T18:30:24.951+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5000b980
[2025-07-19T18:30:24.952+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=138, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.952+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=138),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/138] for update
[2025-07-19T18:30:24.952+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 131.0 in stage 9.0 (TID 934). 5872 bytes result sent to driver
[2025-07-19T18:30:24.952+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 139.0 in stage 9.0 (TID 942) (8b44f3d35cfa, executor driver, partition 139, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.952+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 131.0 in stage 9.0 (TID 934) in 97 ms on 8b44f3d35cfa (executor driver) (132/200)
[2025-07-19T18:30:24.952+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 132 (task 935, attempt 0, stage 9.0)
[2025-07-19T18:30:24.952+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 139.0 in stage 9.0 (TID 942)
[2025-07-19T18:30:24.952+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.953+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/135/.2.delta.0d1872ef-666a-4a26-b9df-1dabae1feb03.TID938.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/135/2.delta
[2025-07-19T18:30:24.953+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=135),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/135] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/135/2.delta
[2025-07-19T18:30:24.953+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.953+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.953+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 135 (task 938, attempt 0, stage 9.0)
[2025-07-19T18:30:24.953+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 132 (task 935, attempt 0, stage 9.0)
[2025-07-19T18:30:24.954+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a3f0cbb
[2025-07-19T18:30:24.954+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 132.0 in stage 9.0 (TID 935). 5872 bytes result sent to driver
[2025-07-19T18:30:24.954+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=139, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.955+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=139),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/139] for update
[2025-07-19T18:30:24.955+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 140.0 in stage 9.0 (TID 943) (8b44f3d35cfa, executor driver, partition 140, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.955+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 132.0 in stage 9.0 (TID 935) in 95 ms on 8b44f3d35cfa (executor driver) (133/200)
[2025-07-19T18:30:24.955+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 140.0 in stage 9.0 (TID 943)
[2025-07-19T18:30:24.955+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.955+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.955+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.955+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@266c6d18
[2025-07-19T18:30:24.956+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=140, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.957+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=140),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/140] for update
[2025-07-19T18:30:24.958+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/133/.2.delta.9305cea6-6448-49fa-8fa9-7d1256523369.TID936.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/133/2.delta
[2025-07-19T18:30:24.958+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=133),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/133] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/133/2.delta
[2025-07-19T18:30:24.958+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 133 (task 936, attempt 0, stage 9.0)
[2025-07-19T18:30:24.959+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 135 (task 938, attempt 0, stage 9.0)
[2025-07-19T18:30:24.960+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.961+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 135.0 in stage 9.0 (TID 938). 5872 bytes result sent to driver
[2025-07-19T18:30:24.961+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 133 (task 936, attempt 0, stage 9.0)
[2025-07-19T18:30:24.962+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 133.0 in stage 9.0 (TID 936). 5872 bytes result sent to driver
[2025-07-19T18:30:24.962+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 141.0 in stage 9.0 (TID 944) (8b44f3d35cfa, executor driver, partition 141, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.963+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 141.0 in stage 9.0 (TID 944)
[2025-07-19T18:30:24.963+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 142.0 in stage 9.0 (TID 945) (8b44f3d35cfa, executor driver, partition 142, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.964+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 135.0 in stage 9.0 (TID 938) in 91 ms on 8b44f3d35cfa (executor driver) (134/200)
[2025-07-19T18:30:24.965+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 133.0 in stage 9.0 (TID 936) in 99 ms on 8b44f3d35cfa (executor driver) (135/200)
[2025-07-19T18:30:24.966+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 142.0 in stage 9.0 (TID 945)
[2025-07-19T18:30:24.967+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/139/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/139/.2.delta.6ff563cb-2835-46ed-bca7-c355aaefd502.TID942.tmp
[2025-07-19T18:30:24.967+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.970+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.970+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.971+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.972+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@768cded0
[2025-07-19T18:30:24.973+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=141, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.974+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=141),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/141] for update
[2025-07-19T18:30:24.974+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ed0349
[2025-07-19T18:30:24.974+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.974+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=142, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.974+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=142),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/142] for update
[2025-07-19T18:30:24.975+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/140/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/140/.2.delta.cf37476d-5a4b-4754-ac19-60e849bf02ff.TID943.tmp
[2025-07-19T18:30:24.975+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.977+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/136/.2.delta.d69993f8-5253-4de8-a787-48433d8f583d.TID939.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/136/2.delta
[2025-07-19T18:30:24.977+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=136),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/136] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/136/2.delta
[2025-07-19T18:30:24.979+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 136 (task 939, attempt 0, stage 9.0)
[2025-07-19T18:30:24.979+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 136 (task 939, attempt 0, stage 9.0)
[2025-07-19T18:30:24.980+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 136.0 in stage 9.0 (TID 939). 5829 bytes result sent to driver
[2025-07-19T18:30:24.980+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 143.0 in stage 9.0 (TID 946) (8b44f3d35cfa, executor driver, partition 143, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.980+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 143.0 in stage 9.0 (TID 946)
[2025-07-19T18:30:24.981+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 136.0 in stage 9.0 (TID 939) in 88 ms on 8b44f3d35cfa (executor driver) (136/200)
[2025-07-19T18:30:24.982+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/138/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/138/.2.delta.cb90d4a0-3252-4a53-a7b2-d3e8655d89f2.TID941.tmp
[2025-07-19T18:30:24.982+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/141/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/141/.2.delta.00175795-99e5-4f77-9520-da4997f02c7f.TID944.tmp
[2025-07-19T18:30:24.982+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/142/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/142/.2.delta.460c7d02-f7d5-421d-b353-bbe08d819a5e.TID945.tmp
[2025-07-19T18:30:24.982+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.984+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.985+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25ca3e4a
[2025-07-19T18:30:24.985+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=143, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.985+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=143),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/143] for update
[2025-07-19T18:30:24.986+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/137/.2.delta.58afe9a2-6eb8-4b10-a605-f1ff81636fa7.TID940.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/137/2.delta
[2025-07-19T18:30:24.986+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=137),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/137] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/137/2.delta
[2025-07-19T18:30:24.986+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.987+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 137 (task 940, attempt 0, stage 9.0)
[2025-07-19T18:30:24.988+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/134/.2.delta.1a56b453-4fae-4aad-a4a3-76338a751164.TID937.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/134/2.delta
[2025-07-19T18:30:24.988+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=134),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/134] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/134/2.delta
[2025-07-19T18:30:24.988+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 134 (task 937, attempt 0, stage 9.0)
[2025-07-19T18:30:24.989+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 137 (task 940, attempt 0, stage 9.0)
[2025-07-19T18:30:24.989+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 137.0 in stage 9.0 (TID 940). 5829 bytes result sent to driver
[2025-07-19T18:30:24.990+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 144.0 in stage 9.0 (TID 947) (8b44f3d35cfa, executor driver, partition 144, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.990+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 137.0 in stage 9.0 (TID 940) in 76 ms on 8b44f3d35cfa (executor driver) (137/200)
[2025-07-19T18:30:24.990+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 134 (task 937, attempt 0, stage 9.0)
[2025-07-19T18:30:24.990+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 144.0 in stage 9.0 (TID 947)
[2025-07-19T18:30:24.991+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 134.0 in stage 9.0 (TID 937). 5872 bytes result sent to driver
[2025-07-19T18:30:24.991+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 145.0 in stage 9.0 (TID 948) (8b44f3d35cfa, executor driver, partition 145, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:24.992+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 145.0 in stage 9.0 (TID 948)
[2025-07-19T18:30:24.992+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Finished task 134.0 in stage 9.0 (TID 937) in 119 ms on 8b44f3d35cfa (executor driver) (138/200)
[2025-07-19T18:30:24.992+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.993+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.993+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7bcb707e
[2025-07-19T18:30:24.993+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=145, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.995+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=145),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/145] for update
[2025-07-19T18:30:24.996+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:24.996+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:24.997+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:24.997+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@acb233
[2025-07-19T18:30:24.997+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=144, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:24.998+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=144),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/144] for update
[2025-07-19T18:30:24.999+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/143/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/143/.2.delta.081fbbd0-b952-4c76-8472-a07eeba14b59.TID946.tmp
[2025-07-19T18:30:25.000+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.001+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/145/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/145/.2.delta.5122c26c-ba7b-4746-bb3d-bf9b7a27fd4d.TID948.tmp
[2025-07-19T18:30:25.002+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/144/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/144/.2.delta.a669f035-ce2b-4bde-b862-02fc285e3bbe.TID947.tmp
[2025-07-19T18:30:25.003+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/139/.2.delta.6ff563cb-2835-46ed-bca7-c355aaefd502.TID942.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/139/2.delta
[2025-07-19T18:30:25.005+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=139),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/139] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/139/2.delta
[2025-07-19T18:30:25.006+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 139 (task 942, attempt 0, stage 9.0)
[2025-07-19T18:30:25.006+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/138/.2.delta.cb90d4a0-3252-4a53-a7b2-d3e8655d89f2.TID941.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/138/2.delta
[2025-07-19T18:30:25.007+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=138),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/138] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/138/2.delta
[2025-07-19T18:30:25.008+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 138 (task 941, attempt 0, stage 9.0)
[2025-07-19T18:30:25.008+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/140/.2.delta.cf37476d-5a4b-4754-ac19-60e849bf02ff.TID943.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/140/2.delta
[2025-07-19T18:30:25.009+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=140),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/140] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/140/2.delta
[2025-07-19T18:30:25.009+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Commit authorized for partition 140 (task 943, attempt 0, stage 9.0)
[2025-07-19T18:30:25.010+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 138 (task 941, attempt 0, stage 9.0)
[2025-07-19T18:30:25.010+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 138.0 in stage 9.0 (TID 941). 5829 bytes result sent to driver
[2025-07-19T18:30:25.011+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 139 (task 942, attempt 0, stage 9.0)
[2025-07-19T18:30:25.011+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Finished task 139.0 in stage 9.0 (TID 942). 5829 bytes result sent to driver
[2025-07-19T18:30:25.011+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 146.0 in stage 9.0 (TID 949) (8b44f3d35cfa, executor driver, partition 146, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.012+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO TaskSetManager: Starting task 147.0 in stage 9.0 (TID 950) (8b44f3d35cfa, executor driver, partition 147, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.013+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO Executor: Running task 146.0 in stage 9.0 (TID 949)
[2025-07-19T18:30:25.013+0000] {subprocess.py:93} INFO - 25/07/19 18:30:24 INFO DataWritingSparkTask: Committed partition 140 (task 943, attempt 0, stage 9.0)
[2025-07-19T18:30:25.014+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 147.0 in stage 9.0 (TID 950)
[2025-07-19T18:30:25.015+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 140.0 in stage 9.0 (TID 943). 5829 bytes result sent to driver
[2025-07-19T18:30:25.016+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 138.0 in stage 9.0 (TID 941) in 85 ms on 8b44f3d35cfa (executor driver) (139/200)
[2025-07-19T18:30:25.017+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 139.0 in stage 9.0 (TID 942) in 77 ms on 8b44f3d35cfa (executor driver) (140/200)
[2025-07-19T18:30:25.018+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.019+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.019+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 148.0 in stage 9.0 (TID 951) (8b44f3d35cfa, executor driver, partition 148, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.020+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 148.0 in stage 9.0 (TID 951)
[2025-07-19T18:30:25.021+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/142/.2.delta.460c7d02-f7d5-421d-b353-bbe08d819a5e.TID945.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/142/2.delta
[2025-07-19T18:30:25.022+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=142),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/142] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/142/2.delta
[2025-07-19T18:30:25.022+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3dceb0e3
[2025-07-19T18:30:25.022+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.023+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.023+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=146, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.024+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 140.0 in stage 9.0 (TID 943) in 70 ms on 8b44f3d35cfa (executor driver) (141/200)
[2025-07-19T18:30:25.024+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 142 (task 945, attempt 0, stage 9.0)
[2025-07-19T18:30:25.025+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=146),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/146] for update
[2025-07-19T18:30:25.027+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d9bacc0
[2025-07-19T18:30:25.027+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/141/.2.delta.00175795-99e5-4f77-9520-da4997f02c7f.TID944.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/141/2.delta
[2025-07-19T18:30:25.028+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=147, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.029+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=141),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/141] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/141/2.delta
[2025-07-19T18:30:25.030+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=147),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/147] for update
[2025-07-19T18:30:25.030+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.031+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.031+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.033+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d9719dc
[2025-07-19T18:30:25.033+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=148, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.035+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=148),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/148] for update
[2025-07-19T18:30:25.035+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.036+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 141 (task 944, attempt 0, stage 9.0)
[2025-07-19T18:30:25.037+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.039+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 142 (task 945, attempt 0, stage 9.0)
[2025-07-19T18:30:25.040+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 142.0 in stage 9.0 (TID 945). 5829 bytes result sent to driver
[2025-07-19T18:30:25.040+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 149.0 in stage 9.0 (TID 952) (8b44f3d35cfa, executor driver, partition 149, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.040+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 142.0 in stage 9.0 (TID 945) in 67 ms on 8b44f3d35cfa (executor driver) (142/200)
[2025-07-19T18:30:25.041+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 149.0 in stage 9.0 (TID 952)
[2025-07-19T18:30:25.041+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 141 (task 944, attempt 0, stage 9.0)
[2025-07-19T18:30:25.041+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.041+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.042+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/147/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/147/.2.delta.28ad9190-4fc3-4d9c-9094-6d80a3ebf3bd.TID950.tmp
[2025-07-19T18:30:25.042+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 141.0 in stage 9.0 (TID 944). 5829 bytes result sent to driver
[2025-07-19T18:30:25.043+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 150.0 in stage 9.0 (TID 953) (8b44f3d35cfa, executor driver, partition 150, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.043+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 141.0 in stage 9.0 (TID 944) in 73 ms on 8b44f3d35cfa (executor driver) (143/200)
[2025-07-19T18:30:25.044+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 150.0 in stage 9.0 (TID 953)
[2025-07-19T18:30:25.044+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@21654b80
[2025-07-19T18:30:25.044+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=149, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.045+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=149),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/149] for update
[2025-07-19T18:30:25.046+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/146/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/146/.2.delta.4c4ac056-2a0c-4ccf-b72b-5e0ff8e3202f.TID949.tmp
[2025-07-19T18:30:25.047+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.047+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.048+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.048+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/148/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/148/.2.delta.daf5011a-990a-4c56-b71e-93e0e4746fab.TID951.tmp
[2025-07-19T18:30:25.048+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/143/.2.delta.081fbbd0-b952-4c76-8472-a07eeba14b59.TID946.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/143/2.delta
[2025-07-19T18:30:25.049+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=143),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/143] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/143/2.delta
[2025-07-19T18:30:25.050+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@104e221b
[2025-07-19T18:30:25.050+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 143 (task 946, attempt 0, stage 9.0)
[2025-07-19T18:30:25.051+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=150, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.052+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=150),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/150] for update
[2025-07-19T18:30:25.052+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.053+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 143 (task 946, attempt 0, stage 9.0)
[2025-07-19T18:30:25.054+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 143.0 in stage 9.0 (TID 946). 5829 bytes result sent to driver
[2025-07-19T18:30:25.055+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 151.0 in stage 9.0 (TID 954) (8b44f3d35cfa, executor driver, partition 151, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.057+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 151.0 in stage 9.0 (TID 954)
[2025-07-19T18:30:25.058+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 143.0 in stage 9.0 (TID 946) in 70 ms on 8b44f3d35cfa (executor driver) (144/200)
[2025-07-19T18:30:25.060+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/145/.2.delta.5122c26c-ba7b-4746-bb3d-bf9b7a27fd4d.TID948.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/145/2.delta
[2025-07-19T18:30:25.061+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=145),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/145] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/145/2.delta
[2025-07-19T18:30:25.061+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.061+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.062+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 145 (task 948, attempt 0, stage 9.0)
[2025-07-19T18:30:25.062+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d20ee26
[2025-07-19T18:30:25.062+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=151, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.062+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=151),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/151] for update
[2025-07-19T18:30:25.063+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.063+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/150/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/150/.2.delta.e525c975-e310-46c7-8c26-f4ac6fca6246.TID953.tmp
[2025-07-19T18:30:25.064+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/144/.2.delta.a669f035-ce2b-4bde-b862-02fc285e3bbe.TID947.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/144/2.delta
[2025-07-19T18:30:25.064+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=144),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/144] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/144/2.delta
[2025-07-19T18:30:25.065+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 144 (task 947, attempt 0, stage 9.0)
[2025-07-19T18:30:25.066+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 145 (task 948, attempt 0, stage 9.0)
[2025-07-19T18:30:25.066+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/149/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/149/.2.delta.0e4ac7a7-dcf1-43f2-bc72-d29c272a19ac.TID952.tmp
[2025-07-19T18:30:25.068+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 145.0 in stage 9.0 (TID 948). 5829 bytes result sent to driver
[2025-07-19T18:30:25.068+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 152.0 in stage 9.0 (TID 955) (8b44f3d35cfa, executor driver, partition 152, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.068+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 152.0 in stage 9.0 (TID 955)
[2025-07-19T18:30:25.069+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 145.0 in stage 9.0 (TID 948) in 68 ms on 8b44f3d35cfa (executor driver) (145/200)
[2025-07-19T18:30:25.070+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 144 (task 947, attempt 0, stage 9.0)
[2025-07-19T18:30:25.070+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 144.0 in stage 9.0 (TID 947). 5829 bytes result sent to driver
[2025-07-19T18:30:25.071+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 153.0 in stage 9.0 (TID 956) (8b44f3d35cfa, executor driver, partition 153, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.071+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.071+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/151/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/151/.2.delta.cf7de757-27b0-4d62-bfb7-1e7ec7f97791.TID954.tmp
[2025-07-19T18:30:25.072+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T18:30:25.072+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 144.0 in stage 9.0 (TID 947) in 76 ms on 8b44f3d35cfa (executor driver) (146/200)
[2025-07-19T18:30:25.074+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 153.0 in stage 9.0 (TID 956)
[2025-07-19T18:30:25.074+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6babe553
[2025-07-19T18:30:25.074+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=152, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.075+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=152),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/152] for update
[2025-07-19T18:30:25.075+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.075+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.075+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.076+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/147/.2.delta.28ad9190-4fc3-4d9c-9094-6d80a3ebf3bd.TID950.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/147/2.delta
[2025-07-19T18:30:25.076+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=147),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/147] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/147/2.delta
[2025-07-19T18:30:25.076+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1aa25a91
[2025-07-19T18:30:25.076+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=153, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.076+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=153),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/153] for update
[2025-07-19T18:30:25.076+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.076+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 147 (task 950, attempt 0, stage 9.0)
[2025-07-19T18:30:25.076+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/146/.2.delta.4c4ac056-2a0c-4ccf-b72b-5e0ff8e3202f.TID949.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/146/2.delta
[2025-07-19T18:30:25.077+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=146),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/146] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/146/2.delta
[2025-07-19T18:30:25.077+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 146 (task 949, attempt 0, stage 9.0)
[2025-07-19T18:30:25.078+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 147 (task 950, attempt 0, stage 9.0)
[2025-07-19T18:30:25.078+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 147.0 in stage 9.0 (TID 950). 5829 bytes result sent to driver
[2025-07-19T18:30:25.078+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/148/.2.delta.daf5011a-990a-4c56-b71e-93e0e4746fab.TID951.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/148/2.delta
[2025-07-19T18:30:25.079+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=148),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/148] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/148/2.delta
[2025-07-19T18:30:25.080+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 148 (task 951, attempt 0, stage 9.0)
[2025-07-19T18:30:25.081+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 154.0 in stage 9.0 (TID 957) (8b44f3d35cfa, executor driver, partition 154, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.082+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 147.0 in stage 9.0 (TID 950) in 57 ms on 8b44f3d35cfa (executor driver) (147/200)
[2025-07-19T18:30:25.082+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 154.0 in stage 9.0 (TID 957)
[2025-07-19T18:30:25.083+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 146 (task 949, attempt 0, stage 9.0)
[2025-07-19T18:30:25.084+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 146.0 in stage 9.0 (TID 949). 5829 bytes result sent to driver
[2025-07-19T18:30:25.085+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 155.0 in stage 9.0 (TID 958) (8b44f3d35cfa, executor driver, partition 155, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.086+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 155.0 in stage 9.0 (TID 958)
[2025-07-19T18:30:25.087+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.088+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.089+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 148 (task 951, attempt 0, stage 9.0)
[2025-07-19T18:30:25.089+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3fe4583f
[2025-07-19T18:30:25.089+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 146.0 in stage 9.0 (TID 949) in 60 ms on 8b44f3d35cfa (executor driver) (148/200)
[2025-07-19T18:30:25.089+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=154, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.090+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 148.0 in stage 9.0 (TID 951). 5786 bytes result sent to driver
[2025-07-19T18:30:25.090+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=154),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/154] for update
[2025-07-19T18:30:25.090+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 156.0 in stage 9.0 (TID 959) (8b44f3d35cfa, executor driver, partition 156, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.090+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 156.0 in stage 9.0 (TID 959)
[2025-07-19T18:30:25.091+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/152/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/152/.2.delta.71ddbafd-60cb-4802-8955-b2f99b097b4f.TID955.tmp
[2025-07-19T18:30:25.091+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 148.0 in stage 9.0 (TID 951) in 59 ms on 8b44f3d35cfa (executor driver) (149/200)
[2025-07-19T18:30:25.092+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/153/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/153/.2.delta.575ada13-1f27-454d-ac77-e9a055c82ed3.TID956.tmp
[2025-07-19T18:30:25.092+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.093+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.094+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.095+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5fc79579
[2025-07-19T18:30:25.096+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.096+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.096+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=155, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.096+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=155),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/155] for update
[2025-07-19T18:30:25.096+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.097+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@668928d0
[2025-07-19T18:30:25.097+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=156, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.098+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=156),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/156] for update
[2025-07-19T18:30:25.099+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.100+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/150/.2.delta.e525c975-e310-46c7-8c26-f4ac6fca6246.TID953.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/150/2.delta
[2025-07-19T18:30:25.101+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=150),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/150] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/150/2.delta
[2025-07-19T18:30:25.101+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 150 (task 953, attempt 0, stage 9.0)
[2025-07-19T18:30:25.103+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/149/.2.delta.0e4ac7a7-dcf1-43f2-bc72-d29c272a19ac.TID952.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/149/2.delta
[2025-07-19T18:30:25.103+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=149),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/149] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/149/2.delta
[2025-07-19T18:30:25.105+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 149 (task 952, attempt 0, stage 9.0)
[2025-07-19T18:30:25.105+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 150 (task 953, attempt 0, stage 9.0)
[2025-07-19T18:30:25.106+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 150.0 in stage 9.0 (TID 953). 5829 bytes result sent to driver
[2025-07-19T18:30:25.106+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/154/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/154/.2.delta.99e731cc-750c-49ca-8e53-b1e1091723b0.TID957.tmp
[2025-07-19T18:30:25.106+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 149 (task 952, attempt 0, stage 9.0)
[2025-07-19T18:30:25.106+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 149.0 in stage 9.0 (TID 952). 5829 bytes result sent to driver
[2025-07-19T18:30:25.107+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/156/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/156/.2.delta.7d96bb94-017a-4175-91a8-223e6dd23cfe.TID959.tmp
[2025-07-19T18:30:25.107+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/155/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/155/.2.delta.c96ef1b6-dbcb-4d44-9555-2a68532b77c8.TID958.tmp
[2025-07-19T18:30:25.108+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 157.0 in stage 9.0 (TID 960) (8b44f3d35cfa, executor driver, partition 157, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.108+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 158.0 in stage 9.0 (TID 961) (8b44f3d35cfa, executor driver, partition 158, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.109+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 158.0 in stage 9.0 (TID 961)
[2025-07-19T18:30:25.109+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 157.0 in stage 9.0 (TID 960)
[2025-07-19T18:30:25.109+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 150.0 in stage 9.0 (TID 953) in 63 ms on 8b44f3d35cfa (executor driver) (150/200)
[2025-07-19T18:30:25.110+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 149.0 in stage 9.0 (TID 952) in 68 ms on 8b44f3d35cfa (executor driver) (151/200)
[2025-07-19T18:30:25.110+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.110+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.111+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.112+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.113+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@61177ca8
[2025-07-19T18:30:25.113+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/151/.2.delta.cf7de757-27b0-4d62-bfb7-1e7ec7f97791.TID954.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/151/2.delta
[2025-07-19T18:30:25.114+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=151),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/151] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/151/2.delta
[2025-07-19T18:30:25.115+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 151 (task 954, attempt 0, stage 9.0)
[2025-07-19T18:30:25.117+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=157, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.117+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=157),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/157] for update
[2025-07-19T18:30:25.117+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.117+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ed5a6d9
[2025-07-19T18:30:25.117+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 151 (task 954, attempt 0, stage 9.0)
[2025-07-19T18:30:25.117+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=158, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.117+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=158),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/158] for update
[2025-07-19T18:30:25.118+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.118+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 151.0 in stage 9.0 (TID 954). 5829 bytes result sent to driver
[2025-07-19T18:30:25.119+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 159.0 in stage 9.0 (TID 962) (8b44f3d35cfa, executor driver, partition 159, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.119+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 151.0 in stage 9.0 (TID 954) in 62 ms on 8b44f3d35cfa (executor driver) (152/200)
[2025-07-19T18:30:25.120+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/153/.2.delta.575ada13-1f27-454d-ac77-e9a055c82ed3.TID956.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/153/2.delta
[2025-07-19T18:30:25.121+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=153),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/153] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/153/2.delta
[2025-07-19T18:30:25.121+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 159.0 in stage 9.0 (TID 962)
[2025-07-19T18:30:25.121+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/152/.2.delta.71ddbafd-60cb-4802-8955-b2f99b097b4f.TID955.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/152/2.delta
[2025-07-19T18:30:25.121+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=152),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/152] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/152/2.delta
[2025-07-19T18:30:25.121+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/157/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/157/.2.delta.8683659e-5dec-4f1f-9431-f24d2d688201.TID960.tmp
[2025-07-19T18:30:25.121+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 153 (task 956, attempt 0, stage 9.0)
[2025-07-19T18:30:25.121+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 152 (task 955, attempt 0, stage 9.0)
[2025-07-19T18:30:25.121+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.121+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.121+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@327c739d
[2025-07-19T18:30:25.122+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=159, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.122+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=159),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/159] for update
[2025-07-19T18:30:25.122+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/158/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/158/.2.delta.23f23082-dcf3-41a2-a651-743e86c4b775.TID961.tmp
[2025-07-19T18:30:25.122+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 153 (task 956, attempt 0, stage 9.0)
[2025-07-19T18:30:25.122+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 153.0 in stage 9.0 (TID 956). 5829 bytes result sent to driver
[2025-07-19T18:30:25.123+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.123+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 160.0 in stage 9.0 (TID 963) (8b44f3d35cfa, executor driver, partition 160, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.123+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 160.0 in stage 9.0 (TID 963)
[2025-07-19T18:30:25.124+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 152 (task 955, attempt 0, stage 9.0)
[2025-07-19T18:30:25.124+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 152.0 in stage 9.0 (TID 955). 5829 bytes result sent to driver
[2025-07-19T18:30:25.125+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 153.0 in stage 9.0 (TID 956) in 58 ms on 8b44f3d35cfa (executor driver) (153/200)
[2025-07-19T18:30:25.125+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 161.0 in stage 9.0 (TID 964) (8b44f3d35cfa, executor driver, partition 161, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.126+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 152.0 in stage 9.0 (TID 955) in 63 ms on 8b44f3d35cfa (executor driver) (154/200)
[2025-07-19T18:30:25.126+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 161.0 in stage 9.0 (TID 964)
[2025-07-19T18:30:25.127+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.127+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.127+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e084660
[2025-07-19T18:30:25.127+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=160, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.127+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=160),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/160] for update
[2025-07-19T18:30:25.127+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.127+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.128+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.128+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c3ba1c3
[2025-07-19T18:30:25.128+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=161, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.128+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=161),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/161] for update
[2025-07-19T18:30:25.128+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/156/.2.delta.7d96bb94-017a-4175-91a8-223e6dd23cfe.TID959.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/156/2.delta
[2025-07-19T18:30:25.128+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=156),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/156] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/156/2.delta
[2025-07-19T18:30:25.128+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 156 (task 959, attempt 0, stage 9.0)
[2025-07-19T18:30:25.130+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/159/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/159/.2.delta.16218198-8cee-48ea-a798-80dee6d873b7.TID962.tmp
[2025-07-19T18:30:25.130+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/160/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/160/.2.delta.acc8d63f-ae86-473f-b411-7eabcb8301d3.TID963.tmp
[2025-07-19T18:30:25.130+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 156 (task 959, attempt 0, stage 9.0)
[2025-07-19T18:30:25.130+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 156.0 in stage 9.0 (TID 959). 5829 bytes result sent to driver
[2025-07-19T18:30:25.130+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 162.0 in stage 9.0 (TID 965) (8b44f3d35cfa, executor driver, partition 162, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.130+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 156.0 in stage 9.0 (TID 959) in 52 ms on 8b44f3d35cfa (executor driver) (155/200)
[2025-07-19T18:30:25.131+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.131+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 162.0 in stage 9.0 (TID 965)
[2025-07-19T18:30:25.132+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/155/.2.delta.c96ef1b6-dbcb-4d44-9555-2a68532b77c8.TID958.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/155/2.delta
[2025-07-19T18:30:25.132+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=155),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/155] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/155/2.delta
[2025-07-19T18:30:25.133+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 155 (task 958, attempt 0, stage 9.0)
[2025-07-19T18:30:25.133+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.133+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.133+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/154/.2.delta.99e731cc-750c-49ca-8e53-b1e1091723b0.TID957.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/154/2.delta
[2025-07-19T18:30:25.134+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=154),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/154] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/154/2.delta
[2025-07-19T18:30:25.134+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 154 (task 957, attempt 0, stage 9.0)
[2025-07-19T18:30:25.135+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@199716e0
[2025-07-19T18:30:25.135+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 155 (task 958, attempt 0, stage 9.0)
[2025-07-19T18:30:25.136+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=162, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.136+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=162),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/162] for update
[2025-07-19T18:30:25.137+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 155.0 in stage 9.0 (TID 958). 5829 bytes result sent to driver
[2025-07-19T18:30:25.138+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 163.0 in stage 9.0 (TID 966) (8b44f3d35cfa, executor driver, partition 163, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.139+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/161/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/161/.2.delta.3aaf8e41-c03c-427a-a961-b3c14b4a632b.TID964.tmp
[2025-07-19T18:30:25.139+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 155.0 in stage 9.0 (TID 958) in 66 ms on 8b44f3d35cfa (executor driver) (156/200)
[2025-07-19T18:30:25.140+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.140+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 163.0 in stage 9.0 (TID 966)
[2025-07-19T18:30:25.140+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 154 (task 957, attempt 0, stage 9.0)
[2025-07-19T18:30:25.141+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 154.0 in stage 9.0 (TID 957). 5829 bytes result sent to driver
[2025-07-19T18:30:25.142+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 154.0 in stage 9.0 (TID 957) in 70 ms on 8b44f3d35cfa (executor driver) (157/200)
[2025-07-19T18:30:25.142+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 164.0 in stage 9.0 (TID 967) (8b44f3d35cfa, executor driver, partition 164, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.142+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.143+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.144+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 164.0 in stage 9.0 (TID 967)
[2025-07-19T18:30:25.144+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28a8924
[2025-07-19T18:30:25.144+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=163, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.144+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=163),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/163] for update
[2025-07-19T18:30:25.144+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.145+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.145+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.145+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@12822fa6
[2025-07-19T18:30:25.146+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=164, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.146+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=164),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/164] for update
[2025-07-19T18:30:25.146+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.147+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/162/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/162/.2.delta.3b60e9f5-17d3-4ff8-92de-93928e913a5c.TID965.tmp
[2025-07-19T18:30:25.147+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/163/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/163/.2.delta.87d08b85-19ad-43ad-82b3-89cd4c3b4640.TID966.tmp
[2025-07-19T18:30:25.148+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/159/.2.delta.16218198-8cee-48ea-a798-80dee6d873b7.TID962.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/159/2.delta
[2025-07-19T18:30:25.149+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=159),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/159] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/159/2.delta
[2025-07-19T18:30:25.151+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 159 (task 962, attempt 0, stage 9.0)
[2025-07-19T18:30:25.151+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/164/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/164/.2.delta.cbc3fc81-2da5-4ae9-9071-a8b264bf8f3f.TID967.tmp
[2025-07-19T18:30:25.151+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/158/.2.delta.23f23082-dcf3-41a2-a651-743e86c4b775.TID961.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/158/2.delta
[2025-07-19T18:30:25.152+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=158),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/158] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/158/2.delta
[2025-07-19T18:30:25.153+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 158 (task 961, attempt 0, stage 9.0)
[2025-07-19T18:30:25.154+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 159 (task 962, attempt 0, stage 9.0)
[2025-07-19T18:30:25.155+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 159.0 in stage 9.0 (TID 962). 5829 bytes result sent to driver
[2025-07-19T18:30:25.157+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 165.0 in stage 9.0 (TID 968) (8b44f3d35cfa, executor driver, partition 165, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.157+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/160/.2.delta.acc8d63f-ae86-473f-b411-7eabcb8301d3.TID963.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/160/2.delta
[2025-07-19T18:30:25.157+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=160),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/160] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/160/2.delta
[2025-07-19T18:30:25.157+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 160 (task 963, attempt 0, stage 9.0)
[2025-07-19T18:30:25.157+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 158 (task 961, attempt 0, stage 9.0)
[2025-07-19T18:30:25.157+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/157/.2.delta.8683659e-5dec-4f1f-9431-f24d2d688201.TID960.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/157/2.delta
[2025-07-19T18:30:25.158+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=157),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/157] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/157/2.delta
[2025-07-19T18:30:25.158+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 157 (task 960, attempt 0, stage 9.0)
[2025-07-19T18:30:25.158+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 158.0 in stage 9.0 (TID 961). 5829 bytes result sent to driver
[2025-07-19T18:30:25.158+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 165.0 in stage 9.0 (TID 968)
[2025-07-19T18:30:25.158+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 166.0 in stage 9.0 (TID 969) (8b44f3d35cfa, executor driver, partition 166, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.158+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 158.0 in stage 9.0 (TID 961) in 80 ms on 8b44f3d35cfa (executor driver) (158/200)
[2025-07-19T18:30:25.158+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 166.0 in stage 9.0 (TID 969)
[2025-07-19T18:30:25.159+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 159.0 in stage 9.0 (TID 962) in 71 ms on 8b44f3d35cfa (executor driver) (159/200)
[2025-07-19T18:30:25.160+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.160+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.160+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 160 (task 963, attempt 0, stage 9.0)
[2025-07-19T18:30:25.162+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 160.0 in stage 9.0 (TID 963). 5829 bytes result sent to driver
[2025-07-19T18:30:25.162+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 157 (task 960, attempt 0, stage 9.0)
[2025-07-19T18:30:25.163+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 157.0 in stage 9.0 (TID 960). 5829 bytes result sent to driver
[2025-07-19T18:30:25.164+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.164+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.164+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 167.0 in stage 9.0 (TID 970) (8b44f3d35cfa, executor driver, partition 167, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.164+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 167.0 in stage 9.0 (TID 970)
[2025-07-19T18:30:25.165+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 168.0 in stage 9.0 (TID 971) (8b44f3d35cfa, executor driver, partition 168, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.166+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 157.0 in stage 9.0 (TID 960) in 85 ms on 8b44f3d35cfa (executor driver) (160/200)
[2025-07-19T18:30:25.167+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/161/.2.delta.3aaf8e41-c03c-427a-a961-b3c14b4a632b.TID964.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/161/2.delta
[2025-07-19T18:30:25.167+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=161),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/161] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/161/2.delta
[2025-07-19T18:30:25.167+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 161 (task 964, attempt 0, stage 9.0)
[2025-07-19T18:30:25.167+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 168.0 in stage 9.0 (TID 971)
[2025-07-19T18:30:25.167+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 160.0 in stage 9.0 (TID 963) in 63 ms on 8b44f3d35cfa (executor driver) (161/200)
[2025-07-19T18:30:25.167+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23e5da54
[2025-07-19T18:30:25.167+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.167+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.168+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=165, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.168+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=165),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/165] for update
[2025-07-19T18:30:25.168+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.168+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.168+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@49016e79
[2025-07-19T18:30:25.168+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=167, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.168+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=167),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/167] for update
[2025-07-19T18:30:25.168+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.168+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ceab5a6
[2025-07-19T18:30:25.168+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.169+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=168, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.169+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=168),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/168] for update
[2025-07-19T18:30:25.169+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 161 (task 964, attempt 0, stage 9.0)
[2025-07-19T18:30:25.169+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 161.0 in stage 9.0 (TID 964). 5829 bytes result sent to driver
[2025-07-19T18:30:25.169+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 169.0 in stage 9.0 (TID 972) (8b44f3d35cfa, executor driver, partition 169, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.169+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 161.0 in stage 9.0 (TID 964) in 67 ms on 8b44f3d35cfa (executor driver) (162/200)
[2025-07-19T18:30:25.170+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 169.0 in stage 9.0 (TID 972)
[2025-07-19T18:30:25.170+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.170+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.171+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.172+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55fd0f27
[2025-07-19T18:30:25.172+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=166, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.173+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=166),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/166] for update
[2025-07-19T18:30:25.173+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/167/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/167/.2.delta.171deeb4-f1bf-4e85-8efd-8ed29b1d0611.TID970.tmp
[2025-07-19T18:30:25.174+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/162/.2.delta.3b60e9f5-17d3-4ff8-92de-93928e913a5c.TID965.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/162/2.delta
[2025-07-19T18:30:25.174+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=162),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/162] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/162/2.delta
[2025-07-19T18:30:25.176+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 162 (task 965, attempt 0, stage 9.0)
[2025-07-19T18:30:25.177+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@10aaa2c4
[2025-07-19T18:30:25.177+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=169, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.177+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=169),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/169] for update
[2025-07-19T18:30:25.178+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.178+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.179+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/165/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/165/.2.delta.e2b9c091-8810-4c7b-bb30-e31b24998abe.TID968.tmp
[2025-07-19T18:30:25.180+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 162 (task 965, attempt 0, stage 9.0)
[2025-07-19T18:30:25.180+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/168/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/168/.2.delta.0edebc58-8a2d-467c-951a-8a3a1fe967c7.TID971.tmp
[2025-07-19T18:30:25.181+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 162.0 in stage 9.0 (TID 965). 5829 bytes result sent to driver
[2025-07-19T18:30:25.182+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 170.0 in stage 9.0 (TID 973) (8b44f3d35cfa, executor driver, partition 170, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.182+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/163/.2.delta.87d08b85-19ad-43ad-82b3-89cd4c3b4640.TID966.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/163/2.delta
[2025-07-19T18:30:25.183+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=163),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/163] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/163/2.delta
[2025-07-19T18:30:25.183+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 170.0 in stage 9.0 (TID 973)
[2025-07-19T18:30:25.183+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/166/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/166/.2.delta.b7e97bc8-4dd6-4f74-9589-f5e858033399.TID969.tmp
[2025-07-19T18:30:25.183+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 163 (task 966, attempt 0, stage 9.0)
[2025-07-19T18:30:25.184+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.184+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.184+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2fd5f447
[2025-07-19T18:30:25.184+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 162.0 in stage 9.0 (TID 965) in 71 ms on 8b44f3d35cfa (executor driver) (163/200)
[2025-07-19T18:30:25.185+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=170, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.187+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=170),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/170] for update
[2025-07-19T18:30:25.187+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 163 (task 966, attempt 0, stage 9.0)
[2025-07-19T18:30:25.188+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.188+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 163.0 in stage 9.0 (TID 966). 5829 bytes result sent to driver
[2025-07-19T18:30:25.188+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 171.0 in stage 9.0 (TID 974) (8b44f3d35cfa, executor driver, partition 171, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.189+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/169/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/169/.2.delta.3a356333-d97b-46f0-8d8b-2b2f8c5ad586.TID972.tmp
[2025-07-19T18:30:25.189+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 171.0 in stage 9.0 (TID 974)
[2025-07-19T18:30:25.190+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.190+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.190+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 163.0 in stage 9.0 (TID 966) in 69 ms on 8b44f3d35cfa (executor driver) (164/200)
[2025-07-19T18:30:25.191+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@78e5ec5f
[2025-07-19T18:30:25.191+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=171, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.192+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=171),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/171] for update
[2025-07-19T18:30:25.192+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/164/.2.delta.cbc3fc81-2da5-4ae9-9071-a8b264bf8f3f.TID967.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/164/2.delta
[2025-07-19T18:30:25.193+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=164),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/164] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/164/2.delta
[2025-07-19T18:30:25.193+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 164 (task 967, attempt 0, stage 9.0)
[2025-07-19T18:30:25.195+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.196+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 164 (task 967, attempt 0, stage 9.0)
[2025-07-19T18:30:25.197+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 164.0 in stage 9.0 (TID 967). 5829 bytes result sent to driver
[2025-07-19T18:30:25.197+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 172.0 in stage 9.0 (TID 975) (8b44f3d35cfa, executor driver, partition 172, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.197+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 172.0 in stage 9.0 (TID 975)
[2025-07-19T18:30:25.197+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 164.0 in stage 9.0 (TID 967) in 70 ms on 8b44f3d35cfa (executor driver) (165/200)
[2025-07-19T18:30:25.205+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/170/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/170/.2.delta.25dcb45c-1caf-497c-80ba-e28c205f1964.TID973.tmp
[2025-07-19T18:30:25.208+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/171/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/171/.2.delta.02c04cf2-2982-4995-b794-10df17970a3a.TID974.tmp
[2025-07-19T18:30:25.212+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.212+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.213+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@675cae0
[2025-07-19T18:30:25.215+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=172, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.215+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=172),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/172] for update
[2025-07-19T18:30:25.215+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/168/.2.delta.0edebc58-8a2d-467c-951a-8a3a1fe967c7.TID971.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/168/2.delta
[2025-07-19T18:30:25.216+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=168),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/168] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/168/2.delta
[2025-07-19T18:30:25.216+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 168 (task 971, attempt 0, stage 9.0)
[2025-07-19T18:30:25.217+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.220+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/167/.2.delta.171deeb4-f1bf-4e85-8efd-8ed29b1d0611.TID970.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/167/2.delta
[2025-07-19T18:30:25.223+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=167),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/167] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/167/2.delta
[2025-07-19T18:30:25.224+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 167 (task 970, attempt 0, stage 9.0)
[2025-07-19T18:30:25.224+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 168 (task 971, attempt 0, stage 9.0)
[2025-07-19T18:30:25.230+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 168.0 in stage 9.0 (TID 971). 5829 bytes result sent to driver
[2025-07-19T18:30:25.231+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 173.0 in stage 9.0 (TID 976) (8b44f3d35cfa, executor driver, partition 173, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.233+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 173.0 in stage 9.0 (TID 976)
[2025-07-19T18:30:25.233+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/165/.2.delta.e2b9c091-8810-4c7b-bb30-e31b24998abe.TID968.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/165/2.delta
[2025-07-19T18:30:25.234+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=165),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/165] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/165/2.delta
[2025-07-19T18:30:25.235+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 165 (task 968, attempt 0, stage 9.0)
[2025-07-19T18:30:25.235+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 168.0 in stage 9.0 (TID 971) in 71 ms on 8b44f3d35cfa (executor driver) (166/200)
[2025-07-19T18:30:25.235+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/169/.2.delta.3a356333-d97b-46f0-8d8b-2b2f8c5ad586.TID972.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/169/2.delta
[2025-07-19T18:30:25.236+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=169),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/169] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/169/2.delta
[2025-07-19T18:30:25.236+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 167 (task 970, attempt 0, stage 9.0)
[2025-07-19T18:30:25.237+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/166/.2.delta.b7e97bc8-4dd6-4f74-9589-f5e858033399.TID969.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/166/2.delta
[2025-07-19T18:30:25.237+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=166),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/166] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/166/2.delta
[2025-07-19T18:30:25.238+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 166 (task 969, attempt 0, stage 9.0)
[2025-07-19T18:30:25.238+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 169 (task 972, attempt 0, stage 9.0)
[2025-07-19T18:30:25.239+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/172/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/172/.2.delta.3c566b84-df32-49dc-adc7-aa260e9de502.TID975.tmp
[2025-07-19T18:30:25.239+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 167.0 in stage 9.0 (TID 970). 5915 bytes result sent to driver
[2025-07-19T18:30:25.240+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 165 (task 968, attempt 0, stage 9.0)
[2025-07-19T18:30:25.241+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 174.0 in stage 9.0 (TID 977) (8b44f3d35cfa, executor driver, partition 174, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.245+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 165.0 in stage 9.0 (TID 968). 5872 bytes result sent to driver
[2025-07-19T18:30:25.248+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 174.0 in stage 9.0 (TID 977)
[2025-07-19T18:30:25.249+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 175.0 in stage 9.0 (TID 978) (8b44f3d35cfa, executor driver, partition 175, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.251+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 165.0 in stage 9.0 (TID 968) in 86 ms on 8b44f3d35cfa (executor driver) (167/200)
[2025-07-19T18:30:25.251+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 167.0 in stage 9.0 (TID 970) in 80 ms on 8b44f3d35cfa (executor driver) (168/200)
[2025-07-19T18:30:25.252+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.252+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.252+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a654d2d
[2025-07-19T18:30:25.252+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=174, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.252+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=174),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/174] for update
[2025-07-19T18:30:25.252+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 175.0 in stage 9.0 (TID 978)
[2025-07-19T18:30:25.257+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/171/.2.delta.02c04cf2-2982-4995-b794-10df17970a3a.TID974.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/171/2.delta
[2025-07-19T18:30:25.257+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=171),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/171] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/171/2.delta
[2025-07-19T18:30:25.274+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 171 (task 974, attempt 0, stage 9.0)
[2025-07-19T18:30:25.278+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 169 (task 972, attempt 0, stage 9.0)
[2025-07-19T18:30:25.279+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 166 (task 969, attempt 0, stage 9.0)
[2025-07-19T18:30:25.279+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 166.0 in stage 9.0 (TID 969). 5872 bytes result sent to driver
[2025-07-19T18:30:25.280+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.281+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T18:30:25.286+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 176.0 in stage 9.0 (TID 979) (8b44f3d35cfa, executor driver, partition 176, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.287+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.287+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/170/.2.delta.25dcb45c-1caf-497c-80ba-e28c205f1964.TID973.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/170/2.delta
[2025-07-19T18:30:25.287+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=170),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/170] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/170/2.delta
[2025-07-19T18:30:25.287+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 170 (task 973, attempt 0, stage 9.0)
[2025-07-19T18:30:25.292+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 169.0 in stage 9.0 (TID 972). 5872 bytes result sent to driver
[2025-07-19T18:30:25.292+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 176.0 in stage 9.0 (TID 979)
[2025-07-19T18:30:25.292+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 171 (task 974, attempt 0, stage 9.0)
[2025-07-19T18:30:25.292+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 171.0 in stage 9.0 (TID 974). 5829 bytes result sent to driver
[2025-07-19T18:30:25.293+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5afdd18d
[2025-07-19T18:30:25.293+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 166.0 in stage 9.0 (TID 969) in 93 ms on 8b44f3d35cfa (executor driver) (169/200)
[2025-07-19T18:30:25.293+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.293+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.293+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.294+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T18:30:25.294+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=173, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.295+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 177.0 in stage 9.0 (TID 980) (8b44f3d35cfa, executor driver, partition 177, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.295+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=173),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/173] for update
[2025-07-19T18:30:25.296+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 178.0 in stage 9.0 (TID 981) (8b44f3d35cfa, executor driver, partition 178, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.296+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 178.0 in stage 9.0 (TID 981)
[2025-07-19T18:30:25.297+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 171.0 in stage 9.0 (TID 974) in 87 ms on 8b44f3d35cfa (executor driver) (170/200)
[2025-07-19T18:30:25.297+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.297+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.298+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6467ee7f
[2025-07-19T18:30:25.298+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=175, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.299+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=175),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/175] for update
[2025-07-19T18:30:25.299+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 170 (task 973, attempt 0, stage 9.0)
[2025-07-19T18:30:25.300+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e0eecd4
[2025-07-19T18:30:25.300+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=176, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.301+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=176),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/176] for update
[2025-07-19T18:30:25.302+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.302+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.302+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.303+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 177.0 in stage 9.0 (TID 980)
[2025-07-19T18:30:25.303+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 169.0 in stage 9.0 (TID 972) in 109 ms on 8b44f3d35cfa (executor driver) (171/200)
[2025-07-19T18:30:25.303+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 170.0 in stage 9.0 (TID 973). 5872 bytes result sent to driver
[2025-07-19T18:30:25.304+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.304+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.304+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 179.0 in stage 9.0 (TID 982) (8b44f3d35cfa, executor driver, partition 179, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.305+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a819153
[2025-07-19T18:30:25.305+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 179.0 in stage 9.0 (TID 982)
[2025-07-19T18:30:25.305+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=178, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.306+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=178),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/178] for update
[2025-07-19T18:30:25.306+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 170.0 in stage 9.0 (TID 973) in 104 ms on 8b44f3d35cfa (executor driver) (172/200)
[2025-07-19T18:30:25.307+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3a2af761
[2025-07-19T18:30:25.307+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=177, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.308+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=177),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/177] for update
[2025-07-19T18:30:25.308+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.308+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.309+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/172/.2.delta.3c566b84-df32-49dc-adc7-aa260e9de502.TID975.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/172/2.delta
[2025-07-19T18:30:25.309+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=172),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/172] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/172/2.delta
[2025-07-19T18:30:25.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e28e9f9
[2025-07-19T18:30:25.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=179, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=179),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/179] for update
[2025-07-19T18:30:25.310+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/174/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/174/.2.delta.db9c8d7a-f212-40a2-8cf7-f843eea4c533.TID977.tmp
[2025-07-19T18:30:25.311+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 172 (task 975, attempt 0, stage 9.0)
[2025-07-19T18:30:25.312+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/173/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/173/.2.delta.4478ebb5-9d00-496a-8ac5-e79d749e6bc7.TID976.tmp
[2025-07-19T18:30:25.313+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.313+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.313+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 172 (task 975, attempt 0, stage 9.0)
[2025-07-19T18:30:25.313+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/176/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/176/.2.delta.eaed5593-800a-4c4d-ad70-321b5cd07a1d.TID979.tmp
[2025-07-19T18:30:25.313+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 172.0 in stage 9.0 (TID 975). 5872 bytes result sent to driver
[2025-07-19T18:30:25.313+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 180.0 in stage 9.0 (TID 983) (8b44f3d35cfa, executor driver, partition 180, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.313+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/175/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/175/.2.delta.6c9b98b7-c33a-4c50-b41c-9d96693fb039.TID978.tmp
[2025-07-19T18:30:25.313+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 180.0 in stage 9.0 (TID 983)
[2025-07-19T18:30:25.313+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 172.0 in stage 9.0 (TID 975) in 109 ms on 8b44f3d35cfa (executor driver) (173/200)
[2025-07-19T18:30:25.314+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/178/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/178/.2.delta.c9b50e6e-899d-4c10-bb58-1e51b7f56935.TID981.tmp
[2025-07-19T18:30:25.314+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/177/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/177/.2.delta.512b95e3-9156-4153-b2ac-d2a0b06d8cbb.TID980.tmp
[2025-07-19T18:30:25.314+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/179/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/179/.2.delta.206bea34-d76e-4acd-a1a3-c4a0ae83c507.TID982.tmp
[2025-07-19T18:30:25.314+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.314+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:25.314+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@eb14966
[2025-07-19T18:30:25.314+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=180, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.314+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=180),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/180] for update
[2025-07-19T18:30:25.314+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.319+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/180/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/180/.2.delta.9f4e20f9-d6e5-4012-a1b5-d8e83a7eac48.TID983.tmp
[2025-07-19T18:30:25.327+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/174/.2.delta.db9c8d7a-f212-40a2-8cf7-f843eea4c533.TID977.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/174/2.delta
[2025-07-19T18:30:25.328+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=174),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/174] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/174/2.delta
[2025-07-19T18:30:25.328+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 174 (task 977, attempt 0, stage 9.0)
[2025-07-19T18:30:25.333+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/173/.2.delta.4478ebb5-9d00-496a-8ac5-e79d749e6bc7.TID976.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/173/2.delta
[2025-07-19T18:30:25.334+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=173),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/173] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/173/2.delta
[2025-07-19T18:30:25.335+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 173 (task 976, attempt 0, stage 9.0)
[2025-07-19T18:30:25.335+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 174 (task 977, attempt 0, stage 9.0)
[2025-07-19T18:30:25.336+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 174.0 in stage 9.0 (TID 977). 5872 bytes result sent to driver
[2025-07-19T18:30:25.337+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 181.0 in stage 9.0 (TID 984) (8b44f3d35cfa, executor driver, partition 181, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.340+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/176/.2.delta.eaed5593-800a-4c4d-ad70-321b5cd07a1d.TID979.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/176/2.delta
[2025-07-19T18:30:25.341+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=176),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/176] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/176/2.delta
[2025-07-19T18:30:25.343+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 176 (task 979, attempt 0, stage 9.0)
[2025-07-19T18:30:25.343+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 174.0 in stage 9.0 (TID 977) in 96 ms on 8b44f3d35cfa (executor driver) (174/200)
[2025-07-19T18:30:25.344+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 181.0 in stage 9.0 (TID 984)
[2025-07-19T18:30:25.344+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 173 (task 976, attempt 0, stage 9.0)
[2025-07-19T18:30:25.344+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 173.0 in stage 9.0 (TID 976). 5872 bytes result sent to driver
[2025-07-19T18:30:25.345+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/175/.2.delta.6c9b98b7-c33a-4c50-b41c-9d96693fb039.TID978.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/175/2.delta
[2025-07-19T18:30:25.345+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=175),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/175] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/175/2.delta
[2025-07-19T18:30:25.346+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 182.0 in stage 9.0 (TID 985) (8b44f3d35cfa, executor driver, partition 182, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.346+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 173.0 in stage 9.0 (TID 976) in 109 ms on 8b44f3d35cfa (executor driver) (175/200)
[2025-07-19T18:30:25.346+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 182.0 in stage 9.0 (TID 985)
[2025-07-19T18:30:25.348+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.349+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.349+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 176 (task 979, attempt 0, stage 9.0)
[2025-07-19T18:30:25.350+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 176.0 in stage 9.0 (TID 979). 5872 bytes result sent to driver
[2025-07-19T18:30:25.350+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 175 (task 978, attempt 0, stage 9.0)
[2025-07-19T18:30:25.350+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ca6db90
[2025-07-19T18:30:25.350+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/179/.2.delta.206bea34-d76e-4acd-a1a3-c4a0ae83c507.TID982.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/179/2.delta
[2025-07-19T18:30:25.351+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=179),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/179] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/179/2.delta
[2025-07-19T18:30:25.351+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=181, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.352+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=181),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/181] for update
[2025-07-19T18:30:25.352+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.352+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.353+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 183.0 in stage 9.0 (TID 986) (8b44f3d35cfa, executor driver, partition 183, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.353+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 179 (task 982, attempt 0, stage 9.0)
[2025-07-19T18:30:25.354+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 183.0 in stage 9.0 (TID 986)
[2025-07-19T18:30:25.354+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 176.0 in stage 9.0 (TID 979) in 95 ms on 8b44f3d35cfa (executor driver) (176/200)
[2025-07-19T18:30:25.355+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5cd02c1a
[2025-07-19T18:30:25.356+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=182, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.357+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=182),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/182] for update
[2025-07-19T18:30:25.358+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.358+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:25.359+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.360+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.361+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 179 (task 982, attempt 0, stage 9.0)
[2025-07-19T18:30:25.362+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/177/.2.delta.512b95e3-9156-4153-b2ac-d2a0b06d8cbb.TID980.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/177/2.delta
[2025-07-19T18:30:25.363+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=177),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/177] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/177/2.delta
[2025-07-19T18:30:25.364+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 177 (task 980, attempt 0, stage 9.0)
[2025-07-19T18:30:25.364+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 175 (task 978, attempt 0, stage 9.0)
[2025-07-19T18:30:25.364+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/178/.2.delta.c9b50e6e-899d-4c10-bb58-1e51b7f56935.TID981.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/178/2.delta
[2025-07-19T18:30:25.365+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=178),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/178] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/178/2.delta
[2025-07-19T18:30:25.365+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 178 (task 981, attempt 0, stage 9.0)
[2025-07-19T18:30:25.365+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6674b578
[2025-07-19T18:30:25.367+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/180/.2.delta.9f4e20f9-d6e5-4012-a1b5-d8e83a7eac48.TID983.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/180/2.delta
[2025-07-19T18:30:25.368+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=180),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/180] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/180/2.delta
[2025-07-19T18:30:25.368+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 180 (task 983, attempt 0, stage 9.0)
[2025-07-19T18:30:25.369+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 179.0 in stage 9.0 (TID 982). 5872 bytes result sent to driver
[2025-07-19T18:30:25.369+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 184.0 in stage 9.0 (TID 987) (8b44f3d35cfa, executor driver, partition 184, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.369+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 184.0 in stage 9.0 (TID 987)
[2025-07-19T18:30:25.369+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=183, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.370+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=183),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/183] for update
[2025-07-19T18:30:25.370+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 179.0 in stage 9.0 (TID 982) in 65 ms on 8b44f3d35cfa (executor driver) (177/200)
[2025-07-19T18:30:25.370+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 175.0 in stage 9.0 (TID 978). 5872 bytes result sent to driver
[2025-07-19T18:30:25.370+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 185.0 in stage 9.0 (TID 988) (8b44f3d35cfa, executor driver, partition 185, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.371+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 178 (task 981, attempt 0, stage 9.0)
[2025-07-19T18:30:25.371+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 175.0 in stage 9.0 (TID 978) in 112 ms on 8b44f3d35cfa (executor driver) (178/200)
[2025-07-19T18:30:25.372+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 185.0 in stage 9.0 (TID 988)
[2025-07-19T18:30:25.373+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 178.0 in stage 9.0 (TID 981). 5872 bytes result sent to driver
[2025-07-19T18:30:25.373+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 186.0 in stage 9.0 (TID 989) (8b44f3d35cfa, executor driver, partition 186, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.373+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 178.0 in stage 9.0 (TID 981) in 79 ms on 8b44f3d35cfa (executor driver) (179/200)
[2025-07-19T18:30:25.373+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.374+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 177 (task 980, attempt 0, stage 9.0)
[2025-07-19T18:30:25.374+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.375+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 180 (task 983, attempt 0, stage 9.0)
[2025-07-19T18:30:25.376+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.376+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.377+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.377+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 186.0 in stage 9.0 (TID 989)
[2025-07-19T18:30:25.377+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53d09f29
[2025-07-19T18:30:25.378+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 177.0 in stage 9.0 (TID 980). 5872 bytes result sent to driver
[2025-07-19T18:30:25.378+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 180.0 in stage 9.0 (TID 983). 5829 bytes result sent to driver
[2025-07-19T18:30:25.379+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 187.0 in stage 9.0 (TID 990) (8b44f3d35cfa, executor driver, partition 187, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.379+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 187.0 in stage 9.0 (TID 990)
[2025-07-19T18:30:25.379+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 188.0 in stage 9.0 (TID 991) (8b44f3d35cfa, executor driver, partition 188, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.380+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 188.0 in stage 9.0 (TID 991)
[2025-07-19T18:30:25.380+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 177.0 in stage 9.0 (TID 980) in 99 ms on 8b44f3d35cfa (executor driver) (180/200)
[2025-07-19T18:30:25.381+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.381+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.381+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=185, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.381+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=185),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/185] for update
[2025-07-19T18:30:25.382+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 180.0 in stage 9.0 (TID 983) in 52 ms on 8b44f3d35cfa (executor driver) (181/200)
[2025-07-19T18:30:25.382+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.382+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.383+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.383+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.383+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3318810d
[2025-07-19T18:30:25.383+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/182/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/182/.2.delta.fadb437a-3dbf-4602-b779-fb473205bfc6.TID985.tmp
[2025-07-19T18:30:25.384+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/181/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/181/.2.delta.631c8ae8-006c-4d88-a4b1-9417f73bc388.TID984.tmp
[2025-07-19T18:30:25.385+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.385+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=186, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.385+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=186),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/186] for update
[2025-07-19T18:30:25.385+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e69149a
[2025-07-19T18:30:25.386+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=184, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.386+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=184),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/184] for update
[2025-07-19T18:30:25.387+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.387+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.387+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/183/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/183/.2.delta.ca983c8f-d8e5-4193-9f7a-7f029ff83eae.TID986.tmp
[2025-07-19T18:30:25.388+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7864e31b
[2025-07-19T18:30:25.388+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=187, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.388+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=187),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/187] for update
[2025-07-19T18:30:25.389+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.389+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@874f890
[2025-07-19T18:30:25.389+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=188, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.389+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=188),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/188] for update
[2025-07-19T18:30:25.390+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.391+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/186/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/186/.2.delta.a45c53c9-450e-4f22-a2e8-9f3bae84f413.TID989.tmp
[2025-07-19T18:30:25.391+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/184/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/184/.2.delta.301046ad-a2e7-45d7-b8c4-918571178f6e.TID987.tmp
[2025-07-19T18:30:25.392+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/185/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/185/.2.delta.36e39b93-896f-4882-9d05-0bac2dc202f7.TID988.tmp
[2025-07-19T18:30:25.394+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/187/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/187/.2.delta.922c2ef9-741e-4196-90db-e912dddae0e2.TID990.tmp
[2025-07-19T18:30:25.395+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/188/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/188/.2.delta.60d809c6-53b7-4bb5-97cb-a49d2f4d30f6.TID991.tmp
[2025-07-19T18:30:25.395+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/182/.2.delta.fadb437a-3dbf-4602-b779-fb473205bfc6.TID985.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/182/2.delta
[2025-07-19T18:30:25.396+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=182),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/182] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/182/2.delta
[2025-07-19T18:30:25.396+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 182 (task 985, attempt 0, stage 9.0)
[2025-07-19T18:30:25.397+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 182 (task 985, attempt 0, stage 9.0)
[2025-07-19T18:30:25.397+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/186/.2.delta.a45c53c9-450e-4f22-a2e8-9f3bae84f413.TID989.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/186/2.delta
[2025-07-19T18:30:25.397+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=186),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/186] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/186/2.delta
[2025-07-19T18:30:25.397+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 182.0 in stage 9.0 (TID 985). 5829 bytes result sent to driver
[2025-07-19T18:30:25.397+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/183/.2.delta.ca983c8f-d8e5-4193-9f7a-7f029ff83eae.TID986.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/183/2.delta
[2025-07-19T18:30:25.398+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=183),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/183] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/183/2.delta
[2025-07-19T18:30:25.398+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 186 (task 989, attempt 0, stage 9.0)
[2025-07-19T18:30:25.398+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 183 (task 986, attempt 0, stage 9.0)
[2025-07-19T18:30:25.398+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 189.0 in stage 9.0 (TID 992) (8b44f3d35cfa, executor driver, partition 189, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.398+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 189.0 in stage 9.0 (TID 992)
[2025-07-19T18:30:25.398+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 182.0 in stage 9.0 (TID 985) in 55 ms on 8b44f3d35cfa (executor driver) (182/200)
[2025-07-19T18:30:25.400+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.400+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.401+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1fb7d13f
[2025-07-19T18:30:25.401+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=189, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.401+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=189),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/189] for update
[2025-07-19T18:30:25.402+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 186 (task 989, attempt 0, stage 9.0)
[2025-07-19T18:30:25.402+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 186.0 in stage 9.0 (TID 989). 5829 bytes result sent to driver
[2025-07-19T18:30:25.402+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.403+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/181/.2.delta.631c8ae8-006c-4d88-a4b1-9417f73bc388.TID984.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/181/2.delta
[2025-07-19T18:30:25.403+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=181),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/181] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/181/2.delta
[2025-07-19T18:30:25.404+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 183 (task 986, attempt 0, stage 9.0)
[2025-07-19T18:30:25.404+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 190.0 in stage 9.0 (TID 993) (8b44f3d35cfa, executor driver, partition 190, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.404+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 183.0 in stage 9.0 (TID 986). 5829 bytes result sent to driver
[2025-07-19T18:30:25.405+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 191.0 in stage 9.0 (TID 994) (8b44f3d35cfa, executor driver, partition 191, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.406+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 191.0 in stage 9.0 (TID 994)
[2025-07-19T18:30:25.406+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 181 (task 984, attempt 0, stage 9.0)
[2025-07-19T18:30:25.407+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 186.0 in stage 9.0 (TID 989) in 49 ms on 8b44f3d35cfa (executor driver) (183/200)
[2025-07-19T18:30:25.407+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.410+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 190.0 in stage 9.0 (TID 993)
[2025-07-19T18:30:25.411+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T18:30:25.411+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/187/.2.delta.922c2ef9-741e-4196-90db-e912dddae0e2.TID990.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/187/2.delta
[2025-07-19T18:30:25.412+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/188/.2.delta.60d809c6-53b7-4bb5-97cb-a49d2f4d30f6.TID991.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/188/2.delta
[2025-07-19T18:30:25.412+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 181 (task 984, attempt 0, stage 9.0)
[2025-07-19T18:30:25.412+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=188),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/188] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/188/2.delta
[2025-07-19T18:30:25.412+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 183.0 in stage 9.0 (TID 986) in 61 ms on 8b44f3d35cfa (executor driver) (184/200)
[2025-07-19T18:30:25.412+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/184/.2.delta.301046ad-a2e7-45d7-b8c4-918571178f6e.TID987.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/184/2.delta
[2025-07-19T18:30:25.413+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=187),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/187] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/187/2.delta
[2025-07-19T18:30:25.414+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=184),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/184] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/184/2.delta
[2025-07-19T18:30:25.415+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 188 (task 991, attempt 0, stage 9.0)
[2025-07-19T18:30:25.415+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 187 (task 990, attempt 0, stage 9.0)
[2025-07-19T18:30:25.416+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 181.0 in stage 9.0 (TID 984). 5829 bytes result sent to driver
[2025-07-19T18:30:25.416+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@50bec7c7
[2025-07-19T18:30:25.416+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=191, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.416+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=191),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/191] for update
[2025-07-19T18:30:25.416+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/189/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/189/.2.delta.4c6ac4d1-dde7-4185-9b2c-a7a7eec833e2.TID992.tmp
[2025-07-19T18:30:25.416+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 184 (task 987, attempt 0, stage 9.0)
[2025-07-19T18:30:25.417+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 192.0 in stage 9.0 (TID 995) (8b44f3d35cfa, executor driver, partition 192, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.417+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 192.0 in stage 9.0 (TID 995)
[2025-07-19T18:30:25.417+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 181.0 in stage 9.0 (TID 984) in 72 ms on 8b44f3d35cfa (executor driver) (185/200)
[2025-07-19T18:30:25.417+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 188 (task 991, attempt 0, stage 9.0)
[2025-07-19T18:30:25.417+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.418+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.419+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 188.0 in stage 9.0 (TID 991). 5786 bytes result sent to driver
[2025-07-19T18:30:25.420+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/185/.2.delta.36e39b93-896f-4882-9d05-0bac2dc202f7.TID988.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/185/2.delta
[2025-07-19T18:30:25.421+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=185),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/185] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/185/2.delta
[2025-07-19T18:30:25.421+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 193.0 in stage 9.0 (TID 996) (8b44f3d35cfa, executor driver, partition 193, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.421+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 184 (task 987, attempt 0, stage 9.0)
[2025-07-19T18:30:25.421+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 184.0 in stage 9.0 (TID 987). 5829 bytes result sent to driver
[2025-07-19T18:30:25.421+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 188.0 in stage 9.0 (TID 991) in 53 ms on 8b44f3d35cfa (executor driver) (186/200)
[2025-07-19T18:30:25.422+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 185 (task 988, attempt 0, stage 9.0)
[2025-07-19T18:30:25.422+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 193.0 in stage 9.0 (TID 996)
[2025-07-19T18:30:25.422+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 187 (task 990, attempt 0, stage 9.0)
[2025-07-19T18:30:25.423+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 194.0 in stage 9.0 (TID 997) (8b44f3d35cfa, executor driver, partition 194, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.423+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 187.0 in stage 9.0 (TID 990). 5829 bytes result sent to driver
[2025-07-19T18:30:25.423+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54bd423c
[2025-07-19T18:30:25.423+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.425+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.425+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.426+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 184.0 in stage 9.0 (TID 987) in 61 ms on 8b44f3d35cfa (executor driver) (187/200)
[2025-07-19T18:30:25.426+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 194.0 in stage 9.0 (TID 997)
[2025-07-19T18:30:25.427+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.427+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.427+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 195.0 in stage 9.0 (TID 998) (8b44f3d35cfa, executor driver, partition 195, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.428+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 195.0 in stage 9.0 (TID 998)
[2025-07-19T18:30:25.428+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 187.0 in stage 9.0 (TID 990) in 55 ms on 8b44f3d35cfa (executor driver) (188/200)
[2025-07-19T18:30:25.428+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.428+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.428+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.428+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.429+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=190, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.429+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=190),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/190] for update
[2025-07-19T18:30:25.429+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 185 (task 988, attempt 0, stage 9.0)
[2025-07-19T18:30:25.429+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@473897f3
[2025-07-19T18:30:25.429+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 185.0 in stage 9.0 (TID 988). 5786 bytes result sent to driver
[2025-07-19T18:30:25.430+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.431+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=195, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.432+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=195),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/195] for update
[2025-07-19T18:30:25.432+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 196.0 in stage 9.0 (TID 999) (8b44f3d35cfa, executor driver, partition 196, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.432+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 185.0 in stage 9.0 (TID 988) in 64 ms on 8b44f3d35cfa (executor driver) (189/200)
[2025-07-19T18:30:25.433+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58edcec5
[2025-07-19T18:30:25.433+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 196.0 in stage 9.0 (TID 999)
[2025-07-19T18:30:25.434+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=194, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.434+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=194),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/194] for update
[2025-07-19T18:30:25.434+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.435+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ffcdc47
[2025-07-19T18:30:25.435+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=193, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.436+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=193),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/193] for update
[2025-07-19T18:30:25.436+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.437+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.437+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.437+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.438+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1561aef
[2025-07-19T18:30:25.438+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=196, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.438+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=196),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/196] for update
[2025-07-19T18:30:25.438+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@18ddeeb7
[2025-07-19T18:30:25.438+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=192, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.438+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=192),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/192] for update
[2025-07-19T18:30:25.438+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.439+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.439+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/191/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/191/.2.delta.a7aaca75-3a1c-484b-876b-7c10374b45be.TID994.tmp
[2025-07-19T18:30:25.439+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/195/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/195/.2.delta.9b54c566-65de-4f02-b852-f47a4bb24d4e.TID998.tmp
[2025-07-19T18:30:25.440+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/190/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/190/.2.delta.fc7085b9-4baf-428c-a25b-faa5951b1ed3.TID993.tmp
[2025-07-19T18:30:25.440+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/194/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/194/.2.delta.091becb6-ad8e-45c5-bbfc-fb9c1bd9256b.TID997.tmp
[2025-07-19T18:30:25.440+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/193/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/193/.2.delta.f1306d66-ef61-4fec-8180-748c328389f7.TID996.tmp
[2025-07-19T18:30:25.440+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/196/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/196/.2.delta.62162506-12f8-4106-a1af-d437a387cd28.TID999.tmp
[2025-07-19T18:30:25.441+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/192/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/192/.2.delta.9eb4e5f6-f489-46b7-bad3-1a832c730bda.TID995.tmp
[2025-07-19T18:30:25.447+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/189/.2.delta.4c6ac4d1-dde7-4185-9b2c-a7a7eec833e2.TID992.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/189/2.delta
[2025-07-19T18:30:25.447+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=189),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/189] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/189/2.delta
[2025-07-19T18:30:25.447+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 189 (task 992, attempt 0, stage 9.0)
[2025-07-19T18:30:25.453+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 189 (task 992, attempt 0, stage 9.0)
[2025-07-19T18:30:25.454+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 189.0 in stage 9.0 (TID 992). 5829 bytes result sent to driver
[2025-07-19T18:30:25.454+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 197.0 in stage 9.0 (TID 1000) (8b44f3d35cfa, executor driver, partition 197, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.455+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 189.0 in stage 9.0 (TID 992) in 62 ms on 8b44f3d35cfa (executor driver) (190/200)
[2025-07-19T18:30:25.455+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 197.0 in stage 9.0 (TID 1000)
[2025-07-19T18:30:25.456+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/191/.2.delta.a7aaca75-3a1c-484b-876b-7c10374b45be.TID994.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/191/2.delta
[2025-07-19T18:30:25.457+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=191),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/191] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/191/2.delta
[2025-07-19T18:30:25.458+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 191 (task 994, attempt 0, stage 9.0)
[2025-07-19T18:30:25.459+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.459+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.459+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c049784
[2025-07-19T18:30:25.462+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=197, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.463+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=197),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/197] for update
[2025-07-19T18:30:25.464+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/195/.2.delta.9b54c566-65de-4f02-b852-f47a4bb24d4e.TID998.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/195/2.delta
[2025-07-19T18:30:25.465+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=195),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/195] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/195/2.delta
[2025-07-19T18:30:25.465+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 195 (task 998, attempt 0, stage 9.0)
[2025-07-19T18:30:25.466+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.466+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 191 (task 994, attempt 0, stage 9.0)
[2025-07-19T18:30:25.467+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 195 (task 998, attempt 0, stage 9.0)
[2025-07-19T18:30:25.467+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 195.0 in stage 9.0 (TID 998). 5829 bytes result sent to driver
[2025-07-19T18:30:25.468+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 191.0 in stage 9.0 (TID 994). 5829 bytes result sent to driver
[2025-07-19T18:30:25.468+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 198.0 in stage 9.0 (TID 1001) (8b44f3d35cfa, executor driver, partition 198, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.469+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 198.0 in stage 9.0 (TID 1001)
[2025-07-19T18:30:25.469+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/194/.2.delta.091becb6-ad8e-45c5-bbfc-fb9c1bd9256b.TID997.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/194/2.delta
[2025-07-19T18:30:25.470+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=194),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/194] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/194/2.delta
[2025-07-19T18:30:25.471+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 191.0 in stage 9.0 (TID 994) in 67 ms on 8b44f3d35cfa (executor driver) (191/200)
[2025-07-19T18:30:25.472+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Starting task 199.0 in stage 9.0 (TID 1002) (8b44f3d35cfa, executor driver, partition 199, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T18:30:25.473+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 194 (task 997, attempt 0, stage 9.0)
[2025-07-19T18:30:25.474+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 195.0 in stage 9.0 (TID 998) in 57 ms on 8b44f3d35cfa (executor driver) (192/200)
[2025-07-19T18:30:25.474+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Running task 199.0 in stage 9.0 (TID 1002)
[2025-07-19T18:30:25.475+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.476+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.477+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T18:30:25.478+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/192/.2.delta.9eb4e5f6-f489-46b7-bad3-1a832c730bda.TID995.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/192/2.delta
[2025-07-19T18:30:25.479+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=192),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/192] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/192/2.delta
[2025-07-19T18:30:25.480+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/193/.2.delta.f1306d66-ef61-4fec-8180-748c328389f7.TID996.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/193/2.delta
[2025-07-19T18:30:25.480+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=193),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/193] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/193/2.delta
[2025-07-19T18:30:25.480+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T18:30:25.481+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 192 (task 995, attempt 0, stage 9.0)
[2025-07-19T18:30:25.481+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 193 (task 996, attempt 0, stage 9.0)
[2025-07-19T18:30:25.482+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/197/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/197/.2.delta.9183b7fa-ba32-4d19-be28-f3786a2ecf2c.TID1000.tmp
[2025-07-19T18:30:25.483+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/196/.2.delta.62162506-12f8-4106-a1af-d437a387cd28.TID999.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/196/2.delta
[2025-07-19T18:30:25.483+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=196),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/196] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/196/2.delta
[2025-07-19T18:30:25.484+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 194 (task 997, attempt 0, stage 9.0)
[2025-07-19T18:30:25.484+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 194.0 in stage 9.0 (TID 997). 5829 bytes result sent to driver
[2025-07-19T18:30:25.484+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3fccd90d
[2025-07-19T18:30:25.485+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=198, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.487+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=198),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/198] for update
[2025-07-19T18:30:25.487+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/190/.2.delta.fc7085b9-4baf-428c-a25b-faa5951b1ed3.TID993.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/190/2.delta
[2025-07-19T18:30:25.488+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=190),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/190] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/190/2.delta
[2025-07-19T18:30:25.488+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 194.0 in stage 9.0 (TID 997) in 65 ms on 8b44f3d35cfa (executor driver) (193/200)
[2025-07-19T18:30:25.489+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 196 (task 999, attempt 0, stage 9.0)
[2025-07-19T18:30:25.489+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 190 (task 993, attempt 0, stage 9.0)
[2025-07-19T18:30:25.490+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@115e3ce1
[2025-07-19T18:30:25.490+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state, operatorId=0, partitionId=199, storeName=default ],648e1751-6c40-4a55-ad88-6fed441ec877) is active
[2025-07-19T18:30:25.490+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=199),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/199] for update
[2025-07-19T18:30:25.490+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 192 (task 995, attempt 0, stage 9.0)
[2025-07-19T18:30:25.491+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.491+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 192.0 in stage 9.0 (TID 995). 5829 bytes result sent to driver
[2025-07-19T18:30:25.491+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 192.0 in stage 9.0 (TID 995) in 73 ms on 8b44f3d35cfa (executor driver) (194/200)
[2025-07-19T18:30:25.491+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 190 (task 993, attempt 0, stage 9.0)
[2025-07-19T18:30:25.492+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T18:30:25.492+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 193 (task 996, attempt 0, stage 9.0)
[2025-07-19T18:30:25.493+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 190.0 in stage 9.0 (TID 993). 5829 bytes result sent to driver
[2025-07-19T18:30:25.493+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 193.0 in stage 9.0 (TID 996). 5786 bytes result sent to driver
[2025-07-19T18:30:25.494+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 190.0 in stage 9.0 (TID 993) in 81 ms on 8b44f3d35cfa (executor driver) (195/200)
[2025-07-19T18:30:25.494+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 193.0 in stage 9.0 (TID 996) in 72 ms on 8b44f3d35cfa (executor driver) (196/200)
[2025-07-19T18:30:25.495+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 196 (task 999, attempt 0, stage 9.0)
[2025-07-19T18:30:25.496+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 196.0 in stage 9.0 (TID 999). 5829 bytes result sent to driver
[2025-07-19T18:30:25.496+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 196.0 in stage 9.0 (TID 999) in 67 ms on 8b44f3d35cfa (executor driver) (197/200)
[2025-07-19T18:30:25.497+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/198/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/198/.2.delta.cf7e7dee-ad2c-443e-8118-985ed7e8be8e.TID1001.tmp
[2025-07-19T18:30:25.497+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/199/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/199/.2.delta.47ddb1a7-54aa-4417-a8cf-c18417fdfbc2.TID1002.tmp
[2025-07-19T18:30:25.498+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/197/.2.delta.9183b7fa-ba32-4d19-be28-f3786a2ecf2c.TID1000.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/197/2.delta
[2025-07-19T18:30:25.498+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=197),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/197] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/197/2.delta
[2025-07-19T18:30:25.499+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 197 (task 1000, attempt 0, stage 9.0)
[2025-07-19T18:30:25.501+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 197 (task 1000, attempt 0, stage 9.0)
[2025-07-19T18:30:25.501+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 197.0 in stage 9.0 (TID 1000). 5829 bytes result sent to driver
[2025-07-19T18:30:25.501+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 197.0 in stage 9.0 (TID 1000) in 46 ms on 8b44f3d35cfa (executor driver) (198/200)
[2025-07-19T18:30:25.504+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/199/.2.delta.47ddb1a7-54aa-4417-a8cf-c18417fdfbc2.TID1002.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/199/2.delta
[2025-07-19T18:30:25.505+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=199),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/199] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/199/2.delta
[2025-07-19T18:30:25.505+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 199 (task 1002, attempt 0, stage 9.0)
[2025-07-19T18:30:25.508+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/198/.2.delta.cf7e7dee-ad2c-443e-8118-985ed7e8be8e.TID1001.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/198/2.delta
[2025-07-19T18:30:25.509+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=198),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/198] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/state/0/198/2.delta
[2025-07-19T18:30:25.509+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 199 (task 1002, attempt 0, stage 9.0)
[2025-07-19T18:30:25.509+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 199.0 in stage 9.0 (TID 1002). 5829 bytes result sent to driver
[2025-07-19T18:30:25.510+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Commit authorized for partition 198 (task 1001, attempt 0, stage 9.0)
[2025-07-19T18:30:25.511+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 199.0 in stage 9.0 (TID 1002) in 43 ms on 8b44f3d35cfa (executor driver) (199/200)
[2025-07-19T18:30:25.514+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DataWritingSparkTask: Committed partition 198 (task 1001, attempt 0, stage 9.0)
[2025-07-19T18:30:25.514+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO Executor: Finished task 198.0 in stage 9.0 (TID 1001). 5829 bytes result sent to driver
[2025-07-19T18:30:25.514+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSetManager: Finished task 198.0 in stage 9.0 (TID 1001) in 47 ms on 8b44f3d35cfa (executor driver) (200/200)
[2025-07-19T18:30:25.515+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool
[2025-07-19T18:30:25.515+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DAGScheduler: ResultStage 9 (start at <unknown>:0) finished in 5.310 s
[2025-07-19T18:30:25.515+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-19T18:30:25.515+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
[2025-07-19T18:30:25.515+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO DAGScheduler: Job 4 finished: start at <unknown>:0, took 5.372892 s
[2025-07-19T18:30:25.516+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 1, writer: IcebergStreamingWrite(table=my_catalog.bronze.Feedback_raw, format=PARQUET)] is committing.
[2025-07-19T18:30:25.516+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO SparkWrite: Committing epoch 1 for query 8f08e6eb-a24d-42b2-b7ec-753236e406e1 in append mode
[2025-07-19T18:30:25.523+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO SparkWrite: Committing streaming append with 0 new data files to table my_catalog.bronze.Feedback_raw
[2025-07-19T18:30:25.563+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO HadoopTableOperations: Committed a new metadata file s3a://warehouse/bronze/Feedback_raw/metadata/v19.metadata.json
[2025-07-19T18:30:25.575+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO SnapshotProducer: Committed snapshot 4795416303175961939 (FastAppend)
[2025-07-19T18:30:25.588+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO LoggingMetricsReporter: Received metrics report: CommitReport{tableName=my_catalog.bronze.Feedback_raw, snapshotId=4795416303175961939, sequenceNumber=18, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.064724333S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=null, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=433}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=null, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=513}, addedFilesSizeInBytes=null, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=1244297}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}}, metadata={engine-version=3.5.6, app-id=local-1752949808869, engine-name=spark, iceberg-version=Apache Iceberg 1.4.0 (commit 10367c380098c2e06a49521a33681ac7f6c64b2c)}}
[2025-07-19T18:30:25.588+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO SparkWrite: Committed in 65 ms
[2025-07-19T18:30:25.588+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 1, writer: IcebergStreamingWrite(table=my_catalog.bronze.Feedback_raw, format=PARQUET)] committed.
[2025-07-19T18:30:25.591+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/commits/1 using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/commits/.1.0516965b-80c5-4b9c-893d-70ce215c19a5.tmp
[2025-07-19T18:30:25.598+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/commits/.1.0516965b-80c5-4b9c-893d-70ce215c19a5.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T18:28:00+00:00/commits/1
[2025-07-19T18:30:25.599+0000] {subprocess.py:93} INFO - 25/07/19 18:30:25 INFO MicroBatchExecution: Streaming query made progress: {
[2025-07-19T18:30:25.599+0000] {subprocess.py:93} INFO -   "id" : "8f08e6eb-a24d-42b2-b7ec-753236e406e1",
[2025-07-19T18:30:25.599+0000] {subprocess.py:93} INFO -   "runId" : "648e1751-6c40-4a55-ad88-6fed441ec877",
[2025-07-19T18:30:25.599+0000] {subprocess.py:93} INFO -   "name" : null,
[2025-07-19T18:30:25.599+0000] {subprocess.py:93} INFO -   "timestamp" : "2025-07-19T18:30:19.973Z",
[2025-07-19T18:30:25.599+0000] {subprocess.py:93} INFO -   "batchId" : 1,
[2025-07-19T18:30:25.599+0000] {subprocess.py:93} INFO -   "numInputRows" : 0,
[2025-07-19T18:30:25.599+0000] {subprocess.py:93} INFO -   "inputRowsPerSecond" : 0.0,
[2025-07-19T18:30:25.599+0000] {subprocess.py:93} INFO -   "processedRowsPerSecond" : 0.0,
[2025-07-19T18:30:25.600+0000] {subprocess.py:93} INFO -   "durationMs" : {
[2025-07-19T18:30:25.600+0000] {subprocess.py:93} INFO -     "addBatch" : 5518,
[2025-07-19T18:30:25.600+0000] {subprocess.py:93} INFO -     "commitOffsets" : 10,
[2025-07-19T18:30:25.600+0000] {subprocess.py:93} INFO -     "getBatch" : 0,
[2025-07-19T18:30:25.600+0000] {subprocess.py:93} INFO -     "latestOffset" : 21,
[2025-07-19T18:30:25.600+0000] {subprocess.py:93} INFO -     "queryPlanning" : 15,
[2025-07-19T18:30:25.600+0000] {subprocess.py:93} INFO -     "triggerExecution" : 5625,
[2025-07-19T18:30:25.600+0000] {subprocess.py:93} INFO -     "walCommit" : 57
[2025-07-19T18:30:25.600+0000] {subprocess.py:93} INFO -   },
[2025-07-19T18:30:25.600+0000] {subprocess.py:93} INFO -   "eventTime" : {
[2025-07-19T18:30:25.600+0000] {subprocess.py:93} INFO -     "watermark" : "2025-07-17T18:30:03.000Z"
[2025-07-19T18:30:25.600+0000] {subprocess.py:93} INFO -   },
[2025-07-19T18:30:25.601+0000] {subprocess.py:93} INFO -   "stateOperators" : [ {
[2025-07-19T18:30:25.601+0000] {subprocess.py:93} INFO -     "operatorName" : "dedupe",
[2025-07-19T18:30:25.601+0000] {subprocess.py:93} INFO -     "numRowsTotal" : 69,
[2025-07-19T18:30:25.601+0000] {subprocess.py:93} INFO -     "numRowsUpdated" : 0,
[2025-07-19T18:30:25.601+0000] {subprocess.py:93} INFO -     "allUpdatesTimeMs" : 220,
[2025-07-19T18:30:25.601+0000] {subprocess.py:93} INFO -     "numRowsRemoved" : 0,
[2025-07-19T18:30:25.601+0000] {subprocess.py:93} INFO -     "allRemovalsTimeMs" : 80,
[2025-07-19T18:30:25.601+0000] {subprocess.py:93} INFO -     "commitTimeMs" : 10484,
[2025-07-19T18:30:25.601+0000] {subprocess.py:93} INFO -     "memoryUsedBytes" : 104616,
[2025-07-19T18:30:25.601+0000] {subprocess.py:93} INFO -     "numRowsDroppedByWatermark" : 0,
[2025-07-19T18:30:25.601+0000] {subprocess.py:93} INFO -     "numShufflePartitions" : 200,
[2025-07-19T18:30:25.601+0000] {subprocess.py:93} INFO -     "numStateStoreInstances" : 200,
[2025-07-19T18:30:25.601+0000] {subprocess.py:93} INFO -     "customMetrics" : {
[2025-07-19T18:30:25.601+0000] {subprocess.py:93} INFO -       "loadedMapCacheHitCount" : 200,
[2025-07-19T18:30:25.601+0000] {subprocess.py:93} INFO -       "loadedMapCacheMissCount" : 0,
[2025-07-19T18:30:25.602+0000] {subprocess.py:93} INFO -       "numDroppedDuplicateRows" : 0,
[2025-07-19T18:30:25.602+0000] {subprocess.py:93} INFO -       "stateOnCurrentVersionSizeBytes" : 36968
[2025-07-19T18:30:25.602+0000] {subprocess.py:93} INFO -     }
[2025-07-19T18:30:25.602+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T18:30:25.602+0000] {subprocess.py:93} INFO -   "sources" : [ {
[2025-07-19T18:30:25.602+0000] {subprocess.py:93} INFO -     "description" : "KafkaV2[Subscribe[feedback]]",
[2025-07-19T18:30:25.602+0000] {subprocess.py:93} INFO -     "startOffset" : {
[2025-07-19T18:30:25.602+0000] {subprocess.py:93} INFO -       "feedback" : {
[2025-07-19T18:30:25.602+0000] {subprocess.py:93} INFO -         "0" : 69
[2025-07-19T18:30:25.602+0000] {subprocess.py:93} INFO -       }
[2025-07-19T18:30:25.602+0000] {subprocess.py:93} INFO -     },
[2025-07-19T18:30:25.602+0000] {subprocess.py:93} INFO -     "endOffset" : {
[2025-07-19T18:30:25.602+0000] {subprocess.py:93} INFO -       "feedback" : {
[2025-07-19T18:30:25.602+0000] {subprocess.py:93} INFO -         "0" : 69
[2025-07-19T18:30:25.602+0000] {subprocess.py:93} INFO -       }
[2025-07-19T18:30:25.603+0000] {subprocess.py:93} INFO -     },
[2025-07-19T18:30:25.603+0000] {subprocess.py:93} INFO -     "latestOffset" : {
[2025-07-19T18:30:25.603+0000] {subprocess.py:93} INFO -       "feedback" : {
[2025-07-19T18:30:25.603+0000] {subprocess.py:93} INFO -         "0" : 69
[2025-07-19T18:30:25.603+0000] {subprocess.py:93} INFO -       }
[2025-07-19T18:30:25.603+0000] {subprocess.py:93} INFO -     },
[2025-07-19T18:30:25.603+0000] {subprocess.py:93} INFO -     "numInputRows" : 0,
[2025-07-19T18:30:25.603+0000] {subprocess.py:93} INFO -     "inputRowsPerSecond" : 0.0,
[2025-07-19T18:30:25.603+0000] {subprocess.py:93} INFO -     "processedRowsPerSecond" : 0.0,
[2025-07-19T18:30:25.603+0000] {subprocess.py:93} INFO -     "metrics" : {
[2025-07-19T18:30:25.603+0000] {subprocess.py:93} INFO -       "avgOffsetsBehindLatest" : "0.0",
[2025-07-19T18:30:25.603+0000] {subprocess.py:93} INFO -       "maxOffsetsBehindLatest" : "0",
[2025-07-19T18:30:25.603+0000] {subprocess.py:93} INFO -       "minOffsetsBehindLatest" : "0"
[2025-07-19T18:30:25.603+0000] {subprocess.py:93} INFO -     }
[2025-07-19T18:30:25.604+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T18:30:25.604+0000] {subprocess.py:93} INFO -   "sink" : {
[2025-07-19T18:30:25.604+0000] {subprocess.py:93} INFO -     "description" : "my_catalog.bronze.Feedback_raw",
[2025-07-19T18:30:25.604+0000] {subprocess.py:93} INFO -     "numOutputRows" : 0
[2025-07-19T18:30:25.604+0000] {subprocess.py:93} INFO -   }
[2025-07-19T18:30:25.604+0000] {subprocess.py:93} INFO - }
[2025-07-19T18:30:32.025+0000] {subprocess.py:93} INFO - 25/07/19 18:30:32 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T18:30:33.940+0000] {subprocess.py:93} INFO - 25/07/19 18:30:33 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T18:30:35.610+0000] {subprocess.py:93} INFO - 25/07/19 18:30:35 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T18:30:42.029+0000] {subprocess.py:93} INFO - 25/07/19 18:30:42 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T18:30:43.949+0000] {subprocess.py:93} INFO - 25/07/19 18:30:43 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T18:30:45.610+0000] {subprocess.py:93} INFO - 25/07/19 18:30:45 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T18:30:52.030+0000] {subprocess.py:93} INFO - 25/07/19 18:30:52 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T18:30:53.961+0000] {subprocess.py:93} INFO - 25/07/19 18:30:53 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T18:30:55.610+0000] {subprocess.py:93} INFO - 25/07/19 18:30:55 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T18:31:02.032+0000] {subprocess.py:93} INFO - 25/07/19 18:31:02 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T18:31:03.971+0000] {subprocess.py:93} INFO - 25/07/19 18:31:03 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T18:31:05.612+0000] {subprocess.py:93} INFO - 25/07/19 18:31:05 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T18:31:09.632+0000] {subprocess.py:93} INFO - 25/07/19 18:31:09 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 8b44f3d35cfa:40517 in memory (size: 35.4 KiB, free: 434.4 MiB)
[2025-07-19T18:31:09.636+0000] {subprocess.py:93} INFO - 25/07/19 18:31:09 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 8b44f3d35cfa:40517 in memory (size: 29.5 KiB, free: 434.4 MiB)
[2025-07-19T18:31:09.637+0000] {subprocess.py:93} INFO - 25/07/19 18:31:09 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 8b44f3d35cfa:40517 in memory (size: 15.8 KiB, free: 434.4 MiB)
[2025-07-19T18:31:10.966+0000] {subprocess.py:93} INFO - 25/07/19 18:31:10 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-f1e25fe4-84ea-495f-a817-789d74310202--1750756262-executor-1, groupId=spark-kafka-source-f1e25fe4-84ea-495f-a817-789d74310202--1750756262-executor] Resetting generation and member id due to: consumer pro-actively leaving the group
[2025-07-19T18:31:10.967+0000] {subprocess.py:93} INFO - 25/07/19 18:31:10 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-f1e25fe4-84ea-495f-a817-789d74310202--1750756262-executor-1, groupId=spark-kafka-source-f1e25fe4-84ea-495f-a817-789d74310202--1750756262-executor] Request joining group due to: consumer pro-actively leaving the group
[2025-07-19T18:31:10.968+0000] {subprocess.py:93} INFO - 25/07/19 18:31:10 INFO Metrics: Metrics scheduler closed
[2025-07-19T18:31:10.968+0000] {subprocess.py:93} INFO - 25/07/19 18:31:10 INFO Metrics: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[2025-07-19T18:31:10.969+0000] {subprocess.py:93} INFO - 25/07/19 18:31:10 INFO Metrics: Metrics reporters closed
[2025-07-19T18:31:10.970+0000] {subprocess.py:93} INFO - 25/07/19 18:31:10 INFO AppInfoParser: App info kafka.consumer for consumer-spark-kafka-source-f1e25fe4-84ea-495f-a817-789d74310202--1750756262-executor-1 unregistered
[2025-07-19T18:31:10.970+0000] {subprocess.py:93} INFO - 25/07/19 18:31:10 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-6cc9cc98-97fd-4011-b03e-aff31993725d-1566240956-executor-3, groupId=spark-kafka-source-6cc9cc98-97fd-4011-b03e-aff31993725d-1566240956-executor] Resetting generation and member id due to: consumer pro-actively leaving the group
[2025-07-19T18:31:10.970+0000] {subprocess.py:93} INFO - 25/07/19 18:31:10 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-6cc9cc98-97fd-4011-b03e-aff31993725d-1566240956-executor-3, groupId=spark-kafka-source-6cc9cc98-97fd-4011-b03e-aff31993725d-1566240956-executor] Request joining group due to: consumer pro-actively leaving the group
[2025-07-19T18:31:10.971+0000] {subprocess.py:93} INFO - 25/07/19 18:31:10 INFO Metrics: Metrics scheduler closed
[2025-07-19T18:31:10.971+0000] {subprocess.py:93} INFO - 25/07/19 18:31:10 INFO Metrics: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[2025-07-19T18:31:10.971+0000] {subprocess.py:93} INFO - 25/07/19 18:31:10 INFO Metrics: Metrics reporters closed
[2025-07-19T18:31:10.971+0000] {subprocess.py:93} INFO - 25/07/19 18:31:10 INFO AppInfoParser: App info kafka.consumer for consumer-spark-kafka-source-6cc9cc98-97fd-4011-b03e-aff31993725d-1566240956-executor-3 unregistered
[2025-07-19T18:31:10.972+0000] {subprocess.py:93} INFO - 25/07/19 18:31:10 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-64ca2e3e-791f-4994-9d80-fe05a2f1c757--1203258309-executor-2, groupId=spark-kafka-source-64ca2e3e-791f-4994-9d80-fe05a2f1c757--1203258309-executor] Resetting generation and member id due to: consumer pro-actively leaving the group
[2025-07-19T18:31:10.972+0000] {subprocess.py:93} INFO - 25/07/19 18:31:10 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-64ca2e3e-791f-4994-9d80-fe05a2f1c757--1203258309-executor-2, groupId=spark-kafka-source-64ca2e3e-791f-4994-9d80-fe05a2f1c757--1203258309-executor] Request joining group due to: consumer pro-actively leaving the group
[2025-07-19T18:31:10.973+0000] {subprocess.py:93} INFO - 25/07/19 18:31:10 INFO Metrics: Metrics scheduler closed
[2025-07-19T18:31:10.973+0000] {subprocess.py:93} INFO - 25/07/19 18:31:10 INFO Metrics: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[2025-07-19T18:31:10.973+0000] {subprocess.py:93} INFO - 25/07/19 18:31:10 INFO Metrics: Metrics reporters closed
[2025-07-19T18:31:10.973+0000] {subprocess.py:93} INFO - 25/07/19 18:31:10 INFO AppInfoParser: App info kafka.consumer for consumer-spark-kafka-source-64ca2e3e-791f-4994-9d80-fe05a2f1c757--1203258309-executor-2 unregistered
[2025-07-19T18:31:10.974+0000] {subprocess.py:93} INFO - 25/07/19 18:31:10 INFO SparkContext: Invoking stop() from shutdown hook
[2025-07-19T18:31:10.974+0000] {subprocess.py:93} INFO - 25/07/19 18:31:10 INFO SparkContext: SparkContext is stopping with exitCode 0.
[2025-07-19T18:31:10.978+0000] {subprocess.py:93} INFO - 25/07/19 18:31:10 INFO SparkUI: Stopped Spark web UI at http://8b44f3d35cfa:4041
[2025-07-19T18:31:10.987+0000] {subprocess.py:93} INFO - 25/07/19 18:31:10 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2025-07-19T18:31:10.996+0000] {subprocess.py:93} INFO - 25/07/19 18:31:10 INFO MemoryStore: MemoryStore cleared
[2025-07-19T18:31:10.997+0000] {subprocess.py:93} INFO - 25/07/19 18:31:10 INFO BlockManager: BlockManager stopped
[2025-07-19T18:31:10.998+0000] {subprocess.py:93} INFO - 25/07/19 18:31:10 INFO BlockManagerMaster: BlockManagerMaster stopped
[2025-07-19T18:31:10.999+0000] {subprocess.py:93} INFO - 25/07/19 18:31:10 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2025-07-19T18:31:11.007+0000] {subprocess.py:93} INFO - 25/07/19 18:31:11 INFO SparkContext: Successfully stopped SparkContext
[2025-07-19T18:31:11.007+0000] {subprocess.py:93} INFO - 25/07/19 18:31:11 INFO ShutdownHookManager: Shutdown hook called
[2025-07-19T18:31:11.007+0000] {subprocess.py:93} INFO - 25/07/19 18:31:11 INFO ShutdownHookManager: Deleting directory /tmp/spark-39c8bf10-cb4d-49d8-b285-88052d6f2437
[2025-07-19T18:31:11.008+0000] {subprocess.py:93} INFO - 25/07/19 18:31:11 INFO ShutdownHookManager: Deleting directory /tmp/spark-5d96a098-fa01-4c9c-8cd5-e9236545aa1b
[2025-07-19T18:31:11.010+0000] {subprocess.py:93} INFO - 25/07/19 18:31:11 INFO ShutdownHookManager: Deleting directory /tmp/spark-5d96a098-fa01-4c9c-8cd5-e9236545aa1b/pyspark-8cb799a0-c3da-4256-966a-2ebca4bc0d21
[2025-07-19T18:31:11.018+0000] {subprocess.py:93} INFO - 25/07/19 18:31:11 INFO MetricsSystemImpl: Stopping s3a-file-system metrics system...
[2025-07-19T18:31:11.018+0000] {subprocess.py:93} INFO - 25/07/19 18:31:11 INFO MetricsSystemImpl: s3a-file-system metrics system stopped.
[2025-07-19T18:31:11.018+0000] {subprocess.py:93} INFO - 25/07/19 18:31:11 INFO MetricsSystemImpl: s3a-file-system metrics system shutdown complete.
[2025-07-19T18:31:11.422+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2025-07-19T18:31:11.436+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=restaurant_pipeline, task_id=stream_to_bronze, execution_date=20250719T182800, start_date=20250719T183007, end_date=20250719T183111
[2025-07-19T18:31:11.461+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2025-07-19T18:31:11.485+0000] {taskinstance.py:2778} INFO - 1 downstream tasks scheduled from follow-on schedule check
